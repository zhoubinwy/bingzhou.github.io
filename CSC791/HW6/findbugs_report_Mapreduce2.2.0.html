<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>FindBugs Report</title>
<style type="text/css">
		.tablerow0 {
			background: #EEEEEE;
		}

		.tablerow1 {
			background: white;
		}

		.detailrow0 {
			background: #EEEEEE;
		}

		.detailrow1 {
			background: white;
		}

		.tableheader {
			background: #b9b9fe;
			font-size: larger;
		}

		.tablerow0:hover, .tablerow1:hover {
			background: #aaffaa;
		}

		.priority-1 {
		    color: red;
		    font-weight: bold;
		}
		.priority-2 {
		    color: orange;
		    font-weight: bold;
		}
		.priority-3 {
		    color: green;
		    font-weight: bold;
		}
		.priority-4 {
		    color: blue;
		    font-weight: bold;
		}
		</style>
<script type="text/javascript">
			function toggleRow(elid) {
				if (document.getElementById) {
					element = document.getElementById(elid);
					if (element) {
						if (element.style.display == 'none') {
							element.style.display = 'block';
							//window.status = 'Toggle on!';
						} else {
							element.style.display = 'none';
							//window.status = 'Toggle off!';
						}
					}
				}
			}
		</script>
</head>
<body>
<h1>
<a href="http://findbugs.sourceforge.net">FindBugs</a> Report</h1>
<h2>Project Information</h2>
<p>Project: 
		</p>
<p>FindBugs version: 3.0.1-dev-20160919-0987399</p>
<p>Code analyzed:</p>
<ul>
<li>/home/ting/all-200-bugs/BuiltApplications_Java/Mapreduce-5888/ClassFiles</li>
</ul>
<p>
<br/>
<br/>
</p>
<h2>Metrics</h2>
<p>74414 lines of code analyzed,
	in 1055 classes, 
	in 85 packages.</p>
<table width="500" cellpadding="5" cellspacing="2">
<tr class="tableheader">
<th align="left">Metric</th>
<th align="right">Total</th>
<th align="right">Density*</th>
</tr>
<tr class="tablerow0">
<td>High Priority Warnings</td>
<td align="right">213</td>
<td align="right">2.86</td>
</tr>
<tr class="tablerow1">
<td>Medium Priority Warnings</td>
<td align="right">350</td>
<td align="right">4.70</td>
</tr>
<tr class="$totalClass">
<td>
<b>Total Warnings</b>
</td>
<td align="right">
<b>563</b>
</td>
<td align="right">
<b>7.57</b>
</td>
</tr>
</table>
<p>
<i>(* Defects per Thousand lines of non-commenting source statements)</i>
</p>
<p>
<br/>
<br/>
</p>
<h2>Contents</h2>
<ul>
<li>
<a href="#Warnings_BAD_PRACTICE">Bad practice Warnings</a>
</li>
<li>
<a href="#Warnings_CORRECTNESS">Correctness Warnings</a>
</li>
<li>
<a href="#Warnings_EXPERIMENTAL">Experimental Warnings</a>
</li>
<li>
<a href="#Warnings_I18N">Internationalization Warnings</a>
</li>
<li>
<a href="#Warnings_MALICIOUS_CODE">Malicious code vulnerability Warnings</a>
</li>
<li>
<a href="#Warnings_MT_CORRECTNESS">Multithreaded correctness Warnings</a>
</li>
<li>
<a href="#Warnings_PERFORMANCE">Performance Warnings</a>
</li>
<li>
<a href="#Warnings_STYLE">Dodgy code Warnings</a>
</li>
<li>
<a href="#Details">Details</a>
</li>
</ul>
<h1>Summary</h1>
<table width="500" cellpadding="5" cellspacing="2">
<tr class="tableheader">
<th align="left">Warning Type</th>
<th align="right">Number</th>
</tr>
<tr class="tablerow0">
<td>
<a href="#Warnings_BAD_PRACTICE">Bad practice Warnings</a>
</td>
<td align="right">81</td>
</tr>
<tr class="tablerow1">
<td>
<a href="#Warnings_CORRECTNESS">Correctness Warnings</a>
</td>
<td align="right">14</td>
</tr>
<tr class="tablerow0">
<td>
<a href="#Warnings_EXPERIMENTAL">Experimental Warnings</a>
</td>
<td align="right">16</td>
</tr>
<tr class="tablerow1">
<td>
<a href="#Warnings_I18N">Internationalization Warnings</a>
</td>
<td align="right">155</td>
</tr>
<tr class="tablerow0">
<td>
<a href="#Warnings_MALICIOUS_CODE">Malicious code vulnerability Warnings</a>
</td>
<td align="right">96</td>
</tr>
<tr class="tablerow1">
<td>
<a href="#Warnings_MT_CORRECTNESS">Multithreaded correctness Warnings</a>
</td>
<td align="right">22</td>
</tr>
<tr class="tablerow0">
<td>
<a href="#Warnings_PERFORMANCE">Performance Warnings</a>
</td>
<td align="right">99</td>
</tr>
<tr class="tablerow1">
<td>
<a href="#Warnings_STYLE">Dodgy code Warnings</a>
</td>
<td align="right">80</td>
</tr>
<tr class="tablerow0">
<td>
<b>Total</b>
</td>
<td align="right">
<b>563</b>
</td>
</tr>
</table>
<h1>Warnings</h1>
<p>Click on a warning row to see full context information.</p>
<h2>
<a name="Warnings_BAD_PRACTICE">Bad practice Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67547');">
<td>
<span class="priority-2">DE</span>
</td>
<td>org.apache.hadoop.fs.TestFileSystem.testCommandFormat() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67547" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileSystem<br/>In method org.apache.hadoop.fs.TestFileSystem.testCommandFormat()<br/>Exception class java.lang.Exception<br/>At TestFileSystem.java:[line 101]<br/>At TestFileSystem.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N65548');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.FailingMapper.map(Text, Text, Mapper$Context) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N65548" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.FailingMapper<br/>In method org.apache.hadoop.FailingMapper.map(Text, Text, Mapper$Context)<br/>At FailingMapper.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72236');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.MRBench.run(String[]) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72236" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRBench<br/>In method org.apache.hadoop.mapred.MRBench.run(String[])<br/>At MRBench.java:[line 267]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N72899');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.ReliabilityTest.displayUsage() invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N72899" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.ReliabilityTest<br/>In method org.apache.hadoop.mapred.ReliabilityTest.displayUsage()<br/>At ReliabilityTest.java:[line 89]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72953');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.ReliabilityTest.runTest(JobClient, Configuration, String, String[], ReliabilityTest$KillTaskThread, ReliabilityTest$KillTrackerThread) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72953" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.ReliabilityTest<br/>In method org.apache.hadoop.mapred.ReliabilityTest.runTest(JobClient, Configuration, String, String[], ReliabilityTest$KillTaskThread, ReliabilityTest$KillTrackerThread)<br/>At ReliabilityTest.java:[line 228]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73007');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.Task.commit(TaskUmbilicalProtocol, Task$TaskReporter, OutputCommitter) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73007" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.Task<br/>In method org.apache.hadoop.mapred.Task.commit(TaskUmbilicalProtocol, Task$TaskReporter, OutputCommitter)<br/>At Task.java:[line 1149]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N73061');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.Task.done(TaskUmbilicalProtocol, Task$TaskReporter) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N73061" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.Task<br/>In method org.apache.hadoop.mapred.Task.done(TaskUmbilicalProtocol, Task$TaskReporter)<br/>At Task.java:[line 1014]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73115');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.Task.reportFatalError(TaskAttemptID, Throwable, String) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73115" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.Task<br/>In method org.apache.hadoop.mapred.Task.reportFatalError(TaskAttemptID, Throwable, String)<br/>At Task.java:[line 332]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N73169');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.Task.statusUpdate(TaskUmbilicalProtocol) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N73169" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.Task<br/>In method org.apache.hadoop.mapred.Task.statusUpdate(TaskUmbilicalProtocol)<br/>At Task.java:[line 1059]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N103476');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.test.MapredTestDriver.run(String[]) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N103476" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.test.MapredTestDriver<br/>In method org.apache.hadoop.test.MapredTestDriver.run(String[])<br/>At MapredTestDriver.java:[line 119]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67695');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.fs.TestFileSystem.main(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67695" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileSystem<br/>In method org.apache.hadoop.fs.TestFileSystem.main(String[])<br/>Called method java.util.Random.nextLong()<br/>At TestFileSystem.java:[line 448]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N67765');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.fs.TestFileSystem.testFs(long, int, long)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N67765" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileSystem<br/>In method org.apache.hadoop.fs.TestFileSystem.testFs(long, int, long)<br/>Called method java.util.Random.nextLong()<br/>At TestFileSystem.java:[line 78]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81854');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.lib.TestLineInputFormat.testFormat()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81854" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestLineInputFormat<br/>In method org.apache.hadoop.mapred.lib.TestLineInputFormat.testFormat()<br/>Called method java.util.Random.nextInt()<br/>At TestLineInputFormat.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N72027');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.MRBench.generateTextFile(FileSystem, Path, long, MRBench$Order)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N72027" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRBench<br/>In method org.apache.hadoop.mapred.MRBench.generateTextFile(FileSystem, Path, long, MRBench$Order)<br/>Called method java.util.Random.nextLong()<br/>At MRBench.java:[line 104]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72097');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.MRBench.run(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72097" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRBench<br/>In method org.apache.hadoop.mapred.MRBench.run(String[])<br/>Called method java.util.Random.nextInt()<br/>At MRBench.java:[line 283]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N76030');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.TestKeyValueTextInputFormat.testFormat()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N76030" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapred.TestKeyValueTextInputFormat.testFormat()<br/>Called method java.util.Random.nextInt()<br/>At TestKeyValueTextInputFormat.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78583');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.TestSequenceFileAsTextInputFormat.testFormat()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78583" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestSequenceFileAsTextInputFormat<br/>In method org.apache.hadoop.mapred.TestSequenceFileAsTextInputFormat.testFormat()<br/>Called method java.util.Random.nextInt()<br/>At TestSequenceFileAsTextInputFormat.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N78653');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.TestSequenceFileInputFormat.testFormat()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N78653" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestSequenceFileInputFormat<br/>In method org.apache.hadoop.mapred.TestSequenceFileInputFormat.testFormat()<br/>Called method java.util.Random.nextInt()<br/>At TestSequenceFileInputFormat.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N79807');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.TestTextInputFormat.testFormat()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N79807" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextInputFormat<br/>In method org.apache.hadoop.mapred.TestTextInputFormat.testFormat()<br/>Called method java.util.Random.nextInt()<br/>At TestTextInputFormat.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N79877');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.TestTextInputFormat.testSplitableCodecs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N79877" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextInputFormat<br/>In method org.apache.hadoop.mapred.TestTextInputFormat.testSplitableCodecs()<br/>Called method java.util.Random.nextInt()<br/>At TestTextInputFormat.java:[line 152]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89082');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testFormat()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89082" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testFormat()<br/>Called method java.util.Random.nextInt()<br/>At TestMRKeyValueTextInputFormat.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N89152');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testSplitableCodecs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N89152" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testSplitableCodecs()<br/>Called method java.util.Random.nextInt()<br/>At TestMRKeyValueTextInputFormat.java:[line 173]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89575');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsTextInputFormat.testFormat()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89575" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsTextInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsTextInputFormat.testFormat()<br/>Called method java.util.Random.nextInt()<br/>At TestMRSequenceFileAsTextInputFormat.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N81208');">
<td>
<span class="priority-2">Eq</span>
</td>
<td>org.apache.hadoop.mapred.join.IncomparableKey defines compareTo(Object) and uses Object.equals()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N81208" style="display: none;">
<a href="#EQ_COMPARETO_USE_OBJECT_EQUALS">Bug type EQ_COMPARETO_USE_OBJECT_EQUALS (click for details)</a>
<br/>In class org.apache.hadoop.mapred.join.IncomparableKey<br/>In method org.apache.hadoop.mapred.join.IncomparableKey.compareTo(Object)<br/>At IncomparableKey.java:[line 29]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N103834');">
<td>
<span class="priority-2">Eq</span>
</td>
<td>testjar.ExternalWritable defines compareTo(Object) and uses Object.equals()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N103834" style="display: none;">
<a href="#EQ_COMPARETO_USE_OBJECT_EQUALS">Bug type EQ_COMPARETO_USE_OBJECT_EQUALS (click for details)</a>
<br/>In class testjar.ExternalWritable<br/>In method testjar.ExternalWritable.compareTo(Object)<br/>At ExternalWritable.java:[lines 75-80]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N88293');">
<td>
<span class="priority-2">ODR</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat.testDateSplits() may fail to close Statement</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N88293" style="display: none;">
<a href="#ODR_OPEN_DATABASE_RESOURCE">Bug type ODR_OPEN_DATABASE_RESOURCE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat.testDateSplits()<br/>Need to close java.sql.Statement <br/>At TestDataDrivenDBInputFormat.java:[line 174]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66647');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String) may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66647" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.fs.DFSCIOTest<br/>In method org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String)<br/>Need to close java.io.OutputStream <br/>At DFSCIOTest.java:[line 538]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N66713');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String) may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N66713" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.fs.DFSCIOTest<br/>In method org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String)<br/>Need to close java.io.Reader <br/>At DFSCIOTest.java:[line 501]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66917');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean) may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66917" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.fs.DistributedFSCheck<br/>In method org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean)<br/>Need to close java.io.OutputStream <br/>At DistributedFSCheck.java:[line 346]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N66983');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean) may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N66983" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.fs.DistributedFSCheck<br/>In method org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean)<br/>Need to close java.io.Reader <br/>At DistributedFSCheck.java:[line 289]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N70003');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.analyzeResults() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N70003" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>In method org.apache.hadoop.hdfs.NNBench.analyzeResults()<br/>Need to close java.io.OutputStream <br/>At NNBench.java:[line 446]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70069');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.analyzeResults() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70069" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>In method org.apache.hadoop.hdfs.NNBench.analyzeResults()<br/>Need to close java.io.Reader <br/>At NNBench.java:[line 319]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72588');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.mapred.MRCaching.launchMRCache(String, String, String, JobConf, String) may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72588" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRCaching<br/>In method org.apache.hadoop.mapred.MRCaching.launchMRCache(String, String, String, JobConf, String)<br/>Need to close java.io.Reader <br/>At MRCaching.java:[line 275]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N74297');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testBuiltInGzipDecompressor() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N74297" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestConcatenatedCompressedInput<br/>In method org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testBuiltInGzipDecompressor()<br/>Need to close java.io.InputStream <br/>At TestConcatenatedCompressedInput.java:[line 334]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74363');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testMoreBzip2() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74363" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestConcatenatedCompressedInput<br/>In method org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testMoreBzip2()<br/>Need to close java.io.InputStream <br/>At TestConcatenatedCompressedInput.java:[line 541]<br/>Another occurrence at TestConcatenatedCompressedInput.java:[line 542]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N79186');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration) may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N79186" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration)<br/>Need to close java.io.OutputStream <br/>At TestShuffleHandler.java:[line 436]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N79252');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N79252" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess()<br/>Need to close java.io.InputStream <br/>At TestShuffleHandler.java:[line 377]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N103698');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.util.TestRunJar.makeTestJar() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N103698" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.util.TestRunJar<br/>In method org.apache.hadoop.util.TestRunJar.makeTestJar()<br/>Need to close java.io.InputStream <br/>At TestRunJar.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74440');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testPrototypeInflaterGzip() ignores result of java.io.FileInputStream.skip(long)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74440" style="display: none;">
<a href="#SR_NOT_CHECKED">Bug type SR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestConcatenatedCompressedInput<br/>In method org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testPrototypeInflaterGzip()<br/>Called method java.io.FileInputStream.skip(long)<br/>At TestConcatenatedCompressedInput.java:[line 251]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N81069');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.mapred.UtilsForTests.slurpHadoop(Path, FileSystem) ignores result of java.io.InputStream.read(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N81069" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.mapred.UtilsForTests<br/>In method org.apache.hadoop.mapred.UtilsForTests.slurpHadoop(Path, FileSystem)<br/>Called method java.io.InputStream.read(byte[], int, int)<br/>At UtilsForTests.java:[line 182]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68947');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.slive.TestSlive.getWriteLoc()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68947" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.TestSlive<br/>In method org.apache.hadoop.fs.slive.TestSlive.getWriteLoc()<br/>Called method java.io.File.mkdirs()<br/>At TestSlive.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N83112');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapred.pipes.TestPipeApplication.cleanTokenPasswordFile()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N83112" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.cleanTokenPasswordFile()<br/>Called method java.io.File.delete()<br/>At TestPipeApplication.java:[line 517]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83182');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83182" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String)<br/>Called method java.io.File.createNewFile()<br/>At TestPipeApplication.java:[line 529]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N83252');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N83252" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String)<br/>Called method java.io.File.mkdirs()<br/>At TestPipeApplication.java:[line 527]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83322');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.pipes.TestPipeApplication.initStdOut(JobConf)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83322" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.initStdOut(JobConf)<br/>Called method java.io.File.mkdirs()<br/>At TestPipeApplication.java:[line 467]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73995');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapred.TestCommandLineJobSubmission.testJobShell()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73995" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestCommandLineJobSubmission<br/>In method org.apache.hadoop.mapred.TestCommandLineJobSubmission.testJobShell()<br/>Called method java.io.File.delete()<br/>At TestCommandLineJobSubmission.java:[line 129]<br/>Another occurrence at TestCommandLineJobSubmission.java:[line 130]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75216');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestJobConf.testFindContainingJarWithPlus()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75216" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobConf<br/>In method org.apache.hadoop.mapred.TestJobConf.testFindContainingJarWithPlus()<br/>Called method java.io.File.mkdirs()<br/>At TestJobConf.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N75286');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestJobEndNotifier.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N75286" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobEndNotifier<br/>In method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestJobEndNotifier.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76446');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestLocalDistributedCacheManager.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76446" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestLocalDistributedCacheManager<br/>In method org.apache.hadoop.mapred.TestLocalDistributedCacheManager.setup()<br/>Called method java.io.File.mkdirs()<br/>At TestLocalDistributedCacheManager.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N76721');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapred.TestMRWithDistributedCache.testLocalJobRunner()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N76721" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMRWithDistributedCache<br/>In method org.apache.hadoop.mapred.TestMRWithDistributedCache.testLocalJobRunner()<br/>Called method java.io.File.delete()<br/>At TestMRWithDistributedCache.java:[line 166]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N77720');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.mapred.TestMultiFileSplit.testgetLocations()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N77720" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMultiFileSplit<br/>In method org.apache.hadoop.mapred.TestMultiFileSplit.testgetLocations()<br/>Called method java.io.File.createNewFile()<br/>At TestMultiFileSplit.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N78151');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestQueue.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N78151" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestQueue<br/>In method org.apache.hadoop.mapred.TestQueue.setup()<br/>Called method java.io.File.mkdirs()<br/>At TestQueue.java:[line 50]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78221');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapred.TestQueue.testQueue()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78221" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestQueue<br/>In method org.apache.hadoop.mapred.TestQueue.testQueue()<br/>Called method java.io.File.delete()<br/>At TestQueue.java:[line 160]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N79318');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N79318" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration)<br/>Called method java.io.File.createNewFile()<br/>At TestShuffleHandler.java:[line 431]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N79388');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N79388" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration)<br/>Called method java.io.File.delete()<br/>At TestShuffleHandler.java:[line 429]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N79458');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestShuffleHandler.createShuffleHandlerFiles(File, String, String, String, Configuration, List)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N79458" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.createShuffleHandlerFiles(File, String, String, String, Configuration, List)<br/>Called method java.io.File.mkdirs()<br/>At TestShuffleHandler.java:[line 405]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N79597');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.mapred.TestTaskLog.testTaskLog()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N79597" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTaskLog<br/>In method org.apache.hadoop.mapred.TestTaskLog.testTaskLog()<br/>Called method java.io.File.createNewFile()<br/>At TestTaskLog.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N79667');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapred.TestTaskLog.testTaskLog()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N79667" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTaskLog<br/>In method org.apache.hadoop.mapred.TestTaskLog.testTaskLog()<br/>Called method java.io.File.delete()<br/>At TestTaskLog.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N79737');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestTaskLog.testTaskLog()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N79737" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTaskLog<br/>In method org.apache.hadoop.mapred.TestTaskLog.testTaskLog()<br/>Called method java.io.File.mkdirs()<br/>At TestTaskLog.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80760');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestYARNRunner.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80760" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestYARNRunner<br/>In method org.apache.hadoop.mapred.TestYARNRunner.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestYARNRunner.java:[line 147]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92099');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.cleanUpMiniClusterSpecialConfig()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92099" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle<br/>In method org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.cleanUpMiniClusterSpecialConfig()<br/>Called method java.io.File.delete()<br/>At TestEncryptedShuffle.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N92169');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.createCustomYarnClasspath()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N92169" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle<br/>In method org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.createCustomYarnClasspath()<br/>Called method java.io.File.delete()<br/>At TestEncryptedShuffle.java:[line 69]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92239');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92239" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle<br/>In method org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestEncryptedShuffle.java:[line 63]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91891');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapreduce.security.TestMRCredentials.tearDown()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91891" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.TestMRCredentials<br/>In method org.apache.hadoop.mapreduce.security.TestMRCredentials.tearDown()<br/>Called method java.io.File.delete()<br/>At TestMRCredentials.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N93876');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.testMRAsyncDiskService()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N93876" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService<br/>In method org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.testMRAsyncDiskService()<br/>Called method java.io.File.mkdirs()<br/>At TestMRAsyncDiskService.java:[line 185]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 186]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 187]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 188]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93979');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.testMRAsyncDiskServiceMoveAndDeleteAllVolumes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93979" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService<br/>In method org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.testMRAsyncDiskServiceMoveAndDeleteAllVolumes()<br/>Called method java.io.File.mkdirs()<br/>At TestMRAsyncDiskService.java:[line 246]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 247]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 248]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 249]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94082');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.testMRAsyncDiskServiceStartupCleaning()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94082" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService<br/>In method org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.testMRAsyncDiskServiceStartupCleaning()<br/>Called method java.io.File.mkdirs()<br/>At TestMRAsyncDiskService.java:[line 293]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 294]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 295]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 296]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N97013');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler.cleanup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N97013" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler<br/>In method org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler.cleanup()<br/>Called method java.io.File.mkdirs()<br/>At TestCommitterEventHandler.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97083');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl.cleanup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97083" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl<br/>In method org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl.cleanup()<br/>Called method java.io.File.mkdirs()<br/>At TestJobImpl.java:[line 116]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95963');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.app.MRApp.submit(Configuration, boolean, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95963" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MRApp<br/>In method org.apache.hadoop.mapreduce.v2.app.MRApp.submit(Configuration, boolean, boolean)<br/>Called method java.io.File.mkdirs()<br/>At MRApp.java:[line 292]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N96547');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.cleanup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N96547" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster<br/>In method org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.cleanup()<br/>Called method java.io.File.mkdirs()<br/>At TestMRAppMaster.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N96617');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N96617" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster<br/>In method org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.setup()<br/>Called method java.io.File.mkdir()<br/>At TestMRAppMaster.java:[line 90]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N96687');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterCredentials()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N96687" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster<br/>In method org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterCredentials()<br/>Called method java.io.File.mkdirs()<br/>At TestMRAppMaster.java:[line 378]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N96757');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterMaxAppAttempts()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N96757" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster<br/>In method org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterMaxAppAttempts()<br/>Called method java.io.File.mkdirs()<br/>At TestMRAppMaster.java:[line 287]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99096');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99096" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.setUp()<br/>Called method java.io.File.mkdir()<br/>At TestAMWebServicesJobConf.java:[line 141]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N101893');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N101893" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.setUp()<br/>Called method java.io.File.mkdir()<br/>At TestHsWebServicesJobConf.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94657');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapreduce.v2.TestMRJobs.createAndAddJarToJar(JarOutputStream, File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94657" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobs<br/>In method org.apache.hadoop.mapreduce.v2.TestMRJobs.createAndAddJarToJar(JarOutputStream, File)<br/>Called method java.io.File.delete()<br/>At TestMRJobs.java:[line 670]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N94727');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N94727" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobs<br/>In method org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache()<br/>Called method java.io.File.delete()<br/>At TestMRJobs.java:[line 603]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N103406');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.util.TestMRApps.setupTestDirs()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N103406" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.util.TestMRApps<br/>In method org.apache.hadoop.mapreduce.v2.util.TestMRApps.setupTestDirs()<br/>Called method java.io.File.mkdirs()<br/>At TestMRApps.java:[line 64]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N103764');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.util.TestRunJar.testRunjar()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N103764" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestRunJar<br/>In method org.apache.hadoop.util.TestRunJar.testRunjar()<br/>Called method java.io.File.delete()<br/>At TestRunJar.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72797');">
<td>
<span class="priority-2">Se</span>
</td>
<td>org.apache.hadoop.mapred.MergeSorter implements Comparator but not Serializable</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72797" style="display: none;">
<a href="#SE_COMPARATOR_SHOULD_BE_SERIALIZABLE">Bug type SE_COMPARATOR_SHOULD_BE_SERIALIZABLE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MergeSorter<br/>At MergeSorter.java:[lines 35-77]</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_CORRECTNESS">Correctness Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74076');">
<td>
<span class="priority-2">BIT</span>
</td>
<td>Bitwise OR of signed byte value computed in org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testPrototypeInflaterGzip() </td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74076" style="display: none;">
<a href="#BIT_IOR_OF_SIGNED_BYTE">Bug type BIT_IOR_OF_SIGNED_BYTE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestConcatenatedCompressedInput<br/>In method org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testPrototypeInflaterGzip()<br/>At TestConcatenatedCompressedInput.java:[line 250]<br/>Another occurrence at TestConcatenatedCompressedInput.java:[line 271]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N83392');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of dfs in org.apache.hadoop.mapred.pipes.TestPipes.testPipes() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N83392" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipes<br/>In method org.apache.hadoop.mapred.pipes.TestPipes.testPipes()<br/>Value loaded from dfs<br/>Dereferenced at TestPipes.java:[line 97]<br/>Null value at TestPipes.java:[line 75]<br/>Known null at TestPipes.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83488');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of mr in org.apache.hadoop.mapred.pipes.TestPipes.testPipes() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83488" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipes<br/>In method org.apache.hadoop.mapred.pipes.TestPipes.testPipes()<br/>Value loaded from mr<br/>Dereferenced at TestPipes.java:[line 96]<br/>Null value at TestPipes.java:[line 76]<br/>Known null at TestPipes.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91726');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of jobHistoryServer in org.apache.hadoop.mapreduce.security.TestJHSSecurity.testDelegationToken() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91726" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.TestJHSSecurity<br/>In method org.apache.hadoop.mapreduce.security.TestJHSSecurity.testDelegationToken()<br/>Value loaded from jobHistoryServer<br/>Dereferenced at TestJHSSecurity.java:[line 206]<br/>Null value at TestJHSSecurity.java:[line 81]<br/>Known null at TestJHSSecurity.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N93321');">
<td>
<span class="priority-2">NP</span>
</td>
<td>shexec is null guaranteed to be dereferenced in org.apache.hadoop.mapreduce.util.ProcessTree.isSetsidSupported() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N93321" style="display: none;">
<a href="#NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH">Bug type NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.ProcessTree<br/>In method org.apache.hadoop.mapreduce.util.ProcessTree.isSetsidSupported()<br/>Value loaded from shexec<br/>Dereferenced at ProcessTree.java:[line 64]<br/>Dereferenced at ProcessTree.java:[line 64]<br/>Null value at ProcessTree.java:[line 54]<br/>Known null at ProcessTree.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93425');">
<td>
<span class="priority-2">NP</span>
</td>
<td>shexec is null guaranteed to be dereferenced in org.apache.hadoop.mapreduce.util.ProcessTree.sendSignal(String, int, String) on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93425" style="display: none;">
<a href="#NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH">Bug type NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.ProcessTree<br/>In method org.apache.hadoop.mapreduce.util.ProcessTree.sendSignal(String, int, String)<br/>Value loaded from shexec<br/>Dereferenced at ProcessTree.java:[line 136]<br/>Dereferenced at ProcessTree.java:[line 139]<br/>Dereferenced at ProcessTree.java:[line 139]<br/>Dereferenced at ProcessTree.java:[line 136]<br/>Null value at ProcessTree.java:[line 127]<br/>Known null at ProcessTree.java:[line 129]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N93551');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of shexec in org.apache.hadoop.mapreduce.util.ProcessTree.isAlive(String) on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N93551" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.ProcessTree<br/>In method org.apache.hadoop.mapreduce.util.ProcessTree.isAlive(String)<br/>Value loaded from shexec<br/>Dereferenced at ProcessTree.java:[line 298]<br/>Null value at ProcessTree.java:[line 290]<br/>Known null at ProcessTree.java:[line 293]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93638');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of shexec in org.apache.hadoop.mapreduce.util.ProcessTree.isProcessGroupAlive(String) on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93638" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.ProcessTree<br/>In method org.apache.hadoop.mapreduce.util.ProcessTree.isProcessGroupAlive(String)<br/>Value loaded from shexec<br/>Dereferenced at ProcessTree.java:[line 323]<br/>Null value at ProcessTree.java:[line 315]<br/>Known null at ProcessTree.java:[line 318]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N95378');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of server in org.apache.hadoop.mapreduce.v2.TestRPCFactories.testPbClientFactory() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N95378" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestRPCFactories<br/>In method org.apache.hadoop.mapreduce.v2.TestRPCFactories.testPbClientFactory()<br/>Value loaded from server<br/>Dereferenced at TestRPCFactories.java:[line 122]<br/>Null value at TestRPCFactories.java:[line 101]<br/>Known null at TestRPCFactories.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95474');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of server in org.apache.hadoop.mapreduce.v2.TestRPCFactories.testPbServerFactory() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95474" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestRPCFactories<br/>In method org.apache.hadoop.mapreduce.v2.TestRPCFactories.testPbServerFactory()<br/>Value loaded from server<br/>Dereferenced at TestRPCFactories.java:[line 91]<br/>Null value at TestRPCFactories.java:[line 81]<br/>Known null at TestRPCFactories.java:[line 83]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N103036');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Null passed for non-null parameter of String.contains(CharSequence) in org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspath()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N103036" style="display: none;">
<a href="#NP_NULL_PARAM_DEREF">Bug type NP_NULL_PARAM_DEREF (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.util.TestMRApps<br/>In method org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspath()<br/>Called method String.contains(CharSequence)<br/>Argument 1 might be null but must not be null<br/>Value loaded from mrAppClasspath<br/>Method invoked at TestMRApps.java:[line 202]<br/>Known null at TestMRApps.java:[line 198]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N103130');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Null passed for non-null parameter of String.contains(CharSequence) in org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspath()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N103130" style="display: none;">
<a href="#NP_NULL_PARAM_DEREF">Bug type NP_NULL_PARAM_DEREF (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.util.TestMRApps<br/>In method org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspath()<br/>Called method String.contains(CharSequence)<br/>Argument 1 might be null but must not be null<br/>Value loaded from yarnAppClasspath<br/>Method invoked at TestMRApps.java:[line 193]<br/>Known null at TestMRApps.java:[line 189]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N103224');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Null passed for non-null parameter of String.contains(CharSequence) in org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspathWithArchives()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N103224" style="display: none;">
<a href="#NP_NULL_PARAM_DEREF">Bug type NP_NULL_PARAM_DEREF (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.util.TestMRApps<br/>In method org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspathWithArchives()<br/>Called method String.contains(CharSequence)<br/>Argument 1 might be null but must not be null<br/>Value loaded from confClasspath<br/>Method invoked at TestMRApps.java:[line 226]<br/>Known null at TestMRApps.java:[line 222]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91459');">
<td>
<span class="priority-2">USELESS_STRING</span>
</td>
<td>Invocation of toString on secretValue in org.apache.hadoop.mapreduce.security.CredentialsTestJob.checkSecrets(Credentials)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91459" style="display: none;">
<a href="#DMI_INVOKING_TOSTRING_ON_ARRAY">Bug type DMI_INVOKING_TOSTRING_ON_ARRAY (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.CredentialsTestJob<br/>In method org.apache.hadoop.mapreduce.security.CredentialsTestJob.checkSecrets(Credentials)<br/>Local variable named secretValue<br/>At CredentialsTestJob.java:[line 61]</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_EXPERIMENTAL">Experimental Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68749');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.slive.TestSlive.testBadChunks() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68749" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.TestSlive<br/>In method org.apache.hadoop.fs.slive.TestSlive.testBadChunks()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestSlive.java:[line 469] is not discharged<br/>Path continues at TestSlive.java:[line 470]<br/>Path continues at TestSlive.java:[line 471]<br/>Path continues at TestSlive.java:[line 472]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N68859');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.slive.TestSlive.testDataWriting() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N68859" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.TestSlive<br/>In method org.apache.hadoop.fs.slive.TestSlive.testDataWriting()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestSlive.java:[line 254] is not discharged<br/>Path continues at TestSlive.java:[line 255]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81766');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator.configure(String, int) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81766" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator<br/>In method org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator.configure(String, int)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestKeyFieldBasedComparator.java:[line 83] is not discharged<br/>Path continues at TestKeyFieldBasedComparator.java:[line 84]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N82914');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N82914" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestPipeApplication.java:[line 530] is not discharged<br/>Path continues at TestPipeApplication.java:[line 531]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83002');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.pipes.TestPipeApplication.readFile(File) may fail to clean up java.io.InputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83002" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.readFile(File)<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestPipeApplication.java:[line 485] is not discharged<br/>Path continues at TestPipeApplication.java:[line 486]<br/>Path continues at TestPipeApplication.java:[line 487]<br/>Path continues at TestPipeApplication.java:[line 488]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N74209');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testPrototypeInflaterGzip() may fail to clean up java.io.InputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N74209" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestConcatenatedCompressedInput<br/>In method org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testPrototypeInflaterGzip()<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestConcatenatedCompressedInput.java:[line 233] is not discharged<br/>Path continues at TestConcatenatedCompressedInput.java:[line 234]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N77632');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestMultiFileSplit.testgetLocations() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N77632" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMultiFileSplit<br/>In method org.apache.hadoop.mapred.TestMultiFileSplit.testgetLocations()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestMultiFileSplit.java:[line 78] is not discharged<br/>Path continues at TestMultiFileSplit.java:[line 79]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N78999');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestShuffleHandler.createMapOutputFile(File, Configuration) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N78999" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.createMapOutputFile(File, Configuration)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestShuffleHandler.java:[line 418] is not discharged<br/>Path continues at TestShuffleHandler.java:[line 419]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N79087');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess() may fail to clean up java.io.InputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N79087" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess()<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestShuffleHandler.java:[line 383] is not discharged<br/>Path continues at TestShuffleHandler.java:[line 384]<br/>Path continues at TestShuffleHandler.java:[line 392]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80584');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestYARNRunner.testAMAdminCommandOpts() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80584" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestYARNRunner<br/>In method org.apache.hadoop.mapred.TestYARNRunner.testAMAdminCommandOpts()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestYARNRunner.java:[line 400] is not discharged<br/>Path continues at TestYARNRunner.java:[line 401]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N80672');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestYARNRunner.testWarnCommandOpts() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N80672" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestYARNRunner<br/>In method org.apache.hadoop.mapred.TestYARNRunner.testWarnCommandOpts()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestYARNRunner.java:[line 466] is not discharged<br/>Path continues at TestYARNRunner.java:[line 467]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80970');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.UtilsForTests.setUpConfigFile(Properties, File) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80970" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.UtilsForTests<br/>In method org.apache.hadoop.mapred.UtilsForTests.setUpConfigFile(Properties, File)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at UtilsForTests.java:[line 772] is not discharged<br/>Path continues at UtilsForTests.java:[line 774]<br/>Path continues at UtilsForTests.java:[line 779]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N88119');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat.getSplits(JobContext) may fail to clean up java.sql.Statement on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N88119" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat.getSplits(JobContext)<br/>Reference type java.sql.Statement<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at DataDrivenDBInputFormat.java:[line 183] is not discharged<br/>Path continues at DataDrivenDBInputFormat.java:[line 185]<br/>Path continues at DataDrivenDBInputFormat.java:[line 186]<br/>Path continues at DataDrivenDBInputFormat.java:[line 198]<br/>Path continues at DataDrivenDBInputFormat.java:[line 199]<br/>Path continues at DataDrivenDBInputFormat.java:[line 202]<br/>Path continues at DataDrivenDBInputFormat.java:[line 203]<br/>Path continues at DataDrivenDBInputFormat.java:[line 204]<br/>Path continues at DataDrivenDBInputFormat.java:[line 206]<br/>Path continues at DataDrivenDBInputFormat.java:[line 207]<br/>Remaining obligations: {Statement x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N92431');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapreduce.task.reduce.InMemoryReader.dumpOnError() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N92431" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.InMemoryReader<br/>In method org.apache.hadoop.mapreduce.task.reduce.InMemoryReader.dumpOnError()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at InMemoryReader.java:[line 83] is not discharged<br/>Path continues at InMemoryReader.java:[line 84]<br/>Path continues at InMemoryReader.java:[line 86]<br/>Path continues at InMemoryReader.java:[line 87]<br/>Path continues at InMemoryReader.java:[line 89]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N103318');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspathWithArchives() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N103318" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.util.TestMRApps<br/>In method org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspathWithArchives()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestMRApps.java:[line 208] is not discharged<br/>Path continues at TestMRApps.java:[line 209]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N103599');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.util.TestRunJar.makeTestJar() may fail to clean up java.io.InputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N103599" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestRunJar<br/>In method org.apache.hadoop.util.TestRunJar.makeTestJar()<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestRunJar.java:[line 64] is not discharged<br/>Path continues at TestRunJar.java:[line 66]<br/>Path continues at TestRunJar.java:[line 67]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_I18N">Internationalization Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N65602');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestNoDefaultsJobConf.testNoDefaults(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N65602" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestNoDefaultsJobConf<br/>In method org.apache.hadoop.conf.TestNoDefaultsJobConf.testNoDefaults()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestNoDefaultsJobConf.java:[line 89]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N65671');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestNoDefaultsJobConf.testNoDefaults(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N65671" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestNoDefaultsJobConf<br/>In method org.apache.hadoop.conf.TestNoDefaultsJobConf.testNoDefaults()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestNoDefaultsJobConf.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66456');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66456" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.DFSCIOTest<br/>In method org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At DFSCIOTest.java:[line 501]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N66525');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N66525" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.DFSCIOTest<br/>In method org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At DFSCIOTest.java:[line 538]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66779');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66779" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.DistributedFSCheck<br/>In method org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At DistributedFSCheck.java:[line 289]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N66848');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N66848" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.DistributedFSCheck<br/>In method org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At DistributedFSCheck.java:[line 346]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67218');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.JHLogAnalyzer.analyzeResult(FileSystem, int, long, Path): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67218" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.JHLogAnalyzer<br/>In method org.apache.hadoop.fs.JHLogAnalyzer.analyzeResult(FileSystem, int, long, Path)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At JHLogAnalyzer.java:[line 1093]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N67287');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.JHLogAnalyzer.analyzeResult(FileSystem, int, long, Path): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N67287" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.JHLogAnalyzer<br/>In method org.apache.hadoop.fs.JHLogAnalyzer.analyzeResult(FileSystem, int, long, Path)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At JHLogAnalyzer.java:[line 1084]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68485');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.slive.SliveTest.writeReport(ConfigExtractor): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68485" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.SliveTest<br/>In method org.apache.hadoop.fs.slive.SliveTest.writeReport(ConfigExtractor)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At SliveTest.java:[line 233]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N68554');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.slive.SliveTest.writeReport(ConfigExtractor): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N68554" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.SliveTest<br/>In method org.apache.hadoop.fs.slive.SliveTest.writeReport(ConfigExtractor)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At SliveTest.java:[line 265]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67356');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestDFSIO.analyzeResult(FileSystem, TestDFSIO$TestType, long, String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67356" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestDFSIO<br/>In method org.apache.hadoop.fs.TestDFSIO.analyzeResult(FileSystem, TestDFSIO$TestType, long, String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestDFSIO.java:[line 817]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N67425');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestDFSIO.analyzeResult(FileSystem, TestDFSIO$TestType, long, String): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N67425" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestDFSIO<br/>In method org.apache.hadoop.fs.TestDFSIO.analyzeResult(FileSystem, TestDFSIO$TestType, long, String)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestDFSIO.java:[line 853]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67835');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestJHLA.setUp(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67835" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestJHLA<br/>In method org.apache.hadoop.fs.TestJHLA.setUp()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestJHLA.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69137');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.NNBench.analyzeResults(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69137" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>In method org.apache.hadoop.hdfs.NNBench.analyzeResults()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At NNBench.java:[line 319]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69206');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.NNBench.analyzeResults(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69206" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>In method org.apache.hadoop.hdfs.NNBench.analyzeResults()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At NNBench.java:[line 446]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70903');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.JobClientUnitTest.testShowJob(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70903" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At JobClientUnitTest.java:[line 150]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N70972');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.JobClientUnitTest.testShowJob(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N70972" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At JobClientUnitTest.java:[line 149]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N81261');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.join.TestTupleWritable.makeRandomWritables(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N81261" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.join.TestTupleWritable<br/>In method org.apache.hadoop.mapred.join.TestTupleWritable.makeRandomWritables()<br/>Called method String.getBytes()<br/>At TestTupleWritable.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81330');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.join.TestTupleWritable.testIterable(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81330" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.join.TestTupleWritable<br/>In method org.apache.hadoop.mapred.join.TestTupleWritable.testIterable()<br/>Called method String.getBytes()<br/>At TestTupleWritable.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N81399');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.join.TestTupleWritable.testNestedIterable(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N81399" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.join.TestTupleWritable<br/>In method org.apache.hadoop.mapred.join.TestTupleWritable.testNestedIterable()<br/>Called method String.getBytes()<br/>At TestTupleWritable.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81468');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.join.TestTupleWritable.testWritable(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81468" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.join.TestTupleWritable<br/>In method org.apache.hadoop.mapred.join.TestTupleWritable.testWritable()<br/>Called method String.getBytes()<br/>At TestTupleWritable.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N81537');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in new org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N81537" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator<br/>In method new org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator()<br/>Called method String.getBytes()<br/>At TestKeyFieldBasedComparator.java:[line 139]<br/>Another occurrence at TestKeyFieldBasedComparator.java:[line 140]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81617');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator.configure(String, int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81617" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator<br/>In method org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator.configure(String, int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestKeyFieldBasedComparator.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N81686');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator.configure(String, int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N81686" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator<br/>In method org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator.configure(String, int)<br/>Called method String.getBytes()<br/>At TestKeyFieldBasedComparator.java:[line 84]<br/>Another occurrence at TestKeyFieldBasedComparator.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81924');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.lib.TestLineInputFormat.testFormat(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81924" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestLineInputFormat<br/>In method org.apache.hadoop.mapred.lib.TestLineInputFormat.testFormat()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestLineInputFormat.java:[line 63]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N81993');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.lib.TestMultipleOutputs._testMOWithJavaSerialization(boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N81993" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestMultipleOutputs<br/>In method org.apache.hadoop.mapred.lib.TestMultipleOutputs._testMOWithJavaSerialization(boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMultipleOutputs.java:[line 151]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N82062');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.lib.TestMultipleOutputs._testMultipleOutputs(boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N82062" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestMultipleOutputs<br/>In method org.apache.hadoop.mapred.lib.TestMultipleOutputs._testMultipleOutputs(boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMultipleOutputs.java:[line 239]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N72167');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.MRBench.generateTextFile(FileSystem, Path, long, MRBench$Order): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N72167" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRBench<br/>In method org.apache.hadoop.mapred.MRBench.generateTextFile(FileSystem, Path, long, MRBench$Order)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At MRBench.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72519');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.MRCaching.launchMRCache(String, String, String, JobConf, String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72519" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRCaching<br/>In method org.apache.hadoop.mapred.MRCaching.launchMRCache(String, String, String, JobConf, String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At MRCaching.java:[line 275]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N82131');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.CommonStub.initSoket(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N82131" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.CommonStub<br/>In method org.apache.hadoop.mapred.pipes.CommonStub.initSoket()<br/>Called method String.getBytes()<br/>At CommonStub.java:[line 121]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N82200');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N82200" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String)<br/>Called method String.getBytes()<br/>At TestPipeApplication.java:[line 531]<br/>Another occurrence at TestPipeApplication.java:[line 533]<br/>Another occurrence at TestPipeApplication.java:[line 535]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N82291');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.TestPipeApplication.readFile(File): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N82291" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.readFile(File)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestPipeApplication.java:[line 494]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N82360');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.TestPipeApplication.testApplication(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N82360" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.testApplication()<br/>Called method String.getBytes()<br/>At TestPipeApplication.java:[line 171]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N82429');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.TestPipeApplication.testPipesReduser(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N82429" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.testPipesReduser()<br/>Called method String.getBytes()<br/>At TestPipeApplication.java:[line 392]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N82498');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.TestPipeApplication.testRunner(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N82498" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.testRunner()<br/>Called method String.getBytes()<br/>At TestPipeApplication.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N82567');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.TestPipeApplication.testSubmitter(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N82567" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.testSubmitter()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestPipeApplication.java:[line 278]<br/>Another occurrence at TestPipeApplication.java:[line 279]<br/>Another occurrence at TestPipeApplication.java:[line 280]<br/>Another occurrence at TestPipeApplication.java:[line 281]<br/>Another occurrence at TestPipeApplication.java:[line 283]<br/>Another occurrence at TestPipeApplication.java:[line 284]<br/>Another occurrence at TestPipeApplication.java:[line 286]<br/>Another occurrence at TestPipeApplication.java:[line 287]<br/>Another occurrence at TestPipeApplication.java:[line 289]<br/>Another occurrence at TestPipeApplication.java:[line 291]<br/>Another occurrence at TestPipeApplication.java:[line 293]<br/>Another occurrence at TestPipeApplication.java:[line 295]<br/>Another occurrence at TestPipeApplication.java:[line 297]<br/>Another occurrence at TestPipeApplication.java:[line 300]<br/>Another occurrence at TestPipeApplication.java:[line 304]<br/>Another occurrence at TestPipeApplication.java:[line 306]<br/>Another occurrence at TestPipeApplication.java:[line 308]<br/>Another occurrence at TestPipeApplication.java:[line 310]<br/>Another occurrence at TestPipeApplication.java:[line 314]<br/>Another occurrence at TestPipeApplication.java:[line 318]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N82845');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.TestPipeApplication.testSubmitter(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N82845" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.testSubmitter()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestPipeApplication.java:[line 273]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73352');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestBadRecords.createInput(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73352" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestBadRecords<br/>In method org.apache.hadoop.mapred.TestBadRecords.createInput()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestBadRecords.java:[line 104]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N73421');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestBadRecords.validateOutput(JobConf, RunningJob, List, List): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N73421" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestBadRecords<br/>In method org.apache.hadoop.mapred.TestBadRecords.validateOutput(JobConf, RunningJob, List, List)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestBadRecords.java:[line 180]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73490');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestClusterMapReduceTestCase._testMapReduce(boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73490" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestClusterMapReduceTestCase<br/>In method org.apache.hadoop.mapred.TestClusterMapReduceTestCase._testMapReduce(boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestClusterMapReduceTestCase.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N73559');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestClusterMapReduceTestCase._testMapReduce(boolean): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N73559" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestClusterMapReduceTestCase<br/>In method org.apache.hadoop.mapred.TestClusterMapReduceTestCase._testMapReduce(boolean)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestClusterMapReduceTestCase.java:[line 35]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73628');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testDFSRestart(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73628" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestClusterMapReduceTestCase<br/>In method org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testDFSRestart()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestClusterMapReduceTestCase.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N73697');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestCombineFileInputFormat.writeFile(FileSystem, Path, String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N73697" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestCombineFileInputFormat<br/>In method org.apache.hadoop.mapred.TestCombineFileInputFormat.writeFile(FileSystem, Path, String)<br/>Called method String.getBytes()<br/>At TestCombineFileInputFormat.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73766');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestCombineTextInputFormat.createFiles(int, int, Random): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73766" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestCombineTextInputFormat<br/>In method org.apache.hadoop.mapred.TestCombineTextInputFormat.createFiles(int, int, Random)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestCombineTextInputFormat.java:[line 165]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N73835');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestCombineTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N73835" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestCombineTextInputFormat<br/>In method org.apache.hadoop.mapred.TestCombineTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String)<br/>Called method String.getBytes()<br/>At TestCombineTextInputFormat.java:[line 187]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73904');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestCommandLineJobSubmission.testJobShell(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73904" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestCommandLineJobSubmission<br/>In method org.apache.hadoop.mapred.TestCommandLineJobSubmission.testJobShell()<br/>Called method String.getBytes()<br/>At TestCommandLineJobSubmission.java:[line 57]<br/>Another occurrence at TestCommandLineJobSubmission.java:[line 64]<br/>Another occurrence at TestCommandLineJobSubmission.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74140');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestConcatenatedCompressedInput.writeFile(FileSystem, Path, CompressionCodec, String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74140" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestConcatenatedCompressedInput<br/>In method org.apache.hadoop.mapred.TestConcatenatedCompressedInput.writeFile(FileSystem, Path, CompressionCodec, String)<br/>Called method String.getBytes()<br/>At TestConcatenatedCompressedInput.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N74648');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestFileInputFormatPathFilter.createFile(String): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N74648" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFileInputFormatPathFilter<br/>In method org.apache.hadoop.mapred.TestFileInputFormatPathFilter.createFile(String)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestFileInputFormatPathFilter.java:[line 72]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74717');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJavaSerialization.cleanAndCreateInput(FileSystem): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74717" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJavaSerialization<br/>In method org.apache.hadoop.mapred.TestJavaSerialization.cleanAndCreateInput(FileSystem)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestJavaSerialization.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N74786');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJavaSerialization.testMapReduceJob(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N74786" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJavaSerialization<br/>In method org.apache.hadoop.mapred.TestJavaSerialization.testMapReduceJob()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestJavaSerialization.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75147');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJobClient.runJob(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75147" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobClient<br/>In method org.apache.hadoop.mapred.TestJobClient.runJob()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestJobClient.java:[line 39]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N75616');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJobName.testComplexName(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N75616" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobName<br/>In method org.apache.hadoop.mapred.TestJobName.testComplexName()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestJobName.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75685');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJobName.testComplexName(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75685" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobName<br/>In method org.apache.hadoop.mapred.TestJobName.testComplexName()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestJobName.java:[line 37]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N75754');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N75754" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobName<br/>In method org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestJobName.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75823');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75823" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobName<br/>In method org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestJobName.java:[line 71]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N75892');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJobQueueClient.testPrintJobQueueInfo(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N75892" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobQueueClient<br/>In method org.apache.hadoop.mapred.TestJobQueueClient.testPrintJobQueueInfo()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestJobQueueClient.java:[line 50]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75961');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJobQueueClient.testPrintJobQueueInfo(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75961" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobQueueClient<br/>In method org.apache.hadoop.mapred.TestJobQueueClient.testPrintJobQueueInfo()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestJobQueueClient.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N76100');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestKeyValueTextInputFormat.testFormat(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N76100" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapred.TestKeyValueTextInputFormat.testFormat()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestKeyValueTextInputFormat.java:[line 72]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76169');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestKeyValueTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76169" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapred.TestKeyValueTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String)<br/>Called method String.getBytes()<br/>At TestKeyValueTextInputFormat.java:[line 191]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N76308');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestLazyOutput.createInput(FileSystem, int): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N76308" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestLazyOutput<br/>In method org.apache.hadoop.mapred.TestLazyOutput.createInput(FileSystem, int)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestLazyOutput.java:[line 127]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76377');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestLineRecordReader.createInputFile(Configuration): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76377" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestLineRecordReader<br/>In method org.apache.hadoop.mapred.TestLineRecordReader.createInputFile(Configuration)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestLineRecordReader.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N76583');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestLocalModeWithNewApis.readOutput(Path, Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N76583" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestLocalModeWithNewApis<br/>In method org.apache.hadoop.mapred.TestLocalModeWithNewApis.readOutput(Path, Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestLocalModeWithNewApis.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76791');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMapRed.isSequenceFile(FileSystem, Path): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76791" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMapRed<br/>In method org.apache.hadoop.mapred.TestMapRed.isSequenceFile(FileSystem, Path)<br/>Called method String.getBytes()<br/>At TestMapRed.java:[line 683]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N76860');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMapRed.launch(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N76860" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMapRed<br/>In method org.apache.hadoop.mapred.TestMapRed.launch()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMapRed.java:[line 648]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76929');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMapRed.printTextFile(FileSystem, Path): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76929" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMapRed<br/>In method org.apache.hadoop.mapred.TestMapRed.printTextFile(FileSystem, Path)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMapRed.java:[line 660]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77132');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMerge.createInput(FileSystem): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77132" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMerge<br/>In method org.apache.hadoop.mapred.TestMerge.createInput(FileSystem)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMerge.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N77340');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMiniMRClasspath.launchExternal(URI, JobConf, String, int, int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N77340" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMiniMRClasspath<br/>In method org.apache.hadoop.mapred.TestMiniMRClasspath.launchExternal(URI, JobConf, String, int, int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMiniMRClasspath.java:[line 147]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77409');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMiniMRClasspath.launchWordCount(URI, JobConf, String, int, int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77409" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMiniMRClasspath<br/>In method org.apache.hadoop.mapred.TestMiniMRClasspath.launchWordCount(URI, JobConf, String, int, int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMiniMRClasspath.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76652');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMRWithDistributedCache.makeJar(Path, int): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76652" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMRWithDistributedCache<br/>In method org.apache.hadoop.mapred.TestMRWithDistributedCache.makeJar(Path, int)<br/>Called method String.getBytes()<br/>At TestMRWithDistributedCache.java:[line 194]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77563');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMultiFileSplit.testgetLocations(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77563" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMultiFileSplit<br/>In method org.apache.hadoop.mapred.TestMultiFileSplit.testgetLocations()<br/>Called method String.getBytes()<br/>At TestMultiFileSplit.java:[line 79]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N77790');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestNetworkedJob.testJobQueueClient(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N77790" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestNetworkedJob<br/>In method org.apache.hadoop.mapred.TestNetworkedJob.testJobQueueClient()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestNetworkedJob.java:[line 349]<br/>Another occurrence at TestNetworkedJob.java:[line 350]<br/>Another occurrence at TestNetworkedJob.java:[line 355]<br/>Another occurrence at TestNetworkedJob.java:[line 356]<br/>Another occurrence at TestNetworkedJob.java:[line 358]<br/>Another occurrence at TestNetworkedJob.java:[line 367]<br/>Another occurrence at TestNetworkedJob.java:[line 368]<br/>Another occurrence at TestNetworkedJob.java:[line 369]<br/>Another occurrence at TestNetworkedJob.java:[line 376]<br/>Another occurrence at TestNetworkedJob.java:[line 377]<br/>Another occurrence at TestNetworkedJob.java:[line 378]<br/>Another occurrence at TestNetworkedJob.java:[line 379]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77980');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestNetworkedJob.testJobQueueClient(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77980" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestNetworkedJob<br/>In method org.apache.hadoop.mapred.TestNetworkedJob.testJobQueueClient()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestNetworkedJob.java:[line 346]<br/>Another occurrence at TestNetworkedJob.java:[line 352]<br/>Another occurrence at TestNetworkedJob.java:[line 364]<br/>Another occurrence at TestNetworkedJob.java:[line 373]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78082');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestQueue.writeFile(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78082" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestQueue<br/>In method org.apache.hadoop.mapred.TestQueue.writeFile()<br/>Called method new java.io.FileWriter(File)<br/>At TestQueue.java:[line 236]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N78723');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N78723" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration)<br/>Called method String.getBytes()<br/>At TestShuffleHandler.java:[line 439]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78792');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestShuffleHandler.createMapOutputFile(File, Configuration): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78792" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.createMapOutputFile(File, Configuration)<br/>Called method String.getBytes()<br/>At TestShuffleHandler.java:[line 419]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N78861');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess(): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N78861" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess()<br/>Called method new String(byte[])<br/>At TestShuffleHandler.java:[line 390]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78930');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78930" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess()<br/>Called method String.getBytes()<br/>At TestShuffleHandler.java:[line 354]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N79528');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestTaskLog.readTaskLog(TaskLog$LogName, TaskAttemptID, boolean): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N79528" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTaskLog<br/>In method org.apache.hadoop.mapred.TestTaskLog.readTaskLog(TaskLog$LogName, TaskAttemptID, boolean)<br/>Called method new String(byte[])<br/>At TestTaskLog.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N79947');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestTextInputFormat.testFormat(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N79947" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextInputFormat<br/>In method org.apache.hadoop.mapred.TestTextInputFormat.testFormat()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestTextInputFormat.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80016');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestTextInputFormat.testMaxLineLength(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80016" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextInputFormat<br/>In method org.apache.hadoop.mapred.TestTextInputFormat.testMaxLineLength()<br/>Called method String.getBytes()<br/>At TestTextInputFormat.java:[line 316]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N80085');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestTextInputFormat.testNewLines(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N80085" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextInputFormat<br/>In method org.apache.hadoop.mapred.TestTextInputFormat.testNewLines()<br/>Called method String.getBytes()<br/>At TestTextInputFormat.java:[line 276]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80154');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestTextInputFormat.testSplitableCodecs(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80154" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextInputFormat<br/>In method org.apache.hadoop.mapred.TestTextInputFormat.testSplitableCodecs()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestTextInputFormat.java:[line 182]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N80223');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N80223" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextInputFormat<br/>In method org.apache.hadoop.mapred.TestTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String)<br/>Called method String.getBytes()<br/>At TestTextInputFormat.java:[line 388]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80292');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestUserDefinedCounters.cleanAndCreateInput(FileSystem): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80292" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestUserDefinedCounters<br/>In method org.apache.hadoop.mapred.TestUserDefinedCounters.cleanAndCreateInput(FileSystem)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestUserDefinedCounters.java:[line 69]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N80361');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestUserDefinedCounters.testMapReduceJob(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N80361" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestUserDefinedCounters<br/>In method org.apache.hadoop.mapred.TestUserDefinedCounters.testMapReduceJob()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestUserDefinedCounters.java:[line 108]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80515');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestYARNRunner.testWarnCommandOpts(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80515" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestYARNRunner<br/>In method org.apache.hadoop.mapred.TestYARNRunner.testWarnCommandOpts()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestYARNRunner.java:[line 482]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83584');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.FailJob.run(String[]): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83584" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.FailJob<br/>In method org.apache.hadoop.mapreduce.FailJob.run(String[])<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At FailJob.java:[line 124]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N89222');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testFormat(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N89222" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testFormat()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMRKeyValueTextInputFormat.java:[line 90]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89291');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testSplitableCodecs(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89291" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testSplitableCodecs()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMRKeyValueTextInputFormat.java:[line 189]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N89360');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N89360" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String)<br/>Called method String.getBytes()<br/>At TestMRKeyValueTextInputFormat.java:[line 303]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89645');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.input.TestNLineInputFormat.testFormat(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89645" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestNLineInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestNLineInputFormat.testFormat()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestNLineInputFormat.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N89714');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.makeRandomWritables(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N89714" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable<br/>In method org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.makeRandomWritables()<br/>Called method String.getBytes()<br/>At TestJoinTupleWritable.java:[line 63]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89783');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.testIterable(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89783" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable<br/>In method org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.testIterable()<br/>Called method String.getBytes()<br/>At TestJoinTupleWritable.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N89852');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.testNestedIterable(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N89852" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable<br/>In method org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.testNestedIterable()<br/>Called method String.getBytes()<br/>At TestJoinTupleWritable.java:[line 123]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89921');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.testWritable(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89921" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable<br/>In method org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.testWritable()<br/>Called method String.getBytes()<br/>At TestJoinTupleWritable.java:[line 141]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90429');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.output.TestMRMultipleOutputs._testMOWithJavaSerialization(boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90429" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.TestMRMultipleOutputs<br/>In method org.apache.hadoop.mapreduce.lib.output.TestMRMultipleOutputs._testMOWithJavaSerialization(boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRMultipleOutputs.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N90498');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.output.TestMRMultipleOutputs._testMultipleOutputs(boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N90498" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.TestMRMultipleOutputs<br/>In method org.apache.hadoop.mapreduce.lib.output.TestMRMultipleOutputs._testMultipleOutputs(boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRMultipleOutputs.java:[line 200]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90869');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper.testGetWordLengths(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90869" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper<br/>In method org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper.testGetWordLengths()<br/>Called method String.getBytes()<br/>At TestKeyFieldHelper.java:[line 220]<br/>Another occurrence at TestKeyFieldHelper.java:[line 228]<br/>Another occurrence at TestKeyFieldHelper.java:[line 234]<br/>Another occurrence at TestKeyFieldHelper.java:[line 240]<br/>Another occurrence at TestKeyFieldHelper.java:[line 245]<br/>Another occurrence at TestKeyFieldHelper.java:[line 249]<br/>Another occurrence at TestKeyFieldHelper.java:[line 253]<br/>Another occurrence at TestKeyFieldHelper.java:[line 257]<br/>Another occurrence at TestKeyFieldHelper.java:[line 261]<br/>Another occurrence at TestKeyFieldHelper.java:[line 266]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N91037');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper.testKeySpecs(String, String, KeyFieldHelper, int, int): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N91037" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper<br/>In method org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper.testKeySpecs(String, String, KeyFieldHelper, int, int)<br/>Called method new String(byte[])<br/>At TestKeyFieldHelper.java:[line 404]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91106');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper.testKeySpecs(String, String, KeyFieldHelper, int, int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91106" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper<br/>In method org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper.testKeySpecs(String, String, KeyFieldHelper, int, int)<br/>Called method String.getBytes()<br/>At TestKeyFieldHelper.java:[line 379]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N91175');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in new org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedComparator(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N91175" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedComparator<br/>In method new org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedComparator()<br/>Called method String.getBytes()<br/>At TestMRKeyFieldBasedComparator.java:[line 117]<br/>Another occurrence at TestMRKeyFieldBasedComparator.java:[line 118]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91255');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedComparator.testComparator(String, int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91255" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedComparator<br/>In method org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedComparator.testComparator(String, int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRKeyFieldBasedComparator.java:[line 76]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N91324');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedPartitioner.testEmptyKey(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N91324" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedPartitioner<br/>In method org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedPartitioner.testEmptyKey()<br/>Called method String.getBytes()<br/>At TestMRKeyFieldBasedPartitioner.java:[line 56]<br/>Another occurrence at TestMRKeyFieldBasedPartitioner.java:[line 68]<br/>Another occurrence at TestMRKeyFieldBasedPartitioner.java:[line 80]<br/>Another occurrence at TestMRKeyFieldBasedPartitioner.java:[line 101]<br/>Another occurrence at TestMRKeyFieldBasedPartitioner.java:[line 104]<br/>Another occurrence at TestMRKeyFieldBasedPartitioner.java:[line 116]<br/>Another occurrence at TestMRKeyFieldBasedPartitioner.java:[line 119]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N83881');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.MapReduceTestUtil.readOutput(Path, Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N83881" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.MapReduceTestUtil<br/>In method org.apache.hadoop.mapreduce.MapReduceTestUtil.readOutput(Path, Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At MapReduceTestUtil.java:[line 414]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83950');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.MapReduceTestUtil.readTaskLog(TaskLog$LogName, TaskAttemptID, boolean): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83950" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.MapReduceTestUtil<br/>In method org.apache.hadoop.mapreduce.MapReduceTestUtil.readTaskLog(TaskLog$LogName, TaskAttemptID, boolean)<br/>Called method new String(byte[])<br/>At MapReduceTestUtil.java:[line 454]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84019');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.MiniHadoopClusterManager.start(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84019" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.MiniHadoopClusterManager<br/>In method org.apache.hadoop.mapreduce.MiniHadoopClusterManager.start()<br/>Called method new java.io.FileWriter(File)<br/>At MiniHadoopClusterManager.java:[line 194]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N91519');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.security.CredentialsTestJob.checkSecrets(Credentials): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N91519" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.CredentialsTestJob<br/>In method org.apache.hadoop.mapreduce.security.CredentialsTestJob.checkSecrets(Credentials)<br/>Called method new String(byte[])<br/>At CredentialsTestJob.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91588');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.security.SecureShuffleUtils.toHex(byte[]): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91588" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.SecureShuffleUtils<br/>In method org.apache.hadoop.mapreduce.security.SecureShuffleUtils.toHex(byte[])<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At SecureShuffleUtils.java:[line 148]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N91657');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.security.SecureShuffleUtils.toHex(byte[]): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N91657" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.SecureShuffleUtils<br/>In method org.apache.hadoop.mapreduce.security.SecureShuffleUtils.toHex(byte[])<br/>Called method new java.io.PrintStream(OutputStream)<br/>At SecureShuffleUtils.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91961');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(boolean): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91961" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle<br/>In method org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(boolean)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestEncryptedShuffle.java:[line 139]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92030');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.startCluster(Configuration): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92030" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle<br/>In method org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.startCluster(Configuration)<br/>Called method new java.io.FileWriter(String)<br/>At TestEncryptedShuffle.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91822');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.security.TestMRCredentials.createKeysAsJson(String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91822" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.TestMRCredentials<br/>In method org.apache.hadoop.mapreduce.security.TestMRCredentials.createKeysAsJson(String)<br/>Called method String.getBytes()<br/>At TestMRCredentials.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92670');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostBogusHeader(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92670" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestFetcher<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostBogusHeader()<br/>Called method String.getBytes()<br/>At TestFetcher.java:[line 174]<br/>Another occurrence at TestFetcher.java:[line 183]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N92750');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostCompressFailure(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N92750" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestFetcher<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostCompressFailure()<br/>Called method String.getBytes()<br/>At TestFetcher.java:[line 275]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92819');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostIncompatibleShuffleVersion(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92819" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestFetcher<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostIncompatibleShuffleVersion()<br/>Called method String.getBytes()<br/>At TestFetcher.java:[line 202]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N92888');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostWait(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N92888" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestFetcher<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostWait()<br/>Called method String.getBytes()<br/>At TestFetcher.java:[line 236]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92957');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptInMemory(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92957" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestFetcher<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptInMemory()<br/>Called method String.getBytes()<br/>At TestFetcher.java:[line 314]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93026');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptOnDisk(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93026" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestFetcher<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptOnDisk()<br/>Called method String.getBytes()<br/>At TestFetcher.java:[line 362]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N93095');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testReduceOutOfDiskSpace(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N93095" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestFetcher<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testReduceOutOfDiskSpace()<br/>Called method String.getBytes()<br/>At TestFetcher.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84582');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestJobMonitorAndPrint.testJobMonitorAndPrint(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84582" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestJobMonitorAndPrint<br/>In method org.apache.hadoop.mapreduce.TestJobMonitorAndPrint.testJobMonitorAndPrint()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestJobMonitorAndPrint.java:[line 108]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N84789');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestLocalRunner.createInputFile(Path, int, int): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N84789" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestLocalRunner<br/>In method org.apache.hadoop.mapreduce.TestLocalRunner.createInputFile(Path, int, int)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestLocalRunner.java:[line 156]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84858');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestLocalRunner.verifyOutput(Path): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84858" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestLocalRunner<br/>In method org.apache.hadoop.mapreduce.TestLocalRunner.verifyOutput(Path)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestLocalRunner.java:[line 227]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86223');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMapperReducerCleanup.createInputFile(Path, int, int): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86223" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMapperReducerCleanup<br/>In method org.apache.hadoop.mapreduce.TestMapperReducerCleanup.createInputFile(Path, int, int)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMapperReducerCleanup.java:[line 190]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85947');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMapReduce.isSequenceFile(FileSystem, Path): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85947" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMapReduce<br/>In method org.apache.hadoop.mapreduce.TestMapReduce.isSequenceFile(FileSystem, Path)<br/>Called method String.getBytes()<br/>At TestMapReduce.java:[line 456]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86016');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMapReduce.launch(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86016" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMapReduce<br/>In method org.apache.hadoop.mapreduce.TestMapReduce.launch()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMapReduce.java:[line 420]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N86085');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMapReduce.printTextFile(FileSystem, Path): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N86085" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMapReduce<br/>In method org.apache.hadoop.mapreduce.TestMapReduce.printTextFile(FileSystem, Path)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMapReduce.java:[line 433]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86154');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.createInput(FileSystem, int): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86154" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMapReduceLazyOutput<br/>In method org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.createInput(FileSystem, int)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMapReduceLazyOutput.java:[line 117]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84981');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.runTool(Configuration, Tool, String[], OutputStream): new java.io.PrintStream(OutputStream, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84981" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.runTool(Configuration, Tool, String[], OutputStream)<br/>Called method new java.io.PrintStream(OutputStream, boolean)<br/>At TestMRJobClient.java:[line 84]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N85050');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.startStop(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N85050" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.startStop()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestMRJobClient.java:[line 255]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85119');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.startStop(): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85119" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.startStop()<br/>Called method new String(byte[])<br/>At TestMRJobClient.java:[line 270]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N85188');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testAllJobList(String, Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N85188" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testAllJobList(String, Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 466]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85257');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testGetCounter(String, Configuration): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85257" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testGetCounter(String, Configuration)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestMRJobClient.java:[line 449]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N85326');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testJobEvents(String, Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N85326" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testJobEvents(String, Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 396]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85395');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testJobHistory(Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85395" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testJobHistory(Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 372]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N85464');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testJobStatus(String, Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N85464" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testJobStatus(String, Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 421]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85533');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testListAttemptIds(String, Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85533" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testListAttemptIds(String, Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 321]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N85602');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testListBlackList(Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N85602" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testListBlackList(Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 299]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85671');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testListTrackers(Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85671" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testListTrackers(Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 342]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N85740');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testSubmit(Configuration): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N85740" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testSubmit(Configuration)<br/>Called method new String(byte[])<br/>At TestMRJobClient.java:[line 245]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85809');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testSubmittedJobList(Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85809" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testSubmittedJobList(Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 489]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N85878');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.verifyJobPriority(String, String, Configuration, CLI): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N85878" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.verifyJobPriority(String, String, Configuration, CLI)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 509]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N86604');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestValueIterReset.createInput(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N86604" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestValueIterReset<br/>In method org.apache.hadoop.mapreduce.TestValueIterReset.createInput()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestValueIterReset.java:[line 515]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86673');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestValueIterReset.validateOutput(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86673" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestValueIterReset<br/>In method org.apache.hadoop.mapreduce.TestValueIterReset.validateOutput()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestValueIterReset.java:[line 557]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N86815');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N86815" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider<br/>In method org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken()<br/>Called method String.getBytes()<br/>At TestYarnClientProtocolProvider.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97153');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttemptContainerRequest.testAttemptContainerRequest(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97153" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttemptContainerRequest<br/>In method org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttemptContainerRequest.testAttemptContainerRequest()<br/>Called method String.getBytes()<br/>At TestTaskAttemptContainerRequest.java:[line 75]<br/>Another occurrence at TestTaskAttemptContainerRequest.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N97233');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncher.testSlowNM(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N97233" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncher<br/>In method org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncher.testSlowNM()<br/>Called method String.getBytes()<br/>At TestContainerLauncher.java:[line 249]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97302');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncherImpl.createNewContainerToken(ContainerId, String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97302" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncherImpl<br/>In method org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncherImpl.createNewContainerToken(ContainerId, String)<br/>Called method String.getBytes()<br/>At TestContainerLauncherImpl.java:[line 401]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95738');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.MRApp.initJobCredentialsAndUGI(Configuration): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95738" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MRApp<br/>In method org.apache.hadoop.mapreduce.v2.app.MRApp.initJobCredentialsAndUGI(Configuration)<br/>Called method String.getBytes()<br/>At MRApp.java:[line 158]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N96365');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterCredentials(): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N96365" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster<br/>In method org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterCredentials()<br/>Called method new String(byte[])<br/>At TestMRAppMaster.java:[line 404]<br/>Another occurrence at TestMRAppMaster.java:[line 412]<br/>Another occurrence at TestMRAppMaster.java:[line 421]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N96456');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterCredentials(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N96456" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster<br/>In method org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterCredentials()<br/>Called method String.getBytes()<br/>At TestMRAppMaster.java:[line 339]<br/>Another occurrence at TestMRAppMaster.java:[line 340]<br/>Another occurrence at TestMRAppMaster.java:[line 355]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N101161');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.checkHistoryParsing(int, int, int): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N101161" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing<br/>In method org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.checkHistoryParsing(int, int, int)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestJobHistoryParsing.java:[line 350]<br/>Another occurrence at TestJobHistoryParsing.java:[line 351]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N101241');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.checkHistoryParsing(int, int, int): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N101241" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing<br/>In method org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.checkHistoryParsing(int, int, int)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestJobHistoryParsing.java:[line 338]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94983');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94983" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser<br/>In method org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMiniMRProxyUser.java:[line 108]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N94423');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.TestMRJobs.makeJar(Path, int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N94423" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobs<br/>In method org.apache.hadoop.mapreduce.v2.TestMRJobs.makeJar(Path, int)<br/>Called method String.getBytes()<br/>At TestMRJobs.java:[line 625]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N103530');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.Hello.main(String[]): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N103530" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.Hello<br/>In method org.apache.hadoop.util.Hello.main(String[])<br/>Called method String.getBytes()<br/>At Hello.java:[line 33]</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_MALICIOUS_CODE">Malicious code vulnerability Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N70757');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapred.IFileInputStream.getChecksum() may expose internal representation by returning IFileInputStream.csum</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N70757" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapred.IFileInputStream<br/>In method org.apache.hadoop.mapred.IFileInputStream.getChecksum()<br/>Field org.apache.hadoop.mapred.IFileInputStream.csum<br/>At IFileInputStream.java:[line 248]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N72654');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate.getMapTaskCompletionEvents() may expose internal representation by returning MapTaskCompletionEventsUpdate.events</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N72654" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate<br/>In method org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate.getMapTaskCompletionEvents()<br/>Field org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate.events<br/>At MapTaskCompletionEventsUpdate.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86951');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getClockSplits() may expose internal representation by returning MapAttemptFinishedEvent.clockSplits</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86951" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getClockSplits()<br/>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.clockSplits<br/>At MapAttemptFinishedEvent.java:[line 209]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87019');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getCpuUsages() may expose internal representation by returning MapAttemptFinishedEvent.cpuUsages</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87019" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getCpuUsages()<br/>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.cpuUsages<br/>At MapAttemptFinishedEvent.java:[line 212]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N87087');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getPhysMemKbytes() may expose internal representation by returning MapAttemptFinishedEvent.physMemKbytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N87087" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getPhysMemKbytes()<br/>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.physMemKbytes<br/>At MapAttemptFinishedEvent.java:[line 218]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87155');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getVMemKbytes() may expose internal representation by returning MapAttemptFinishedEvent.vMemKbytes</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87155" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getVMemKbytes()<br/>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.vMemKbytes<br/>At MapAttemptFinishedEvent.java:[line 215]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N87298');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getClockSplits() may expose internal representation by returning ReduceAttemptFinishedEvent.clockSplits</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N87298" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getClockSplits()<br/>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.clockSplits<br/>At ReduceAttemptFinishedEvent.java:[line 214]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87366');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getCpuUsages() may expose internal representation by returning ReduceAttemptFinishedEvent.cpuUsages</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87366" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getCpuUsages()<br/>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.cpuUsages<br/>At ReduceAttemptFinishedEvent.java:[line 217]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N87434');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getPhysMemKbytes() may expose internal representation by returning ReduceAttemptFinishedEvent.physMemKbytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N87434" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getPhysMemKbytes()<br/>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.physMemKbytes<br/>At ReduceAttemptFinishedEvent.java:[line 223]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87502');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getVMemKbytes() may expose internal representation by returning ReduceAttemptFinishedEvent.vMemKbytes</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87502" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getVMemKbytes()<br/>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.vMemKbytes<br/>At ReduceAttemptFinishedEvent.java:[line 220]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N87645');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getClockSplits() may expose internal representation by returning TaskAttemptUnsuccessfulCompletionEvent.clockSplits</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N87645" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getClockSplits()<br/>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.clockSplits<br/>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 239]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87713');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getCpuUsages() may expose internal representation by returning TaskAttemptUnsuccessfulCompletionEvent.cpuUsages</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87713" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getCpuUsages()<br/>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.cpuUsages<br/>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 242]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N87781');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getPhysMemKbytes() may expose internal representation by returning TaskAttemptUnsuccessfulCompletionEvent.physMemKbytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N87781" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getPhysMemKbytes()<br/>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.physMemKbytes<br/>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 248]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87849');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getVMemKbytes() may expose internal representation by returning TaskAttemptUnsuccessfulCompletionEvent.vMemKbytes</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87849" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getVMemKbytes()<br/>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.vMemKbytes<br/>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 245]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N88592');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getLengths() may expose internal representation by returning CombineFileSplit.lengths</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N88592" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit<br/>In method org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getLengths()<br/>Field org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.lengths<br/>At CombineFileSplit.java:[line 108]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N88660');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getLocations() may expose internal representation by returning CombineFileSplit.locations</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N88660" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit<br/>In method org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getLocations()<br/>Field org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.locations<br/>At CombineFileSplit.java:[line 138]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N88728');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getPaths() may expose internal representation by returning CombineFileSplit.paths</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N88728" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit<br/>In method org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getPaths()<br/>Field org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.paths<br/>At CombineFileSplit.java:[line 133]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N88796');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getStartOffsets() may expose internal representation by returning CombineFileSplit.startoffset</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N88796" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit<br/>In method org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getStartOffsets()<br/>Field org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.startoffset<br/>At CombineFileSplit.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N88864');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.input.FileSplit.getLocations() may expose internal representation by returning FileSplit.hosts</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N88864" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.FileSplit<br/>In method org.apache.hadoop.mapreduce.lib.input.FileSplit.getLocations()<br/>Field org.apache.hadoop.mapreduce.lib.input.FileSplit.hosts<br/>At FileSplit.java:[line 98]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84088');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.QueueAclsInfo.getOperations() may expose internal representation by returning QueueAclsInfo.operations</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84088" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.QueueAclsInfo<br/>In method org.apache.hadoop.mapreduce.QueueAclsInfo.getOperations()<br/>Field org.apache.hadoop.mapreduce.QueueAclsInfo.operations<br/>At QueueAclsInfo.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N84231');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.QueueInfo.getJobStatuses() may expose internal representation by returning QueueInfo.stats</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N84231" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.QueueInfo<br/>In method org.apache.hadoop.mapreduce.QueueInfo.getJobStatuses()<br/>Field org.apache.hadoop.mapreduce.QueueInfo.stats<br/>At QueueInfo.java:[line 189]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N97542');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.getHosts() may expose internal representation by returning ContainerRequestEvent.hosts</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N97542" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent<br/>In method org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.getHosts()<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.hosts<br/>At ContainerRequestEvent.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97610');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.getRacks() may expose internal representation by returning ContainerRequestEvent.racks</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97610" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent<br/>In method org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.getRacks()<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.racks<br/>At ContainerRequestEvent.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N98324');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.security.authorize.ClientHSPolicyProvider.getServices() may expose internal representation by returning ClientHSPolicyProvider.mrHSServices</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N98324" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.security.authorize.ClientHSPolicyProvider<br/>In method org.apache.hadoop.mapreduce.v2.app.security.authorize.ClientHSPolicyProvider.getServices()<br/>Field org.apache.hadoop.mapreduce.v2.app.security.authorize.ClientHSPolicyProvider.mrHSServices<br/>At ClientHSPolicyProvider.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98392');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.security.authorize.MRAMPolicyProvider.getServices() may expose internal representation by returning MRAMPolicyProvider.mapReduceApplicationMasterServices</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98392" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.security.authorize.MRAMPolicyProvider<br/>In method org.apache.hadoop.mapreduce.v2.app.security.authorize.MRAMPolicyProvider.getServices()<br/>Field org.apache.hadoop.mapreduce.v2.app.security.authorize.MRAMPolicyProvider.mapReduceApplicationMasterServices<br/>At MRAMPolicyProvider.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100777');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo.getSource() may expose internal representation by returning ConfEntryInfo.source</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100777" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo.getSource()<br/>Field org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo.source<br/>At ConfEntryInfo.java:[line 54]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72722');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate(TaskCompletionEvent[], boolean) may expose internal representation by storing an externally mutable object into MapTaskCompletionEventsUpdate.events</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72722" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate<br/>In method new org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate(TaskCompletionEvent[], boolean)<br/>Field org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate.events<br/>Local variable named events<br/>At MapTaskCompletionEventsUpdate.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87223');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent(TaskAttemptID, TaskType, String, long, long, String, int, String, String, Counters, int[][]) may expose internal representation by storing an externally mutable object into MapAttemptFinishedEvent.allSplits</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87223" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent<br/>In method new org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent(TaskAttemptID, TaskType, String, long, long, String, int, String, String, Counters, int[][])<br/>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.allSplits<br/>Local variable named allSplits<br/>At MapAttemptFinishedEvent.java:[line 90]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N87570');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent(TaskAttemptID, TaskType, String, long, long, long, String, int, String, String, Counters, int[][]) may expose internal representation by storing an externally mutable object into ReduceAttemptFinishedEvent.allSplits</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N87570" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent<br/>In method new org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent(TaskAttemptID, TaskType, String, long, long, long, String, int, String, String, Counters, int[][])<br/>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.allSplits<br/>Local variable named allSplits<br/>At ReduceAttemptFinishedEvent.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87917');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent(TaskAttemptID, TaskType, String, long, String, int, String, String, Counters, int[][]) may expose internal representation by storing an externally mutable object into TaskAttemptUnsuccessfulCompletionEvent.allSplits</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87917" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent<br/>In method new org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent(TaskAttemptID, TaskType, String, long, String, int, String, String, Counters, int[][])<br/>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.allSplits<br/>Local variable named allSplits<br/>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 89]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N88044');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.lib.db.DBRecordReader(DBInputFormat$DBInputSplit, Class, Configuration, Connection, DBConfiguration, String, String[], String) may expose internal representation by storing an externally mutable object into DBRecordReader.fieldNames</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N88044" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.db.DBRecordReader<br/>In method new org.apache.hadoop.mapreduce.lib.db.DBRecordReader(DBInputFormat$DBInputSplit, Class, Configuration, Connection, DBConfiguration, String, String[], String)<br/>Field org.apache.hadoop.mapreduce.lib.db.DBRecordReader.fieldNames<br/>Local variable named fields<br/>At DBRecordReader.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N88932');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.lib.input.FileSplit(Path, long, long, String[]) may expose internal representation by storing an externally mutable object into FileSplit.hosts</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N88932" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.FileSplit<br/>In method new org.apache.hadoop.mapreduce.lib.input.FileSplit(Path, long, long, String[])<br/>Field org.apache.hadoop.mapreduce.lib.input.FileSplit.hosts<br/>Local variable named hosts<br/>At FileSplit.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89007');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.lib.input.LineRecordReader(byte[]) may expose internal representation by storing an externally mutable object into LineRecordReader.recordDelimiterBytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89007" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.LineRecordReader<br/>In method new org.apache.hadoop.mapreduce.lib.input.LineRecordReader(byte[])<br/>Field org.apache.hadoop.mapreduce.lib.input.LineRecordReader.recordDelimiterBytes<br/>Local variable named recordDelimiter<br/>At LineRecordReader.java:[line 72]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N89990');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.lib.join.TupleWritable(Writable[]) may expose internal representation by storing an externally mutable object into TupleWritable.values</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N89990" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.join.TupleWritable<br/>In method new org.apache.hadoop.mapreduce.lib.join.TupleWritable(Writable[])<br/>Field org.apache.hadoop.mapreduce.lib.join.TupleWritable.values<br/>Local variable named vals<br/>At TupleWritable.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N84156');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.QueueAclsInfo(String, String[]) may expose internal representation by storing an externally mutable object into QueueAclsInfo.operations</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N84156" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.QueueAclsInfo<br/>In method new org.apache.hadoop.mapreduce.QueueAclsInfo(String, String[])<br/>Field org.apache.hadoop.mapreduce.QueueAclsInfo.operations<br/>Local variable named operations<br/>At QueueAclsInfo.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84299');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.QueueInfo(String, String, QueueState, JobStatus[]) may expose internal representation by storing an externally mutable object into QueueInfo.stats</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84299" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.QueueInfo<br/>In method new org.apache.hadoop.mapreduce.QueueInfo(String, String, QueueState, JobStatus[])<br/>Field org.apache.hadoop.mapreduce.QueueInfo.stats<br/>Local variable named stats<br/>At QueueInfo.java:[line 94]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92356');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.task.reduce.InMemoryReader(MergeManagerImpl, TaskAttemptID, byte[], int, int, Configuration) may expose internal representation by storing an externally mutable object into InMemoryReader.buffer</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92356" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.InMemoryReader<br/>In method new org.apache.hadoop.mapreduce.task.reduce.InMemoryReader(MergeManagerImpl, TaskAttemptID, byte[], int, int, Configuration)<br/>Field org.apache.hadoop.mapreduce.task.reduce.InMemoryReader.buffer<br/>Local variable named data<br/>At InMemoryReader.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N97678');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent(TaskAttemptId, Resource, String[], String[]) may expose internal representation by storing an externally mutable object into ContainerRequestEvent.hosts</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N97678" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent<br/>In method new org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent(TaskAttemptId, Resource, String[], String[])<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.hosts<br/>Local variable named hosts<br/>At ContainerRequestEvent.java:[line 37]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97753');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent(TaskAttemptId, Resource, String[], String[]) may expose internal representation by storing an externally mutable object into ContainerRequestEvent.racks</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97753" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent<br/>In method new org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent(TaskAttemptId, Resource, String[], String[])<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.racks<br/>Local variable named racks<br/>At ContainerRequestEvent.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100845');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo(String, String, String[]) may expose internal representation by storing an externally mutable object into ConfEntryInfo.source</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100845" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo<br/>In method new org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo(String, String, String[])<br/>Field org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo.source<br/>Local variable named source<br/>At ConfEntryInfo.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N65813');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.examples.dancing.Pentomino.fourRotations should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N65813" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.examples.dancing.Pentomino<br/>Field org.apache.hadoop.examples.dancing.Pentomino.fourRotations<br/>At Pentomino.java:[line 268]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N65865');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.examples.dancing.Pentomino.oneRotation should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N65865" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.examples.dancing.Pentomino<br/>Field org.apache.hadoop.examples.dancing.Pentomino.oneRotation<br/>At Pentomino.java:[line 258]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N65917');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.examples.dancing.Pentomino.twoRotations should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N65917" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.examples.dancing.Pentomino<br/>Field org.apache.hadoop.examples.dancing.Pentomino.twoRotations<br/>At Pentomino.java:[line 263]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69275');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.baseDir should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69275" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.baseDir<br/>At NNBench.java:[line 100]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69327');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.blockSize should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69327" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.blockSize<br/>At NNBench.java:[line 95]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69379');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.bytesPerChecksum should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69379" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.bytesPerChecksum<br/>At NNBench.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69431');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.bytesToWrite should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69431" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.bytesToWrite<br/>At NNBench.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69483');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.numberOfFiles should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69483" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.numberOfFiles<br/>At NNBench.java:[line 98]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69535');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.numberOfMaps should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69535" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.numberOfMaps<br/>At NNBench.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69587');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.numberOfReduces should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69587" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.numberOfReduces<br/>At NNBench.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69639');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.operation should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69639" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.operation<br/>At NNBench.java:[line 90]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69691');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.readFileAfterOpen should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69691" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.readFileAfterOpen<br/>At NNBench.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69743');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.replicationFactorPerFile should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69743" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.replicationFactorPerFile<br/>At NNBench.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69795');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.startTime should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69795" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.startTime<br/>At NNBench.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69847');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.CONTROL_DIR_NAME isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69847" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.CONTROL_DIR_NAME<br/>At NNBench.java:[line 84]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69899');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.DATA_DIR_NAME isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69899" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.DATA_DIR_NAME<br/>At NNBench.java:[line 86]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69951');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.OUTPUT_DIR_NAME isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69951" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.OUTPUT_DIR_NAME<br/>At NNBench.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70372');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapred.BigMapOutput.MAX_KEY isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70372" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapred.BigMapOutput<br/>Field org.apache.hadoop.mapred.BigMapOutput.MAX_KEY<br/>At BigMapOutput.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N70424');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapred.BigMapOutput.MAX_VALUE isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N70424" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapred.BigMapOutput<br/>Field org.apache.hadoop.mapred.BigMapOutput.MAX_VALUE<br/>At BigMapOutput.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70476');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapred.BigMapOutput.MIN_KEY isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70476" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapred.BigMapOutput<br/>Field org.apache.hadoop.mapred.BigMapOutput.MIN_KEY<br/>At BigMapOutput.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N70528');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapred.BigMapOutput.MIN_VALUE isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N70528" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapred.BigMapOutput<br/>Field org.apache.hadoop.mapred.BigMapOutput.MIN_VALUE<br/>At BigMapOutput.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73223');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapred.Task.MERGED_OUTPUT_PREFIX isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73223" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapred.Task<br/>Field org.apache.hadoop.mapred.Task.MERGED_OUTPUT_PREFIX<br/>At Task.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78291');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.mySuite should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78291" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestReduceFetchFromPartialMem<br/>Field org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.mySuite<br/>In TestReduceFetchFromPartialMem.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N78339');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.dfsCluster isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N78339" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestReduceFetchFromPartialMem<br/>Field org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.dfsCluster<br/>At TestReduceFetchFromPartialMem.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78391');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.mrCluster isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78391" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestReduceFetchFromPartialMem<br/>Field org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.mrCluster<br/>At TestReduceFetchFromPartialMem.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N83653');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.FailJob.FAIL_MAP isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N83653" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.FailJob<br/>Field org.apache.hadoop.mapreduce.FailJob.FAIL_MAP<br/>At FailJob.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83705');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.FailJob.FAIL_REDUCE isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83705" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.FailJob<br/>Field org.apache.hadoop.mapreduce.FailJob.FAIL_REDUCE<br/>At FailJob.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87992');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase.aggregatorDescriptorList should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87992" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase<br/>Field org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase.aggregatorDescriptorList<br/>At ValueAggregatorJobBase.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N88442');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.emptyText isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N88442" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper<br/>Field org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.emptyText<br/>At FieldSelectionHelper.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90065');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.MAP_CLASS isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90065" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper<br/>Field org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.MAP_CLASS<br/>At MultithreadedMapper.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N90117');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.NUM_THREADS isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N90117" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper<br/>Field org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.NUM_THREADS<br/>At MultithreadedMapper.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90169');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.map.RegexMapper.GROUP isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90169" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.map.RegexMapper<br/>Field org.apache.hadoop.mapreduce.lib.map.RegexMapper.GROUP<br/>At RegexMapper.java:[line 39]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N90221');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.map.RegexMapper.PATTERN isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N90221" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.map.RegexMapper<br/>Field org.apache.hadoop.mapreduce.lib.map.RegexMapper.PATTERN<br/>At RegexMapper.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90273');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat.OUTPUT_FORMAT isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90273" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat<br/>Field org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat.OUTPUT_FORMAT<br/>At LazyOutputFormat.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N90325');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.KEY_CLASS isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N90325" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat<br/>Field org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.KEY_CLASS<br/>At SequenceFileAsBinaryOutputFormat.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90377');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.VALUE_CLASS isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90377" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat<br/>Field org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.VALUE_CLASS<br/>At SequenceFileAsBinaryOutputFormat.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N90713');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.SEPERATOR isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N90713" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.TextOutputFormat<br/>Field org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.SEPERATOR<br/>At TextOutputFormat.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90765');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator.COMPARATOR_OPTIONS isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90765" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator<br/>Field org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator.COMPARATOR_OPTIONS<br/>At KeyFieldBasedComparator.java:[line 56]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N90817');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner.PARTITIONER_OPTIONS isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N90817" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner<br/>Field org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner.PARTITIONER_OPTIONS<br/>At KeyFieldBasedPartitioner.java:[line 56]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84374');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.SleepJob.MAP_SLEEP_COUNT isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84374" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.SleepJob<br/>Field org.apache.hadoop.mapreduce.SleepJob.MAP_SLEEP_COUNT<br/>At SleepJob.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N84426');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.SleepJob.MAP_SLEEP_TIME isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N84426" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.SleepJob<br/>Field org.apache.hadoop.mapreduce.SleepJob.MAP_SLEEP_TIME<br/>At SleepJob.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84478');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.SleepJob.REDUCE_SLEEP_COUNT isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84478" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.SleepJob<br/>Field org.apache.hadoop.mapreduce.SleepJob.REDUCE_SLEEP_COUNT<br/>At SleepJob.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N84530');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.SleepJob.REDUCE_SLEEP_TIME isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N84530" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.SleepJob<br/>Field org.apache.hadoop.mapreduce.SleepJob.REDUCE_SLEEP_TIME<br/>At SleepJob.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93217');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.tools.CLI.dataPattern isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93217" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.tools.CLI<br/>Field org.apache.hadoop.mapreduce.tools.CLI.dataPattern<br/>At CLI.java:[line 591]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N93269');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.tools.CLI.headerPattern isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N93269" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.tools.CLI<br/>Field org.apache.hadoop.mapreduce.tools.CLI.headerPattern<br/>At CLI.java:[line 589]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95807');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.MRApp.NM_HOST isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95807" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MRApp<br/>Field org.apache.hadoop.mapreduce.v2.app.MRApp.NM_HOST<br/>At MRApp.java:[line 120]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N95859');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.MRApp.NM_HTTP_PORT isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N95859" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MRApp<br/>Field org.apache.hadoop.mapreduce.v2.app.MRApp.NM_HTTP_PORT<br/>At MRApp.java:[line 122]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95911');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.MRApp.NM_PORT isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95911" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MRApp<br/>Field org.apache.hadoop.mapreduce.v2.app.MRApp.NM_PORT<br/>At MRApp.java:[line 121]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102984');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.jobhistory.JHAdminConfig.DEFAULT_MR_HS_HTTP_POLICY isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102984" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.JHAdminConfig<br/>Field org.apache.hadoop.mapreduce.v2.jobhistory.JHAdminConfig.DEFAULT_MR_HS_HTTP_POLICY<br/>At JHAdminConfig.java:[line 119]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N94254');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities.mrCluster should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N94254" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities<br/>Field org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities.mrCluster<br/>At TestMRAMWithNonNormalizedCapabilities.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94375');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner.mrCluster should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94375" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner<br/>Field org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner.mrCluster<br/>In TestMRAppWithCombiner.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N94561');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.TestMRJobs.dfsCluster should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N94561" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobs<br/>Field org.apache.hadoop.mapreduce.v2.TestMRJobs.dfsCluster<br/>In TestMRJobs.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94609');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.TestMRJobs.mrCluster should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94609" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobs<br/>Field org.apache.hadoop.mapreduce.v2.TestMRJobs.mrCluster<br/>In TestMRJobs.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N94935');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.TestMROldApiJobs.mrCluster should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N94935" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMROldApiJobs<br/>Field org.apache.hadoop.mapreduce.v2.TestMROldApiJobs.mrCluster<br/>In TestMROldApiJobs.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N95263');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.TestRMNMInfo.mrCluster should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N95263" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestRMNMInfo<br/>Field org.apache.hadoop.mapreduce.v2.TestRMNMInfo.mrCluster<br/>In TestRMNMInfo.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95636');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution.mrCluster should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95636" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution<br/>Field org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution.mrCluster<br/>In TestSpeculativeExecution.java</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_MT_CORRECTNESS">Multithreaded correctness Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N70644');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapred.ClusterMapReduceTestCase.dfsCluster; locked 42% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N70644" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapred.ClusterMapReduceTestCase<br/>Field org.apache.hadoop.mapred.ClusterMapReduceTestCase.dfsCluster<br/>Synchronized 42% of the time<br/>Unsynchronized access at ClusterMapReduceTestCase.java:[line 131]<br/>Unsynchronized access at ClusterMapReduceTestCase.java:[line 132]<br/>Unsynchronized access at ClusterMapReduceTestCase.java:[line 133]<br/>Synchronized access at ClusterMapReduceTestCase.java:[line 157]<br/>Synchronized access at ClusterMapReduceTestCase.java:[line 74]<br/>Synchronized access at ClusterMapReduceTestCase.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N96944');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler.commitThreadCancelTimeoutMs; locked 50% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N96944" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler<br/>Field org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler.commitThreadCancelTimeoutMs<br/>Synchronized 50% of the time<br/>Unsynchronized access at CommitterEventHandler.java:[line 92]<br/>Synchronized access at CommitterEventHandler.java:[line 189]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97371');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.local.LocalContainerAllocator.retryInterval; locked 75% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97371" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.local.LocalContainerAllocator<br/>Field org.apache.hadoop.mapreduce.v2.app.local.LocalContainerAllocator.retryInterval<br/>Synchronized 75% of the time<br/>Unsynchronized access at LocalContainerAllocator.java:[line 85]<br/>Synchronized access at LocalContainerAllocator.java:[line 108]<br/>Synchronized access at LocalContainerAllocator.java:[line 109]<br/>Synchronized access at LocalContainerAllocator.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N97462');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.local.LocalContainerAllocator.retrystartTime; locked 66% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N97462" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.local.LocalContainerAllocator<br/>Field org.apache.hadoop.mapreduce.v2.app.local.LocalContainerAllocator.retrystartTime<br/>Synchronized 66% of the time<br/>Unsynchronized access at LocalContainerAllocator.java:[line 90]<br/>Synchronized access at LocalContainerAllocator.java:[line 108]<br/>Synchronized access at LocalContainerAllocator.java:[line 104]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97828');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.mapResourceReqt; locked 91% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97828" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.mapResourceReqt<br/>Synchronized 91% of the time<br/>Unsynchronized access at RMContainerAllocator.java:[line 692]<br/>Synchronized access at RMContainerAllocator.java:[line 392]<br/>Synchronized access at RMContainerAllocator.java:[line 403]<br/>Synchronized access at RMContainerAllocator.java:[line 406]<br/>Synchronized access at RMContainerAllocator.java:[line 233]<br/>Synchronized access at RMContainerAllocator.java:[line 294]<br/>Synchronized access at RMContainerAllocator.java:[line 311]<br/>Synchronized access at RMContainerAllocator.java:[line 295]<br/>Synchronized access at RMContainerAllocator.java:[line 296]<br/>Synchronized access at RMContainerAllocator.java:[line 299]<br/>Synchronized access at RMContainerAllocator.java:[line 300]<br/>Synchronized access at RMContainerAllocator.java:[line 301]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N98007');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.maxReduceRampupLimit; locked 50% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N98007" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.maxReduceRampupLimit<br/>Synchronized 50% of the time<br/>Unsynchronized access at RMContainerAllocator.java:[line 166]<br/>Synchronized access at RMContainerAllocator.java:[line 233]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98076');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.reduceResourceReqt; locked 91% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98076" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.reduceResourceReqt<br/>Synchronized 91% of the time<br/>Unsynchronized access at RMContainerAllocator.java:[line 692]<br/>Synchronized access at RMContainerAllocator.java:[line 382]<br/>Synchronized access at RMContainerAllocator.java:[line 389]<br/>Synchronized access at RMContainerAllocator.java:[line 409]<br/>Synchronized access at RMContainerAllocator.java:[line 233]<br/>Synchronized access at RMContainerAllocator.java:[line 314]<br/>Synchronized access at RMContainerAllocator.java:[line 333]<br/>Synchronized access at RMContainerAllocator.java:[line 315]<br/>Synchronized access at RMContainerAllocator.java:[line 316]<br/>Synchronized access at RMContainerAllocator.java:[line 320]<br/>Synchronized access at RMContainerAllocator.java:[line 321]<br/>Synchronized access at RMContainerAllocator.java:[line 322]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N98255');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.reduceSlowStart; locked 50% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N98255" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.reduceSlowStart<br/>Synchronized 50% of the time<br/>Unsynchronized access at RMContainerAllocator.java:[line 163]<br/>Synchronized access at RMContainerAllocator.java:[line 233]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66387');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.fi.FiConfig.conf in org.apache.hadoop.fi.FiConfig.init()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66387" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.fi.FiConfig<br/>In method org.apache.hadoop.fi.FiConfig.init()<br/>On field org.apache.hadoop.fi.FiConfig.conf<br/>At FiConfig.java:[lines 40-41]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77201');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapred.TestMiniMRChildTask.mr in org.apache.hadoop.mapred.TestMiniMRChildTask.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77201" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMiniMRChildTask<br/>In method org.apache.hadoop.mapred.TestMiniMRChildTask.setup()<br/>On field org.apache.hadoop.mapred.TestMiniMRChildTask.mr<br/>At TestMiniMRChildTask.java:[lines 311-312]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94185');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities.mrCluster in org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94185" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities<br/>In method org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities.mrCluster<br/>At TestMRAMWithNonNormalizedCapabilities.java:[lines 69-70]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N94306');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner.mrCluster in org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N94306" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner<br/>In method org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner.mrCluster<br/>At TestMRAppWithCombiner.java:[lines 76-77]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94492');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestMRJobs.mrCluster in org.apache.hadoop.mapreduce.v2.TestMRJobs.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94492" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobs<br/>In method org.apache.hadoop.mapreduce.v2.TestMRJobs.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestMRJobs.mrCluster<br/>At TestMRJobs.java:[lines 124-125]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N94797');">
<td>
<span class="priority-1">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService.mrCluster in org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N94797" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService<br/>In method org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService.mrCluster<br/>At TestMRJobsWithHistoryService.java:[lines 89-90]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94866');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestMROldApiJobs.mrCluster in org.apache.hadoop.mapreduce.v2.TestMROldApiJobs.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94866" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMROldApiJobs<br/>In method org.apache.hadoop.mapreduce.v2.TestMROldApiJobs.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestMROldApiJobs.mrCluster<br/>At TestMROldApiJobs.java:[lines 74-75]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95125');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization of static field org.apache.hadoop.mapreduce.v2.TestRMNMInfo.mrCluster in org.apache.hadoop.mapreduce.v2.TestRMNMInfo.tearDown()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95125" style="display: none;">
<a href="#LI_LAZY_INIT_STATIC">Bug type LI_LAZY_INIT_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestRMNMInfo<br/>In method org.apache.hadoop.mapreduce.v2.TestRMNMInfo.tearDown()<br/>On field org.apache.hadoop.mapreduce.v2.TestRMNMInfo.mrCluster<br/>At TestRMNMInfo.java:[lines 90-92]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N95194');">
<td>
<span class="priority-1">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestRMNMInfo.mrCluster in org.apache.hadoop.mapreduce.v2.TestRMNMInfo.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N95194" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestRMNMInfo<br/>In method org.apache.hadoop.mapreduce.v2.TestRMNMInfo.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestRMNMInfo.mrCluster<br/>At TestRMNMInfo.java:[lines 75-76]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95567');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution.mrCluster in org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95567" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution<br/>In method org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution.mrCluster<br/>At TestSpeculativeExecution.java:[lines 114-115]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92552');">
<td>
<span class="priority-2">SC</span>
</td>
<td>new org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl(TaskAttemptID, JobConf, FileSystem, LocalDirAllocator, Reporter, CompressionCodec, Class, Task$CombineOutputCollector, Counters$Counter, Counters$Counter, Counters$Counter, ExceptionReporter, Progress, MapOutputFile) invokes org.apache.hadoop.mapreduce.task.reduce.MergeThread.start()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92552" style="display: none;">
<a href="#SC_START_IN_CTOR">Bug type SC_START_IN_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl<br/>In method new org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl(TaskAttemptID, JobConf, FileSystem, LocalDirAllocator, Reporter, CompressionCodec, Class, Task$CombineOutputCollector, Counters$Counter, Counters$Counter, Counters$Counter, ExceptionReporter, Progress, MapOutputFile)<br/>Called method org.apache.hadoop.mapreduce.task.reduce.MergeThread.start()<br/>At MergeManagerImpl.java:[line 218]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70135');">
<td>
<span class="priority-2">STCAL</span>
</td>
<td>Call to method of static java.text.DateFormat in org.apache.hadoop.hdfs.NNBench.analyzeResults()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70135" style="display: none;">
<a href="#STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE">Bug type STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>In method org.apache.hadoop.hdfs.NNBench.analyzeResults()<br/>Called method java.text.SimpleDateFormat.format(Date)<br/>Field org.apache.hadoop.hdfs.NNBench.sdf<br/>At NNBench.java:[line 412]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N70215');">
<td>
<span class="priority-2">STCAL</span>
</td>
<td>Call to method of static java.text.DateFormat in org.apache.hadoop.hdfs.NNBench.parseInputs(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N70215" style="display: none;">
<a href="#STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE">Bug type STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>In method org.apache.hadoop.hdfs.NNBench.parseInputs(String[])<br/>Called method java.text.SimpleDateFormat.format(Date)<br/>Field org.apache.hadoop.hdfs.NNBench.sdf<br/>At NNBench.java:[line 275]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70580');">
<td>
<span class="priority-2">SWL</span>
</td>
<td>org.apache.hadoop.mapred.ClientServiceDelegate.invoke(String, Class, Object) calls Thread.sleep() with a lock held</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70580" style="display: none;">
<a href="#SWL_SLEEP_WITH_LOCK_HELD">Bug type SWL_SLEEP_WITH_LOCK_HELD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.ClientServiceDelegate<br/>In method org.apache.hadoop.mapred.ClientServiceDelegate.invoke(String, Class, Object)<br/>At ClientServiceDelegate.java:[line 347]<br/>Another occurrence at ClientServiceDelegate.java:[line 333]</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_PERFORMANCE">Performance Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67957');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>Primitive boxed just to call toString in org.apache.hadoop.fs.slive.ConfigMerger.handleOperations(ArgumentParser$ParsedOutput, Configuration, ConfigExtractor)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67957" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_TOSTRING">Bug type DM_BOXED_PRIMITIVE_TOSTRING (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.ConfigMerger<br/>In method org.apache.hadoop.fs.slive.ConfigMerger.handleOperations(ArgumentParser$ParsedOutput, Configuration, ConfigExtractor)<br/>Called method Double.toString()<br/>Should call Double.toString(double) instead<br/>At ConfigMerger.java:[line 180]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N68195');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>Primitive boxed just to call toString in org.apache.hadoop.fs.slive.PathFinder.getPath(int, int, PathFinder$Type)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N68195" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_TOSTRING">Bug type DM_BOXED_PRIMITIVE_TOSTRING (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.PathFinder<br/>In method org.apache.hadoop.fs.slive.PathFinder.getPath(int, int, PathFinder$Type)<br/>Called method Integer.toString()<br/>Should call Integer.toString(int) instead<br/>At PathFinder.java:[line 71]<br/>Another occurrence at PathFinder.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68283');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.fs.slive.PathFinder.getPath(int, int, PathFinder$Type) invokes inefficient new Integer(int) constructor; use Integer.valueOf(int) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68283" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.PathFinder<br/>In method org.apache.hadoop.fs.slive.PathFinder.getPath(int, int, PathFinder$Type)<br/>Called method new Integer(int)<br/>Should call Integer.valueOf(int) instead<br/>At PathFinder.java:[line 71]<br/>Another occurrence at PathFinder.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70295');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.io.FileBench.run(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70295" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.io.FileBench<br/>In method org.apache.hadoop.io.FileBench.run(String[])<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At FileBench.java:[line 175]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72290');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.mapred.MRBench.runJobInSequence(JobConf, int) invokes inefficient new Long(long) constructor; use Long.valueOf(long) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72290" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRBench<br/>In method org.apache.hadoop.mapred.MRBench.runJobInSequence(JobConf, int)<br/>Called method new Long(long)<br/>Should call Long.valueOf(long) instead<br/>At MRBench.java:[line 193]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N72442');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.mapred.MRCaching.validateCacheFileSizes(Configuration, long[], String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N72442" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRCaching<br/>In method org.apache.hadoop.mapred.MRCaching.validateCacheFileSizes(Configuration, long[], String)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At MRCaching.java:[line 313]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N73275');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.mapred.TaskLogAppender.setOptionsFromSystemProperties()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N73275" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TaskLogAppender<br/>In method org.apache.hadoop.mapred.TaskLogAppender.setOptionsFromSystemProperties()<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At TaskLogAppender.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77478');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.mapred.TestMultiFileInputFormat.initFiles(FileSystem, int, int) invokes inefficient new Long(long) constructor; use Long.valueOf(long) instead</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77478" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMultiFileInputFormat<br/>In method org.apache.hadoop.mapred.TestMultiFileInputFormat.initFiles(FileSystem, int, int)<br/>Called method new Long(long)<br/>Should call Long.valueOf(long) instead<br/>At TestMultiFileInputFormat.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N88357');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.extractFields(String[], List) invokes inefficient new Integer(String) constructor; use Integer.valueOf(String) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N88357" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper<br/>In method org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.extractFields(String[], List)<br/>Called method new Integer(String)<br/>Should call Integer.valueOf(String) instead<br/>At FieldSelectionHelper.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84712');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.mapreduce.TestLocalRunner.verifyOutput(Path)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84712" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestLocalRunner<br/>In method org.apache.hadoop.mapreduce.TestLocalRunner.verifyOutput(Path)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At TestLocalRunner.java:[line 232]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66594');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.fs.DFSCIOTest.&lt;static initializer for DFSCIOTest&gt;() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66594" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.DFSCIOTest<br/>In method org.apache.hadoop.fs.DFSCIOTest.&lt;static initializer for DFSCIOTest&gt;()<br/>At DFSCIOTest.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N96106');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.MockJobs.newJobReport(JobId) uses the nextDouble method of Random to generate a random integer; using nextInt is more efficient</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N96106" style="display: none;">
<a href="#DM_NEXTINT_VIA_NEXTDOUBLE">Bug type DM_NEXTINT_VIA_NEXTDOUBLE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MockJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.MockJobs.newJobReport(JobId)<br/>At MockJobs.java:[line 158]<br/>Another occurrence at MockJobs.java:[line 160]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N96170');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.MockJobs.newTaskAttemptReport(TaskAttemptId) uses the nextDouble method of Random to generate a random integer; using nextInt is more efficient</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N96170" style="display: none;">
<a href="#DM_NEXTINT_VIA_NEXTDOUBLE">Bug type DM_NEXTINT_VIA_NEXTDOUBLE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MockJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.MockJobs.newTaskAttemptReport(TaskAttemptId)<br/>At MockJobs.java:[line 184]<br/>Another occurrence at MockJobs.java:[line 186]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N96234');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.MockJobs.newTaskReport(TaskId) uses the nextDouble method of Random to generate a random integer; using nextInt is more efficient</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N96234" style="display: none;">
<a href="#DM_NEXTINT_VIA_NEXTDOUBLE">Bug type DM_NEXTINT_VIA_NEXTDOUBLE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MockJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.MockJobs.newTaskReport(TaskId)<br/>At MockJobs.java:[line 171]<br/>Another occurrence at MockJobs.java:[line 173]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N96880');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup.testDeletionofStagingOnUnregistrationFailure(int, boolean) invokes inefficient Boolean constructor; use Boolean.valueOf(...) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N96880" style="display: none;">
<a href="#DM_BOOLEAN_CTOR">Bug type DM_BOOLEAN_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup<br/>In method org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup.testDeletionofStagingOnUnregistrationFailure(int, boolean)<br/>At TestStagingCleanup.java:[line 108]<br/>Another occurrence at TestStagingCleanup.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N86292');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.mapreduce.TestMapperReducerCleanup.INPUT_DIR; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N86292" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMapperReducerCleanup<br/>Field org.apache.hadoop.mapreduce.TestMapperReducerCleanup.INPUT_DIR<br/>At TestMapperReducerCleanup.java:[line 199]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86343');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.mapreduce.TestMapperReducerCleanup.OUTPUT_DIR; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86343" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMapperReducerCleanup<br/>Field org.apache.hadoop.mapreduce.TestMapperReducerCleanup.OUTPUT_DIR<br/>At TestMapperReducerCleanup.java:[line 200]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N101059');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEntities.confFileName; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N101059" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEntities<br/>Field org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEntities.confFileName<br/>At TestJobHistoryEntities.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N101110');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEntities.historyFileName; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N101110" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEntities<br/>Field org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEntities.historyFileName<br/>At TestJobHistoryEntities.java:[line 56]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N67904');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.fs.slive.ConfigExtractor.dumpOptions(ConfigExtractor) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N67904" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.ConfigExtractor<br/>In method org.apache.hadoop.fs.slive.ConfigExtractor.dumpOptions(ConfigExtractor)<br/>At ConfigExtractor.java:[line 723]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68034');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.fs.slive.ConfigMerger.handleOperations(ArgumentParser$ParsedOutput, Configuration, ConfigExtractor) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68034" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.ConfigMerger<br/>In method org.apache.hadoop.fs.slive.ConfigMerger.handleOperations(ArgumentParser$ParsedOutput, Configuration, ConfigExtractor)<br/>At ConfigMerger.java:[line 110]<br/>Another occurrence at ConfigMerger.java:[line 124]<br/>Another occurrence at ConfigMerger.java:[line 138]<br/>Another occurrence at ConfigMerger.java:[line 153]<br/>Another occurrence at ConfigMerger.java:[line 166]<br/>Another occurrence at ConfigMerger.java:[line 178]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N68432');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.fs.slive.ReportWriter.opReport(String, List, PrintWriter) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N68432" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.ReportWriter<br/>In method org.apache.hadoop.fs.slive.ReportWriter.opReport(String, List, PrintWriter)<br/>At ReportWriter.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68623');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.fs.slive.SliveTest.writeReport(ConfigExtractor) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68623" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.SliveTest<br/>In method org.apache.hadoop.fs.slive.SliveTest.writeReport(ConfigExtractor)<br/>At SliveTest.java:[line 274]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69017');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.fs.slive.WeightSelector.configureOperations(ConfigExtractor) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69017" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.WeightSelector<br/>In method org.apache.hadoop.fs.slive.WeightSelector.configureOperations(ConfigExtractor)<br/>At WeightSelector.java:[line 124]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69070');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.fs.slive.WeightSelector.select(int, int) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69070" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.WeightSelector<br/>In method org.apache.hadoop.fs.slive.WeightSelector.select(int, int)<br/>Field org.apache.hadoop.fs.slive.WeightSelector.operations<br/>At WeightSelector.java:[line 176]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N72832');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapred.QueueManager.getJobQueueInfoMapping() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N72832" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapred.QueueManager<br/>In method org.apache.hadoop.mapred.QueueManager.getJobQueueInfoMapping()<br/>Field org.apache.hadoop.mapred.QueueManager.allQueues<br/>At QueueManager.java:[line 445]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86884');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86884" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler<br/>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop()<br/>Field org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.fileMap<br/>At JobHistoryEventHandler.java:[line 341]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93164');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.task.reduce.TestMerger.writeMapOutput(Configuration, Map) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93164" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestMerger<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestMerger.writeMapOutput(Configuration, Map)<br/>At TestMerger.java:[line 149]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N96827');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.TestRecovery.recoveryChecker(MapTaskImpl, TaskState, Map, ArgumentCaptor, List, long, long) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N96827" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestRecovery<br/>In method org.apache.hadoop.mapreduce.v2.app.TestRecovery.recoveryChecker(MapTaskImpl, TaskState, Map, ArgumentCaptor, List, long, long)<br/>At TestRecovery.java:[line 1462]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N98513');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptId() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N98513" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptId()<br/>At TestAMWebServicesAttempts.java:[line 214]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98566');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdCounters() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98566" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdCounters()<br/>At TestAMWebServicesAttempts.java:[line 550]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N98619');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N98619" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdDefault()<br/>At TestAMWebServicesAttempts.java:[line 272]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98672');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdErrorGeneric(String, String) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98672" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdErrorGeneric(String, String)<br/>At TestAMWebServicesAttempts.java:[line 371]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N98725');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N98725" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdSlash()<br/>At TestAMWebServicesAttempts.java:[line 243]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98778');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98778" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdXML()<br/>At TestAMWebServicesAttempts.java:[line 298]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N98831');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdXMLCounters() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N98831" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdXMLCounters()<br/>At TestAMWebServicesAttempts.java:[line 577]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98884');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttempts() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98884" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttempts()<br/>At TestAMWebServicesAttempts.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N98937');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptsDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N98937" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptsDefault()<br/>At TestAMWebServicesAttempts.java:[line 164]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98990');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptsSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98990" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptsSlash()<br/>At TestAMWebServicesAttempts.java:[line 145]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99043');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptsXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99043" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptsXML()<br/>At TestAMWebServicesAttempts.java:[line 183]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99166');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConf() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99166" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConf()<br/>At TestAMWebServicesJobConf.java:[line 172]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99219');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConfDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99219" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConfDefault()<br/>At TestAMWebServicesJobConf.java:[line 207]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99272');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConfSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99272" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConfSlash()<br/>At TestAMWebServicesJobConf.java:[line 190]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99325');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConfXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99325" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConfXML()<br/>At TestAMWebServicesJobConf.java:[line 229]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99452');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttempts() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99452" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttempts()<br/>At TestAMWebServicesJobs.java:[line 791]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99505');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttemptsDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99505" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttemptsDefault()<br/>At TestAMWebServicesJobs.java:[line 827]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99558');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttemptsSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99558" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttemptsSlash()<br/>At TestAMWebServicesJobs.java:[line 809]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99611');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttemptsXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99611" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttemptsXML()<br/>At TestAMWebServicesJobs.java:[line 851]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99664');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCounters() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99664" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCounters()<br/>At TestAMWebServicesJobs.java:[line 639]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99717');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCountersDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99717" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCountersDefault()<br/>At TestAMWebServicesJobs.java:[line 674]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99770');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCountersSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99770" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCountersSlash()<br/>At TestAMWebServicesJobs.java:[line 657]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99823');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCountersXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99823" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCountersXML()<br/>At TestAMWebServicesJobs.java:[line 696]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99876');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobId() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99876" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobId()<br/>At TestAMWebServicesJobs.java:[line 208]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99929');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobIdDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99929" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobIdDefault()<br/>At TestAMWebServicesJobs.java:[line 244]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99982');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobIdSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99982" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobIdSlash()<br/>At TestAMWebServicesJobs.java:[line 227]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100035');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testJobTaskCountersXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100035" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testJobTaskCountersXML()<br/>At TestAMWebServicesTasks.java:[line 677]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N100088');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskId() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N100088" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskId()<br/>At TestAMWebServicesTasks.java:[line 280]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100141');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdCounters() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100141" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdCounters()<br/>At TestAMWebServicesTasks.java:[line 614]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N100194');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdCountersDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N100194" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdCountersDefault()<br/>At TestAMWebServicesTasks.java:[line 656]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100247');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdCountersSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100247" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdCountersSlash()<br/>At TestAMWebServicesTasks.java:[line 635]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N100300');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N100300" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdDefault()<br/>At TestAMWebServicesTasks.java:[line 322]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100353');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100353" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdSlash()<br/>At TestAMWebServicesTasks.java:[line 301]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N100406');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N100406" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdXML()<br/>At TestAMWebServicesTasks.java:[line 503]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100459');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasks() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100459" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasks()<br/>At TestAMWebServicesTasks.java:[line 133]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N100512');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N100512" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksDefault()<br/>At TestAMWebServicesTasks.java:[line 152]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100565');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksQueryMap() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100565" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksQueryMap()<br/>At TestAMWebServicesTasks.java:[line 216]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N100618');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksQueryReduce() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N100618" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksQueryReduce()<br/>At TestAMWebServicesTasks.java:[line 236]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100671');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100671" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksSlash()<br/>At TestAMWebServicesTasks.java:[line 172]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N100724');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N100724" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksXML()<br/>At TestAMWebServicesTasks.java:[line 196]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100920');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.CompletedJob.constructTaskAttemptCompletionEvents() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100920" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.CompletedJob<br/>In method org.apache.hadoop.mapreduce.v2.hs.CompletedJob.constructTaskAttemptCompletionEvents()<br/>Field org.apache.hadoop.mapreduce.v2.hs.CompletedJob.tasks<br/>At CompletedJob.java:[line 218]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N101310');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptId() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N101310" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptId()<br/>At TestHsWebServicesAttempts.java:[line 228]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N101363');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdCounters() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N101363" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdCounters()<br/>At TestHsWebServicesAttempts.java:[line 569]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N101416');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N101416" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdDefault()<br/>At TestHsWebServicesAttempts.java:[line 286]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N101469');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdErrorGeneric(String, String) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N101469" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdErrorGeneric(String, String)<br/>At TestHsWebServicesAttempts.java:[line 389]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N101522');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N101522" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdSlash()<br/>At TestHsWebServicesAttempts.java:[line 257]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N101575');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N101575" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdXML()<br/>At TestHsWebServicesAttempts.java:[line 312]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N101628');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdXMLCounters() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N101628" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdXMLCounters()<br/>At TestHsWebServicesAttempts.java:[line 596]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N101681');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttempts() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N101681" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttempts()<br/>At TestHsWebServicesAttempts.java:[line 137]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N101734');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptsDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N101734" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptsDefault()<br/>At TestHsWebServicesAttempts.java:[line 177]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N101787');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptsSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N101787" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptsSlash()<br/>At TestHsWebServicesAttempts.java:[line 157]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N101840');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptsXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N101840" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptsXML()<br/>At TestHsWebServicesAttempts.java:[line 196]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N101963');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConf() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N101963" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConf()<br/>At TestHsWebServicesJobConf.java:[line 176]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102016');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConfDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102016" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConfDefault()<br/>At TestHsWebServicesJobConf.java:[line 211]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102069');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConfSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102069" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConfSlash()<br/>At TestHsWebServicesJobConf.java:[line 194]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102122');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConfXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102122" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConfXML()<br/>At TestHsWebServicesJobConf.java:[line 233]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102242');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testJobTaskCountersXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102242" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testJobTaskCountersXML()<br/>At TestHsWebServicesTasks.java:[line 692]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102295');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskId() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102295" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskId()<br/>At TestHsWebServicesTasks.java:[line 292]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102348');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdCounters() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102348" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdCounters()<br/>At TestHsWebServicesTasks.java:[line 627]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102401');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdCountersDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102401" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdCountersDefault()<br/>At TestHsWebServicesTasks.java:[line 671]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102454');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdCountersSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102454" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdCountersSlash()<br/>At TestHsWebServicesTasks.java:[line 649]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102507');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102507" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdDefault()<br/>At TestHsWebServicesTasks.java:[line 335]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102560');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102560" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdSlash()<br/>At TestHsWebServicesTasks.java:[line 313]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102613');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102613" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdXML()<br/>At TestHsWebServicesTasks.java:[line 516]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102666');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasks() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102666" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasks()<br/>At TestHsWebServicesTasks.java:[line 142]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102719');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102719" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksDefault()<br/>At TestHsWebServicesTasks.java:[line 162]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102772');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksQueryMap() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102772" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksQueryMap()<br/>At TestHsWebServicesTasks.java:[line 227]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102825');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksQueryReduce() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102825" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksQueryReduce()<br/>At TestHsWebServicesTasks.java:[line 248]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102878');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102878" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksSlash()<br/>At TestHsWebServicesTasks.java:[line 182]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102931');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102931" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksXML()<br/>At TestHsWebServicesTasks.java:[line 206]</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_STYLE">Dodgy code Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66334');">
<td>
<span class="priority-2">BSHIFT</span>
</td>
<td>Unsigned right shift cast to short/byte in org.apache.hadoop.examples.terasort.Unsigned16.getHexDigit(int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66334" style="display: none;">
<a href="#ICAST_QUESTIONABLE_UNSIGNED_RIGHT_SHIFT">Bug type ICAST_QUESTIONABLE_UNSIGNED_RIGHT_SHIFT (click for details)</a>
<br/>In class org.apache.hadoop.examples.terasort.Unsigned16<br/>In method org.apache.hadoop.examples.terasort.Unsigned16.getHexDigit(int)<br/>At Unsigned16.java:[line 181]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N66122');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to max in org.apache.hadoop.examples.pi.math.TestLongLong.testMultiplication()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N66122" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.examples.pi.math.TestLongLong<br/>In method org.apache.hadoop.examples.pi.math.TestLongLong.testMultiplication()<br/>Local variable named max<br/>At TestLongLong.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67625');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to fs in org.apache.hadoop.fs.TestFileSystem.testFsClose()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67625" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileSystem<br/>In method org.apache.hadoop.fs.TestFileSystem.testFsClose()<br/>Local variable named fs<br/>At TestFileSystem.java:[line 576]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71954');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to execTimes in org.apache.hadoop.mapred.MRBench.run(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71954" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRBench<br/>In method org.apache.hadoop.mapred.MRBench.run(String[])<br/>Local variable named execTimes<br/>At MRBench.java:[line 288]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74505');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to namenode in org.apache.hadoop.mapred.TestFileInputFormat.testMultiLevelInput()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74505" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFileInputFormat<br/>In method org.apache.hadoop.mapred.TestFileInputFormat.testMultiLevelInput()<br/>Local variable named namenode<br/>At TestFileInputFormat.java:[line 168]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N74578');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to splits in org.apache.hadoop.mapred.TestFileInputFormat.testNumInputs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N74578" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFileInputFormat<br/>In method org.apache.hadoop.mapred.TestFileInputFormat.testNumInputs()<br/>Local variable named splits<br/>At TestFileInputFormat.java:[line 132]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74855');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to tmpJobACLs in org.apache.hadoop.mapred.TestJobAclsManager.testAclsOff()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74855" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobAclsManager<br/>In method org.apache.hadoop.mapred.TestJobAclsManager.testAclsOff()<br/>Local variable named tmpJobACLs<br/>At TestJobAclsManager.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N74928');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to tmpJobACLs in org.apache.hadoop.mapred.TestJobAclsManager.testClusterAdmins()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N74928" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobAclsManager<br/>In method org.apache.hadoop.mapred.TestJobAclsManager.testClusterAdmins()<br/>Local variable named tmpJobACLs<br/>At TestJobAclsManager.java:[line 40]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75001');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to tmpJobACLs in org.apache.hadoop.mapred.TestJobAclsManager.testClusterNoAdmins()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75001" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobAclsManager<br/>In method org.apache.hadoop.mapred.TestJobAclsManager.testClusterNoAdmins()<br/>Local variable named tmpJobACLs<br/>At TestJobAclsManager.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N75074');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to tmpJobACLs in org.apache.hadoop.mapred.TestJobAclsManager.testGroups()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N75074" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobAclsManager<br/>In method org.apache.hadoop.mapred.TestJobAclsManager.testGroups()<br/>Local variable named tmpJobACLs<br/>At TestJobAclsManager.java:[line 122]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76238');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to client in org.apache.hadoop.mapred.TestLazyOutput.runTestLazyOutput(JobConf, Path, int, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76238" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestLazyOutput<br/>In method org.apache.hadoop.mapred.TestLazyOutput.runTestLazyOutput(JobConf, Path, int, boolean)<br/>Local variable named client<br/>At TestLazyOutput.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77270');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to parents in org.apache.hadoop.mapred.TestMiniMRClasspath.launchWordCount(URI, JobConf, String, int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77270" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMiniMRClasspath<br/>In method org.apache.hadoop.mapred.TestMiniMRClasspath.launchWordCount(URI, JobConf, String, int, int)<br/>Local variable named parents<br/>At TestMiniMRClasspath.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78443');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to buf in org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat.testBinary()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78443" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat<br/>In method org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat.testBinary()<br/>Local variable named buf<br/>At TestSequenceFileAsBinaryOutputFormat.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N78513');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to fs in org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat.testSequenceOutputClassDefaultsToMapRedOutputClass()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N78513" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat<br/>In method org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat.testSequenceOutputClassDefaultsToMapRedOutputClass()<br/>Local variable named fs<br/>At TestSequenceFileAsBinaryOutputFormat.java:[line 135]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N80430');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to submissionContext rather than field with same name in org.apache.hadoop.mapred.TestYARNRunner.testWarnCommandOpts()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N80430" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE_SHADOWS_FIELD">Bug type DLS_DEAD_LOCAL_STORE_SHADOWS_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestYARNRunner<br/>In method org.apache.hadoop.mapred.TestYARNRunner.testWarnCommandOpts()<br/>Local variable named submissionContext<br/>Did you mean to refer to the field org.apache.hadoop.mapred.TestYARNRunner.submissionContext?<br/>At TestYARNRunner.java:[line 479]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80900');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to numBytes in org.apache.hadoop.mapred.UtilsForTests.formatBytes2(long)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80900" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.UtilsForTests<br/>In method org.apache.hadoop.mapred.UtilsForTests.formatBytes2(long)<br/>Local variable named numBytes<br/>At UtilsForTests.java:[line 131]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89429');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to bkey in org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsBinaryInputFormat.testBinary()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89429" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsBinaryInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsBinaryInputFormat.testBinary()<br/>Local variable named bkey<br/>At TestMRSequenceFileAsBinaryInputFormat.java:[line 73]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N89502');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to bval in org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsBinaryInputFormat.testBinary()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N89502" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsBinaryInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsBinaryInputFormat.testBinary()<br/>Local variable named bval<br/>At TestMRSequenceFileAsBinaryInputFormat.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N90567');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to dwritable in org.apache.hadoop.mapreduce.lib.output.TestMRSequenceFileAsBinaryOutputFormat.testBinary()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N90567" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.TestMRSequenceFileAsBinaryOutputFormat<br/>In method org.apache.hadoop.mapreduce.lib.output.TestMRSequenceFileAsBinaryOutputFormat.testBinary()<br/>Local variable named dwritable<br/>At TestMRSequenceFileAsBinaryOutputFormat.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90640');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to iwritable in org.apache.hadoop.mapreduce.lib.output.TestMRSequenceFileAsBinaryOutputFormat.testBinary()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90640" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.TestMRSequenceFileAsBinaryOutputFormat<br/>In method org.apache.hadoop.mapreduce.lib.output.TestMRSequenceFileAsBinaryOutputFormat.testBinary()<br/>Local variable named iwritable<br/>At TestMRSequenceFileAsBinaryOutputFormat.java:[line 84]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86742');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to conf in org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86742" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider<br/>In method org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken()<br/>Local variable named conf<br/>At TestYarnClientProtocolProvider.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N96033');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to tmpJobACLs in org.apache.hadoop.mapreduce.v2.app.MockJobs.newJob(ApplicationId, int, int, int, Path, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N96033" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MockJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.MockJobs.newJob(ApplicationId, int, int, int, Path, boolean)<br/>Local variable named tmpJobACLs<br/>At MockJobs.java:[line 481]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N96298');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to mapTask in org.apache.hadoop.mapreduce.v2.app.TestAMInfos.testAMInfosWithoutRecoveryEnabled()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N96298" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestAMInfos<br/>In method org.apache.hadoop.mapreduce.v2.app.TestAMInfos.testAMInfosWithoutRecoveryEnabled()<br/>Local variable named mapTask<br/>At TestAMInfos.java:[line 76]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95052');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to proxyUser in org.apache.hadoop.mapreduce.v2.TestNonExistentJob.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95052" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestNonExistentJob<br/>In method org.apache.hadoop.mapreduce.v2.TestNonExistentJob.setUp()<br/>Local variable named proxyUser<br/>At TestNonExistentJob.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N95311');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to client in org.apache.hadoop.mapreduce.v2.TestRPCFactories.testPbClientFactory()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N95311" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestRPCFactories<br/>In method org.apache.hadoop.mapreduce.v2.TestRPCFactories.testPbClientFactory()<br/>Local variable named client<br/>At TestRPCFactories.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N65740');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.examples.TestWordStats.deleteDir(File) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N65740" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.examples.TestWordStats<br/>In method org.apache.hadoop.examples.TestWordStats.deleteDir(File)<br/>Value loaded from children<br/>Dereferenced at TestWordStats.java:[line 228]<br/>Known null at TestWordStats.java:[line 227]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68676');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.fs.slive.TestSlive.deleteDir(File) due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68676" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.TestSlive<br/>In method org.apache.hadoop.fs.slive.TestSlive.deleteDir(File)<br/>Value loaded from fns<br/>Dereferenced at TestSlive.java:[line 218]<br/>Known null at TestSlive.java:[line 216]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71881');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in new org.apache.hadoop.mapred.LocalContainerLauncher(AppContext, TaskUmbilicalProtocol) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71881" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.LocalContainerLauncher<br/>In method new org.apache.hadoop.mapred.LocalContainerLauncher(AppContext, TaskUmbilicalProtocol)<br/>Value loaded from curLocalFiles<br/>Dereferenced at LocalContainerLauncher.java:[line 98]<br/>Known null at LocalContainerLauncher.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N84651');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Dereference of the result of readLine() without nullcheck in org.apache.hadoop.mapreduce.TestJobMonitorAndPrint.testJobMonitorAndPrint()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N84651" style="display: none;">
<a href="#NP_DEREFERENCE_OF_READLINE_VALUE">Bug type NP_DEREFERENCE_OF_READLINE_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestJobMonitorAndPrint<br/>In method org.apache.hadoop.mapreduce.TestJobMonitorAndPrint.testJobMonitorAndPrint()<br/>Value loaded from line<br/>At TestJobMonitorAndPrint.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84927');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Immediate dereference of the result of readLine() in org.apache.hadoop.mapreduce.TestLocalRunner.verifyOutput(Path)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84927" style="display: none;">
<a href="#NP_IMMEDIATE_DEREFERENCE_OF_READLINE">Bug type NP_IMMEDIATE_DEREFERENCE_OF_READLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestLocalRunner<br/>In method org.apache.hadoop.mapreduce.TestLocalRunner.verifyOutput(Path)<br/>At TestLocalRunner.java:[line 230]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N93803');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.makeSureCleanedUp(String[], MRAsyncDiskService) due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N93803" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService<br/>In method org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.makeSureCleanedUp(String[], MRAsyncDiskService)<br/>Value loaded from subDirContent<br/>Dereferenced at TestMRAsyncDiskService.java:[line 323]<br/>Known null at TestMRAsyncDiskService.java:[line 322]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70825');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of info, which is known to be non-null in org.apache.hadoop.mapred.IndexCache.removeMap(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70825" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.IndexCache<br/>In method org.apache.hadoop.mapred.IndexCache.removeMap(String)<br/>Value loaded from info<br/>Return value of java.util.concurrent.ConcurrentHashMap.get(Object) of type Object<br/>Redundant null check at IndexCache.java:[line 148]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83810');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of org.apache.hadoop.mapreduce.task.JobContextImpl.getWorkingDirectory(), which is known to be non-null in org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(Job, Path)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83810" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.JobSubmitter<br/>In method org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(Job, Path)<br/>Return value of org.apache.hadoop.mapreduce.task.JobContextImpl.getWorkingDirectory() of type org.apache.hadoop.fs.Path<br/>Redundant null check at JobSubmitter.java:[line 303]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93725');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of value, which is known to be non-null in org.apache.hadoop.mapreduce.util.ResourceBundles.getValue(String, String, String, Object)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93725" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.ResourceBundles<br/>In method org.apache.hadoop.mapreduce.util.ResourceBundles.getValue(String, String, String, Object)<br/>Value loaded from value<br/>Return value of java.util.ResourceBundle.getObject(String) of type Object<br/>Redundant null check at ResourceBundles.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99378');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of id, which is known to be non-null in org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.verifyAMJobXML(NodeList, AppContext)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99378" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.verifyAMJobXML(NodeList, AppContext)<br/>Value loaded from id<br/>Return value of org.w3c.dom.Element.getElementsByTagName(String) of type org.w3c.dom.NodeList<br/>Redundant null check at TestAMWebServicesJobs.java:[line 526]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100987');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of old, which is known to be non-null in org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.scanIntermediateDirectory(Path)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100987" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager<br/>In method org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.scanIntermediateDirectory(Path)<br/>Value loaded from old<br/>Return value of org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$JobListCache.addIfAbsent(HistoryFileManager$HistoryFileInfo) of type org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo<br/>Redundant null check at HistoryFileManager.java:[line 767]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N95684');">
<td>
<span class="priority-2">REC</span>
</td>
<td>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.v2.TestUberAM.testFailingMapper()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N95684" style="display: none;">
<a href="#REC_CATCH_EXCEPTION">Bug type REC_CATCH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestUberAM<br/>In method org.apache.hadoop.mapreduce.v2.TestUberAM.testFailingMapper()<br/>At TestUberAM.java:[line 134]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71041');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getJobID() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71041" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getJobID()<br/>At JobClientUnitTest.java:[line 154]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N71111');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getNeededMem() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N71111" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getNeededMem()<br/>At JobClientUnitTest.java:[line 164]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71181');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getNumReservedSlots() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71181" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getNumReservedSlots()<br/>At JobClientUnitTest.java:[line 161]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N71251');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getNumUsedSlots() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N71251" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getNumUsedSlots()<br/>At JobClientUnitTest.java:[line 160]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71321');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getPriority() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71321" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getPriority()<br/>At JobClientUnitTest.java:[line 159]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N71391');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getQueue() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N71391" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getQueue()<br/>At JobClientUnitTest.java:[line 158]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71461');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getReservedMem() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71461" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getReservedMem()<br/>At JobClientUnitTest.java:[line 163]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N71531');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getSchedulingInfo() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N71531" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getSchedulingInfo()<br/>At JobClientUnitTest.java:[line 165]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71601');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getStartTime() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71601" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getStartTime()<br/>At JobClientUnitTest.java:[line 156]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N71671');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getState() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N71671" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getState()<br/>At JobClientUnitTest.java:[line 155]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71741');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getUsedMem() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71741" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getUsedMem()<br/>At JobClientUnitTest.java:[line 162]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N71811');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getUsername() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N71811" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getUsername()<br/>At JobClientUnitTest.java:[line 157]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N81138');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.task.JobContextImpl.getJobID() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N81138" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.jobcontrol.TestJobControl<br/>In method org.apache.hadoop.mapred.jobcontrol.TestJobControl.testGetAssignedJobId()<br/>Called method org.apache.hadoop.mapreduce.task.JobContextImpl.getJobID()<br/>At TestJobControl.java:[line 273]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N80830');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of ResourceMgrDelegate.getConnectAddress() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N80830" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestYARNRunner<br/>In method org.apache.hadoop.mapred.TestYARNRunner.testGetHSDelegationToken()<br/>Called method org.apache.hadoop.mapred.ResourceMgrDelegate.getConnectAddress()<br/>At TestYARNRunner.java:[line 301]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N86394');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapred.ReduceTask.getNumMaps() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N86394" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestShufflePlugin<br/>In method org.apache.hadoop.mapreduce.TestShufflePlugin.testConsumerApi()<br/>Called method org.apache.hadoop.mapred.ReduceTask.getNumMaps()<br/>At TestShufflePlugin.java:[line 170]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86464');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapred.Task.getPartition() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86464" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestShufflePlugin<br/>In method org.apache.hadoop.mapreduce.TestShufflePlugin.testConsumerApi()<br/>Called method org.apache.hadoop.mapred.Task.getPartition()<br/>At TestShufflePlugin.java:[line 171]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N86534');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapred.Task.getTaskID() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N86534" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestShufflePlugin<br/>In method org.apache.hadoop.mapreduce.TestShufflePlugin.testConsumerApi()<br/>Called method org.apache.hadoop.mapred.Task.getTaskID()<br/>At TestShufflePlugin.java:[line 168]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68142');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.fs.slive.OperationFactory.getOperation(Constants$OperationType) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68142" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.OperationFactory<br/>In method org.apache.hadoop.fs.slive.OperationFactory.getOperation(Constants$OperationType)<br/>At OperationFactory.java:[lines 56-76]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N68379');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.fs.slive.PathFinder.getPath(int, int, PathFinder$Type) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N68379" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.PathFinder<br/>In method org.apache.hadoop.fs.slive.PathFinder.getPath(int, int, PathFinder$Type)<br/>At PathFinder.java:[lines 69-74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67494');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.fs.TestDFSIO.run(String[]) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67494" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestDFSIO<br/>In method org.apache.hadoop.fs.TestDFSIO.run(String[])<br/>At TestDFSIO.java:[lines 753-766]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N83757');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.Job.printTaskEvents(TaskCompletionEvent[], Job$TaskStatusFilter, boolean, Configuration$IntegerRanges, Configuration$IntegerRanges) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N83757" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.Job<br/>In method org.apache.hadoop.mapreduce.Job.printTaskEvents(TaskCompletionEvent[], Job$TaskStatusFilter, boolean, Configuration$IntegerRanges, Configuration$IntegerRanges)<br/>At Job.java:[lines 1412-1441]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92617');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.resolve(TaskCompletionEvent) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92617" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl<br/>In method org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.resolve(TaskCompletionEvent)<br/>At ShuffleSchedulerImpl.java:[lines 139-156]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N98460');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.processSpeculatorEvent(SpeculatorEvent) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N98460" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator<br/>In method org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.processSpeculatorEvent(SpeculatorEvent)<br/>At DefaultSpeculator.java:[lines 274-297]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66189');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.examples.terasort.TeraInputFormat.lastResult from instance method org.apache.hadoop.examples.terasort.TeraInputFormat.getSplits(JobContext)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66189" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.examples.terasort.TeraInputFormat<br/>In method org.apache.hadoop.examples.terasort.TeraInputFormat.getSplits(JobContext)<br/>Field org.apache.hadoop.examples.terasort.TeraInputFormat.lastResult<br/>At TeraInputFormat.java:[line 300]<br/>Another occurrence at TeraInputFormat.java:[line 294]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N66267');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.examples.terasort.TeraInputFormat.lastContext from instance method org.apache.hadoop.examples.terasort.TeraInputFormat.getSplits(JobContext)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N66267" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.examples.terasort.TeraInputFormat<br/>In method org.apache.hadoop.examples.terasort.TeraInputFormat.getSplits(JobContext)<br/>Field org.apache.hadoop.examples.terasort.TeraInputFormat.lastContext<br/>At TeraInputFormat.java:[line 293]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67049');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.DistributedFSCheck.fsConfig from instance method new org.apache.hadoop.fs.DistributedFSCheck(Configuration)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67049" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.DistributedFSCheck<br/>In method new org.apache.hadoop.fs.DistributedFSCheck(Configuration)<br/>Field org.apache.hadoop.fs.DistributedFSCheck.fsConfig<br/>At DistributedFSCheck.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N72375');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.MRBench.BASE_DIR from instance method org.apache.hadoop.mapred.MRBench.run(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N72375" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRBench<br/>In method org.apache.hadoop.mapred.MRBench.run(String[])<br/>Field org.apache.hadoop.mapred.MRBench.BASE_DIR<br/>At MRBench.java:[line 245]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75356');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.TestJobEndNotifier$DelayServlet.calledTimes from instance method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75356" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobEndNotifier<br/>In method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()<br/>Field org.apache.hadoop.mapred.TestJobEndNotifier$DelayServlet.calledTimes<br/>At TestJobEndNotifier.java:[line 115]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N75421');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.TestJobEndNotifier$FailServlet.calledTimes from instance method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N75421" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobEndNotifier<br/>In method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()<br/>Field org.apache.hadoop.mapred.TestJobEndNotifier$FailServlet.calledTimes<br/>At TestJobEndNotifier.java:[line 116]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75486');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.TestJobEndNotifier$JobEndServlet.calledTimes from instance method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75486" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobEndNotifier<br/>In method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()<br/>Field org.apache.hadoop.mapred.TestJobEndNotifier$JobEndServlet.calledTimes<br/>At TestJobEndNotifier.java:[line 113]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N75551');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.TestJobEndNotifier$JobEndServlet.requestUri from instance method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N75551" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobEndNotifier<br/>In method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()<br/>Field org.apache.hadoop.mapred.TestJobEndNotifier$JobEndServlet.requestUri<br/>At TestJobEndNotifier.java:[line 114]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76516');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.TestLocalDistributedCacheManager.mockfs from instance method org.apache.hadoop.mapred.TestLocalDistributedCacheManager.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76516" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestLocalDistributedCacheManager<br/>In method org.apache.hadoop.mapred.TestLocalDistributedCacheManager.setup()<br/>Field org.apache.hadoop.mapred.TestLocalDistributedCacheManager.mockfs<br/>At TestLocalDistributedCacheManager.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N76998');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.TestMapRed.counts from instance method org.apache.hadoop.mapred.TestMapRed.run(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N76998" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMapRed<br/>In method org.apache.hadoop.mapred.TestMapRed.run(String[])<br/>Field org.apache.hadoop.mapred.TestMapRed.counts<br/>At TestMapRed.java:[line 786]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N77065');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.TestMapRed.range from instance method org.apache.hadoop.mapred.TestMapRed.run(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N77065" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMapRed<br/>In method org.apache.hadoop.mapred.TestMapRed.run(String[])<br/>Field org.apache.hadoop.mapred.TestMapRed.range<br/>At TestMapRed.java:[line 785]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102175');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobs.appContext from instance method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobs.testJobCountersForKilledJob()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102175" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobs.testJobCountersForKilledJob()<br/>Field org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobs.appContext<br/>At TestHsWebServicesJobs.java:[line 529]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N65969');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.examples.pi.math.Montgomery.N_I</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N65969" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.examples.pi.math.Montgomery<br/>Field org.apache.hadoop.examples.pi.math.Montgomery.N_I<br/>At Montgomery.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N66020');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.examples.pi.math.Montgomery.R_1</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N66020" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.examples.pi.math.Montgomery<br/>Field org.apache.hadoop.examples.pi.math.Montgomery.R_1<br/>At Montgomery.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66071');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.examples.pi.math.Montgomery.s</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66071" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.examples.pi.math.Montgomery<br/>Field org.apache.hadoop.examples.pi.math.Montgomery.s<br/>At Montgomery.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N67116');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.fs.IOMapperBase.buffer</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N67116" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.fs.IOMapperBase<br/>Field org.apache.hadoop.fs.IOMapperBase.buffer<br/>At IOMapperBase.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67167');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.fs.IOMapperBase.fs</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67167" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.fs.IOMapperBase<br/>Field org.apache.hadoop.fs.IOMapperBase.fs<br/>At IOMapperBase.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N88494');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.rrClass</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N88494" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader<br/>Field org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.rrClass<br/>At CombineFileRecordReader.java:[line 114]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N88545');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused public or protected field: org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.fs</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N88545" style="display: none;">
<a href="#UUF_UNUSED_PUBLIC_OR_PROTECTED_FIELD">Bug type UUF_UNUSED_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader<br/>Field org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.fs<br/>In CombineFileRecordReader.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N92309');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused public or protected field: org.apache.hadoop.mapreduce.task.ReduceContextImpl.reporter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N92309" style="display: none;">
<a href="#UUF_UNUSED_PUBLIC_OR_PROTECTED_FIELD">Bug type UUF_UNUSED_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.ReduceContextImpl<br/>Field org.apache.hadoop.mapreduce.task.ReduceContextImpl.reporter<br/>In ReduceContextImpl.java</p>
</td>
</tr>
</table>
<h1>
<a name="Details">Details</a>
</h1>
<h2>
<a name="BIT_IOR_OF_SIGNED_BYTE">BIT_IOR_OF_SIGNED_BYTE: Bitwise OR of signed byte value</a>
</h2>

<p> Loads a byte value (e.g., a value loaded from a byte array or returned by a method
with return type byte)  and performs a bitwise OR with
that value. Byte values are sign extended to 32 bits
before any any bitwise operations are performed on the value.
Thus, if <code>b[0]</code> contains the value <code>0xff</code>, and
<code>x</code> is initially 0, then the code
<code>((x &lt;&lt; 8) | b[0])</code>  will sign extend <code>0xff</code>
to get <code>0xffffffff</code>, and thus give the value
<code>0xffffffff</code> as the result.
</p>

<p>In particular, the following code for packing a byte array into an int is badly wrong: </p>
<pre>
int result = 0;
for(int i = 0; i &lt; 4; i++)
  result = ((result &lt;&lt; 8) | b[i]);
</pre>

<p>The following idiom will work instead: </p>
<pre>
int result = 0;
for(int i = 0; i &lt; 4; i++)
  result = ((result &lt;&lt; 8) | (b[i] &amp; 0xff));
</pre>


    
<h2>
<a name="ICAST_QUESTIONABLE_UNSIGNED_RIGHT_SHIFT">ICAST_QUESTIONABLE_UNSIGNED_RIGHT_SHIFT: Unsigned right shift cast to short/byte</a>
</h2>

<p>
The code performs an unsigned right shift, whose result is then
cast to a short or byte, which discards the upper bits of the result.
Since the upper bits are discarded, there may be no difference between
a signed and unsigned right shift (depending upon the size of the shift).
</p>

    
<h2>
<a name="DM_BOXED_PRIMITIVE_FOR_PARSING">DM_BOXED_PRIMITIVE_FOR_PARSING: Boxing/unboxing to parse a primitive</a>
</h2>

  <p>A boxed primitive is created from a String, just to extract the unboxed primitive value.
  It is more efficient to just call the static parseXXX method.</p>

    
<h2>
<a name="DM_BOXED_PRIMITIVE_TOSTRING">DM_BOXED_PRIMITIVE_TOSTRING: Method allocates a boxed primitive just to call toString</a>
</h2>

  <p>A boxed primitive is allocated just to call toString(). It is more effective to just use the static
  form of toString which takes the primitive value. So,</p>
  <table>
     <tr><th>Replace...</th><th>With this...</th></tr>
     <tr><td>new Integer(1).toString()</td><td>Integer.toString(1)</td></tr>
     <tr><td>new Long(1).toString()</td><td>Long.toString(1)</td></tr>
     <tr><td>new Float(1.0).toString()</td><td>Float.toString(1.0)</td></tr>
     <tr><td>new Double(1.0).toString()</td><td>Double.toString(1.0)</td></tr>
     <tr><td>new Byte(1).toString()</td><td>Byte.toString(1)</td></tr>
     <tr><td>new Short(1).toString()</td><td>Short.toString(1)</td></tr>
     <tr><td>new Boolean(true).toString()</td><td>Boolean.toString(true)</td></tr>
  </table>

    
<h2>
<a name="DM_NUMBER_CTOR">DM_NUMBER_CTOR: Method invokes inefficient Number constructor; use static valueOf instead</a>
</h2>
      
      <p>
      Using <code>new Integer(int)</code> is guaranteed to always result in a new object whereas
      <code>Integer.valueOf(int)</code> allows caching of values to be done by the compiler, class library, or JVM.
      Using of cached values avoids object allocation and the code will be faster.
      </p>
      <p>
      Values between -128 and 127 are guaranteed to have corresponding cached instances
      and using <code>valueOf</code> is approximately 3.5 times faster than using constructor.
      For values outside the constant range the performance of both styles is the same.
      </p>
      <p>
      Unless the class must be compatible with JVMs predating Java 1.5,
      use either autoboxing or the <code>valueOf()</code> method when creating instances of
      <code>Long</code>, <code>Integer</code>, <code>Short</code>, <code>Character</code>, and <code>Byte</code>.
      </p>
      
    
<h2>
<a name="DE_MIGHT_IGNORE">DE_MIGHT_IGNORE: Method might ignore exception</a>
</h2>

  <p> This method might ignore an exception.&nbsp; In general, exceptions
  should be handled or reported in some way, or they should be thrown
  out of the method.</p>

    
<h2>
<a name="DLS_DEAD_LOCAL_STORE">DLS_DEAD_LOCAL_STORE: Dead store to local variable</a>
</h2>

<p>
This instruction assigns a value to a local variable,
but the value is not read or used in any subsequent instruction.
Often, this indicates an error, because the value computed is never
used.
</p>
<p>
Note that Sun's javac compiler often generates dead stores for
final local variables.  Because FindBugs is a bytecode-based tool,
there is no easy way to eliminate these false positives.
</p>

    
<h2>
<a name="DLS_DEAD_LOCAL_STORE_SHADOWS_FIELD">DLS_DEAD_LOCAL_STORE_SHADOWS_FIELD: Dead store to local variable that shadows field</a>
</h2>

<p>
This instruction assigns a value to a local variable,
but the value is not read or used in any subsequent instruction.
Often, this indicates an error, because the value computed is never
used. There is a field with the same name as the local variable. Did you
mean to assign to that variable instead?
</p>

    
<h2>
<a name="DM_BOOLEAN_CTOR">DM_BOOLEAN_CTOR: Method invokes inefficient Boolean constructor; use Boolean.valueOf(...) instead</a>
</h2>

  <p> Creating new instances of <code>java.lang.Boolean</code> wastes
  memory, since <code>Boolean</code> objects are immutable and there are
  only two useful values of this type.&nbsp; Use the <code>Boolean.valueOf()</code>
  method (or Java 1.5 autoboxing) to create <code>Boolean</code> objects instead.</p>

    
<h2>
<a name="DM_STRING_CTOR">DM_STRING_CTOR: Method invokes inefficient new String(String) constructor</a>
</h2>

  <p> Using the <code>java.lang.String(String)</code> constructor wastes memory
  because the object so constructed will be functionally indistinguishable
  from the <code>String</code> passed as a parameter.&nbsp; Just use the
  argument <code>String</code> directly.</p>

    
<h2>
<a name="DM_EXIT">DM_EXIT: Method invokes System.exit(...)</a>
</h2>

  <p> Invoking System.exit shuts down the entire Java virtual machine. This
   should only been done when it is appropriate. Such calls make it
   hard or impossible for your code to be invoked by other code.
   Consider throwing a RuntimeException instead.</p>

    
<h2>
<a name="DM_DEFAULT_ENCODING">DM_DEFAULT_ENCODING: Reliance on default encoding</a>
</h2>

<p> Found a call to a method which will perform a byte to String (or String to byte) conversion, and will assume that the default platform encoding is suitable. This will cause the application behaviour to vary between platforms. Use an alternative API and specify a charset name or Charset object explicitly.  </p>

      
<h2>
<a name="DM_NEXTINT_VIA_NEXTDOUBLE">DM_NEXTINT_VIA_NEXTDOUBLE: Use the nextInt method of Random rather than nextDouble to generate a random integer</a>
</h2>

  <p>If <code>r</code> is a <code>java.util.Random</code>, you can generate a random number from <code>0</code> to <code>n-1</code>
using <code>r.nextInt(n)</code>, rather than using <code>(int)(r.nextDouble() * n)</code>.
</p>
<p>The argument to nextInt must be positive. If, for example, you want to generate a random
value from -99 to 0, use <code>-r.nextInt(100)</code>.
</p>

    
<h2>
<a name="DMI_RANDOM_USED_ONLY_ONCE">DMI_RANDOM_USED_ONLY_ONCE: Random object created and used only once</a>
</h2>

<p> This code creates a java.util.Random object, uses it to generate one random number, and then discards
the Random object. This produces mediocre quality random numbers and is inefficient.
If possible, rewrite the code so that the Random object is created once and saved, and each time a new random number
is required invoke a method on the existing Random object to obtain it.
</p>

<p>If it is important that the generated Random numbers not be guessable, you <em>must</em> not create a new Random for each random
number; the values are too easily guessable. You should strongly consider using a java.security.SecureRandom instead
(and avoid allocating a new SecureRandom for each random number needed).
</p>

    
<h2>
<a name="EI_EXPOSE_REP">EI_EXPOSE_REP: May expose internal representation by returning reference to mutable object</a>
</h2>

  <p> Returning a reference to a mutable object value stored in one of the object's fields
  exposes the internal representation of the object.&nbsp;
   If instances
   are accessed by untrusted code, and unchecked changes to
   the mutable object would compromise security or other
   important properties, you will need to do something different.
  Returning a new copy of the object is better approach in many situations.</p>

    
<h2>
<a name="EI_EXPOSE_REP2">EI_EXPOSE_REP2: May expose internal representation by incorporating reference to mutable object</a>
</h2>

  <p> This code stores a reference to an externally mutable object into the
  internal representation of the object.&nbsp;
   If instances
   are accessed by untrusted code, and unchecked changes to
   the mutable object would compromise security or other
   important properties, you will need to do something different.
  Storing a copy of the object is better approach in many situations.</p>

    
<h2>
<a name="EQ_COMPARETO_USE_OBJECT_EQUALS">EQ_COMPARETO_USE_OBJECT_EQUALS: Class defines compareTo(...) and uses Object.equals()</a>
</h2>

  <p> This class defines a <code>compareTo(...)</code> method but inherits its
  <code>equals()</code> method from <code>java.lang.Object</code>.
    Generally, the value of compareTo should return zero if and only if
    equals returns true. If this is violated, weird and unpredictable
    failures will occur in classes such as PriorityQueue.
    In Java 5 the PriorityQueue.remove method uses the compareTo method,
    while in Java 6 it uses the equals method.</p>

<p>From the JavaDoc for the compareTo method in the Comparable interface:
<blockquote>
It is strongly recommended, but not strictly required that <code>(x.compareTo(y)==0) == (x.equals(y))</code>.
Generally speaking, any class that implements the Comparable interface and violates this condition
should clearly indicate this fact. The recommended language
is "Note: this class has a natural ordering that is inconsistent with equals."
</blockquote></p>

    
<h2>
<a name="IS2_INCONSISTENT_SYNC">IS2_INCONSISTENT_SYNC: Inconsistent synchronization</a>
</h2>

  <p> The fields of this class appear to be accessed inconsistently with respect
  to synchronization.&nbsp; This bug report indicates that the bug pattern detector
  judged that
  </p>
  <ul>
  <li> The class contains a mix of locked and unlocked accesses,</li>
  <li> The class is <b>not</b> annotated as javax.annotation.concurrent.NotThreadSafe,</li>
  <li> At least one locked access was performed by one of the class's own methods, and</li>
  <li> The number of unsynchronized field accesses (reads and writes) was no more than
       one third of all accesses, with writes being weighed twice as high as reads</li>
  </ul>

  <p> A typical bug matching this bug pattern is forgetting to synchronize
  one of the methods in a class that is intended to be thread-safe.</p>

  <p> You can select the nodes labeled "Unsynchronized access" to show the
  code locations where the detector believed that a field was accessed
  without synchronization.</p>

  <p> Note that there are various sources of inaccuracy in this detector;
  for example, the detector cannot statically detect all situations in which
  a lock is held.&nbsp; Also, even when the detector is accurate in
  distinguishing locked vs. unlocked accesses, the code in question may still
  be correct.</p>


    
<h2>
<a name="LI_LAZY_INIT_UPDATE_STATIC">LI_LAZY_INIT_UPDATE_STATIC: Incorrect lazy initialization and update of static field</a>
</h2>

<p> This method contains an unsynchronized lazy initialization of a static field.
After the field is set, the object stored into that location is further updated or accessed.
The setting of the field is visible to other threads as soon as it is set. If the
futher accesses in the method that set the field serve to initialize the object, then
you have a <em>very serious</em> multithreading bug, unless something else prevents
any other thread from accessing the stored object until it is fully initialized.
</p>
<p>Even if you feel confident that the method is never called by multiple
threads, it might be better to not set the static field until the value
you are setting it to is fully populated/initialized.

    
<h2>
<a name="LI_LAZY_INIT_STATIC">LI_LAZY_INIT_STATIC: Incorrect lazy initialization of static field</a>
</h2>

<p> This method contains an unsynchronized lazy initialization of a non-volatile static field.
Because the compiler or processor may reorder instructions,
threads are not guaranteed to see a completely initialized object,
<em>if the method can be called by multiple threads</em>.
You can make the field volatile to correct the problem.
For more information, see the
<a href="http://www.cs.umd.edu/~pugh/java/memoryModel/">Java Memory Model web site</a>.
</p>

    
<h2>
<a name="MS_SHOULD_BE_FINAL">MS_SHOULD_BE_FINAL: Field isn't final but should be</a>
</h2>

   <p>
This static field public but not final, and
could be changed by malicious code or
        by accident from another package.
        The field could be made final to avoid
        this vulnerability.</p>

    
<h2>
<a name="MS_PKGPROTECT">MS_PKGPROTECT: Field should be package protected</a>
</h2>

  <p> A mutable static field could be changed by malicious code or
   by accident.
   The field could be made package protected to avoid
   this vulnerability.</p>

    
<h2>
<a name="NP_DEREFERENCE_OF_READLINE_VALUE">NP_DEREFERENCE_OF_READLINE_VALUE: Dereference of the result of readLine() without nullcheck</a>
</h2>

  <p> The result of invoking readLine() is dereferenced without checking to see if the result is null. If there are no more lines of text
to read, readLine() will return null and dereferencing that will generate a null pointer exception.
</p>

    
<h2>
<a name="NP_IMMEDIATE_DEREFERENCE_OF_READLINE">NP_IMMEDIATE_DEREFERENCE_OF_READLINE: Immediate dereference of the result of readLine()</a>
</h2>

  <p> The result of invoking readLine() is immediately dereferenced. If there are no more lines of text
to read, readLine() will return null and dereferencing that will generate a null pointer exception.
</p>

    
<h2>
<a name="NP_NULL_PARAM_DEREF">NP_NULL_PARAM_DEREF: Method call passes null for non-null parameter</a>
</h2>
      
      <p>
      This method call passes a null value for a non-null method parameter.
    Either the parameter is annotated as a parameter that should
    always be non-null, or analysis has shown that it will always be
    dereferenced.
      </p>
      
   
<h2>
<a name="NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE: Possible null pointer dereference due to return value of called method</a>
</h2>
      
<p> The return value from a method is dereferenced without a null check,
and the return value of that method is one that should generally be checked
for null.  This may lead to a <code>NullPointerException</code> when the code is executed.
</p>
      
   
<h2>
<a name="NP_NULL_ON_SOME_PATH_EXCEPTION">NP_NULL_ON_SOME_PATH_EXCEPTION: Possible null pointer dereference in method on exception path</a>
</h2>

<p> A reference value which is null on some exception control path is
dereferenced here.&nbsp; This may lead to a <code>NullPointerException</code>
when the code is executed.&nbsp;
Note that because FindBugs currently does not prune infeasible exception paths,
this may be a false warning.</p>

<p> Also note that FindBugs considers the default case of a switch statement to
be an exception path, since the default case is often infeasible.</p>

    
<h2>
<a name="NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH">NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH: Value is null and guaranteed to be dereferenced on exception path</a>
</h2>
          
              <p>
              There is a statement or branch on an exception path
                that if executed guarantees that
              a value is null at this point, and that
              value that is guaranteed to be dereferenced
              (except on forward paths involving runtime exceptions).
              </p>
          
      
<h2>
<a name="OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE: Method may fail to clean up stream or resource on checked exception</a>
</h2>
          
          <p>
          This method may fail to clean up (close, dispose of) a stream,
          database object, or other
          resource requiring an explicit cleanup operation.
          </p>

          <p>
          In general, if a method opens a stream or other resource,
          the method should use a try/finally block to ensure that
          the stream or resource is cleaned up before the method
          returns.
          </p>

          <p>
          This bug pattern is essentially the same as the
          OS_OPEN_STREAM and ODR_OPEN_DATABASE_RESOURCE
          bug patterns, but is based on a different
          (and hopefully better) static analysis technique.
          We are interested is getting feedback about the
          usefulness of this bug pattern.
          To send feedback, either:
          </p>
          <ul>
            <li>send email to findbugs@cs.umd.edu</li>
            <li>file a bug report: <a href="http://findbugs.sourceforge.net/reportingBugs.html">http://findbugs.sourceforge.net/reportingBugs.html</a></li>
          </ul>

          <p>
          In particular,
          the false-positive suppression heuristics for this
          bug pattern have not been extensively tuned, so
          reports about false positives are helpful to us.
          </p>

          <p>
          See Weimer and Necula, <i>Finding and Preventing Run-Time Error Handling Mistakes</i>, for
          a description of the analysis technique.
          </p>
          
      
<h2>
<a name="ODR_OPEN_DATABASE_RESOURCE">ODR_OPEN_DATABASE_RESOURCE: Method may fail to close database resource</a>
</h2>

<p> The method creates a database resource (such as a database connection
or row set), does not assign it to any
fields, pass it to other methods, or return it, and does not appear to close
the object on all paths out of the method.&nbsp; Failure to
close database resources on all paths out of a method may
result in poor performance, and could cause the application to
have problems communicating with the database.
</p>

    
<h2>
<a name="OS_OPEN_STREAM">OS_OPEN_STREAM: Method may fail to close stream</a>
</h2>

<p> The method creates an IO stream object, does not assign it to any
fields, pass it to other methods that might close it,
or return it, and does not appear to close
the stream on all paths out of the method.&nbsp; This may result in
a file descriptor leak.&nbsp; It is generally a good
idea to use a <code>finally</code> block to ensure that streams are
closed.</p>

    
<h2>
<a name="RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE: Redundant nullcheck of value known to be non-null</a>
</h2>

<p> This method contains a redundant check of a known non-null value against
the constant null.</p>

    
<h2>
<a name="REC_CATCH_EXCEPTION">REC_CATCH_EXCEPTION: Exception is caught when Exception is not thrown</a>
</h2>
  
  <p>
  This method uses a try-catch block that catches Exception objects, but Exception is not
  thrown within the try block, and RuntimeException is not explicitly caught.  It is a common bug pattern to
  say try { ... } catch (Exception e) { something } as a shorthand for catching a number of types of exception
  each of whose catch blocks is identical, but this construct also accidentally catches RuntimeException as well,
  masking potential bugs.
  </p>
  <p>A better approach is to either explicitly catch the specific exceptions that are thrown,
  or to explicitly catch RuntimeException exception, rethrow it, and then catch all non-Runtime Exceptions, as shown below:</p>
  <pre>
  try {
    ...
  } catch (RuntimeException e) {
    throw e;
  } catch (Exception e) {
    ... deal with all non-runtime exceptions ...
  }</pre>
  
     
<h2>
<a name="RR_NOT_CHECKED">RR_NOT_CHECKED: Method ignores results of InputStream.read()</a>
</h2>

  <p> This method ignores the return value of one of the variants of
  <code>java.io.InputStream.read()</code> which can return multiple bytes.&nbsp;
  If the return value is not checked, the caller will not be able to correctly
  handle the case where fewer bytes were read than the caller requested.&nbsp;
  This is a particularly insidious kind of bug, because in many programs,
  reads from input streams usually do read the full amount of data requested,
  causing the program to fail only sporadically.</p>

    
<h2>
<a name="SR_NOT_CHECKED">SR_NOT_CHECKED: Method ignores results of InputStream.skip()</a>
</h2>

  <p> This method ignores the return value of
  <code>java.io.InputStream.skip()</code> which can skip multiple bytes.&nbsp;
  If the return value is not checked, the caller will not be able to correctly
  handle the case where fewer bytes were skipped than the caller requested.&nbsp;
  This is a particularly insidious kind of bug, because in many programs,
  skips from input streams usually do skip the full amount of data requested,
  causing the program to fail only sporadically. With Buffered streams, however,
  skip() will only skip data in the buffer, and will routinely fail to skip the
  requested number of bytes.</p>

    
<h2>
<a name="RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">RV_RETURN_VALUE_IGNORED_BAD_PRACTICE: Method ignores exceptional return value</a>
</h2>

   <p> This method returns a value that is not checked. The return value should be checked
since it can indicate an unusual or unexpected function execution. For
example, the <code>File.delete()</code> method returns false
if the file could not be successfully deleted (rather than
throwing an Exception).
If you don't check the result, you won't notice if the method invocation
signals unexpected behavior by returning an atypical return value.
</p>

    
<h2>
<a name="RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT: Return value of method without side effect is ignored</a>
</h2>

<p>This code calls a method and ignores the return value. However our analysis shows that
the method (including its implementations in subclasses if any) does not produce any effect 
other than return value. Thus this call can be removed.
</p>
<p>We are trying to reduce the false positives as much as possible, but in some cases this warning might be wrong.
Common false-positive cases include:</p>
<p>- The method is designed to be overridden and produce a side effect in other projects which are out of the scope of the analysis.</p>
<p>- The method is called to trigger the class loading which may have a side effect.</p>
<p>- The method is called just to get some exception.</p>
<p>If you feel that our assumption is incorrect, you can use a @CheckReturnValue annotation
to instruct FindBugs that ignoring the return value of this method is acceptable.
</p>

    
<h2>
<a name="SC_START_IN_CTOR">SC_START_IN_CTOR: Constructor invokes Thread.start()</a>
</h2>

  <p> The constructor starts a thread. This is likely to be wrong if
   the class is ever extended/subclassed, since the thread will be started
   before the subclass constructor is started.</p>

    
<h2>
<a name="SE_COMPARATOR_SHOULD_BE_SERIALIZABLE">SE_COMPARATOR_SHOULD_BE_SERIALIZABLE: Comparator doesn't implement Serializable</a>
</h2>

  <p> This class implements the <code>Comparator</code> interface. You
should consider whether or not it should also implement the <code>Serializable</code>
interface. If a comparator is used to construct an ordered collection
such as a <code>TreeMap</code>, then the <code>TreeMap</code>
will be serializable only if the comparator is also serializable.
As most comparators have little or no state, making them serializable
is generally easy and good defensive programming.
</p>

    
<h2>
<a name="SF_SWITCH_NO_DEFAULT">SF_SWITCH_NO_DEFAULT: Switch statement found where default case is missing</a>
</h2>

  <p> This method contains a switch statement where default case is missing.
  Usually you need to provide a default case.</p>
  <p>Because the analysis only looks at the generated bytecode, this warning can be incorrect triggered if
the default case is at the end of the switch statement and the switch statement doesn't contain break statements for other
cases.

    
<h2>
<a name="SS_SHOULD_BE_STATIC">SS_SHOULD_BE_STATIC: Unread field: should this field be static?</a>
</h2>

  <p> This class contains an instance final field that
   is initialized to a compile-time static value.
   Consider making the field static.</p>

    
<h2>
<a name="ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD: Write to static field from instance method</a>
</h2>

  <p> This instance method writes to a static field. This is tricky to get
correct if multiple instances are being manipulated,
and generally bad practice.
</p>

    
<h2>
<a name="STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE">STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE: Call to static DateFormat</a>
</h2>

<p>As the JavaDoc states, DateFormats are inherently unsafe for multithreaded use.
The detector has found a call to an instance of DateFormat that has been obtained via a static
field. This looks suspicous.</p>
<p>For more information on this see <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6231579">Sun Bug #6231579</a>
and <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6178997">Sun Bug #6178997</a>.</p>


<h2>
<a name="SWL_SLEEP_WITH_LOCK_HELD">SWL_SLEEP_WITH_LOCK_HELD: Method calls Thread.sleep() with a lock held</a>
</h2>
      
      <p>
      This method calls Thread.sleep() with a lock held.  This may result
      in very poor performance and scalability, or a deadlock, since other threads may
      be waiting to acquire the lock.  It is a much better idea to call
      wait() on the lock, which releases the lock and allows other threads
      to run.
      </p>
      
   
<h2>
<a name="URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD: Unread public/protected field</a>
</h2>

  <p> This field is never read.&nbsp;
The field is public or protected, so perhaps
    it is intended to be used with classes not seen as part of the analysis. If not,
consider removing it from the class.</p>

    
<h2>
<a name="DMI_INVOKING_TOSTRING_ON_ARRAY">DMI_INVOKING_TOSTRING_ON_ARRAY: Invocation of toString on an array</a>
</h2>

<p>
The code invokes toString on an array, which will generate a fairly useless result
such as [C@16f0472. Consider using Arrays.toString to convert the array into a readable
String that gives the contents of the array. See Programming Puzzlers, chapter 3, puzzle 12.
</p>

    
<h2>
<a name="UUF_UNUSED_PUBLIC_OR_PROTECTED_FIELD">UUF_UNUSED_PUBLIC_OR_PROTECTED_FIELD: Unused public or protected field</a>
</h2>

  <p> This field is never used.&nbsp;
The field is public or protected, so perhaps
    it is intended to be used with classes not seen as part of the analysis. If not,
consider removing it from the class.</p>

    
<h2>
<a name="WMI_WRONG_MAP_ITERATOR">WMI_WRONG_MAP_ITERATOR: Inefficient use of keySet iterator instead of entrySet iterator</a>
</h2>

<p> This method accesses the value of a Map entry, using a key that was retrieved from
a keySet iterator. It is more efficient to use an iterator on the entrySet of the map, to avoid the
Map.get(key) lookup.</p>

        </body>
</html>
