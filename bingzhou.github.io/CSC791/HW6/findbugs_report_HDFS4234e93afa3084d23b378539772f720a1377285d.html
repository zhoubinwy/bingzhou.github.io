<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>FindBugs Report</title>
<style type="text/css">
		.tablerow0 {
			background: #EEEEEE;
		}

		.tablerow1 {
			background: white;
		}

		.detailrow0 {
			background: #EEEEEE;
		}

		.detailrow1 {
			background: white;
		}

		.tableheader {
			background: #b9b9fe;
			font-size: larger;
		}

		.tablerow0:hover, .tablerow1:hover {
			background: #aaffaa;
		}

		.priority-1 {
		    color: red;
		    font-weight: bold;
		}
		.priority-2 {
		    color: orange;
		    font-weight: bold;
		}
		.priority-3 {
		    color: green;
		    font-weight: bold;
		}
		.priority-4 {
		    color: blue;
		    font-weight: bold;
		}
		</style>
<script type="text/javascript">
			function toggleRow(elid) {
				if (document.getElementById) {
					element = document.getElementById(elid);
					if (element) {
						if (element.style.display == 'none') {
							element.style.display = 'block';
							//window.status = 'Toggle on!';
						} else {
							element.style.display = 'none';
							//window.status = 'Toggle off!';
						}
					}
				}
			}
		</script>
</head>
<body>
<h1>
<a href="http://findbugs.sourceforge.net">FindBugs</a> Report</h1>
<h2>Project Information</h2>
<p>Project: 
		</p>
<p>FindBugs version: 3.0.1-dev-20160919-0987399</p>
<p>Code analyzed:</p>
<ul>
<li>/home/ting/all-200-bugs/BuiltApplications_Java/HDFS-6411/ClassFiles</li>
</ul>
<p>
<br/>
<br/>
</p>
<h2>Metrics</h2>
<p>386465 lines of code analyzed,
	in 4927 classes, 
	in 365 packages.</p>
<table width="500" cellpadding="5" cellspacing="2">
<tr class="tableheader">
<th align="left">Metric</th>
<th align="right">Total</th>
<th align="right">Density*</th>
</tr>
<tr class="tablerow0">
<td>High Priority Warnings</td>
<td align="right">1025</td>
<td align="right">2.65</td>
</tr>
<tr class="tablerow1">
<td>Medium Priority Warnings</td>
<td align="right">1943</td>
<td align="right">5.03</td>
</tr>
<tr class="$totalClass">
<td>
<b>Total Warnings</b>
</td>
<td align="right">
<b>2968</b>
</td>
<td align="right">
<b>7.68</b>
</td>
</tr>
</table>
<p>
<i>(* Defects per Thousand lines of non-commenting source statements)</i>
</p>
<p>
<br/>
<br/>
</p>
<h2>Contents</h2>
<ul>
<li>
<a href="#Warnings_BAD_PRACTICE">Bad practice Warnings</a>
</li>
<li>
<a href="#Warnings_CORRECTNESS">Correctness Warnings</a>
</li>
<li>
<a href="#Warnings_EXPERIMENTAL">Experimental Warnings</a>
</li>
<li>
<a href="#Warnings_I18N">Internationalization Warnings</a>
</li>
<li>
<a href="#Warnings_MALICIOUS_CODE">Malicious code vulnerability Warnings</a>
</li>
<li>
<a href="#Warnings_MT_CORRECTNESS">Multithreaded correctness Warnings</a>
</li>
<li>
<a href="#Warnings_PERFORMANCE">Performance Warnings</a>
</li>
<li>
<a href="#Warnings_SECURITY">Security Warnings</a>
</li>
<li>
<a href="#Warnings_STYLE">Dodgy code Warnings</a>
</li>
<li>
<a href="#Details">Details</a>
</li>
</ul>
<h1>Summary</h1>
<table width="500" cellpadding="5" cellspacing="2">
<tr class="tableheader">
<th align="left">Warning Type</th>
<th align="right">Number</th>
</tr>
<tr class="tablerow0">
<td>
<a href="#Warnings_BAD_PRACTICE">Bad practice Warnings</a>
</td>
<td align="right">539</td>
</tr>
<tr class="tablerow1">
<td>
<a href="#Warnings_CORRECTNESS">Correctness Warnings</a>
</td>
<td align="right">100</td>
</tr>
<tr class="tablerow0">
<td>
<a href="#Warnings_EXPERIMENTAL">Experimental Warnings</a>
</td>
<td align="right">90</td>
</tr>
<tr class="tablerow1">
<td>
<a href="#Warnings_I18N">Internationalization Warnings</a>
</td>
<td align="right">774</td>
</tr>
<tr class="tablerow0">
<td>
<a href="#Warnings_MALICIOUS_CODE">Malicious code vulnerability Warnings</a>
</td>
<td align="right">298</td>
</tr>
<tr class="tablerow1">
<td>
<a href="#Warnings_MT_CORRECTNESS">Multithreaded correctness Warnings</a>
</td>
<td align="right">112</td>
</tr>
<tr class="tablerow0">
<td>
<a href="#Warnings_PERFORMANCE">Performance Warnings</a>
</td>
<td align="right">311</td>
</tr>
<tr class="tablerow1">
<td>
<a href="#Warnings_SECURITY">Security Warnings</a>
</td>
<td align="right">1</td>
</tr>
<tr class="tablerow0">
<td>
<a href="#Warnings_STYLE">Dodgy code Warnings</a>
</td>
<td align="right">741</td>
</tr>
<tr class="tablerow1">
<td>
<b>Total</b>
</td>
<td align="right">
<b>2966</b>
</td>
</tr>
</table>
<h1>Warnings</h1>
<p>Click on a warning row to see full context information.</p>
<h2>
<a name="Warnings_BAD_PRACTICE">Bad practice Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N148461');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Equals method for org.apache.hadoop.io.RandomDatum assumes the argument is of type RandomDatum</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N148461" style="display: none;">
<a href="#BC_EQUALS_METHOD_SHOULD_WORK_FOR_ALL_OBJECTS">Bug type BC_EQUALS_METHOD_SHOULD_WORK_FOR_ALL_OBJECTS (click for details)</a>
<br/>In class org.apache.hadoop.io.RandomDatum<br/>In method org.apache.hadoop.io.RandomDatum.equals(Object)<br/>At RandomDatum.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N66151');">
<td>
<span class="priority-1">CNT</span>
</td>
<td>Rough value of Math.PI found: 3.1415</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N66151" style="display: none;">
<a href="#CNT_ROUGH_CONSTANT_VALUE">Bug type CNT_ROUGH_CONSTANT_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testDoubleValues()<br/>Value 3.1415<br/>Value Math.PI<br/>At TestConfiguration.java:[line 643]<br/>Another occurrence at TestConfiguration.java:[line 644]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66223');">
<td>
<span class="priority-1">CNT</span>
</td>
<td>Rough value of Math.PI found: 3.1415</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66223" style="display: none;">
<a href="#CNT_ROUGH_CONSTANT_VALUE">Bug type CNT_ROUGH_CONSTANT_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testFloatValues()<br/>Value 3.1415<br/>Value Math.PI<br/>At TestConfiguration.java:[line 620]<br/>Another occurrence at TestConfiguration.java:[line 621]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N148052');">
<td>
<span class="priority-2">Co</span>
</td>
<td>org.apache.hadoop.io.DoubleWritable.compareTo(DoubleWritable) incorrectly handles double value</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N148052" style="display: none;">
<a href="#CO_COMPARETO_INCORRECT_FLOATING">Bug type CO_COMPARETO_INCORRECT_FLOATING (click for details)</a>
<br/>In class org.apache.hadoop.io.DoubleWritable<br/>In method org.apache.hadoop.io.DoubleWritable.compareTo(DoubleWritable)<br/>Type double<br/>Should call Double.compare(double, double) instead<br/>Value loaded from field org.apache.hadoop.io.DoubleWritable.value<br/>Value loaded from field org.apache.hadoop.io.DoubleWritable.value<br/>At DoubleWritable.java:[line 78]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N148231');">
<td>
<span class="priority-2">Co</span>
</td>
<td>org.apache.hadoop.io.FloatWritable.compareTo(FloatWritable) incorrectly handles float value</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N148231" style="display: none;">
<a href="#CO_COMPARETO_INCORRECT_FLOATING">Bug type CO_COMPARETO_INCORRECT_FLOATING (click for details)</a>
<br/>In class org.apache.hadoop.io.FloatWritable<br/>In method org.apache.hadoop.io.FloatWritable.compareTo(FloatWritable)<br/>Type float<br/>Should call Float.compare(float, float) instead<br/>Local variable named thatValue<br/>Local variable named thisValue<br/>At FloatWritable.java:[line 71]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N88467');">
<td>
<span class="priority-1">DE</span>
</td>
<td>org.apache.hadoop.fs.s3native.TestJets3tNativeFileSystemStore.tearDown() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N88467" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.fs.s3native.TestJets3tNativeFileSystemStore<br/>In method org.apache.hadoop.fs.s3native.TestJets3tNativeFileSystemStore.tearDown()<br/>Exception class java.lang.Exception<br/>At TestJets3tNativeFileSystemStore.java:[line 63]<br/>At TestJets3tNativeFileSystemStore.java:[line 63]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78286');">
<td>
<span class="priority-2">DE</span>
</td>
<td>org.apache.hadoop.fs.TestFileSystem.testCommandFormat() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78286" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileSystem<br/>In method org.apache.hadoop.fs.TestFileSystem.testCommandFormat()<br/>Exception class java.lang.Exception<br/>At TestFileSystem.java:[line 101]<br/>At TestFileSystem.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N140039');">
<td>
<span class="priority-1">DE</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotMetrics.testSnapshots() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N140039" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotMetrics<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotMetrics.testSnapshots()<br/>Exception class java.lang.Exception<br/>At TestSnapshotMetrics.java:[line 144]<br/>At TestSnapshotMetrics.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N126380');">
<td>
<span class="priority-2">DE</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestBackupNode.waitCheckpointDone(MiniDFSCluster, long) might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N126380" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestBackupNode<br/>In method org.apache.hadoop.hdfs.server.namenode.TestBackupNode.waitCheckpointDone(MiniDFSCluster, long)<br/>Exception class java.lang.Exception<br/>At TestBackupNode.java:[line 118]<br/>At TestBackupNode.java:[line 118]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N130737');">
<td>
<span class="priority-1">DE</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckMove() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N130737" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckMove()<br/>Exception class java.lang.Exception<br/>At TestFsck.java:[line 384]<br/>At TestFsck.java:[line 384]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N130815');">
<td>
<span class="priority-1">DE</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckMoveAndDelete() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N130815" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckMoveAndDelete()<br/>Exception class java.lang.Exception<br/>At TestFsck.java:[line 552]<br/>At TestFsck.java:[line 552]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N130893');">
<td>
<span class="priority-1">DE</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckSymlink() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N130893" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckSymlink()<br/>Exception class java.lang.Exception<br/>At TestFsck.java:[line 1057]<br/>At TestFsck.java:[line 1057]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N130971');">
<td>
<span class="priority-2">DE</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N130971" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck()<br/>Exception class java.lang.Exception<br/>At TestFsck.java:[line 157]<br/>At TestFsck.java:[line 157]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N131049');">
<td>
<span class="priority-2">DE</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckNonExistent() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N131049" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckNonExistent()<br/>Exception class java.lang.Exception<br/>At TestFsck.java:[line 241]<br/>At TestFsck.java:[line 241]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N131127');">
<td>
<span class="priority-2">DE</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckOpenFiles() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N131127" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckOpenFiles()<br/>Exception class java.lang.Exception<br/>At TestFsck.java:[line 601]<br/>At TestFsck.java:[line 601]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100668');">
<td>
<span class="priority-1">DE</span>
</td>
<td>org.apache.hadoop.hdfs.TestDFSShell.testPut() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100668" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testPut()<br/>Exception class java.lang.Exception<br/>At TestDFSShell.java:[line 322]<br/>At TestDFSShell.java:[line 322]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N100746');">
<td>
<span class="priority-1">DE</span>
</td>
<td>org.apache.hadoop.hdfs.TestDFSShell.testZeroSizeFile() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N100746" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testZeroSizeFile()<br/>Exception class java.lang.Exception<br/>At TestDFSShell.java:[line 152]<br/>At TestDFSShell.java:[line 152]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N109772');">
<td>
<span class="priority-1">DE</span>
</td>
<td>org.apache.hadoop.hdfs.TestSetrepIncreasing.setrep(int, int, boolean) might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N109772" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestSetrepIncreasing<br/>In method org.apache.hadoop.hdfs.TestSetrepIncreasing.setrep(int, int, boolean)<br/>Exception class java.lang.Exception<br/>At TestSetrepIncreasing.java:[line 73]<br/>At TestSetrepIncreasing.java:[line 73]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N156195');">
<td>
<span class="priority-2">DE</span>
</td>
<td>org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureBadCompressionCodec() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N156195" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureBadCompressionCodec()<br/>Exception class java.lang.Exception<br/>At TestTFileByteArrays.java:[line 371]<br/>At TestTFileByteArrays.java:[line 371]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N156273');">
<td>
<span class="priority-2">DE</span>
</td>
<td>org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureFileWriteNotAt0Position() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N156273" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureFileWriteNotAt0Position()<br/>Exception class java.lang.Exception<br/>At TestTFileByteArrays.java:[line 568]<br/>At TestTFileByteArrays.java:[line 568]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N156351');">
<td>
<span class="priority-2">DE</span>
</td>
<td>org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOutOfOrderKeys() might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N156351" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOutOfOrderKeys()<br/>Exception class java.lang.Exception<br/>At TestTFileByteArrays.java:[line 441]<br/>At TestTFileByteArrays.java:[line 441]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N213041');">
<td>
<span class="priority-2">DE</span>
</td>
<td>org.apache.hadoop.net.TestNetUtils.verifyGetByName(String, String[]) might ignore java.net.UnknownHostException</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N213041" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.net.TestNetUtils<br/>In method org.apache.hadoop.net.TestNetUtils.verifyGetByName(String, String[])<br/>Exception class java.net.UnknownHostException<br/>At TestNetUtils.java:[line 435]<br/>At TestNetUtils.java:[line 435]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N213119');">
<td>
<span class="priority-2">DE</span>
</td>
<td>org.apache.hadoop.net.TestNetUtils.verifyResolve(String, String[]) might ignore java.net.UnknownHostException</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N213119" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.net.TestNetUtils<br/>In method org.apache.hadoop.net.TestNetUtils.verifyResolve(String, String[])<br/>Exception class java.net.UnknownHostException<br/>At TestNetUtils.java:[line 469]<br/>At TestNetUtils.java:[line 469]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N223168');">
<td>
<span class="priority-1">DE</span>
</td>
<td>org.apache.hadoop.streaming.TestStreamingStatus.deleteOutDir(FileSystem) might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N223168" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamingStatus<br/>In method org.apache.hadoop.streaming.TestStreamingStatus.deleteOutDir(FileSystem)<br/>Exception class java.lang.Exception<br/>At TestStreamingStatus.java:[line 180]<br/>At TestStreamingStatus.java:[line 180]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N251804');">
<td>
<span class="priority-2">DE</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.localizeFiles(LocalizationProtocol, CompletionService, UserGroupInformation) might ignore org.apache.hadoop.yarn.exceptions.YarnException</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N251804" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.localizeFiles(LocalizationProtocol, CompletionService, UserGroupInformation)<br/>Exception class org.apache.hadoop.yarn.exceptions.YarnException<br/>At ContainerLocalizer.java:[line 256]<br/>At ContainerLocalizer.java:[line 256]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N253007');">
<td>
<span class="priority-2">DE</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.eventToString(Event, String[]) might ignore java.lang.Exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N253007" style="display: none;">
<a href="#DE_MIGHT_IGNORE">Bug type DE_MIGHT_IGNORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.eventToString(Event, String[])<br/>Exception class java.lang.Exception<br/>At TestLogAggregationService.java:[line 983]<br/>At TestLogAggregationService.java:[line 983]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N65548');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.FailingMapper.map(Text, Text, Mapper$Context) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N65548" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.FailingMapper<br/>In method org.apache.hadoop.FailingMapper.map(Text, Text, Mapper$Context)<br/>At FailingMapper.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N86934');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.fs.loadGenerator.DataGenerator.init(String[]) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N86934" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.DataGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.DataGenerator.init(String[])<br/>At DataGenerator.java:[line 100]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N125481');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.MetaRecoveryContext.quit() invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N125481" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.MetaRecoveryContext<br/>In method org.apache.hadoop.hdfs.server.namenode.MetaRecoveryContext.quit()<br/>At MetaRecoveryContext.java:[line 120]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N110359');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.hdfs.TestWriteRead.usage() invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N110359" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestWriteRead<br/>In method org.apache.hadoop.hdfs.TestWriteRead.usage()<br/>At TestWriteRead.java:[line 438]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N168371');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.MRBench.run(String[]) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N168371" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRBench<br/>In method org.apache.hadoop.mapred.MRBench.run(String[])<br/>At MRBench.java:[line 267]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N169128');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.ReliabilityTest.displayUsage() invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N169128" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.ReliabilityTest<br/>In method org.apache.hadoop.mapred.ReliabilityTest.displayUsage()<br/>At ReliabilityTest.java:[line 89]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N169182');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.ReliabilityTest.runTest(JobClient, Configuration, String, String[], ReliabilityTest$KillTaskThread, ReliabilityTest$KillTrackerThread) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N169182" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.ReliabilityTest<br/>In method org.apache.hadoop.mapred.ReliabilityTest.runTest(JobClient, Configuration, String, String[], ReliabilityTest$KillTaskThread, ReliabilityTest$KillTrackerThread)<br/>At ReliabilityTest.java:[line 228]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N169236');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.Task.commit(TaskUmbilicalProtocol, Task$TaskReporter, OutputCommitter) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N169236" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.Task<br/>In method org.apache.hadoop.mapred.Task.commit(TaskUmbilicalProtocol, Task$TaskReporter, OutputCommitter)<br/>At Task.java:[line 1149]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N169290');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.Task.done(TaskUmbilicalProtocol, Task$TaskReporter) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N169290" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.Task<br/>In method org.apache.hadoop.mapred.Task.done(TaskUmbilicalProtocol, Task$TaskReporter)<br/>At Task.java:[line 1014]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N169344');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.Task.reportFatalError(TaskAttemptID, Throwable, String) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N169344" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.Task<br/>In method org.apache.hadoop.mapred.Task.reportFatalError(TaskAttemptID, Throwable, String)<br/>At Task.java:[line 332]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N169398');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.Task.statusUpdate(TaskUmbilicalProtocol) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N169398" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.Task<br/>In method org.apache.hadoop.mapred.Task.statusUpdate(TaskUmbilicalProtocol)<br/>At Task.java:[line 1059]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N215361');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.record.compiler.generated.Rcc.Include() invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N215361" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.Rcc<br/>In method org.apache.hadoop.record.compiler.generated.Rcc.Include()<br/>At Rcc.java:[line 170]<br/>Another occurrence at Rcc.java:[line 179]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N215426');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.record.compiler.generated.Rcc.Type() invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N215426" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.Rcc<br/>In method org.apache.hadoop.record.compiler.generated.Rcc.Type()<br/>At Rcc.java:[line 346]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N224332');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.test.CoreTestDriver.run(String[]) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N224332" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.test.CoreTestDriver<br/>In method org.apache.hadoop.test.CoreTestDriver.run(String[])<br/>At CoreTestDriver.java:[line 60]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N224726');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.test.HdfsTestDriver.run(String[]) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N224726" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.test.HdfsTestDriver<br/>In method org.apache.hadoop.test.HdfsTestDriver.run(String[])<br/>At HdfsTestDriver.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N224780');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.test.MapredTestDriver.run(String[]) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N224780" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.test.MapredTestDriver<br/>In method org.apache.hadoop.test.MapredTestDriver.run(String[])<br/>At MapredTestDriver.java:[line 122]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N230581');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.util.ProgramDriver.driver(String[]) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N230581" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.util.ProgramDriver<br/>In method org.apache.hadoop.util.ProgramDriver.driver(String[])<br/>At ProgramDriver.java:[line 154]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N237160');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.yarn.applications.distributedshell.TestDSFailedAppMaster.run() invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N237160" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.distributedshell.TestDSFailedAppMaster<br/>In method org.apache.hadoop.yarn.applications.distributedshell.TestDSFailedAppMaster.run()<br/>At TestDSFailedAppMaster.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N243339');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(Event) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N243339" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.event.AsyncDispatcher<br/>In method org.apache.hadoop.yarn.event.AsyncDispatcher.dispatch(Event)<br/>At AsyncDispatcher.java:[line 185]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N246706');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(Configuration, boolean) invokes System.exit(...), which shuts down the entire virtual machine</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N246706" style="display: none;">
<a href="#DM_EXIT">Bug type DM_EXIT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.NodeManager<br/>In method org.apache.hadoop.yarn.server.nodemanager.NodeManager.initAndStartNodeManager(Configuration, boolean)<br/>At NodeManager.java:[line 361]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78434');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.fs.TestFileSystem.main(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78434" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileSystem<br/>In method org.apache.hadoop.fs.TestFileSystem.main(String[])<br/>Called method java.util.Random.nextLong()<br/>At TestFileSystem.java:[line 448]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N78504');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.fs.TestFileSystem.testFs(long, int, long)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N78504" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileSystem<br/>In method org.apache.hadoop.fs.TestFileSystem.testFs(long, int, long)<br/>Called method java.util.Random.nextLong()<br/>At TestFileSystem.java:[line 78]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83513');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.fs.TestLocalFileSystem.testBufferedFSInputStream()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83513" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestLocalFileSystem<br/>In method org.apache.hadoop.fs.TestLocalFileSystem.testBufferedFSInputStream()<br/>Called method java.util.Random.nextBytes(byte[])<br/>At TestLocalFileSystem.java:[line 408]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N94679');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.hdfs.BlockReaderTestUtil.writeFile(Path, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N94679" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.BlockReaderTestUtil<br/>In method org.apache.hadoop.hdfs.BlockReaderTestUtil.writeFile(Path, int)<br/>Called method java.util.Random.nextBytes(byte[])<br/>At BlockReaderTestUtil.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N113716');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.hdfs.qjournal.client.TestQJMWithFaults.testRandomized()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N113716" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.qjournal.client.TestQJMWithFaults<br/>In method org.apache.hadoop.hdfs.qjournal.client.TestQJMWithFaults.testRandomized()<br/>Called method java.util.Random.nextLong()<br/>At TestQJMWithFaults.java:[line 214]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N121734');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart.testRbwReplicas(MiniDFSCluster, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N121734" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart<br/>In method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart.testRbwReplicas(MiniDFSCluster, boolean)<br/>Called method java.util.Random.nextBytes(byte[])<br/>At TestDatanodeRestart.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N120578');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.hdfs.server.datanode.TestHSync.testSequenceFileSync()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N120578" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestHSync<br/>In method org.apache.hadoop.hdfs.server.datanode.TestHSync.testSequenceFileSync()<br/>Called method java.util.Random.nextInt()<br/>At TestHSync.java:[line 153]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N138469');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.testRenameAndAppend()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N138469" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.testRenameAndAppend()<br/>Called method java.util.Random.nextBytes(byte[])<br/>At TestRenameWithSnapshots.java:[line 1242]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99643');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.hdfs.TestDFSClientRetries.namenodeRestartTest(Configuration, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99643" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSClientRetries<br/>In method org.apache.hadoop.hdfs.TestDFSClientRetries.namenodeRestartTest(Configuration, boolean)<br/>Called method java.util.Random.nextBytes(byte[])<br/>At TestDFSClientRetries.java:[line 857]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N146116');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract.testSeek()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N146116" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract<br/>In method org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract.testSeek()<br/>Called method java.util.Random.nextBytes(byte[])<br/>At TestWebHdfsFileSystemContract.java:[line 209]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N151795');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in new org.apache.hadoop.io.compress.TestCodec()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N151795" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.TestCodec<br/>In method new org.apache.hadoop.io.compress.TestCodec()<br/>Called method java.util.Random.nextInt()<br/>At TestCodec.java:[line 82]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N150446');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.io.TestSequenceFile.compressedSeqFileTest(CompressionCodec)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N150446" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.io.TestSequenceFile<br/>In method org.apache.hadoop.io.TestSequenceFile.compressedSeqFileTest(CompressionCodec)<br/>Called method java.util.Random.nextInt()<br/>At TestSequenceFile.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N150516');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.io.TestSequenceFile.main(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N150516" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.io.TestSequenceFile<br/>In method org.apache.hadoop.io.TestSequenceFile.main(String[])<br/>Called method java.util.Random.nextInt()<br/>At TestSequenceFile.java:[line 631]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N150586');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.io.TestSequenceFile.testSequenceFileMetadata()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N150586" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.io.TestSequenceFile<br/>In method org.apache.hadoop.io.TestSequenceFile.testSequenceFileMetadata()<br/>Called method java.util.Random.nextInt()<br/>At TestSequenceFile.java:[line 331]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N183910');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.lib.TestLineInputFormat.testFormat()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N183910" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestLineInputFormat<br/>In method org.apache.hadoop.mapred.lib.TestLineInputFormat.testFormat()<br/>Called method java.util.Random.nextInt()<br/>At TestLineInputFormat.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N168162');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.MRBench.generateTextFile(FileSystem, Path, long, MRBench$Order)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N168162" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRBench<br/>In method org.apache.hadoop.mapred.MRBench.generateTextFile(FileSystem, Path, long, MRBench$Order)<br/>Called method java.util.Random.nextLong()<br/>At MRBench.java:[line 104]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N168232');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.MRBench.run(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N168232" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRBench<br/>In method org.apache.hadoop.mapred.MRBench.run(String[])<br/>Called method java.util.Random.nextInt()<br/>At MRBench.java:[line 283]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N171361');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.TestFixedLengthInputFormat.runRandomTests(CompressionCodec)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N171361" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFixedLengthInputFormat<br/>In method org.apache.hadoop.mapred.TestFixedLengthInputFormat.runRandomTests(CompressionCodec)<br/>Called method java.util.Random.nextInt()<br/>At TestFixedLengthInputFormat.java:[line 261]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N173094');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.TestKeyValueTextInputFormat.testFormat()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N173094" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapred.TestKeyValueTextInputFormat.testFormat()<br/>Called method java.util.Random.nextInt()<br/>At TestKeyValueTextInputFormat.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N176325');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.TestSequenceFileAsTextInputFormat.testFormat()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N176325" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestSequenceFileAsTextInputFormat<br/>In method org.apache.hadoop.mapred.TestSequenceFileAsTextInputFormat.testFormat()<br/>Called method java.util.Random.nextInt()<br/>At TestSequenceFileAsTextInputFormat.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N176395');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.TestSequenceFileInputFormat.testFormat()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N176395" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestSequenceFileInputFormat<br/>In method org.apache.hadoop.mapred.TestSequenceFileInputFormat.testFormat()<br/>Called method java.util.Random.nextInt()<br/>At TestSequenceFileInputFormat.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N177450');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.TestTextInputFormat.testFormat()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N177450" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextInputFormat<br/>In method org.apache.hadoop.mapred.TestTextInputFormat.testFormat()<br/>Called method java.util.Random.nextInt()<br/>At TestTextInputFormat.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N177520');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapred.TestTextInputFormat.testSplitableCodecs()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N177520" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextInputFormat<br/>In method org.apache.hadoop.mapred.TestTextInputFormat.testSplitableCodecs()<br/>Called method java.util.Random.nextInt()<br/>At TestTextInputFormat.java:[line 152]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N192110');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testFormat()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N192110" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testFormat()<br/>Called method java.util.Random.nextInt()<br/>At TestMRKeyValueTextInputFormat.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N192180');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testSplitableCodecs()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N192180" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testSplitableCodecs()<br/>Called method java.util.Random.nextInt()<br/>At TestMRKeyValueTextInputFormat.java:[line 173]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N192603');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsTextInputFormat.testFormat()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N192603" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsTextInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsTextInputFormat.testFormat()<br/>Called method java.util.Random.nextInt()<br/>At TestMRSequenceFileAsTextInputFormat.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N213608');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in new org.apache.hadoop.net.unix.TemporarySocketDirectory()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N213608" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.net.unix.TemporarySocketDirectory<br/>In method new org.apache.hadoop.net.unix.TemporarySocketDirectory()<br/>Called method java.util.Random.nextInt()<br/>At TemporarySocketDirectory.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N226825');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.tools.TestCopyFiles.createFile(Path, FileSystem, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N226825" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestCopyFiles<br/>In method org.apache.hadoop.tools.TestCopyFiles.createFile(Path, FileSystem, int)<br/>Called method java.util.Random.nextBytes(byte[])<br/>At TestCopyFiles.java:[line 146]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N231036');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.util.TestDataChecksum.doBulkTest(DataChecksum, int, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N231036" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestDataChecksum<br/>In method org.apache.hadoop.util.TestDataChecksum.doBulkTest(DataChecksum, int, boolean)<br/>Called method java.util.Random.nextBytes(byte[])<br/>At TestDataChecksum.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N234046');">
<td>
<span class="priority-1">DMI</span>
</td>
<td>Random object created and used only once in org.apache.hadoop.util.TestPureJavaCrc32.testCorrectness()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N234046" style="display: none;">
<a href="#DMI_RANDOM_USED_ONLY_ONCE">Bug type DMI_RANDOM_USED_ONLY_ONCE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestPureJavaCrc32<br/>In method org.apache.hadoop.util.TestPureJavaCrc32.testCorrectness()<br/>Called method java.util.Random.nextBytes(byte[])<br/>At TestPureJavaCrc32.java:[line 54]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N183264');">
<td>
<span class="priority-2">Eq</span>
</td>
<td>org.apache.hadoop.mapred.join.IncomparableKey defines compareTo(Object) and uses Object.equals()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N183264" style="display: none;">
<a href="#EQ_COMPARETO_USE_OBJECT_EQUALS">Bug type EQ_COMPARETO_USE_OBJECT_EQUALS (click for details)</a>
<br/>In class org.apache.hadoop.mapred.join.IncomparableKey<br/>In method org.apache.hadoop.mapred.join.IncomparableKey.compareTo(Object)<br/>At IncomparableKey.java:[line 29]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N216655');">
<td>
<span class="priority-2">Eq</span>
</td>
<td>org.apache.hadoop.record.meta.RecordTypeInfo defines compareTo(Object) and uses Object.equals()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N216655" style="display: none;">
<a href="#EQ_COMPARETO_USE_OBJECT_EQUALS">Bug type EQ_COMPARETO_USE_OBJECT_EQUALS (click for details)</a>
<br/>In class org.apache.hadoop.record.meta.RecordTypeInfo<br/>In method org.apache.hadoop.record.meta.RecordTypeInfo.compareTo(Object)<br/>At RecordTypeInfo.java:[lines 155-158]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N252153');">
<td>
<span class="priority-1">Eq</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.MockLocalizerStatus.equals(Object) checks for operand being a String </td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N252153" style="display: none;">
<a href="#EQ_CHECK_FOR_OPERAND_NOT_COMPATIBLE_WITH_THIS">Bug type EQ_CHECK_FOR_OPERAND_NOT_COMPATIBLE_WITH_THIS (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.MockLocalizerStatus<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.MockLocalizerStatus.equals(Object)<br/>Actual type String<br/>At MockLocalizerStatus.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N271989');">
<td>
<span class="priority-2">Eq</span>
</td>
<td>org.apache.hadoop.yarn.sls.scheduler.ContainerSimulator defines compareTo(Object) and uses Object.equals()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N271989" style="display: none;">
<a href="#EQ_COMPARETO_USE_OBJECT_EQUALS">Bug type EQ_COMPARETO_USE_OBJECT_EQUALS (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.scheduler.ContainerSimulator<br/>In method org.apache.hadoop.yarn.sls.scheduler.ContainerSimulator.compareTo(Object)<br/>At ContainerSimulator.java:[line 27]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N276832');">
<td>
<span class="priority-2">Eq</span>
</td>
<td>testjar.ExternalWritable defines compareTo(Object) and uses Object.equals()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N276832" style="display: none;">
<a href="#EQ_COMPARETO_USE_OBJECT_EQUALS">Bug type EQ_COMPARETO_USE_OBJECT_EQUALS (click for details)</a>
<br/>In class testjar.ExternalWritable<br/>In method testjar.ExternalWritable.compareTo(Object)<br/>At ExternalWritable.java:[lines 75-80]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73790');">
<td>
<span class="priority-2">ES</span>
</td>
<td>Comparison of String objects using == or != in org.apache.hadoop.fs.FileSystem.checkPath(Path) </td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73790" style="display: none;">
<a href="#ES_COMPARING_STRINGS_WITH_EQ">Bug type ES_COMPARING_STRINGS_WITH_EQ (click for details)</a>
<br/>In class org.apache.hadoop.fs.FileSystem<br/>In method org.apache.hadoop.fs.FileSystem.checkPath(Path)<br/>Actual type String<br/>Value loaded from thatAuthority<br/>Value loaded from thisAuthority<br/>At FileSystem.java:[line 637]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75021');">
<td>
<span class="priority-2">ES</span>
</td>
<td>Comparison of String objects using == or != in org.apache.hadoop.fs.MD5MD5CRC32FileChecksum.valueOf(Attributes) </td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75021" style="display: none;">
<a href="#ES_COMPARING_STRINGS_WITH_EQ">Bug type ES_COMPARING_STRINGS_WITH_EQ (click for details)</a>
<br/>In class org.apache.hadoop.fs.MD5MD5CRC32FileChecksum<br/>In method org.apache.hadoop.fs.MD5MD5CRC32FileChecksum.valueOf(Attributes)<br/>Actual type String<br/>String constant ""<br/>Value loaded from crcType<br/>At MD5MD5CRC32FileChecksum.java:[line 137]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N239993');">
<td>
<span class="priority-2">ES</span>
</td>
<td>Comparison of String objects using == or != in org.apache.hadoop.yarn.client.cli.RMAdminCLI.buildHelpMsg(String, StringBuilder) </td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N239993" style="display: none;">
<a href="#ES_COMPARING_STRINGS_WITH_EQ">Bug type ES_COMPARING_STRINGS_WITH_EQ (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.RMAdminCLI<br/>In method org.apache.hadoop.yarn.client.cli.RMAdminCLI.buildHelpMsg(String, StringBuilder)<br/>Actual type String<br/>String constant ""<br/>Value loaded from field org.apache.hadoop.ha.HAAdmin$UsageInfo.args<br/>At RMAdminCLI.java:[line 109]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N240081');">
<td>
<span class="priority-2">ES</span>
</td>
<td>Comparison of String objects using == or != in org.apache.hadoop.yarn.client.cli.RMAdminCLI.buildIndividualUsageMsg(String, StringBuilder) </td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N240081" style="display: none;">
<a href="#ES_COMPARING_STRINGS_WITH_EQ">Bug type ES_COMPARING_STRINGS_WITH_EQ (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.RMAdminCLI<br/>In method org.apache.hadoop.yarn.client.cli.RMAdminCLI.buildIndividualUsageMsg(String, StringBuilder)<br/>Actual type String<br/>String constant ""<br/>Value loaded from field org.apache.hadoop.ha.HAAdmin$UsageInfo.args<br/>At RMAdminCLI.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N66003');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.conf.ReconfigurationServlet.printHeader(PrintWriter, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N66003" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.conf.ReconfigurationServlet<br/>In method org.apache.hadoop.conf.ReconfigurationServlet.printHeader(PrintWriter, String)<br/>Called method java.io.PrintWriter.printf(String, Object[])<br/>Format string "&lt;h1&gt;%s Reconfiguration Utility&lt;/h1&gt;\n"<br/>At ReconfigurationServlet.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66077');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.conf.ReconfigurationServlet.printHeader(PrintWriter, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66077" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.conf.ReconfigurationServlet<br/>In method org.apache.hadoop.conf.ReconfigurationServlet.printHeader(PrintWriter, String)<br/>Called method java.io.PrintWriter.printf(String, Object[])<br/>Format string "&lt;title&gt;%s Reconfiguration Utility&lt;/title&gt;\n"<br/>At ReconfigurationServlet.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73949');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.fs.FileSystemContractBaseTest.writeAndRead(Path, byte[], int, boolean, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73949" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.fs.FileSystemContractBaseTest<br/>In method org.apache.hadoop.fs.FileSystemContractBaseTest.writeAndRead(Path, byte[], int, boolean, boolean)<br/>Called method String.format(String, Object[])<br/>Format string "[%04d] %2x %s -expected %2x %s\n"<br/>At FileSystemContractBaseTest.java:[line 567]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74023');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.fs.FileSystemContractBaseTest.writeAndRead(Path, byte[], int, boolean, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74023" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.fs.FileSystemContractBaseTest<br/>In method org.apache.hadoop.fs.FileSystemContractBaseTest.writeAndRead(Path, byte[], int, boolean, boolean)<br/>Called method String.format(String, Object[])<br/>Format string "[%04d] %2x %s\n"<br/>At FileSystemContractBaseTest.java:[line 565]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90846');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.fs.swift.util.SwiftTestUtils.compareByteArrays(byte[], byte[], int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90846" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.fs.swift.util.SwiftTestUtils<br/>In method org.apache.hadoop.fs.swift.util.SwiftTestUtils.compareByteArrays(byte[], byte[], int)<br/>Called method String.format(String, Object[])<br/>Format string "[%04d] %2x %s -expected %2x %s\n"<br/>At SwiftTestUtils.java:[line 224]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N90920');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.fs.swift.util.SwiftTestUtils.compareByteArrays(byte[], byte[], int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N90920" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.fs.swift.util.SwiftTestUtils<br/>In method org.apache.hadoop.fs.swift.util.SwiftTestUtils.compareByteArrays(byte[], byte[], int)<br/>Called method String.format(String, Object[])<br/>Format string "[%04d] %2x %s\n"<br/>At SwiftTestUtils.java:[line 222]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N106115');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.hdfs.TestFileConcurrentReader.tailFile(Path, long)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N106115" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileConcurrentReader<br/>In method org.apache.hadoop.hdfs.TestFileConcurrentReader.tailFile(Path, long)<br/>Called method String.format(String, Object[])<br/>Format string "invalid bytes: [%s]\n"<br/>At TestFileConcurrentReader.java:[line 445]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N143740');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.hdfs.tools.offlineImageViewer.LsrPBImage.listINode(String, FsImageProto$INodeSection$INode)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N143740" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.LsrPBImage<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.LsrPBImage.listINode(String, FsImageProto$INodeSection$INode)<br/>Called method String.format(String, Object[])<br/>Format string "-%s  - %8s %10s %10s %10d %s%s -&gt; %s\n"<br/>At LsrPBImage.java:[line 181]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N143814');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.hdfs.tools.offlineImageViewer.LsrPBImage.listINode(String, FsImageProto$INodeSection$INode)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N143814" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.LsrPBImage<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.LsrPBImage.listINode(String, FsImageProto$INodeSection$INode)<br/>Called method String.format(String, Object[])<br/>Format string "-%s %2s %8s %10s %10s %10d %s%s\n"<br/>At LsrPBImage.java:[line 162]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N143888');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.hdfs.tools.offlineImageViewer.LsrPBImage.listINode(String, FsImageProto$INodeSection$INode)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N143888" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.LsrPBImage<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.LsrPBImage.listINode(String, FsImageProto$INodeSection$INode)<br/>Called method String.format(String, Object[])<br/>Format string "d%s  - %8s %10s %10s %10d %s%s\n"<br/>At LsrPBImage.java:[line 172]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N158496');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.io.file.tfile.TestTFileSeek.createTFile()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N158496" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileSeek<br/>In method org.apache.hadoop.io.file.tfile.TestTFileSeek.createTFile()<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "time: %s...file size: %.2fMB...disk thrpt: %.2fMB/s\n"<br/>At TestTFileSeek.java:[line 139]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N158570');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.io.file.tfile.TestTFileSeek.createTFile()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N158570" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileSeek<br/>In method org.apache.hadoop.io.file.tfile.TestTFileSeek.createTFile()<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "time: %s...uncompressed: %.2fMB...raw thrpt: %.2fMB/s\n"<br/>At TestTFileSeek.java:[line 135]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N158644');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.io.file.tfile.TestTFileSeek.seekTFile()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N158644" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileSeek<br/>In method org.apache.hadoop.io.file.tfile.TestTFileSeek.seekTFile()<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "time: %s...avg seek: %s...%d hit...%d miss...avg I/O size: %.2fKB\n"<br/>At TestTFileSeek.java:[line 171]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N154763');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.io.file.tfile.TFile.main(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N154763" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TFile<br/>In method org.apache.hadoop.io.file.tfile.TFile.main(String[])<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "TFile Dumper (TFile %s, BCFile %s)\n"<br/>At TFile.java:[line 2344]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N154906');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.io.file.tfile.TFileDumper.dumpInfo(String, PrintStream, Configuration)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N154906" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TFileDumper<br/>In method org.apache.hadoop.io.file.tfile.TFileDumper.dumpInfo(String, PrintStream, Configuration)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "%s %s %s %s %s %s\n"<br/>At TFileDumper.java:[line 203]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N154980');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.io.file.tfile.TFileDumper.dumpInfo(String, PrintStream, Configuration)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N154980" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TFileDumper<br/>In method org.apache.hadoop.io.file.tfile.TFileDumper.dumpInfo(String, PrintStream, Configuration)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "%s %s %s %s %s\n"<br/>At TFileDumper.java:[line 270]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N155054');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.io.file.tfile.TFileDumper.dumpInfo(String, PrintStream, Configuration)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N155054" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TFileDumper<br/>In method org.apache.hadoop.io.file.tfile.TFileDumper.dumpInfo(String, PrintStream, Configuration)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "%s %s %s %s %s\n"<br/>At TFileDumper.java:[line 283]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N155128');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.io.file.tfile.TFileDumper.dumpInfo(String, PrintStream, Configuration)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N155128" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TFileDumper<br/>In method org.apache.hadoop.io.file.tfile.TFileDumper.dumpInfo(String, PrintStream, Configuration)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "%s : %s\n"<br/>At TFileDumper.java:[line 179]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N179215');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N179215" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : Default queue\n"<br/>At Gridmix.java:[line 742]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N179289');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N179289" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : Enable/disable using queues in trace\n"<br/>At Gridmix.java:[line 744]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N179363');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N179363" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : Job submission policy (%s)\n"<br/>At Gridmix.java:[line 746]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N179437');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N179437" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : Job types (%s)\n"<br/>At Gridmix.java:[line 740]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N179511');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N179511" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : Key fraction of rec\n"<br/>At Gridmix.java:[line 749]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N179585');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N179585" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : Maximum map task runtime in mili-sec\n"<br/>At Gridmix.java:[line 756]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N179659');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N179659" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : Maximum reduce task runtime in mili-sec (merge+reduce)\n"<br/>At Gridmix.java:[line 758]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N179733');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N179733" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : Number of fake locations for map tasks\n"<br/>At Gridmix.java:[line 754]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N179807');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N179807" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : Output directory\n"<br/>At Gridmix.java:[line 736]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N179881');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N179881" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : Queued job desc\n"<br/>At Gridmix.java:[line 738]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N179955');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N179955" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : Submitting threads\n"<br/>At Gridmix.java:[line 737]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N180029');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N180029" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : User resolution class\n"<br/>At Gridmix.java:[line 739]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N180103');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N180103" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : Whether to ignore reduce tasks\n"<br/>At Gridmix.java:[line 752]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N180177');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N180177" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : jobs vs task-tracker ratio\n"<br/>At Gridmix.java:[line 761]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N180251');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N180251" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : map-slot share per job\n"<br/>At Gridmix.java:[line 767]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N180325');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N180325" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : maps vs map-slot ratio\n"<br/>At Gridmix.java:[line 763]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N180399');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N180399" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : reduce-slot share per job\n"<br/>At Gridmix.java:[line 769]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N180473');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N180473" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Gridmix<br/>In method org.apache.hadoop.mapred.gridmix.Gridmix.printUsage(PrintStream)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "       %-48s : reduces vs reduce-slot ratio\n"<br/>At Gridmix.java:[line 765]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N182793');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.mapred.gridmix.TestRandomAlgorithm.verifyResults(Map, int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N182793" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestRandomAlgorithm<br/>In method org.apache.hadoop.mapred.gridmix.TestRandomAlgorithm.verifyResults(Map, int, int)<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string " ==&gt; %d\n"<br/>At TestRandomAlgorithm.java:[line 116]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N214160');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.nfs.nfs3.IdUserGroup.reportDuplicateEntry(String, Integer, String, Integer, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N214160" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.nfs.nfs3.IdUserGroup<br/>In method org.apache.hadoop.nfs.nfs3.IdUserGroup.reportDuplicateEntry(String, Integer, String, Integer, String)<br/>Called method String.format(String, Object[])<br/>Format string "new entry (%d, %s), existing entry: (%d, %s).\n%s\n%s"<br/>At IdUserGroup.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N225692');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N225692" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.test.TimedOutTestsListener<br/>In method org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump()<br/>Called method String.format(String, Object[])<br/>Format string ""%s" %s prio=%d tid=%d %s\njava.lang.Thread.State: %s"<br/>At TimedOutTestsListener.java:[line 89]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N230145');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.util.NativeLibraryChecker.main(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N230145" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.util.NativeLibraryChecker<br/>In method org.apache.hadoop.util.NativeLibraryChecker.main(String[])<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "bzip2:  %b %s\n"<br/>At NativeLibraryChecker.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N230219');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.util.NativeLibraryChecker.main(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N230219" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.util.NativeLibraryChecker<br/>In method org.apache.hadoop.util.NativeLibraryChecker.main(String[])<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "hadoop: %b %s\n"<br/>At NativeLibraryChecker.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N230293');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.util.NativeLibraryChecker.main(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N230293" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.util.NativeLibraryChecker<br/>In method org.apache.hadoop.util.NativeLibraryChecker.main(String[])<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "lz4:    %b %s\n"<br/>At NativeLibraryChecker.java:[line 90]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N230367');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.util.NativeLibraryChecker.main(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N230367" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.util.NativeLibraryChecker<br/>In method org.apache.hadoop.util.NativeLibraryChecker.main(String[])<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "snappy: %b %s\n"<br/>At NativeLibraryChecker.java:[line 89]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N230441');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.util.NativeLibraryChecker.main(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N230441" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.util.NativeLibraryChecker<br/>In method org.apache.hadoop.util.NativeLibraryChecker.main(String[])<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "zlib:   %b %s\n"<br/>At NativeLibraryChecker.java:[line 88]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N272862');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.yarn.state.Graph.generateGraphViz(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N272862" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.state.Graph<br/>In method org.apache.hadoop.yarn.state.Graph.generateGraphViz(String)<br/>Called method String.format(String, Object[])<br/>Format string "%s%s -&gt; %s [ label = %s ];\n"<br/>At Graph.java:[line 172]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N272936');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.yarn.state.Graph.generateGraphViz(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N272936" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.state.Graph<br/>In method org.apache.hadoop.yarn.state.Graph.generateGraphViz(String)<br/>Called method String.format(String, Object[])<br/>Format string "%s%s [ label = %s ];\n"<br/>At Graph.java:[line 165]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N273010');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.yarn.state.Graph.generateGraphViz(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N273010" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.state.Graph<br/>In method org.apache.hadoop.yarn.state.Graph.generateGraphViz(String)<br/>Called method String.format(String, Object[])<br/>Format string "graph [ label=%s, fontsize=24, fontname=Helvetica];\n"<br/>At Graph.java:[line 152]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N273151');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.yarn.state.VisualizeStateMachine.main(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N273151" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.state.VisualizeStateMachine<br/>In method org.apache.hadoop.yarn.state.VisualizeStateMachine.main(String[])<br/>Called method java.io.PrintStream.printf(String, Object[])<br/>Format string "Usage: %s &lt;GraphName&gt; &lt;class[,class[,...]]&gt; &lt;OutputFile&gt;\n"<br/>At VisualizeStateMachine.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N273643');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.getProcessTreeDump()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N273643" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.ProcfsBasedProcessTree<br/>In method org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.getProcessTreeDump()<br/>Called method String.format(String, Object[])<br/>Format string "	|- %s %s %d %d %s %d %d %d %d %s\n"<br/>At ProcfsBasedProcessTree.java:[line 324]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N273717');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.getProcessTreeDump()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N273717" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.ProcfsBasedProcessTree<br/>In method org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.getProcessTreeDump()<br/>Called method String.format(String, Object[])<br/>Format string "	|- PID PPID PGRPID SESSID CMD_NAME USER_MODE_TIME(MILLIS) SYSTEM_TIME(MILLIS) VMEM_USAGE(BYTES) RSSMEM_USAGE(PAGES) FULL_CMD_LINE\n"<br/>At ProcfsBasedProcessTree.java:[line 319]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N275127');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.parsingProcMemFile()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N275127" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin<br/>In method org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.parsingProcMemFile()<br/>Called method String.format(String, Object[])<br/>Format string "MemTotal:      %d kB\nMemFree:         %d kB\nBuffers:        138244 kB\nCached:         947780 kB\nSwapCached:     142880 kB\nActive:        3229888 kB\nInactive:       %d kB\nSwapTotal:     %d kB\nSwapFree:      %d kB\nDirty:          122012 kB\nWriteback:           0 kB\nAnonPages:     2710792 kB\nMapped:          24740 kB\nSlab:           132528 kB\nSReclaimable:   105096 kB\nSUnreclaim:      27432 kB\nPageTables:      11448 kB\nNFS_Unstable:        0 kB\nBounce:              0 kB\nCommitLimit:   4125904 kB\nCommitted_AS:  4143556 kB\nVmallocTotal: 34359738367 kB\nVmallocUsed:      1632 kB\nVmallocChunk: 34359736375 kB\nHugePages_Total:     0\nHugePages_Free:      0\nHugePages_Rsvd:      0\nHugepagesize:     2048 kB"<br/>At TestLinuxResourceCalculatorPlugin.java:[line 224]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N275201');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.parsingProcStatAndCpuFile()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N275201" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin<br/>In method org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.parsingProcStatAndCpuFile()<br/>Called method String.format(String, Object[])<br/>Format string "processor : %s\nvendor_id : AuthenticAMD\ncpu family  : 15\nmodel   : 33\nmodel name  : Dual Core AMD Opteron(tm) Processor 280\nstepping  : 2\ncpu MHz   : %f\ncache size  : 1024 KB\nphysical id : 0\nsiblings  : 2\ncore id   : 0\ncpu cores : 2\nfpu   : yes\nfpu_exception : yes\ncpuid level : 1\nwp    : yes\nflags   : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx mmxext fxsr_opt lm 3dnowext 3dnow pni lahf_lm cmp_legacy\nbogomips  : 4792.41\nTLB size  : 1024 4K pages\nclflush size  : 64\ncache_alignment : 64\naddress sizes : 40 bits physical, 48 bits virtual\npower management: ts fid vid ttp"<br/>At TestLinuxResourceCalculatorPlugin.java:[line 154]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N275275');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.updateStatFile(long, long, long)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N275275" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin<br/>In method org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.updateStatFile(long, long, long)<br/>Called method String.format(String, Object[])<br/>Format string "cpu  %d %d %d 1646495089 831319 48713 164346 0\ncpu0 15096055 30805 3823005 411456015 206027 13 14269 0\ncpu1 14760561 89890 6432036 408707910 456857 48074 130857 0\ncpu2 12761169 20842 3758639 413976772 98028 411 10288 0\ncpu3 12355207 47322 5789691 412354390 70406 213 8931 0\nintr 114648668 20010764 2 0 945665 2 0 0 0 0 0 0 0 4 0 0 0 0 0 0\nctxt 242017731764\nbtime 1257808753\nprocesses 26414943\nprocs_running 1\nprocs_blocked 0\n"<br/>At TestLinuxResourceCalculatorPlugin.java:[line 206]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N276037');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.yarn.util.WindowsBasedProcessTree.getProcessTreeDump()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N276037" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.WindowsBasedProcessTree<br/>In method org.apache.hadoop.yarn.util.WindowsBasedProcessTree.getProcessTreeDump()<br/>Called method String.format(String, Object[])<br/>Format string "	|- %s %d %d %d\n"<br/>At WindowsBasedProcessTree.java:[line 168]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N276111');">
<td>
<span class="priority-2">FS</span>
</td>
<td>Format string should use %n rather than \n in org.apache.hadoop.yarn.util.WindowsBasedProcessTree.getProcessTreeDump()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N276111" style="display: none;">
<a href="#VA_FORMAT_STRING_USES_NEWLINE">Bug type VA_FORMAT_STRING_USES_NEWLINE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.WindowsBasedProcessTree<br/>In method org.apache.hadoop.yarn.util.WindowsBasedProcessTree.getProcessTreeDump()<br/>Called method String.format(String, Object[])<br/>Format string "	|- PID CPU_TIME(MILLIS) VMEM(BYTES) WORKING_SET(BYTES)\n"<br/>At WindowsBasedProcessTree.java:[line 164]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N148514');">
<td>
<span class="priority-1">HE</span>
</td>
<td>org.apache.hadoop.io.RandomDatum defines equals and uses Object.hashCode()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N148514" style="display: none;">
<a href="#HE_EQUALS_USE_HASHCODE">Bug type HE_EQUALS_USE_HASHCODE (click for details)</a>
<br/>In class org.apache.hadoop.io.RandomDatum<br/>In method org.apache.hadoop.io.RandomDatum.equals(Object)<br/>At RandomDatum.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N168967');">
<td>
<span class="priority-2">ME</span>
</td>
<td>org.apache.hadoop.mapred.Operation.jobACLNeeded field is public and mutable</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N168967" style="display: none;">
<a href="#ME_MUTABLE_ENUM_FIELD">Bug type ME_MUTABLE_ENUM_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.Operation<br/>Field org.apache.hadoop.mapred.Operation.jobACLNeeded<br/>In Operation.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N169014');">
<td>
<span class="priority-2">ME</span>
</td>
<td>org.apache.hadoop.mapred.Operation.qACLNeeded field is public and mutable</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N169014" style="display: none;">
<a href="#ME_MUTABLE_ENUM_FIELD">Bug type ME_MUTABLE_ENUM_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.Operation<br/>Field org.apache.hadoop.mapred.Operation.qACLNeeded<br/>In Operation.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N211421');">
<td>
<span class="priority-2">ME</span>
</td>
<td>org.apache.hadoop.metrics2.lib.DefaultMetricsFactory.setInstance(MutableMetricsFactory) unconditionally sets the field mmfImpl</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N211421" style="display: none;">
<a href="#ME_ENUM_FIELD_SETTER">Bug type ME_ENUM_FIELD_SETTER (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.lib.DefaultMetricsFactory<br/>In method org.apache.hadoop.metrics2.lib.DefaultMetricsFactory.setInstance(MutableMetricsFactory)<br/>Field org.apache.hadoop.metrics2.lib.DefaultMetricsFactory.mmfImpl<br/>At DefaultMetricsFactory.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N211488');">
<td>
<span class="priority-2">ME</span>
</td>
<td>org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.setMiniClusterMode(boolean) unconditionally sets the field miniClusterMode</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N211488" style="display: none;">
<a href="#ME_ENUM_FIELD_SETTER">Bug type ME_ENUM_FIELD_SETTER (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.lib.DefaultMetricsSystem<br/>In method org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.setMiniClusterMode(boolean)<br/>Field org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.miniClusterMode<br/>At DefaultMetricsSystem.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N78127');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.fs.TestFcHdfsCreateMkdir.ClusterShutdownAtEnd() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N78127" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFcHdfsCreateMkdir<br/>In method org.apache.hadoop.fs.TestFcHdfsCreateMkdir.ClusterShutdownAtEnd()<br/>At TestFcHdfsCreateMkdir.java:[lines 61-62]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78180');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.fs.TestFcHdfsPermission.ClusterShutdownAtEnd() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78180" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFcHdfsPermission<br/>In method org.apache.hadoop.fs.TestFcHdfsPermission.ClusterShutdownAtEnd()<br/>At TestFcHdfsPermission.java:[lines 69-70]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N78233');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.fs.TestFcHdfsSetUMask.ClusterShutdownAtEnd() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N78233" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFcHdfsSetUMask<br/>In method org.apache.hadoop.fs.TestFcHdfsSetUMask.ClusterShutdownAtEnd()<br/>At TestFcHdfsSetUMask.java:[lines 99-100]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81800');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.fs.TestHDFSFileContextMainOperations.ClusterShutdownAtEnd() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81800" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestHDFSFileContextMainOperations<br/>In method org.apache.hadoop.fs.TestHDFSFileContextMainOperations.ClusterShutdownAtEnd()<br/>At TestHDFSFileContextMainOperations.java:[lines 83-87]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91293');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.fs.viewfs.TestViewFileSystemHdfs.ClusterShutdownAtEnd() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91293" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.TestViewFileSystemHdfs<br/>In method org.apache.hadoop.fs.viewfs.TestViewFileSystemHdfs.ClusterShutdownAtEnd()<br/>At TestViewFileSystemHdfs.java:[lines 91-92]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N91346');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.fs.viewfs.TestViewFsAtHdfsRoot.ClusterShutdownAtEnd() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N91346" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.TestViewFsAtHdfsRoot<br/>In method org.apache.hadoop.fs.viewfs.TestViewFsAtHdfsRoot.ClusterShutdownAtEnd()<br/>At TestViewFsAtHdfsRoot.java:[lines 67-68]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91399');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.fs.viewfs.TestViewFsHdfs.ClusterShutdownAtEnd() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91399" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.TestViewFsHdfs<br/>In method org.apache.hadoop.fs.viewfs.TestViewFsHdfs.ClusterShutdownAtEnd()<br/>At TestViewFsHdfs.java:[lines 67-68]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N91713');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The field name org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.SupportsBlocks doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N91713" style="display: none;">
<a href="#NM_FIELD_NAMING_CONVENTION">Bug type NM_FIELD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest<br/>Field org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.SupportsBlocks<br/>In ViewFileSystemBaseTest.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91900');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The field name org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.ViewFSTestDir doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91900" style="display: none;">
<a href="#NM_FIELD_NAMING_CONVENTION">Bug type NM_FIELD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup<br/>Field org.apache.hadoop.fs.viewfs.ViewFileSystemTestSetup.ViewFSTestDir<br/>In ViewFileSystemTestSetup.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N91999');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The field name org.apache.hadoop.fs.viewfs.ViewFsBaseTest.SupportsBlocks doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N91999" style="display: none;">
<a href="#NM_FIELD_NAMING_CONVENTION">Bug type NM_FIELD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.ViewFsBaseTest<br/>Field org.apache.hadoop.fs.viewfs.ViewFsBaseTest.SupportsBlocks<br/>In ViewFsBaseTest.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N92140');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The field name org.apache.hadoop.fs.viewfs.ViewFsTestSetup.ViewFSTestDir doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N92140" style="display: none;">
<a href="#NM_FIELD_NAMING_CONVENTION">Bug type NM_FIELD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.ViewFsTestSetup<br/>Field org.apache.hadoop.fs.viewfs.ViewFsTestSetup.ViewFSTestDir<br/>In ViewFsTestSetup.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N113515');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.hdfs.protocolPB.TestPBHelper.TestConvertDatanodeStorage() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N113515" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocolPB.TestPBHelper<br/>In method org.apache.hadoop.hdfs.protocolPB.TestPBHelper.TestConvertDatanodeStorage()<br/>At TestPBHelper.java:[lines 536-542]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N119594');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner.TestScanInfo() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N119594" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDirectoryScanner.TestScanInfo()<br/>At TestDirectoryScanner.java:[lines 458-480]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N137001');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.hdfs.server.namenode.ha.TestFailoverWithBlockTokensEnabled.TestFailoverAfterAccessKeyUpdate() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N137001" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestFailoverWithBlockTokensEnabled<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestFailoverWithBlockTokensEnabled.TestFailoverAfterAccessKeyUpdate()<br/>At TestFailoverWithBlockTokensEnabled.java:[lines 157-161]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N140117');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.TestSnapshotWithInvalidName() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N140117" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.TestSnapshotWithInvalidName()<br/>At TestSnapshotNameWithInvalidCharacters.java:[lines 64-72]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N140170');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.TestSnapshotWithInvalidName1() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N140170" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.TestSnapshotWithInvalidName1()<br/>At TestSnapshotNameWithInvalidCharacters.java:[lines 76-84]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N97791');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>Class org.apache.hadoop.hdfs.TestBlockMissingException is not derived from an Exception, even though it is named as such</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N97791" style="display: none;">
<a href="#NM_CLASS_NOT_EXCEPTION">Bug type NM_CLASS_NOT_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockMissingException<br/>At TestBlockMissingException.java:[lines 37-129]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98566');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.hdfs.TestBlockReaderLocal.TestStatisticsForLocalRead() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98566" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockReaderLocal<br/>In method org.apache.hadoop.hdfs.TestBlockReaderLocal.TestStatisticsForLocalRead()<br/>At TestBlockReaderLocal.java:[lines 710-711]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N98619');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.hdfs.TestBlockReaderLocal.TestStatisticsForShortCircuitLocalRead() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N98619" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockReaderLocal<br/>In method org.apache.hadoop.hdfs.TestBlockReaderLocal.TestStatisticsForShortCircuitLocalRead()<br/>At TestBlockReaderLocal.java:[lines 705-706]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N105186');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.hdfs.TestFSOutputSummer.TestDFSCheckSumType() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N105186" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFSOutputSummer<br/>In method org.apache.hadoop.hdfs.TestFSOutputSummer.TestDFSCheckSumType()<br/>At TestFSOutputSummer.java:[lines 150-167]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N142703');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.hdfs.tools.TestGetConf.TestGetConfExcludeCommand() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N142703" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.TestGetConf<br/>In method org.apache.hadoop.hdfs.tools.TestGetConf.TestGetConfExcludeCommand()<br/>At TestGetConf.java:[lines 389-406]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N142756');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.hdfs.tools.TestGetConf.TestGetConfIncludeCommand() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N142756" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.TestGetConf<br/>In method org.apache.hadoop.hdfs.tools.TestGetConf.TestGetConfIncludeCommand()<br/>At TestGetConf.java:[lines 410-427]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N147942');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The class name org.apache.hadoop.io.Closeable shadows the simple name of implemented interface java.io.Closeable</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N147942" style="display: none;">
<a href="#NM_SAME_SIMPLE_NAME_AS_INTERFACE">Bug type NM_SAME_SIMPLE_NAME_AS_INTERFACE (click for details)</a>
<br/>In class org.apache.hadoop.io.Closeable<br/>In class java.io.Closeable<br/>In Closeable.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N149270');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.io.TestDataByteBuffers.TestDataInputByteBufferCompatibility() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N149270" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.io.TestDataByteBuffers<br/>In method org.apache.hadoop.io.TestDataByteBuffers.TestDataInputByteBufferCompatibility()<br/>At TestDataByteBuffers.java:[lines 164-175]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N149323');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.io.TestDataByteBuffers.TestDataOutputByteBufferCompatibility() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N149323" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.io.TestDataByteBuffers<br/>In method org.apache.hadoop.io.TestDataByteBuffers.TestDataOutputByteBufferCompatibility()<br/>At TestDataByteBuffers.java:[lines 179-193]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N164917');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>Class org.apache.hadoop.lib.lang.TestXException is not derived from an Exception, even though it is named as such</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N164917" style="display: none;">
<a href="#NM_CLASS_NOT_EXCEPTION">Bug type NM_CLASS_NOT_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.lib.lang.TestXException<br/>At TestXException.java:[lines 28-62]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N165030');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.NameNodeNotinWhitelists() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N165030" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService<br/>In method org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.NameNodeNotinWhitelists()<br/>At TestFileSystemAccessService.java:[lines 235-247]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N212943');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>VERY confusing (but perhaps intentional) to have methods org.apache.hadoop.net.StaticMapping.setconf(Configuration) and org.apache.hadoop.net.AbstractDNSToSwitchMapping.setConf(Configuration)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N212943" style="display: none;">
<a href="#NM_VERY_CONFUSING_INTENTIONAL">Bug type NM_VERY_CONFUSING_INTENTIONAL (click for details)</a>
<br/>In class org.apache.hadoop.net.StaticMapping<br/>In method org.apache.hadoop.net.StaticMapping.setconf(Configuration)<br/>superclass is org.apache.hadoop.net.AbstractDNSToSwitchMapping<br/>Did you intend to override org.apache.hadoop.net.AbstractDNSToSwitchMapping.setConf(Configuration)<br/>Overrides org.apache.hadoop.net.StaticMapping.setConf(Configuration)<br/>At StaticMapping.java:[lines 81-82]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N215912');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.record.compiler.generated.RccTokenManager.ReInit(SimpleCharStream) doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N215912" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.RccTokenManager<br/>In method org.apache.hadoop.record.compiler.generated.RccTokenManager.ReInit(SimpleCharStream)<br/>At RccTokenManager.java:[lines 656-660]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N215965');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.record.compiler.generated.RccTokenManager.ReInit(SimpleCharStream, int) doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N215965" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.RccTokenManager<br/>In method org.apache.hadoop.record.compiler.generated.RccTokenManager.ReInit(SimpleCharStream, int)<br/>At RccTokenManager.java:[lines 670-672]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N216018');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.record.compiler.generated.RccTokenManager.SwitchTo(int) doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N216018" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.RccTokenManager<br/>In method org.apache.hadoop.record.compiler.generated.RccTokenManager.SwitchTo(int)<br/>At RccTokenManager.java:[lines 675-679]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N216602');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.record.compiler.generated.TokenMgrError.LexicalError(boolean, int, int, int, String, char) doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N216602" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.TokenMgrError<br/>In method org.apache.hadoop.record.compiler.generated.TokenMgrError.LexicalError(boolean, int, int, int, String, char)<br/>At TokenMgrError.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N216708');">
<td>
<span class="priority-1">Nm</span>
</td>
<td>The class name org.apache.hadoop.security.AccessControlException shadows the simple name of the superclass org.apache.hadoop.fs.permission.AccessControlException</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N216708" style="display: none;">
<a href="#NM_SAME_SIMPLE_NAME_AS_SUPERCLASS">Bug type NM_SAME_SIMPLE_NAME_AS_SUPERCLASS (click for details)</a>
<br/>In class org.apache.hadoop.security.AccessControlException<br/>In class org.apache.hadoop.fs.permission.AccessControlException<br/>At AccessControlException.java:[lines 39-60]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N236839');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>Class org.apache.hadoop.yarn.api.records.SerializedException is not derived from an Exception, even though it is named as such</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N236839" style="display: none;">
<a href="#NM_CLASS_NOT_EXCEPTION">Bug type NM_CLASS_NOT_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.api.records.SerializedException<br/>At SerializedException.java:[lines 27-35]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N236786');">
<td>
<span class="priority-2">Nm</span>
</td>
<td>The method name org.apache.hadoop.yarn.api.TestContainerResourceIncreaseRequest.ContainerResourceIncreaseRequest() doesn't start with a lower case letter</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N236786" style="display: none;">
<a href="#NM_METHOD_NAMING_CONVENTION">Bug type NM_METHOD_NAMING_CONVENTION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.api.TestContainerResourceIncreaseRequest<br/>In method org.apache.hadoop.yarn.api.TestContainerResourceIncreaseRequest.ContainerResourceIncreaseRequest()<br/>At TestContainerResourceIncreaseRequest.java:[lines 35-51]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N148567');">
<td>
<span class="priority-2">NP</span>
</td>
<td>org.apache.hadoop.io.RandomDatum.equals(Object) does not check for null argument</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N148567" style="display: none;">
<a href="#NP_EQUALS_SHOULD_HANDLE_NULL_ARGUMENT">Bug type NP_EQUALS_SHOULD_HANDLE_NULL_ARGUMENT (click for details)</a>
<br/>In class org.apache.hadoop.io.RandomDatum<br/>In method org.apache.hadoop.io.RandomDatum.equals(Object)<br/>Parameter o<br/>At RandomDatum.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N191115');">
<td>
<span class="priority-2">ODR</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat.testDateSplits() may fail to close Statement</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N191115" style="display: none;">
<a href="#ODR_OPEN_DATABASE_RESOURCE">Bug type ODR_OPEN_DATABASE_RESOURCE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.db.TestDataDrivenDBInputFormat.testDateSplits()<br/>Need to close java.sql.Statement <br/>At TestDataDrivenDBInputFormat.java:[line 174]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72617');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String) may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72617" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.fs.DFSCIOTest<br/>In method org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String)<br/>Need to close java.io.OutputStream <br/>At DFSCIOTest.java:[line 538]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N72683');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String) may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N72683" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.fs.DFSCIOTest<br/>In method org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String)<br/>Need to close java.io.Reader <br/>At DFSCIOTest.java:[line 501]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72887');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean) may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72887" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.fs.DistributedFSCheck<br/>In method org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean)<br/>Need to close java.io.OutputStream <br/>At DistributedFSCheck.java:[line 346]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N72953');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean) may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N72953" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.fs.DistributedFSCheck<br/>In method org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean)<br/>Need to close java.io.Reader <br/>At DistributedFSCheck.java:[line 289]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86988');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.fs.loadGenerator.DataGenerator.genDirStructure() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86988" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.DataGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.DataGenerator.genDirStructure()<br/>Need to close java.io.Reader <br/>At DataGenerator.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87054');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.fs.loadGenerator.DataGenerator.genFiles() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87054" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.DataGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.DataGenerator.genFiles()<br/>Need to close java.io.Reader <br/>At DataGenerator.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97434');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.analyzeResults() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97434" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>In method org.apache.hadoop.hdfs.NNBench.analyzeResults()<br/>Need to close java.io.OutputStream <br/>At NNBench.java:[line 446]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N97500');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.analyzeResults() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N97500" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>In method org.apache.hadoop.hdfs.NNBench.analyzeResults()<br/>Need to close java.io.Reader <br/>At NNBench.java:[line 319]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N113930');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.hdfs.qjournal.server.Journal.persistPaxosData(long, QJournalProtocolProtos$PersistedRecoveryPaxosData) may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N113930" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.qjournal.server.Journal<br/>In method org.apache.hadoop.hdfs.qjournal.server.Journal.persistPaxosData(long, QJournalProtocolProtos$PersistedRecoveryPaxosData)<br/>Need to close java.io.Writer <br/>At Journal.java:[line 972]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N145049');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testBasicsReadArray() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N145049" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestExactSizeInputStream<br/>In method org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testBasicsReadArray()<br/>Need to close java.io.InputStream <br/>At TestExactSizeInputStream.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N145115');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testBasicsReadSingle() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N145115" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestExactSizeInputStream<br/>In method org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testBasicsReadSingle()<br/>Need to close java.io.InputStream <br/>At TestExactSizeInputStream.java:[line 34]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N145181');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testBasicsSkip() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N145181" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestExactSizeInputStream<br/>In method org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testBasicsSkip()<br/>Need to close java.io.InputStream <br/>At TestExactSizeInputStream.java:[line 63]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N145247');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testReadArrayNotEnough() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N145247" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestExactSizeInputStream<br/>In method org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testReadArrayNotEnough()<br/>Need to close java.io.InputStream <br/>At TestExactSizeInputStream.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N145313');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testReadNotEnough() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N145313" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestExactSizeInputStream<br/>In method org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testReadNotEnough()<br/>Need to close java.io.InputStream <br/>At TestExactSizeInputStream.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N145379');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testSkipNotEnough() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N145379" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestExactSizeInputStream<br/>In method org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testSkipNotEnough()<br/>Need to close java.io.InputStream <br/>At TestExactSizeInputStream.java:[line 90]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N146255');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract.testCaseInsensitive() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N146255" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract<br/>In method org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract.testCaseInsensitive()<br/>Need to close java.io.Reader <br/>At TestWebHdfsFileSystemContract.java:[line 171]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N152367');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.io.compress.TestCodec.GzipConcatTest(Configuration, Class) may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N152367" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.TestCodec<br/>In method org.apache.hadoop.io.compress.TestCodec.GzipConcatTest(Configuration, Class)<br/>Need to close java.io.OutputStream <br/>At TestCodec.java:[line 677]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N152433');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.io.compress.TestCodec.codecTest(Configuration, int, int, String) may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N152433" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.TestCodec<br/>In method org.apache.hadoop.io.compress.TestCodec.codecTest(Configuration, int, int, String)<br/>Need to close java.io.InputStream <br/>At TestCodec.java:[line 239]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N152499');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.io.compress.TestCodec.codecTest(Configuration, int, int, String) may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N152499" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.TestCodec<br/>In method org.apache.hadoop.io.compress.TestCodec.codecTest(Configuration, int, int, String)<br/>Need to close java.io.OutputStream <br/>At TestCodec.java:[line 197]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N152565');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.io.compress.TestCodec.writeSplitTestFile(FileSystem, Random, CompressionCodec, long) may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N152565" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.TestCodec<br/>In method org.apache.hadoop.io.compress.TestCodec.writeSplitTestFile(FileSystem, Random, CompressionCodec, long)<br/>Need to close java.io.OutputStream <br/>At TestCodec.java:[line 331]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N153867');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.io.compress.zlib.TestZlibCompressorDecompressor.testBuiltInGzipDecompressorExceptions() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N153867" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.zlib.TestZlibCompressorDecompressor<br/>In method org.apache.hadoop.io.compress.zlib.TestZlibCompressorDecompressor.testBuiltInGzipDecompressorExceptions()<br/>Need to close java.io.InputStream <br/>At TestZlibCompressorDecompressor.java:[line 364]<br/>Another occurrence at TestZlibCompressorDecompressor.java:[line 379]<br/>Another occurrence at TestZlibCompressorDecompressor.java:[line 393]<br/>Another occurrence at TestZlibCompressorDecompressor.java:[line 406]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N148724');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.io.TestBoundedByteArrayOutputStream.testBoundedStream() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N148724" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.io.TestBoundedByteArrayOutputStream<br/>In method org.apache.hadoop.io.TestBoundedByteArrayOutputStream.testBoundedStream()<br/>Need to close java.io.OutputStream <br/>At TestBoundedByteArrayOutputStream.java:[line 39]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N181810');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.mapred.gridmix.TestFileQueue.testEmpty() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N181810" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestFileQueue<br/>In method org.apache.hadoop.mapred.gridmix.TestFileQueue.testEmpty()<br/>Need to close java.io.InputStream <br/>At TestFileQueue.java:[line 139]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N181876');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.mapred.gridmix.TestFileQueue.testRepeat() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N181876" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestFileQueue<br/>In method org.apache.hadoop.mapred.gridmix.TestFileQueue.testRepeat()<br/>Need to close java.io.InputStream <br/>At TestFileQueue.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N181942');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.mapred.gridmix.TestFileQueue.testUneven() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N181942" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestFileQueue<br/>In method org.apache.hadoop.mapred.gridmix.TestFileQueue.testUneven()<br/>Need to close java.io.InputStream <br/>At TestFileQueue.java:[line 124]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N168723');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.mapred.MRCaching.launchMRCache(String, String, String, JobConf, String) may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N168723" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRCaching<br/>In method org.apache.hadoop.mapred.MRCaching.launchMRCache(String, String, String, JobConf, String)<br/>Need to close java.io.Reader <br/>At MRCaching.java:[line 275]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N170911');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testBuiltInGzipDecompressor() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N170911" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestConcatenatedCompressedInput<br/>In method org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testBuiltInGzipDecompressor()<br/>Need to close java.io.InputStream <br/>At TestConcatenatedCompressedInput.java:[line 334]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N170977');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testMoreBzip2() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N170977" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestConcatenatedCompressedInput<br/>In method org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testMoreBzip2()<br/>Need to close java.io.InputStream <br/>At TestConcatenatedCompressedInput.java:[line 541]<br/>Another occurrence at TestConcatenatedCompressedInput.java:[line 542]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N176259');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat.testBinary() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N176259" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat<br/>In method org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat.testBinary()<br/>Need to close java.io.InputStream <br/>At TestSequenceFileAsBinaryOutputFormat.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N176829');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration) may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N176829" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration)<br/>Need to close java.io.OutputStream <br/>At TestShuffleHandler.java:[line 640]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N176895');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N176895" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess()<br/>Need to close java.io.InputStream <br/>At TestShuffleHandler.java:[line 581]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N218876');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.security.authentication.client.AuthenticatorTestCase._testAuthentication(Authenticator, boolean) may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N218876" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.security.authentication.client.AuthenticatorTestCase<br/>In method org.apache.hadoop.security.authentication.client.AuthenticatorTestCase._testAuthentication(Authenticator, boolean)<br/>Need to close java.io.Reader <br/>At AuthenticatorTestCase.java:[line 153]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N218125');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.security.TestProxyUserFromEnv.testProxyUserFromEnvironment() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N218125" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.security.TestProxyUserFromEnv<br/>In method org.apache.hadoop.security.TestProxyUserFromEnv.testProxyUserFromEnvironment()<br/>Need to close java.io.Reader <br/>At TestProxyUserFromEnv.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N218594');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.security.TestUserGroupInformation.testGetServerSideGroups() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N218594" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.security.TestUserGroupInformation<br/>In method org.apache.hadoop.security.TestUserGroupInformation.testGetServerSideGroups()<br/>Need to close java.io.Reader <br/>At TestUserGroupInformation.java:[line 188]<br/>Another occurrence at TestUserGroupInformation.java:[line 204]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N221876');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N221876" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestMultipleCachefiles<br/>In method org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles()<br/>Need to close java.io.Reader <br/>At TestMultipleCachefiles.java:[line 137]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N223535');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.streaming.TestSymLink.testSymLink() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N223535" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestSymLink<br/>In method org.apache.hadoop.streaming.TestSymLink.testSymLink()<br/>Need to close java.io.Reader <br/>At TestSymLink.java:[line 124]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N225419');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.test.SysPropsForTestsLoader.&lt;static initializer for SysPropsForTestsLoader&gt;() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N225419" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.test.SysPropsForTestsLoader<br/>In method org.apache.hadoop.test.SysPropsForTestsLoader.&lt;static initializer for SysPropsForTestsLoader&gt;()<br/>Need to close java.io.Reader <br/>At SysPropsForTestsLoader.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N230515');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.util.PrintJarMainClass.main(String[]) may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N230515" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.util.PrintJarMainClass<br/>In method org.apache.hadoop.util.PrintJarMainClass.main(String[])<br/>Need to close java.util.zip.ZipFile <br/>At PrintJarMainClass.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N233841');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.util.TestMRCJCRunJar.makeTestJar() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N233841" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.util.TestMRCJCRunJar<br/>In method org.apache.hadoop.util.TestMRCJCRunJar.makeTestJar()<br/>Need to close java.io.InputStream <br/>At TestMRCJCRunJar.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N234957');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.util.TestWinUtils.readFile(File) may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N234957" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.readFile(File)<br/>Need to close java.io.InputStream <br/>At TestWinUtils.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N244254');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat.testContainerLogsFileAccess() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N244254" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat<br/>In method org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat.testContainerLogsFileAccess()<br/>Need to close java.io.Reader <br/>At TestAggregatedLogFormat.java:[line 290]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N251414');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerEnvVariables() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N251414" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerEnvVariables()<br/>Need to close java.io.Reader <br/>At TestContainerLaunch.java:[line 510]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N254971');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerKillOnMemoryOverflow() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N254971" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerKillOnMemoryOverflow()<br/>Need to close java.io.Reader <br/>At TestContainersMonitor.java:[line 256]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N250152');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerLaunchAndStop() may fail to close stream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N250152" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerLaunchAndStop()<br/>Need to close java.io.Reader <br/>At TestContainerManager.java:[line 322]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N250218');">
<td>
<span class="priority-2">OS</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerSetup() may fail to close stream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N250218" style="display: none;">
<a href="#OS_OPEN_STREAM">Bug type OS_OPEN_STREAM (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerSetup()<br/>Need to close java.io.Reader <br/>At TestContainerManager.java:[line 251]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73390');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.fs.FileContextMainOperationsBaseTest.testFileContextStatistics() ignores result of org.apache.hadoop.fs.FSDataInputStream.read(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73390" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.fs.FileContextMainOperationsBaseTest<br/>In method org.apache.hadoop.fs.FileContextMainOperationsBaseTest.testFileContextStatistics()<br/>Called method org.apache.hadoop.fs.FSDataInputStream.read(byte[])<br/>At FileContextMainOperationsBaseTest.java:[line 1313]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N73455');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.fs.FileContextMainOperationsBaseTest.testSetVerifyChecksum() ignores result of org.apache.hadoop.fs.FSDataInputStream.read(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N73455" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.fs.FileContextMainOperationsBaseTest<br/>In method org.apache.hadoop.fs.FileContextMainOperationsBaseTest.testSetVerifyChecksum()<br/>Called method org.apache.hadoop.fs.FSDataInputStream.read(byte[])<br/>At FileContextMainOperationsBaseTest.java:[line 1252]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N97726');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.hdfs.NNBenchWithoutMR.openRead() ignores result of org.apache.hadoop.fs.FSDataInputStream.read(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N97726" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBenchWithoutMR<br/>In method org.apache.hadoop.hdfs.NNBenchWithoutMR.openRead()<br/>Called method org.apache.hadoop.fs.FSDataInputStream.read(byte[], int, int)<br/>At NNBenchWithoutMR.java:[line 162]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N137566');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics.readFile(FileSystem, Path) ignores result of java.io.DataInputStream.read(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N137566" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics<br/>In method org.apache.hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics.readFile(FileSystem, Path)<br/>Called method java.io.DataInputStream.read(byte[], int, int)<br/>At TestNameNodeMetrics.java:[line 137]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99713');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.hdfs.TestDFSClientRetries.testRetryOnChecksumFailure() ignores result of org.apache.hadoop.hdfs.DFSInputStream.read(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99713" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSClientRetries<br/>In method org.apache.hadoop.hdfs.TestDFSClientRetries.testRetryOnChecksumFailure()<br/>Called method org.apache.hadoop.hdfs.DFSInputStream.read(byte[], int, int)<br/>At TestDFSClientRetries.java:[line 1114]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N108950');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.hdfs.TestSeekBug.seekReadFile(FileSystem, Path) ignores result of org.apache.hadoop.fs.FSDataInputStream.read(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N108950" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestSeekBug<br/>In method org.apache.hadoop.hdfs.TestSeekBug.seekReadFile(FileSystem, Path)<br/>Called method org.apache.hadoop.fs.FSDataInputStream.read(byte[], int, int)<br/>At TestSeekBug.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N109015');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.hdfs.TestSeekBug.smallReadSeek(FileSystem, Path) ignores result of org.apache.hadoop.fs.FSDataInputStream.read(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N109015" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestSeekBug<br/>In method org.apache.hadoop.hdfs.TestSeekBug.smallReadSeek(FileSystem, Path)<br/>Called method org.apache.hadoop.fs.FSDataInputStream.read(byte[], int, int)<br/>At TestSeekBug.java:[line 100]<br/>Another occurrence at TestSeekBug.java:[line 106]<br/>Another occurrence at TestSeekBug.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N145445');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testReadArrayNotEnough() ignores result of org.apache.hadoop.hdfs.util.ExactSizeInputStream.read(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N145445" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestExactSizeInputStream<br/>In method org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testReadArrayNotEnough()<br/>Called method org.apache.hadoop.hdfs.util.ExactSizeInputStream.read(byte[], int, int)<br/>At TestExactSizeInputStream.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N145514');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testSkipNotEnough() ignores result of org.apache.hadoop.hdfs.util.ExactSizeInputStream.skip(long)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N145514" style="display: none;">
<a href="#SR_NOT_CHECKED">Bug type SR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestExactSizeInputStream<br/>In method org.apache.hadoop.hdfs.util.TestExactSizeInputStream.testSkipNotEnough()<br/>Called method org.apache.hadoop.hdfs.util.ExactSizeInputStream.skip(long)<br/>At TestExactSizeInputStream.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N153966');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.io.compress.zlib.TestZlibCompressorDecompressor.testBuiltInGzipDecompressorExceptions() ignores result of java.io.InputStream.read(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N153966" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.zlib.TestZlibCompressorDecompressor<br/>In method org.apache.hadoop.io.compress.zlib.TestZlibCompressorDecompressor.testBuiltInGzipDecompressorExceptions()<br/>Called method java.io.InputStream.read(byte[])<br/>At TestZlibCompressorDecompressor.java:[line 366]<br/>Another occurrence at TestZlibCompressorDecompressor.java:[line 381]<br/>Another occurrence at TestZlibCompressorDecompressor.java:[line 395]<br/>Another occurrence at TestZlibCompressorDecompressor.java:[line 408]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N149482');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.io.TestIOUtils.testCopyBytesShouldCloseInputSteamWhenOutputStreamCloseThrowsException() ignores result of java.io.InputStream.read(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N149482" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.io.TestIOUtils<br/>In method org.apache.hadoop.io.TestIOUtils.testCopyBytesShouldCloseInputSteamWhenOutputStreamCloseThrowsException()<br/>Called method java.io.InputStream.read(byte[])<br/>At TestIOUtils.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N149551');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.io.TestIOUtils.testCopyBytesShouldCloseStreamsWhenCloseIsTrue() ignores result of java.io.InputStream.read(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N149551" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.io.TestIOUtils<br/>In method org.apache.hadoop.io.TestIOUtils.testCopyBytesShouldCloseStreamsWhenCloseIsTrue()<br/>Called method java.io.InputStream.read(byte[])<br/>At TestIOUtils.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N149620');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.io.TestIOUtils.testCopyBytesShouldNotCloseStreamsWhenCloseIsFalse() ignores result of java.io.InputStream.read(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N149620" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.io.TestIOUtils<br/>In method org.apache.hadoop.io.TestIOUtils.testCopyBytesShouldNotCloseStreamsWhenCloseIsFalse()<br/>Called method java.io.InputStream.read(byte[])<br/>At TestIOUtils.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N149689');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.io.TestIOUtils.testCopyBytesWithCountShouldCloseStreamsWhenCloseIsTrue() ignores result of java.io.InputStream.read(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N149689" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.io.TestIOUtils<br/>In method org.apache.hadoop.io.TestIOUtils.testCopyBytesWithCountShouldCloseStreamsWhenCloseIsTrue()<br/>Called method java.io.InputStream.read(byte[], int, int)<br/>At TestIOUtils.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N149758');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.io.TestIOUtils.testCopyBytesWithCountShouldNotCloseStreamsWhenCloseIsFalse() ignores result of java.io.InputStream.read(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N149758" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.io.TestIOUtils<br/>In method org.apache.hadoop.io.TestIOUtils.testCopyBytesWithCountShouldNotCloseStreamsWhenCloseIsFalse()<br/>Called method java.io.InputStream.read(byte[], int, int)<br/>At TestIOUtils.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N149827');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.io.TestIOUtils.testCopyBytesWithCountShouldThrowOutTheStreamClosureExceptions() ignores result of java.io.InputStream.read(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N149827" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.io.TestIOUtils<br/>In method org.apache.hadoop.io.TestIOUtils.testCopyBytesWithCountShouldThrowOutTheStreamClosureExceptions()<br/>Called method java.io.InputStream.read(byte[], int, int)<br/>At TestIOUtils.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N149896');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.io.TestIOUtils.testWriteFully() ignores result of java.io.RandomAccessFile.read(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N149896" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.io.TestIOUtils<br/>In method org.apache.hadoop.io.TestIOUtils.testWriteFully()<br/>Called method java.io.RandomAccessFile.read(byte[])<br/>At TestIOUtils.java:[line 137]<br/>Another occurrence at TestIOUtils.java:[line 147]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N181456');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testFileQueueDecompression() ignores result of org.apache.hadoop.mapred.gridmix.FileQueue.read(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N181456" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils<br/>In method org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testFileQueueDecompression()<br/>Called method org.apache.hadoop.mapred.gridmix.FileQueue.read(byte[])<br/>At TestCompressionEmulationUtils.java:[line 555]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N182008');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.mapred.gridmix.TestFileQueue.testRepeat() ignores result of org.apache.hadoop.mapred.gridmix.FileQueue.read(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N182008" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestFileQueue<br/>In method org.apache.hadoop.mapred.gridmix.TestFileQueue.testRepeat()<br/>Called method org.apache.hadoop.mapred.gridmix.FileQueue.read(byte[], int, int)<br/>At TestFileQueue.java:[line 101]<br/>Another occurrence at TestFileQueue.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N182088');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.mapred.gridmix.TestFileQueue.testUneven() ignores result of org.apache.hadoop.mapred.gridmix.FileQueue.read(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N182088" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestFileQueue<br/>In method org.apache.hadoop.mapred.gridmix.TestFileQueue.testUneven()<br/>Called method org.apache.hadoop.mapred.gridmix.FileQueue.read(byte[], int, int)<br/>At TestFileQueue.java:[line 129]<br/>Another occurrence at TestFileQueue.java:[line 131]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N171054');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testPrototypeInflaterGzip() ignores result of java.io.FileInputStream.skip(long)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N171054" style="display: none;">
<a href="#SR_NOT_CHECKED">Bug type SR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestConcatenatedCompressedInput<br/>In method org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testPrototypeInflaterGzip()<br/>Called method java.io.FileInputStream.skip(long)<br/>At TestConcatenatedCompressedInput.java:[line 251]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N178871');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.mapred.UtilsForTests.slurpHadoop(Path, FileSystem) ignores result of java.io.InputStream.read(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N178871" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.mapred.UtilsForTests<br/>In method org.apache.hadoop.mapred.UtilsForTests.slurpHadoop(Path, FileSystem)<br/>Called method java.io.InputStream.read(byte[], int, int)<br/>At UtilsForTests.java:[line 182]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N213400');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.net.TestSocketIOWithTimeout.doIO(InputStream, OutputStream, int) ignores result of java.io.InputStream.read(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N213400" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.net.TestSocketIOWithTimeout<br/>In method org.apache.hadoop.net.TestSocketIOWithTimeout.doIO(InputStream, OutputStream, int)<br/>Called method java.io.InputStream.read(byte[])<br/>At TestSocketIOWithTimeout.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N213469');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.net.TestSocketIOWithTimeout.testSocketIOWithTimeout() ignores result of java.io.InputStream.read(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N213469" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.net.TestSocketIOWithTimeout<br/>In method org.apache.hadoop.net.TestSocketIOWithTimeout.testSocketIOWithTimeout()<br/>Called method java.io.InputStream.read(byte[])<br/>At TestSocketIOWithTimeout.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N235023');">
<td>
<span class="priority-2">RR</span>
</td>
<td>org.apache.hadoop.util.TestWinUtils.readFile(File) ignores result of java.io.FileInputStream.read(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N235023" style="display: none;">
<a href="#RR_NOT_CHECKED">Bug type RR_NOT_CHECKED (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.readFile(File)<br/>Called method java.io.FileInputStream.read(byte[])<br/>At TestWinUtils.java:[line 72]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68175');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.conf.TestConfiguration.tearDown()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68175" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.tearDown()<br/>Called method java.io.File.delete()<br/>At TestConfiguration.java:[line 77]<br/>Another occurrence at TestConfiguration.java:[line 78]<br/>Another occurrence at TestConfiguration.java:[line 79]<br/>Another occurrence at TestConfiguration.java:[line 80]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N68278');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.conf.TestConfiguration.testRelativeIncludes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N68278" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testRelativeIncludes()<br/>Called method java.io.File.delete()<br/>At TestConfiguration.java:[line 436]<br/>Another occurrence at TestConfiguration.java:[line 437]<br/>Another occurrence at TestConfiguration.java:[line 438]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68370');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.conf.TestConfiguration.testRelativeIncludes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68370" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testRelativeIncludes()<br/>Called method java.io.File.mkdirs()<br/>At TestConfiguration.java:[line 416]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N68611');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.conf.TestConfigurationDeprecation.tearDown()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N68611" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfigurationDeprecation<br/>In method org.apache.hadoop.conf.TestConfigurationDeprecation.tearDown()<br/>Called method java.io.File.delete()<br/>At TestConfigurationDeprecation.java:[line 71]<br/>Another occurrence at TestConfigurationDeprecation.java:[line 72]<br/>Another occurrence at TestConfigurationDeprecation.java:[line 73]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68980');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.contrib.bkjournal.BKJMUtil.newBookie()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68980" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.BKJMUtil<br/>In method org.apache.hadoop.contrib.bkjournal.BKJMUtil.newBookie()<br/>Called method java.io.File.delete()<br/>At BKJMUtil.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69050');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.contrib.bkjournal.BKJMUtil.newBookie()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69050" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.BKJMUtil<br/>In method org.apache.hadoop.contrib.bkjournal.BKJMUtil.newBookie()<br/>Called method java.io.File.mkdir()<br/>At BKJMUtil.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69699');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.contrib.bkjournal.TestBookKeeperConfiguration.setupZooKeeper()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69699" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestBookKeeperConfiguration<br/>In method org.apache.hadoop.contrib.bkjournal.TestBookKeeperConfiguration.setupZooKeeper()<br/>Called method java.io.File.delete()<br/>At TestBookKeeperConfiguration.java:[line 89]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69769');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.contrib.bkjournal.TestBookKeeperConfiguration.setupZooKeeper()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69769" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestBookKeeperConfiguration<br/>In method org.apache.hadoop.contrib.bkjournal.TestBookKeeperConfiguration.setupZooKeeper()<br/>Called method java.io.File.mkdir()<br/>At TestBookKeeperConfiguration.java:[line 90]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N70163');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.contrib.bkjournal.TestCurrentInprogress.setupZooKeeper()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N70163" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestCurrentInprogress<br/>In method org.apache.hadoop.contrib.bkjournal.TestCurrentInprogress.setupZooKeeper()<br/>Called method java.io.File.delete()<br/>At TestCurrentInprogress.java:[line 78]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70233');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.contrib.bkjournal.TestCurrentInprogress.setupZooKeeper()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70233" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestCurrentInprogress<br/>In method org.apache.hadoop.contrib.bkjournal.TestCurrentInprogress.setupZooKeeper()<br/>Called method java.io.File.mkdir()<br/>At TestCurrentInprogress.java:[line 79]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N70303');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.contrib.bkjournal.TestCurrentInprogress.shutDownServer()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N70303" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestCurrentInprogress<br/>In method org.apache.hadoop.contrib.bkjournal.TestCurrentInprogress.shutDownServer()<br/>Called method java.io.File.delete()<br/>At TestCurrentInprogress.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85420');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.http.client.TestHttpFSFileSystemLocalFileSystem.&lt;static initializer for TestHttpFSFileSystemLocalFileSystem&gt;()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85420" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.client.TestHttpFSFileSystemLocalFileSystem<br/>In method org.apache.hadoop.fs.http.client.TestHttpFSFileSystemLocalFileSystem.&lt;static initializer for TestHttpFSFileSystemLocalFileSystem&gt;()<br/>Called method java.io.File.mkdirs()<br/>At TestHttpFSFileSystemLocalFileSystem.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N85113');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in new org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem(BaseTestHttpFSWith$Operation)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N85113" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem<br/>In method new org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem(BaseTestHttpFSWith$Operation)<br/>Called method java.io.File.mkdirs()<br/>At TestHttpFSFWithSWebhdfsFileSystem.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85183');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem.cleanUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85183" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem<br/>In method org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem.cleanUp()<br/>Called method java.io.File.delete()<br/>At TestHttpFSFWithSWebhdfsFileSystem.java:[line 72]<br/>Another occurrence at TestHttpFSFWithSWebhdfsFileSystem.java:[line 73]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86411');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.http.server.TestHttpFSServer.createHttpFSServer(boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86411" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSServer<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSServer.createHttpFSServer(boolean)<br/>Called method java.io.File.mkdirs()<br/>At TestHttpFSServer.java:[line 127]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N86726');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.http.server.TestHttpFSWithKerberos.createHttpFSServer()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N86726" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSWithKerberos<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSWithKerberos.createHttpFSServer()<br/>Called method java.io.File.mkdirs()<br/>At TestHttpFSWithKerberos.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N87732');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.fs.loadGenerator.TestLoadGenerator.testLoadGenerator()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N87732" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.TestLoadGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.TestLoadGenerator.testLoadGenerator()<br/>Called method java.io.File.delete()<br/>At TestLoadGenerator.java:[line 245]<br/>Another occurrence at TestLoadGenerator.java:[line 246]<br/>Another occurrence at TestLoadGenerator.java:[line 247]<br/>Another occurrence at TestLoadGenerator.java:[line 248]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87835');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.fs.loadGenerator.TestLoadGenerator.testStructureGenerator()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87835" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.TestLoadGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.TestLoadGenerator.testStructureGenerator()<br/>Called method java.io.File.delete()<br/>At TestLoadGenerator.java:[line 126]<br/>Another occurrence at TestLoadGenerator.java:[line 127]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89269');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.fs.shell.TestTextCommand.createAvroFile(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89269" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.shell.TestTextCommand<br/>In method org.apache.hadoop.fs.shell.TestTextCommand.createAvroFile(byte[])<br/>Called method java.io.File.createNewFile()<br/>At TestTextCommand.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N89339');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.fs.shell.TestTextCommand.createAvroFile(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N89339" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.shell.TestTextCommand<br/>In method org.apache.hadoop.fs.shell.TestTextCommand.createAvroFile(byte[])<br/>Called method java.io.File.mkdir()<br/>At TestTextCommand.java:[line 90]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N90342');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.slive.TestSlive.getWriteLoc()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N90342" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.TestSlive<br/>In method org.apache.hadoop.fs.slive.TestSlive.getWriteLoc()<br/>Called method java.io.File.mkdirs()<br/>At TestSlive.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77987');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.fs.TestDU.createFile(File, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77987" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestDU<br/>In method org.apache.hadoop.fs.TestDU.createFile(File, int)<br/>Called method java.io.File.createNewFile()<br/>At TestDU.java:[line 53]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78057');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.fs.TestEnhancedByteBufferAccess.testIndirectFallbackReads()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78057" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestEnhancedByteBufferAccess<br/>In method org.apache.hadoop.fs.TestEnhancedByteBufferAccess.testIndirectFallbackReads()<br/>Called method java.io.File.delete()<br/>At TestEnhancedByteBufferAccess.java:[line 585]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N79350');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.fs.TestFileUtil.setupDirs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N79350" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.setupDirs()<br/>Called method java.io.File.createNewFile()<br/>At TestFileUtil.java:[line 90]<br/>Another occurrence at TestFileUtil.java:[line 92]<br/>Another occurrence at TestFileUtil.java:[line 97]<br/>Another occurrence at TestFileUtil.java:[line 98]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N79453');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.TestFileUtil.setupDirs()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N79453" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.setupDirs()<br/>Called method java.io.File.mkdirs()<br/>At TestFileUtil.java:[line 87]<br/>Another occurrence at TestFileUtil.java:[line 88]<br/>Another occurrence at TestFileUtil.java:[line 89]<br/>Another occurrence at TestFileUtil.java:[line 95]<br/>Another occurrence at TestFileUtil.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N79567');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.fs.TestFileUtil.setupDirsAndNonWritablePermissions()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N79567" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.setupDirsAndNonWritablePermissions()<br/>Called method java.io.File.createNewFile()<br/>At TestFileUtil.java:[line 340]<br/>Another occurrence at TestFileUtil.java:[line 343]<br/>Another occurrence at TestFileUtil.java:[line 352]<br/>Another occurrence at TestFileUtil.java:[line 358]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N79670');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.TestFileUtil.setupDirsAndNonWritablePermissions()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N79670" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.setupDirsAndNonWritablePermissions()<br/>Called method java.io.File.mkdirs()<br/>At TestFileUtil.java:[line 334]<br/>Another occurrence at TestFileUtil.java:[line 339]<br/>Another occurrence at TestFileUtil.java:[line 342]<br/>Another occurrence at TestFileUtil.java:[line 351]<br/>Another occurrence at TestFileUtil.java:[line 356]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N79784');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.fs.TestFileUtil.testCopy5()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N79784" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testCopy5()<br/>Called method java.io.File.delete()<br/>At TestFileUtil.java:[line 772]<br/>Another occurrence at TestFileUtil.java:[line 782]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N79865');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.fs.TestFileUtil.testCreateLocalTempFile()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N79865" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testCreateLocalTempFile()<br/>Called method java.io.File.delete()<br/>At TestFileUtil.java:[line 704]<br/>Another occurrence at TestFileUtil.java:[line 705]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N79946');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.fs.TestFileUtil.testListAPI()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N79946" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testListAPI()<br/>Called method java.io.File.delete()<br/>At TestFileUtil.java:[line 179]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N80016');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.fs.TestFileUtil.testListAPI()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N80016" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testListAPI()<br/>Called method java.io.File.mkdir()<br/>At TestFileUtil.java:[line 175]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80086');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.fs.TestFileUtil.testListFiles()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80086" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testListFiles()<br/>Called method java.io.File.delete()<br/>At TestFileUtil.java:[line 152]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N80156');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.fs.TestFileUtil.testListFiles()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N80156" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testListFiles()<br/>Called method java.io.File.mkdir()<br/>At TestFileUtil.java:[line 148]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80226');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.fs.TestFileUtil.testReplaceFile()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80226" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testReplaceFile()<br/>Called method java.io.File.createNewFile()<br/>At TestFileUtil.java:[line 657]<br/>Another occurrence at TestFileUtil.java:[line 666]<br/>Another occurrence at TestFileUtil.java:[line 673]<br/>Another occurrence at TestFileUtil.java:[line 678]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N80329');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.fs.TestFileUtil.testReplaceFile()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N80329" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testReplaceFile()<br/>Called method java.io.File.delete()<br/>At TestFileUtil.java:[line 675]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80399');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.TestFileUtil.testReplaceFile()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80399" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testReplaceFile()<br/>Called method java.io.File.mkdirs()<br/>At TestFileUtil.java:[line 676]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N80469');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.TestFileUtil.testSymlink()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N80469" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testSymlink()<br/>Called method java.io.File.mkdirs()<br/>At TestFileUtil.java:[line 845]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80539');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.fs.TestFileUtil.testSymlinkDelete()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80539" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testSymlinkDelete()<br/>Called method java.io.File.createNewFile()<br/>At TestFileUtil.java:[line 915]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N80609');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.TestFileUtil.testSymlinkDelete()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N80609" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testSymlinkDelete()<br/>Called method java.io.File.mkdirs()<br/>At TestFileUtil.java:[line 912]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80679');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.fs.TestFileUtil.testSymlinkLength()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80679" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testSymlinkLength()<br/>Called method java.io.File.delete()<br/>At TestFileUtil.java:[line 957]<br/>Another occurrence at TestFileUtil.java:[line 968]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N80760');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.TestFileUtil.testSymlinkLength()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N80760" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testSymlinkLength()<br/>Called method java.io.File.mkdirs()<br/>At TestFileUtil.java:[line 936]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80830');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.fs.TestFileUtil.testSymlinkRenameTo()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80830" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testSymlinkRenameTo()<br/>Called method java.io.File.createNewFile()<br/>At TestFileUtil.java:[line 883]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N80900');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.TestFileUtil.testSymlinkRenameTo()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N80900" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testSymlinkRenameTo()<br/>Called method java.io.File.mkdirs()<br/>At TestFileUtil.java:[line 880]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N80970');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.fs.TestFileUtil.testUnTar()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N80970" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testUnTar()<br/>Called method java.io.File.createNewFile()<br/>At TestFileUtil.java:[line 641]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81040');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.fs.TestFileUtil.testUnZip()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81040" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testUnZip()<br/>Called method java.io.File.createNewFile()<br/>At TestFileUtil.java:[line 738]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N82540');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.TestHardLink.setupDirs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N82540" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestHardLink<br/>In method org.apache.hadoop.fs.TestHardLink.setupDirs()<br/>Called method java.io.File.mkdirs()<br/>At TestHardLink.java:[line 111]<br/>Another occurrence at TestHardLink.java:[line 112]<br/>Another occurrence at TestHardLink.java:[line 113]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N82632');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.TestHardLink.testCreateHardLinkMultOversizeAndEmpty()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N82632" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestHardLink<br/>In method org.apache.hadoop.fs.TestHardLink.testCreateHardLinkMultOversizeAndEmpty()<br/>Called method java.io.File.mkdirs()<br/>At TestHardLink.java:[line 366]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N82702');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.renameTo(File) ignored in org.apache.hadoop.fs.TestHardLink.testCreateHardLinkMultOversizeAndEmpty()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N82702" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestHardLink<br/>In method org.apache.hadoop.fs.TestHardLink.testCreateHardLinkMultOversizeAndEmpty()<br/>Called method java.io.File.renameTo(File)<br/>At TestHardLink.java:[line 328]<br/>Another occurrence at TestHardLink.java:[line 329]<br/>Another occurrence at TestHardLink.java:[line 330]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81853');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.TestHarFileSystemBasics.before()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81853" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestHarFileSystemBasics<br/>In method org.apache.hadoop.fs.TestHarFileSystemBasics.before()<br/>Called method java.io.File.mkdirs()<br/>At TestHarFileSystemBasics.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N82959');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.fs.TestLocalDirAllocator.createTempFile(long)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N82959" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestLocalDirAllocator<br/>In method org.apache.hadoop.fs.TestLocalDirAllocator.createTempFile(long)<br/>Called method java.io.File.delete()<br/>At TestLocalDirAllocator.java:[line 120]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83029');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.setReadOnly() ignored in org.apache.hadoop.fs.TestLocalDirAllocator.test0()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83029" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestLocalDirAllocator<br/>In method org.apache.hadoop.fs.TestLocalDirAllocator.test0()<br/>Called method java.io.File.setReadOnly()<br/>At TestLocalDirAllocator.java:[line 140]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N83099');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.fs.TestLocalDirAllocator.testCreateManyFiles()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N83099" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestLocalDirAllocator<br/>In method org.apache.hadoop.fs.TestLocalDirAllocator.testCreateManyFiles()<br/>Called method java.io.File.delete()<br/>At TestLocalDirAllocator.java:[line 259]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83169');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.setReadOnly() ignored in org.apache.hadoop.fs.TestLocalDirAllocator.testLocalPathForWriteDirCreation()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83169" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestLocalDirAllocator<br/>In method org.apache.hadoop.fs.TestLocalDirAllocator.testLocalPathForWriteDirCreation()<br/>Called method java.io.File.setReadOnly()<br/>At TestLocalDirAllocator.java:[line 282]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N83239');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.setReadOnly() ignored in org.apache.hadoop.fs.TestLocalDirAllocator.testROBufferDirAndRWBufferDir()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N83239" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestLocalDirAllocator<br/>In method org.apache.hadoop.fs.TestLocalDirAllocator.testROBufferDirAndRWBufferDir()<br/>Called method java.io.File.setReadOnly()<br/>At TestLocalDirAllocator.java:[line 162]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83309');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.setReadOnly() ignored in org.apache.hadoop.fs.TestLocalDirAllocator.testRWBufferDirBecomesRO()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83309" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestLocalDirAllocator<br/>In method org.apache.hadoop.fs.TestLocalDirAllocator.testRWBufferDirBecomesRO()<br/>Called method java.io.File.setReadOnly()<br/>At TestLocalDirAllocator.java:[line 218]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N83652');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.TestLocalFileSystem.testListStatusReturnConsistentPathOnWindows()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N83652" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestLocalFileSystem<br/>In method org.apache.hadoop.fs.TestLocalFileSystem.testListStatusReturnConsistentPathOnWindows()<br/>Called method java.io.File.mkdirs()<br/>At TestLocalFileSystem.java:[line 297]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83722');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.TestLocalFileSystem.testListStatusWithColons()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83722" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestLocalFileSystem<br/>In method org.apache.hadoop.fs.TestLocalFileSystem.testListStatusWithColons()<br/>Called method java.io.File.mkdirs()<br/>At TestLocalFileSystem.java:[line 282]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N83792');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.TestLocalFileSystem.testReportChecksumFailure()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N83792" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestLocalFileSystem<br/>In method org.apache.hadoop.fs.TestLocalFileSystem.testReportChecksumFailure()<br/>Called method java.io.File.mkdirs()<br/>At TestLocalFileSystem.java:[line 306]<br/>Another occurrence at TestLocalFileSystem.java:[line 311]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N91521');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.fs.viewfs.TestViewfsFileStatus.testFileStatusSerialziation()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N91521" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.TestViewfsFileStatus<br/>In method org.apache.hadoop.fs.viewfs.TestViewfsFileStatus.testFileStatusSerialziation()<br/>Called method java.io.File.mkdirs()<br/>At TestViewfsFileStatus.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N92632');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.ha.ClientBaseWithFixes.initHostPort()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N92632" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.ha.ClientBaseWithFixes<br/>In method org.apache.hadoop.ha.ClientBaseWithFixes.initHostPort()<br/>Called method java.io.File.mkdirs()<br/>At ClientBaseWithFixes.java:[line 408]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92702');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.ha.ClientBaseWithFixes.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92702" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.ha.ClientBaseWithFixes<br/>In method org.apache.hadoop.ha.ClientBaseWithFixes.setUp()<br/>Called method java.io.File.mkdirs()<br/>At ClientBaseWithFixes.java:[line 394]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N92772');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.ha.ClientBaseWithFixes.tearDown()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N92772" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.ha.ClientBaseWithFixes<br/>In method org.apache.hadoop.ha.ClientBaseWithFixes.tearDown()<br/>Called method java.io.File.delete()<br/>At ClientBaseWithFixes.java:[line 477]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94531');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.BenchmarkThroughput.writeAndReadLocalFile(String, Configuration, long)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94531" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.BenchmarkThroughput<br/>In method org.apache.hadoop.hdfs.BenchmarkThroughput.writeAndReadLocalFile(String, Configuration, long)<br/>Called method java.io.File.delete()<br/>At BenchmarkThroughput.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N110755');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.client.TestShortCircuitShm.testAllocateSlots()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N110755" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.client.TestShortCircuitShm<br/>In method org.apache.hadoop.hdfs.client.TestShortCircuitShm.testAllocateSlots()<br/>Called method java.io.File.mkdirs()<br/>At TestShortCircuitShm.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N110825');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.client.TestShortCircuitShm.testStartupShutdown()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N110825" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.client.TestShortCircuitShm<br/>In method org.apache.hadoop.hdfs.client.TestShortCircuitShm.testStartupShutdown()<br/>Called method java.io.File.mkdirs()<br/>At TestShortCircuitShm.java:[line 53]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N96213');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.hdfs.MiniDFSCluster.addToFile(String, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N96213" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.MiniDFSCluster<br/>In method org.apache.hadoop.hdfs.MiniDFSCluster.addToFile(String, String)<br/>Called method java.io.File.createNewFile()<br/>At MiniDFSCluster.java:[line 2502]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N96283');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.MiniDFSCluster.makeDataNodeDirs(int, StorageType)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N96283" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.MiniDFSCluster<br/>In method org.apache.hadoop.hdfs.MiniDFSCluster.makeDataNodeDirs(int, StorageType)<br/>Called method java.io.File.mkdirs()<br/>At MiniDFSCluster.java:[line 1096]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N96353');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N96353" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.MiniDFSCluster<br/>In method org.apache.hadoop.hdfs.MiniDFSCluster.shutdown(boolean)<br/>Called method java.io.File.delete()<br/>At MiniDFSCluster.java:[line 1566]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N114124');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.testFailToStartWithBadConfig()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N114124" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.qjournal.server.TestJournalNode<br/>In method org.apache.hadoop.hdfs.qjournal.server.TestJournalNode.testFailToStartWithBadConfig()<br/>Called method java.io.File.delete()<br/>At TestJournalNode.java:[line 289]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N114633');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.util.concurrent.locks.Condition.await(long, TimeUnit) ignored in org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.run()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N114633" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor<br/>In method org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.run()<br/>Called method java.util.concurrent.locks.Condition.await(long, TimeUnit)<br/>At CacheReplicationMonitor.java:[line 181]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N121877');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.renameTo(File) ignored in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart.createUnlinkTmpFile(ReplicaInfo, boolean, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N121877" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart<br/>In method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart.createUnlinkTmpFile(ReplicaInfo, boolean, boolean)<br/>Called method java.io.File.renameTo(File)<br/>At TestDatanodeRestart.java:[line 199]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N122223');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica.setup(String, FsDatasetImpl)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N122223" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica<br/>In method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestWriteToReplica.setup(String, FsDatasetImpl)<br/>Called method java.io.File.createNewFile()<br/>At TestWriteToReplica.java:[line 154]<br/>Another occurrence at TestWriteToReplica.java:[line 155]<br/>Another occurrence at TestWriteToReplica.java:[line 165]<br/>Another occurrence at TestWriteToReplica.java:[line 166]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N117633');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery.startUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N117633" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery.startUp()<br/>Called method java.io.File.mkdirs()<br/>At TestBlockRecovery.java:[line 136]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N118275');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.setReadOnly() ignored in org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.testVolumeFailure()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N118275" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.testVolumeFailure()<br/>Called method java.io.File.setReadOnly()<br/>At TestDataNodeVolumeFailure.java:[line 147]<br/>Another occurrence at TestDataNodeVolumeFailure.java:[line 148]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N118627');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.prepareDirToFail(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N118627" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.prepareDirToFail(File)<br/>Called method java.io.File.mkdirs()<br/>At TestDataNodeVolumeFailureToleration.java:[line 250]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N118697');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testValidVolumesAtStartup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N118697" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.testValidVolumesAtStartup()<br/>Called method java.io.File.mkdirs()<br/>At TestDataNodeVolumeFailureToleration.java:[line 106]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N124517');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil.getImageFileMD5IgnoringTxId(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N124517" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil<br/>In method org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil.getImageFileMD5IgnoringTxId(File)<br/>Called method java.io.File.delete()<br/>At FSImageTestUtil.java:[line 114]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N137496');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.renameTo(File) ignored in org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints.testCheckpointCancellation()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N137496" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestStandbyCheckpoints.testCheckpointCancellation()<br/>Called method java.io.File.renameTo(File)<br/>At TestStandbyCheckpoints.java:[line 223]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N140886');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.util.concurrent.ExecutorService.submit(Callable) ignored in org.apache.hadoop.hdfs.server.namenode.startupprogress.TestStartupProgress.testThreadSafety()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N140886" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.startupprogress.TestStartupProgress<br/>In method org.apache.hadoop.hdfs.server.namenode.startupprogress.TestStartupProgress.testThreadSafety()<br/>Called method java.util.concurrent.ExecutorService.submit(Callable)<br/>At TestStartupProgress.java:[line 369]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N126037');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.namenode.TestAllowFormat.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N126037" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestAllowFormat<br/>In method org.apache.hadoop.hdfs.server.namenode.TestAllowFormat.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestAllowFormat.java:[line 79]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N126458');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.namenode.TestBackupNode.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N126458" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestBackupNode<br/>In method org.apache.hadoop.hdfs.server.namenode.TestBackupNode.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestBackupNode.java:[line 78]<br/>Another occurrence at TestBackupNode.java:[line 80]<br/>Another occurrence at TestBackupNode.java:[line 82]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N129256');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.namenode.TestEditLog.testAutoSync()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N129256" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestEditLog<br/>In method org.apache.hadoop.hdfs.server.namenode.TestEditLog.testAutoSync()<br/>Called method java.io.File.mkdirs()<br/>At TestEditLog.java:[line 946]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N129326');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.server.namenode.TestEditLog.testCrashRecovery(int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N129326" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestEditLog<br/>In method org.apache.hadoop.hdfs.server.namenode.TestEditLog.testCrashRecovery(int)<br/>Called method java.io.File.delete()<br/>At TestEditLog.java:[line 681]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N129396');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.renameTo(File) ignored in org.apache.hadoop.hdfs.server.namenode.TestEditLog.testCrashRecovery(int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N129396" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestEditLog<br/>In method org.apache.hadoop.hdfs.server.namenode.TestEditLog.testCrashRecovery(int)<br/>Called method java.io.File.renameTo(File)<br/>At TestEditLog.java:[line 682]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N129466');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.namenode.TestEditLog.testFailedOpen()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N129466" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestEditLog<br/>In method org.apache.hadoop.hdfs.server.namenode.TestEditLog.testFailedOpen()<br/>Called method java.io.File.mkdirs()<br/>At TestEditLog.java:[line 924]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N129536');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.server.namenode.TestEditLogFileOutputStream.deleteEditsFile()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N129536" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestEditLogFileOutputStream<br/>In method org.apache.hadoop.hdfs.server.namenode.TestEditLogFileOutputStream.deleteEditsFile()<br/>Called method java.io.File.delete()<br/>At TestEditLogFileOutputStream.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N129606');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.namenode.TestEditLogJournalFailures.testMultipleRedundantFailedEditsDirOnSetReadyToFlush()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N129606" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestEditLogJournalFailures<br/>In method org.apache.hadoop.hdfs.server.namenode.TestEditLogJournalFailures.testMultipleRedundantFailedEditsDirOnSetReadyToFlush()<br/>Called method java.io.File.mkdirs()<br/>At TestEditLogJournalFailures.java:[line 197]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N132083');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.server.namenode.TestFsck.setupAuditLogs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N132083" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.setupAuditLogs()<br/>Called method java.io.File.delete()<br/>At TestFsck.java:[line 184]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N133565');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N133565" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestNameNodeHttpServer.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N133712');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N133712" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestNameNodeResourceChecker.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N133782');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker.testChecking2NameDirsOnOneVolume()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N133782" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker.testChecking2NameDirsOnOneVolume()<br/>Called method java.io.File.mkdirs()<br/>At TestNameNodeResourceChecker.java:[line 147]<br/>Another occurrence at TestNameNodeResourceChecker.java:[line 148]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N133863');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker.testCheckingExtraVolumes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N133863" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker.testCheckingExtraVolumes()<br/>Called method java.io.File.mkdirs()<br/>At TestNameNodeResourceChecker.java:[line 167]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N133933');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker.testLowResourceVolumePolicy()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N133933" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNameNodeResourceChecker.testLowResourceVolumePolicy()<br/>Called method java.io.File.mkdirs()<br/>At TestNameNodeResourceChecker.java:[line 188]<br/>Another occurrence at TestNameNodeResourceChecker.java:[line 189]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N135777');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.setUpNameDirs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N135777" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestStorageRestore<br/>In method org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.setUpNameDirs()<br/>Called method java.io.File.mkdir()<br/>At TestStorageRestore.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N135847');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.setUpNameDirs()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N135847" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestStorageRestore<br/>In method org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.setUpNameDirs()<br/>Called method java.io.File.mkdirs()<br/>At TestStorageRestore.java:[line 80]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N136273');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testImageUploadTimeout()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N136273" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage<br/>In method org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testImageUploadTimeout()<br/>Called method java.io.File.mkdirs()<br/>At TestTransferFsImage.java:[line 163]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97826');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.TestBlockMissingException.corruptBlock(Path, ExtendedBlock)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97826" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockMissingException<br/>In method org.apache.hadoop.hdfs.TestBlockMissingException.corruptBlock(Path, ExtendedBlock)<br/>Called method java.io.File.delete()<br/>At TestBlockMissingException.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99985');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.TestDFSRollback.deleteMatchingFiles(File[], String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99985" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSRollback<br/>In method org.apache.hadoop.hdfs.TestDFSRollback.deleteMatchingFiles(File[], String)<br/>Called method java.io.File.delete()<br/>At TestDFSRollback.java:[line 340]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102103');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.hdfs.TestDFSShell.createLocalFileWithRandomData(int, File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102103" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.createLocalFileWithRandomData(int, File)<br/>Called method java.io.File.createNewFile()<br/>At TestDFSShell.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102173');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.TestDFSShell.testAppendToFile()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102173" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testAppendToFile()<br/>Called method java.io.File.mkdirs()<br/>At TestDFSShell.java:[line 1788]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102243');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.TestDFSShell.testAppendToFileBadArgs()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102243" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testAppendToFileBadArgs()<br/>Called method java.io.File.mkdirs()<br/>At TestDFSShell.java:[line 1829]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102313');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithForceOption()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102313" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithForceOption()<br/>Called method java.io.File.createNewFile()<br/>At TestDFSShell.java:[line 1623]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102383');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithForceOption()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102383" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testCopyCommandsWithForceOption()<br/>Called method java.io.File.delete()<br/>At TestDFSShell.java:[line 1662]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102453');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.TestDFSShell.testCopyToLocal()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102453" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testCopyToLocal()<br/>Called method java.io.File.delete()<br/>At TestDFSShell.java:[line 731]<br/>Another occurrence at TestDFSShell.java:[line 732]<br/>Another occurrence at TestDFSShell.java:[line 733]<br/>Another occurrence at TestDFSShell.java:[line 734]<br/>Another occurrence at TestDFSShell.java:[line 735]<br/>Another occurrence at TestDFSShell.java:[line 736]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102578');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.TestDFSShell.testGet()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102578" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testGet()<br/>Called method java.io.File.delete()<br/>At TestDFSShell.java:[line 1536]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102648');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.TestDFSShell.testPut()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102648" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testPut()<br/>Called method java.io.File.delete()<br/>At TestDFSShell.java:[line 241]<br/>Another occurrence at TestDFSShell.java:[line 242]<br/>Another occurrence at TestDFSShell.java:[line 319]<br/>Another occurrence at TestDFSShell.java:[line 320]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102751');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.TestDFSShell.testURIPaths()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102751" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testURIPaths()<br/>Called method java.io.File.mkdirs()<br/>At TestDFSShell.java:[line 486]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102821');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.TestDFSShell.testZeroSizeFile()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102821" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testZeroSizeFile()<br/>Called method java.io.File.delete()<br/>At TestDFSShell.java:[line 149]<br/>Another occurrence at TestDFSShell.java:[line 150]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102971');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.TestDFSShellGenericOptions.testConfOption(String[], String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102971" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShellGenericOptions<br/>In method org.apache.hadoop.hdfs.TestDFSShellGenericOptions.testConfOption(String[], String)<br/>Called method java.io.File.delete()<br/>At TestDFSShellGenericOptions.java:[line 88]<br/>Another occurrence at TestDFSShellGenericOptions.java:[line 89]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N105389');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.TestFetchImage.testFetchImage()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N105389" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFetchImage<br/>In method org.apache.hadoop.hdfs.TestFetchImage.testFetchImage()<br/>Called method java.io.File.mkdirs()<br/>At TestFetchImage.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N144387');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.tools.offlineImageViewer.TestDelimitedImageVisitor.testDelimitedImageVisistor()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N144387" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.TestDelimitedImageVisitor<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.TestDelimitedImageVisitor.testDelimitedImageVisistor()<br/>Called method java.io.File.delete()<br/>At TestDelimitedImageVisitor.java:[line 98]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N144457');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.deleteOriginalFSImage()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N144457" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer.deleteOriginalFSImage()<br/>Called method java.io.File.delete()<br/>At TestOfflineImageViewer.java:[line 168]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N142473');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.hdfs.tools.TestDFSHAAdminMiniCluster.testFencer()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N142473" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.TestDFSHAAdminMiniCluster<br/>In method org.apache.hadoop.hdfs.tools.TestDFSHAAdminMiniCluster.testFencer()<br/>Called method java.io.File.delete()<br/>At TestDFSHAAdminMiniCluster.java:[line 173]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N110555');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.UpgradeUtilities.createEmptyDirs(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N110555" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.UpgradeUtilities<br/>In method org.apache.hadoop.hdfs.UpgradeUtilities.createEmptyDirs(String[])<br/>Called method java.io.File.mkdirs()<br/>At UpgradeUtilities.java:[line 223]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N144910');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.util.TestBestEffortLongFile.cleanup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N144910" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestBestEffortLongFile<br/>In method org.apache.hadoop.hdfs.util.TestBestEffortLongFile.cleanup()<br/>Called method java.io.File.mkdirs()<br/>At TestBestEffortLongFile.java:[line 41]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N145842');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.web.TestHftpFileSystem.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N145842" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.web.TestHftpFileSystem<br/>In method org.apache.hadoop.hdfs.web.TestHftpFileSystem.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestHftpFileSystem.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N145912');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.hdfs.web.TestHttpsFileSystem.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N145912" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.web.TestHttpsFileSystem<br/>In method org.apache.hadoop.hdfs.web.TestHttpsFileSystem.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestHttpsFileSystem.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N146991');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.http.TestHttpCookieFlag.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N146991" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.http.TestHttpCookieFlag<br/>In method org.apache.hadoop.http.TestHttpCookieFlag.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestHttpCookieFlag.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N147253');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.http.TestSSLHttpServer.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N147253" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.http.TestSSLHttpServer<br/>In method org.apache.hadoop.http.TestSSLHttpServer.setup()<br/>Called method java.io.File.mkdirs()<br/>At TestSSLHttpServer.java:[line 64]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N152631');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.io.compress.TestCodec.verifyGzipFile(String, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N152631" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.TestCodec<br/>In method org.apache.hadoop.io.compress.TestCodec.verifyGzipFile(String, String)<br/>Called method java.io.File.delete()<br/>At TestCodec.java:[line 771]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N160920');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.io.nativeio.TestNativeIO.setupTestDir()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N160920" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestNativeIO<br/>In method org.apache.hadoop.io.nativeio.TestNativeIO.setupTestDir()<br/>Called method java.io.File.mkdirs()<br/>At TestNativeIO.java:[line 69]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N161278');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory.testCleanupRemainders()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N161278" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory<br/>In method org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory.testCleanupRemainders()<br/>Called method java.io.File.mkdirs()<br/>At TestSharedFileDescriptorFactory.java:[line 76]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N161348');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory.testDirectoryFallbacks()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N161348" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory<br/>In method org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory.testDirectoryFallbacks()<br/>Called method java.io.File.mkdirs()<br/>At TestSharedFileDescriptorFactory.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N161418');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory.testReadAndWrite()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N161418" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory<br/>In method org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory.testReadAndWrite()<br/>Called method java.io.File.mkdirs()<br/>At TestSharedFileDescriptorFactory.java:[line 50]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N149184');">
<td>
<span class="priority-2">RV</span>
</td>
<td>org.apache.hadoop.io.TestBytesWritable.testCompare() negates the return value of org.apache.hadoop.io.BinaryComparable.compareTo(BinaryComparable)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N149184" style="display: none;">
<a href="#RV_NEGATING_RESULT_OF_COMPARETO">Bug type RV_NEGATING_RESULT_OF_COMPARETO (click for details)</a>
<br/>In class org.apache.hadoop.io.TestBytesWritable<br/>In method org.apache.hadoop.io.TestBytesWritable.testCompare()<br/>Called method org.apache.hadoop.io.BinaryComparable.compareTo(BinaryComparable)<br/>Return value of org.apache.hadoop.io.BinaryComparable.compareTo(BinaryComparable) of type int<br/>At TestBytesWritable.java:[line 82]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N149976');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.io.TestIOUtils.testWriteFully()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N149976" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.io.TestIOUtils<br/>In method org.apache.hadoop.io.TestIOUtils.testWriteFully()<br/>Called method java.io.File.delete()<br/>At TestIOUtils.java:[line 154]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N150376');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.io.TestSecureIOUtils.removeTestFile()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N150376" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.io.TestSecureIOUtils<br/>In method org.apache.hadoop.io.TestSecureIOUtils.removeTestFile()<br/>Called method java.io.File.delete()<br/>At TestSecureIOUtils.java:[line 146]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N165281');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.serviceHadoopConfCustomDir()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N165281" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService<br/>In method org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.serviceHadoopConfCustomDir()<br/>Called method java.io.File.mkdirs()<br/>At TestFileSystemAccessService.java:[line 173]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N185168');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapred.pipes.TestPipeApplication.cleanTokenPasswordFile()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N185168" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.cleanTokenPasswordFile()<br/>Called method java.io.File.delete()<br/>At TestPipeApplication.java:[line 517]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N185238');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N185238" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String)<br/>Called method java.io.File.createNewFile()<br/>At TestPipeApplication.java:[line 529]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N185308');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N185308" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String)<br/>Called method java.io.File.mkdirs()<br/>At TestPipeApplication.java:[line 527]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N185378');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.pipes.TestPipeApplication.initStdOut(JobConf)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N185378" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.initStdOut(JobConf)<br/>Called method java.io.File.mkdirs()<br/>At TestPipeApplication.java:[line 467]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N170224');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapred.TestCommandLineJobSubmission.testJobShell()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N170224" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestCommandLineJobSubmission<br/>In method org.apache.hadoop.mapred.TestCommandLineJobSubmission.testJobShell()<br/>Called method java.io.File.delete()<br/>At TestCommandLineJobSubmission.java:[line 129]<br/>Another occurrence at TestCommandLineJobSubmission.java:[line 130]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N171119');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapred.TestFadvisedFileRegion.testCustomShuffleTransfer()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N171119" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFadvisedFileRegion<br/>In method org.apache.hadoop.mapred.TestFadvisedFileRegion.testCustomShuffleTransfer()<br/>Called method java.io.File.delete()<br/>At TestFadvisedFileRegion.java:[line 130]<br/>Another occurrence at TestFadvisedFileRegion.java:[line 131]<br/>Another occurrence at TestFadvisedFileRegion.java:[line 132]<br/>Another occurrence at TestFadvisedFileRegion.java:[line 133]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N171222');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestFadvisedFileRegion.testCustomShuffleTransfer()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N171222" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFadvisedFileRegion<br/>In method org.apache.hadoop.mapred.TestFadvisedFileRegion.testCustomShuffleTransfer()<br/>Called method java.io.File.mkdirs()<br/>At TestFadvisedFileRegion.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N172350');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestJobEndNotifier.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N172350" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobEndNotifier<br/>In method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestJobEndNotifier.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N173648');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestLocalDistributedCacheManager.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N173648" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestLocalDistributedCacheManager<br/>In method org.apache.hadoop.mapred.TestLocalDistributedCacheManager.setup()<br/>Called method java.io.File.mkdirs()<br/>At TestLocalDistributedCacheManager.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N174066');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestMRCJCJobConf.testFindContainingJarWithPlus()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N174066" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMRCJCJobConf<br/>In method org.apache.hadoop.mapred.TestMRCJCJobConf.testFindContainingJarWithPlus()<br/>Called method java.io.File.mkdirs()<br/>At TestMRCJCJobConf.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N174205');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapred.TestMRWithDistributedCache.testLocalJobRunner()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N174205" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMRWithDistributedCache<br/>In method org.apache.hadoop.mapred.TestMRWithDistributedCache.testLocalJobRunner()<br/>Called method java.io.File.delete()<br/>At TestMRWithDistributedCache.java:[line 192]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N175258');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.mapred.TestMultiFileSplit.testgetLocations()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N175258" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMultiFileSplit<br/>In method org.apache.hadoop.mapred.TestMultiFileSplit.testgetLocations()<br/>Called method java.io.File.createNewFile()<br/>At TestMultiFileSplit.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N175827');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestQueue.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N175827" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestQueue<br/>In method org.apache.hadoop.mapred.TestQueue.setup()<br/>Called method java.io.File.mkdirs()<br/>At TestQueue.java:[line 50]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N175897');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapred.TestQueue.testQueue()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N175897" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestQueue<br/>In method org.apache.hadoop.mapred.TestQueue.testQueue()<br/>Called method java.io.File.delete()<br/>At TestQueue.java:[line 165]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N176961');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N176961" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration)<br/>Called method java.io.File.createNewFile()<br/>At TestShuffleHandler.java:[line 635]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N177031');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N177031" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration)<br/>Called method java.io.File.delete()<br/>At TestShuffleHandler.java:[line 633]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N177101');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestShuffleHandler.createShuffleHandlerFiles(File, String, String, String, Configuration, List)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N177101" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.createShuffleHandlerFiles(File, String, String, String, Configuration, List)<br/>Called method java.io.File.mkdirs()<br/>At TestShuffleHandler.java:[line 609]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N177240');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.mapred.TestTaskLog.testTaskLog()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N177240" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTaskLog<br/>In method org.apache.hadoop.mapred.TestTaskLog.testTaskLog()<br/>Called method java.io.File.createNewFile()<br/>At TestTaskLog.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N177310');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapred.TestTaskLog.testTaskLog()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N177310" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTaskLog<br/>In method org.apache.hadoop.mapred.TestTaskLog.testTaskLog()<br/>Called method java.io.File.delete()<br/>At TestTaskLog.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N177380');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestTaskLog.testTaskLog()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N177380" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTaskLog<br/>In method org.apache.hadoop.mapred.TestTaskLog.testTaskLog()<br/>Called method java.io.File.mkdirs()<br/>At TestTaskLog.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N178632');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapred.TestYARNRunner.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N178632" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestYARNRunner<br/>In method org.apache.hadoop.mapred.TestYARNRunner.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestYARNRunner.java:[line 148]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N191973');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader.testProgressIsReportedIfInputASeriesOfEmptyFiles()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N191973" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader<br/>In method org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader.testProgressIsReportedIfInputASeriesOfEmptyFiles()<br/>Called method java.io.File.mkdir()<br/>At TestCombineFileRecordReader.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N195447');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.cleanUpMiniClusterSpecialConfig()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N195447" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle<br/>In method org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.cleanUpMiniClusterSpecialConfig()<br/>Called method java.io.File.delete()<br/>At TestEncryptedShuffle.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N195517');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.createCustomYarnClasspath()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N195517" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle<br/>In method org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.createCustomYarnClasspath()<br/>Called method java.io.File.delete()<br/>At TestEncryptedShuffle.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N195587');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N195587" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle<br/>In method org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestEncryptedShuffle.java:[line 64]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N195151');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapreduce.security.TestMRCredentials.tearDown()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N195151" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.TestMRCredentials<br/>In method org.apache.hadoop.mapreduce.security.TestMRCredentials.tearDown()<br/>Called method java.io.File.delete()<br/>At TestMRCredentials.java:[line 78]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N195657');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsNewSplits()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N195657" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.split.TestJobSplitWriter<br/>In method org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsNewSplits()<br/>Called method java.io.File.mkdirs()<br/>At TestJobSplitWriter.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N195727');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N195727" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.split.TestJobSplitWriter<br/>In method org.apache.hadoop.mapreduce.split.TestJobSplitWriter.testMaxBlockLocationsOldSplits()<br/>Called method java.io.File.mkdirs()<br/>At TestJobSplitWriter.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N197364');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.testMRAsyncDiskService()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N197364" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService<br/>In method org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.testMRAsyncDiskService()<br/>Called method java.io.File.mkdirs()<br/>At TestMRAsyncDiskService.java:[line 185]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 186]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 187]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 188]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N197467');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.testMRAsyncDiskServiceMoveAndDeleteAllVolumes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N197467" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService<br/>In method org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.testMRAsyncDiskServiceMoveAndDeleteAllVolumes()<br/>Called method java.io.File.mkdirs()<br/>At TestMRAsyncDiskService.java:[line 246]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 247]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 248]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 249]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N197570');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.testMRAsyncDiskServiceStartupCleaning()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N197570" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService<br/>In method org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.testMRAsyncDiskServiceStartupCleaning()<br/>Called method java.io.File.mkdirs()<br/>At TestMRAsyncDiskService.java:[line 293]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 294]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 295]<br/>Another occurrence at TestMRAsyncDiskService.java:[line 296]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N200846');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler.cleanup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N200846" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler<br/>In method org.apache.hadoop.mapreduce.v2.app.commit.TestCommitterEventHandler.cleanup()<br/>Called method java.io.File.mkdirs()<br/>At TestCommitterEventHandler.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N200916');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl.cleanup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N200916" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl<br/>In method org.apache.hadoop.mapreduce.v2.app.job.impl.TestJobImpl.cleanup()<br/>Called method java.io.File.mkdirs()<br/>At TestJobImpl.java:[line 116]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N199749');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.app.MRApp.submit(Configuration, boolean, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N199749" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MRApp<br/>In method org.apache.hadoop.mapreduce.v2.app.MRApp.submit(Configuration, boolean, boolean)<br/>Called method java.io.File.mkdirs()<br/>At MRApp.java:[line 306]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N200380');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.cleanup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N200380" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster<br/>In method org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.cleanup()<br/>Called method java.io.File.mkdirs()<br/>At TestMRAppMaster.java:[line 106]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N200450');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N200450" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster<br/>In method org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.setup()<br/>Called method java.io.File.mkdir()<br/>At TestMRAppMaster.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N200520');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterCredentials()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N200520" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster<br/>In method org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterCredentials()<br/>Called method java.io.File.mkdirs()<br/>At TestMRAppMaster.java:[line 394]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N200590');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterMaxAppAttempts()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N200590" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster<br/>In method org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterMaxAppAttempts()<br/>Called method java.io.File.mkdirs()<br/>At TestMRAppMaster.java:[line 303]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N204105');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N204105" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.setUp()<br/>Called method java.io.File.mkdir()<br/>At TestAMWebServicesJobConf.java:[line 141]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N206368');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerFileSystemStateStoreService.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N206368" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerFileSystemStateStoreService<br/>In method org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerFileSystemStateStoreService.setup()<br/>Called method java.io.File.mkdirs()<br/>At TestHistoryServerFileSystemStateStoreService.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N208030');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N208030" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.setUp()<br/>Called method java.io.File.mkdir()<br/>At TestHsWebServicesJobConf.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N198283');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapreduce.v2.TestMRJobs.createAndAddJarToJar(JarOutputStream, File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N198283" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobs<br/>In method org.apache.hadoop.mapreduce.v2.TestMRJobs.createAndAddJarToJar(JarOutputStream, File)<br/>Called method java.io.File.delete()<br/>At TestMRJobs.java:[line 830]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N198353');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N198353" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobs<br/>In method org.apache.hadoop.mapreduce.v2.TestMRJobs.testDistributedCache()<br/>Called method java.io.File.delete()<br/>At TestMRJobs.java:[line 763]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N210663');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.mapreduce.v2.util.TestMRApps.setupTestDirs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N210663" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.util.TestMRApps<br/>In method org.apache.hadoop.mapreduce.v2.util.TestMRApps.setupTestDirs()<br/>Called method java.io.File.mkdirs()<br/>At TestMRApps.java:[line 72]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N212245');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.metrics2.sink.TestFileSink.after()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N212245" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.sink.TestFileSink<br/>In method org.apache.hadoop.metrics2.sink.TestFileSink.after()<br/>Called method java.io.File.delete()<br/>At TestFileSink.java:[line 134]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N212315');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.metrics2.sink.TestFileSink.getTestTempFile(String, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N212315" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.sink.TestFileSink<br/>In method org.apache.hadoop.metrics2.sink.TestFileSink.getTestTempFile(String, String)<br/>Called method java.io.File.mkdirs()<br/>At TestFileSink.java:[line 79]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N213678');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in new org.apache.hadoop.net.unix.TemporarySocketDirectory()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N213678" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.net.unix.TemporarySocketDirectory<br/>In method new org.apache.hadoop.net.unix.TemporarySocketDirectory()<br/>Called method java.io.File.mkdirs()<br/>At TemporarySocketDirectory.java:[line 40]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N219699');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.security.ssl.KeyStoreTestUtil.cleanupSSLConfig(String, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N219699" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.security.ssl.KeyStoreTestUtil<br/>In method org.apache.hadoop.security.ssl.KeyStoreTestUtil.cleanupSSLConfig(String, String)<br/>Called method java.io.File.delete()<br/>At KeyStoreTestUtil.java:[line 192]<br/>Another occurrence at KeyStoreTestUtil.java:[line 194]<br/>Another occurrence at KeyStoreTestUtil.java:[line 196]<br/>Another occurrence at KeyStoreTestUtil.java:[line 198]<br/>Another occurrence at KeyStoreTestUtil.java:[line 200]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N219901');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.security.ssl.TestReloadingX509TrustManager.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N219901" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.security.ssl.TestReloadingX509TrustManager<br/>In method org.apache.hadoop.security.ssl.TestReloadingX509TrustManager.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestReloadingX509TrustManager.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N219971');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.setLastModified(long) ignored in org.apache.hadoop.security.ssl.TestReloadingX509TrustManager.testReloadCorruptTrustStore()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N219971" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.security.ssl.TestReloadingX509TrustManager<br/>In method org.apache.hadoop.security.ssl.TestReloadingX509TrustManager.testReloadCorruptTrustStore()<br/>Called method java.io.File.setLastModified(long)<br/>At TestReloadingX509TrustManager.java:[line 162]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N220041');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.security.ssl.TestReloadingX509TrustManager.testReloadMissingTrustStore()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N220041" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.security.ssl.TestReloadingX509TrustManager<br/>In method org.apache.hadoop.security.ssl.TestReloadingX509TrustManager.testReloadMissingTrustStore()<br/>Called method java.io.File.delete()<br/>At TestReloadingX509TrustManager.java:[line 132]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N220111');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.security.ssl.TestSSLFactory.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N220111" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.security.ssl.TestSSLFactory<br/>In method org.apache.hadoop.security.ssl.TestSSLFactory.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestSSLFactory.java:[line 50]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N217372');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.security.TestAuthenticationFilter.testConfiguration()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N217372" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.security.TestAuthenticationFilter<br/>In method org.apache.hadoop.security.TestAuthenticationFilter.testConfiguration()<br/>Called method java.io.File.mkdirs()<br/>At TestAuthenticationFilter.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N217442');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.security.TestCredentials.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N217442" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.security.TestCredentials<br/>In method org.apache.hadoop.security.TestCredentials.setUp()<br/>Called method java.io.File.mkdir()<br/>At TestCredentials.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N217512');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.security.TestCredentials.tearDown()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N217512" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.security.TestCredentials<br/>In method org.apache.hadoop.security.TestCredentials.tearDown()<br/>Called method java.io.File.delete()<br/>At TestCredentials.java:[line 60]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N217582');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.security.TestCredentials.testReadWriteStorage()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N217582" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.security.TestCredentials<br/>In method org.apache.hadoop.security.TestCredentials.testReadWriteStorage()<br/>Called method java.io.File.delete()<br/>At TestCredentials.java:[line 135]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N217862');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.security.TestLdapGroupsMapping.testExtractPassword()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N217862" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.security.TestLdapGroupsMapping<br/>In method org.apache.hadoop.security.TestLdapGroupsMapping.testExtractPassword()<br/>Called method java.io.File.mkdirs()<br/>At TestLdapGroupsMapping.java:[line 147]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N218260');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.security.TestRefreshUserMappings.tearDown()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N218260" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.security.TestRefreshUserMappings<br/>In method org.apache.hadoop.security.TestRefreshUserMappings.tearDown()<br/>Called method java.io.File.delete()<br/>At TestRefreshUserMappings.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N221993');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.streaming.TestRawBytesStreaming.testCommandLine()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N221993" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestRawBytesStreaming<br/>In method org.apache.hadoop.streaming.TestRawBytesStreaming.testCommandLine()<br/>Called method java.io.File.delete()<br/>At TestRawBytesStreaming.java:[line 76]<br/>Another occurrence at TestRawBytesStreaming.java:[line 85]<br/>Another occurrence at TestRawBytesStreaming.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N222085');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.streaming.TestStreamAggregate.testCommandLine()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N222085" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamAggregate<br/>In method org.apache.hadoop.streaming.TestStreamAggregate.testCommandLine()<br/>Called method java.io.File.delete()<br/>At TestStreamAggregate.java:[line 88]<br/>Another occurrence at TestStreamAggregate.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N222166');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.streaming.TestStreamDataProtocol.testCommandLine()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N222166" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamDataProtocol<br/>In method org.apache.hadoop.streaming.TestStreamDataProtocol.testCommandLine()<br/>Called method java.io.File.delete()<br/>At TestStreamDataProtocol.java:[line 101]<br/>Another occurrence at TestStreamDataProtocol.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N223017');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.streaming.TestStreamingKeyValue.runStreamJob(String, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N223017" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamingKeyValue<br/>In method org.apache.hadoop.streaming.TestStreamingKeyValue.runStreamJob(String, boolean)<br/>Called method java.io.File.delete()<br/>At TestStreamingKeyValue.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N223087');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.streaming.TestStreamingSeparator.testCommandLine()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N223087" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamingSeparator<br/>In method org.apache.hadoop.streaming.TestStreamingSeparator.testCommandLine()<br/>Called method java.io.File.delete()<br/>At TestStreamingSeparator.java:[line 107]<br/>Another occurrence at TestStreamingSeparator.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N222247');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.streaming.TestStreamReduceNone.testCommandLine()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N222247" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamReduceNone<br/>In method org.apache.hadoop.streaming.TestStreamReduceNone.testCommandLine()<br/>Called method java.io.File.delete()<br/>At TestStreamReduceNone.java:[line 100]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N223652');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.streaming.TestTypedBytesStreaming.cleanupOutput()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N223652" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestTypedBytesStreaming<br/>In method org.apache.hadoop.streaming.TestTypedBytesStreaming.cleanupOutput()<br/>Called method java.io.File.delete()<br/>At TestTypedBytesStreaming.java:[line 71]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N223722');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.streaming.TestTypedBytesStreaming.testCommandLine()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N223722" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestTypedBytesStreaming<br/>In method org.apache.hadoop.streaming.TestTypedBytesStreaming.testCommandLine()<br/>Called method java.io.File.delete()<br/>At TestTypedBytesStreaming.java:[line 84]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N223792');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.streaming.TestUnconsumedInput.testUnconsumedInput()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N223792" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestUnconsumedInput<br/>In method org.apache.hadoop.streaming.TestUnconsumedInput.testUnconsumedInput()<br/>Called method java.io.File.delete()<br/>At TestUnconsumedInput.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N224262');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.streaming.UtilTest.redirectIfAntJunit()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N224262" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.UtilTest<br/>In method org.apache.hadoop.streaming.UtilTest.redirectIfAntJunit()<br/>Called method java.io.File.mkdirs()<br/>At UtilTest.java:[line 80]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N225159');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.test.PathUtils.getTestDir(Class, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N225159" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.test.PathUtils<br/>In method org.apache.hadoop.test.PathUtils.getTestDir(Class, boolean)<br/>Called method java.io.File.mkdirs()<br/>At PathUtils.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N229850');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.util.JarFinder.getJar(Class)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N229850" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.JarFinder<br/>In method org.apache.hadoop.util.JarFinder.getJar(Class)<br/>Called method java.io.File.mkdirs()<br/>At JarFinder.java:[line 153]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N231106');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.util.TestDiskChecker._checkDirs(boolean, String, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N231106" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestDiskChecker<br/>In method org.apache.hadoop.util.TestDiskChecker._checkDirs(boolean, String, boolean)<br/>Called method java.io.File.delete()<br/>At TestDiskChecker.java:[line 167]<br/>Another occurrence at TestDiskChecker.java:[line 179]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N231187');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.util.TestDiskChecker._checkDirs(boolean, String, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N231187" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestDiskChecker<br/>In method org.apache.hadoop.util.TestDiskChecker._checkDirs(boolean, String, boolean)<br/>Called method java.io.File.mkdir()<br/>At TestDiskChecker.java:[line 168]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N231257');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.util.TestDiskChecker._checkDirs(boolean, FsPermission, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N231257" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestDiskChecker<br/>In method org.apache.hadoop.util.TestDiskChecker._checkDirs(boolean, FsPermission, boolean)<br/>Called method java.io.File.delete()<br/>At TestDiskChecker.java:[line 118]<br/>Another occurrence at TestDiskChecker.java:[line 130]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N231338');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.util.TestDiskChecker._checkDirs(boolean, FsPermission, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N231338" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestDiskChecker<br/>In method org.apache.hadoop.util.TestDiskChecker._checkDirs(boolean, FsPermission, boolean)<br/>Called method java.io.File.mkdir()<br/>At TestDiskChecker.java:[line 119]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N231547');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.util.TestGenericOptionsParser.testTokenCacheOption()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N231547" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestGenericOptionsParser<br/>In method org.apache.hadoop.util.TestGenericOptionsParser.testTokenCacheOption()<br/>Called method java.io.File.delete()<br/>At TestGenericOptionsParser.java:[line 158]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N232858');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.util.TestHostsFileReader.tearDown()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N232858" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestHostsFileReader<br/>In method org.apache.hadoop.util.TestHostsFileReader.tearDown()<br/>Called method java.io.File.delete()<br/>At TestHostsFileReader.java:[line 48]<br/>Another occurrence at TestHostsFileReader.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N233511');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.util.TestJarFinder.testExistingManifest()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N233511" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestJarFinder<br/>In method org.apache.hadoop.util.TestJarFinder.testExistingManifest()<br/>Called method java.io.File.mkdirs()<br/>At TestJarFinder.java:[line 85]<br/>Another occurrence at TestJarFinder.java:[line 88]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N233592');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.util.TestJarFinder.testNoManifest()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N233592" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestJarFinder<br/>In method org.apache.hadoop.util.TestJarFinder.testNoManifest()<br/>Called method java.io.File.mkdirs()<br/>At TestJarFinder.java:[line 113]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N233907');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.util.TestMRCJCRunJar.testRunjar()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N233907" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestMRCJCRunJar<br/>In method org.apache.hadoop.util.TestMRCJCRunJar.testRunjar()<br/>Called method java.io.File.delete()<br/>At TestMRCJCRunJar.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N234116');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.util.TestRunJar.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N234116" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestRunJar<br/>In method org.apache.hadoop.util.TestRunJar.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestRunJar.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N234255');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.util.TestShell.testShellCommandTimeout()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N234255" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestShell<br/>In method org.apache.hadoop.util.TestShell.testShellCommandTimeout()<br/>Called method java.io.File.delete()<br/>At TestShell.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N235092');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.util.TestWinUtils.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N235092" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestWinUtils.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N235162');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.util.TestWinUtils.testBasicChmod()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N235162" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.testBasicChmod()<br/>Called method java.io.File.createNewFile()<br/>At TestWinUtils.java:[line 231]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N235232');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.util.TestWinUtils.testBasicChmodOnDir()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N235232" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.testBasicChmodOnDir()<br/>Called method java.io.File.createNewFile()<br/>At TestWinUtils.java:[line 306]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N235302');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.util.TestWinUtils.testBasicChmodOnDir()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N235302" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.testBasicChmodOnDir()<br/>Called method java.io.File.mkdirs()<br/>At TestWinUtils.java:[line 282]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N235372');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.util.TestWinUtils.testChmodInternal(String, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N235372" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.testChmodInternal(String, String)<br/>Called method java.io.File.delete()<br/>At TestWinUtils.java:[line 164]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N235442');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.util.TestWinUtils.testLs()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N235442" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.testLs()<br/>Called method java.io.File.delete()<br/>At TestWinUtils.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N235512');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.util.TestWinUtils.testNewFileChmodInternal(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N235512" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.testNewFileChmodInternal(String)<br/>Called method java.io.File.delete()<br/>At TestWinUtils.java:[line 184]<br/>Another occurrence at TestWinUtils.java:[line 185]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N235732');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.util.TestZKUtil.testConfIndirection()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N235732" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestZKUtil<br/>In method org.apache.hadoop.util.TestZKUtil.testConfIndirection()<br/>Called method java.io.File.mkdirs()<br/>At TestZKUtil.java:[line 132]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N237719');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithCustomLogPropertyFile()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N237719" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell<br/>In method org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithCustomLogPropertyFile()<br/>Called method java.io.File.delete()<br/>At TestDistributedShell.java:[line 252]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N237789');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithCustomLogPropertyFile()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N237789" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell<br/>In method org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithCustomLogPropertyFile()<br/>Called method java.io.File.mkdirs()<br/>At TestDistributedShell.java:[line 249]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N237859');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithShellScript()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N237859" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell<br/>In method org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithShellScript()<br/>Called method java.io.File.delete()<br/>At TestDistributedShell.java:[line 381]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N237929');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithShellScript()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N237929" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell<br/>In method org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithShellScript()<br/>Called method java.io.File.mkdirs()<br/>At TestDistributedShell.java:[line 378]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N243926');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.lib.TestZKClient.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N243926" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.lib.TestZKClient<br/>In method org.apache.hadoop.yarn.lib.TestZKClient.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestZKClient.java:[line 145]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N245099');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in new org.apache.hadoop.yarn.server.MiniYARNCluster(String, int, int, int, int, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N245099" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.MiniYARNCluster<br/>In method new org.apache.hadoop.yarn.server.MiniYARNCluster(String, int, int, int, int, boolean)<br/>Called method java.io.File.mkdirs()<br/>At MiniYARNCluster.java:[line 166]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N248925');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N248925" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.setup()<br/>Called method java.io.File.mkdir()<br/>At BaseContainerManagerTest.java:[line 156]<br/>Another occurrence at BaseContainerManagerTest.java:[line 157]<br/>Another occurrence at BaseContainerManagerTest.java:[line 158]<br/>Another occurrence at BaseContainerManagerTest.java:[line 159]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N250662');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.util.concurrent.ExecutorService.submit(Callable) ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle(ContainersLauncherEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N250662" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher.handle(ContainersLauncherEvent)<br/>Called method java.util.concurrent.ExecutorService.submit(Callable)<br/>At ContainersLauncher.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N251480');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerLaunchStdoutAndStderrDiagnostics()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N251480" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerLaunchStdoutAndStderrDiagnostics()<br/>Called method java.io.File.delete()<br/>At TestContainerLaunch.java:[line 359]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N251550');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testInvalidEnvSyntaxDiagnostics()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N251550" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testInvalidEnvSyntaxDiagnostics()<br/>Called method java.io.File.delete()<br/>At TestContainerLaunch.java:[line 285]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N251620');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testInvalidSymlinkDiagnostics()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N251620" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testInvalidSymlinkDiagnostics()<br/>Called method java.io.File.delete()<br/>At TestContainerLaunch.java:[line 228]<br/>Another occurrence at TestContainerLaunch.java:[line 232]<br/>Another occurrence at TestContainerLaunch.java:[line 236]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N251712');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testSpecialCharSymlinks()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N251712" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testSpecialCharSymlinks()<br/>Called method java.io.File.delete()<br/>At TestContainerLaunch.java:[line 157]<br/>Another occurrence at TestContainerLaunch.java:[line 161]<br/>Another occurrence at TestContainerLaunch.java:[line 165]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N253811');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in new org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N253811" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method new org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService()<br/>Called method java.io.File.mkdir()<br/>At TestLogAggregationService.java:[line 128]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N253881');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testAppLogDirCreation()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N253881" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testAppLogDirCreation()<br/>Called method java.io.File.mkdir()<br/>At TestLogAggregationService.java:[line 564]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N253951');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testLocalFileDeletionAfterUpload()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N253951" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testLocalFileDeletionAfterUpload()<br/>Called method java.io.File.mkdir()<br/>At TestLogAggregationService.java:[line 171]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N254021');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testMultipleAppsLogAggregation()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N254021" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testMultipleAppsLogAggregation()<br/>Called method java.io.File.mkdir()<br/>At TestLogAggregationService.java:[line 302]<br/>Another occurrence at TestLogAggregationService.java:[line 323]<br/>Another occurrence at TestLogAggregationService.java:[line 347]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N254113');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testNoContainerOnNode()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N254113" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testNoContainerOnNode()<br/>Called method java.io.File.mkdir()<br/>At TestLogAggregationService.java:[line 249]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N254183');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testVerifyAndCreateRemoteDirNonExistence()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N254183" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testVerifyAndCreateRemoteDirNonExistence()<br/>Called method java.io.File.delete()<br/>At TestLogAggregationService.java:[line 511]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N254253');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testVerifyAndCreateRemoteDirsFailure()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N254253" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testVerifyAndCreateRemoteDirsFailure()<br/>Called method java.io.File.mkdir()<br/>At TestLogAggregationService.java:[line 469]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N254323');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.writeContainerLogs(File, ContainerId)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N254323" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.writeContainerLogs(File, ContainerId)<br/>Called method java.io.File.mkdir()<br/>At TestLogAggregationService.java:[line 680]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N250284');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerSetup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N250284" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerSetup()<br/>Called method java.io.File.mkdirs()<br/>At TestContainerManager.java:[line 183]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N250354');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testLocalFilesCleanup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N250354" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testLocalFilesCleanup()<br/>Called method java.io.File.mkdirs()<br/>At TestContainerManager.java:[line 471]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N246760');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.yarn.server.nodemanager.TestDirectoryCollection.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N246760" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestDirectoryCollection<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestDirectoryCollection.setup()<br/>Called method java.io.File.createNewFile()<br/>At TestDirectoryCollection.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N246830');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.nodemanager.TestDirectoryCollection.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N246830" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestDirectoryCollection<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestDirectoryCollection.setup()<br/>Called method java.io.File.mkdirs()<br/>At TestDirectoryCollection.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N246900');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.yarn.server.nodemanager.TestEventFlow.testSuccessfulContainerLaunch()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N246900" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestEventFlow<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestEventFlow.testSuccessfulContainerLaunch()<br/>Called method java.io.File.mkdir()<br/>At TestEventFlow.java:[line 75]<br/>Another occurrence at TestEventFlow.java:[line 76]<br/>Another occurrence at TestEventFlow.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N247130');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutorWithMocks.deleteMockParamFile()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N247130" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutorWithMocks<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutorWithMocks.deleteMockParamFile()<br/>Called method java.io.File.delete()<br/>At TestLinuxContainerExecutorWithMocks.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N247200');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.yarn.server.nodemanager.TestLocalDirsHandlerService.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N247200" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestLocalDirsHandlerService<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestLocalDirsHandlerService.setup()<br/>Called method java.io.File.createNewFile()<br/>At TestLocalDirsHandlerService.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N247270');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.nodemanager.TestLocalDirsHandlerService.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N247270" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestLocalDirsHandlerService<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestLocalDirsHandlerService.setup()<br/>Called method java.io.File.mkdirs()<br/>At TestLocalDirsHandlerService.java:[line 41]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N247697');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N247697" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService.setup()<br/>Called method java.io.File.mkdirs()<br/>At TestNodeHealthService.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N247837');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerReboot.testClearLocalDirWhenNodeReboot()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N247837" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerReboot<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerReboot.testClearLocalDirWhenNodeReboot()<br/>Called method java.io.File.mkdirs()<br/>At TestNodeManagerReboot.java:[line 110]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N247987');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerResync.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N247987" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerResync<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerResync.setup()<br/>Called method java.io.File.mkdirs()<br/>At TestNodeManagerResync.java:[line 84]<br/>Another occurrence at TestNodeManagerResync.java:[line 85]<br/>Another occurrence at TestNodeManagerResync.java:[line 86]<br/>Another occurrence at TestNodeManagerResync.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N248228');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N248228" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.setup()<br/>Called method java.io.File.mkdirs()<br/>At TestNodeManagerShutdown.java:[line 94]<br/>Another occurrence at TestNodeManagerShutdown.java:[line 95]<br/>Another occurrence at TestNodeManagerShutdown.java:[line 96]<br/>Another occurrence at TestNodeManagerShutdown.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N248470');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.nodemanager.TestNodeStatusUpdater.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N248470" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeStatusUpdater<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestNodeStatusUpdater.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestNodeStatusUpdater.java:[line 123]<br/>Another occurrence at TestNodeStatusUpdater.java:[line 124]<br/>Another occurrence at TestNodeStatusUpdater.java:[line 125]<br/>Another occurrence at TestNodeStatusUpdater.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N255546');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.nodemanager.util.TestProcessIdFileReader.testComplexGet()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N255546" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.util.TestProcessIdFileReader<br/>In method org.apache.hadoop.yarn.server.nodemanager.util.TestProcessIdFileReader.testComplexGet()<br/>Called method java.io.File.delete()<br/>At TestProcessIdFileReader.java:[line 106]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N255616');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.nodemanager.util.TestProcessIdFileReader.testSimpleGet()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N255616" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.util.TestProcessIdFileReader<br/>In method org.apache.hadoop.yarn.server.nodemanager.util.TestProcessIdFileReader.testSimpleGet()<br/>Called method java.io.File.delete()<br/>At TestProcessIdFileReader.java:[line 71]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N255949');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage.testContainerLogPageAccess()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N255949" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage.testContainerLogPageAccess()<br/>Called method java.io.File.createNewFile()<br/>At TestContainerLogsPage.java:[line 161]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N256019');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage.testContainerLogPageAccess()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N256019" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage.testContainerLogPageAccess()<br/>Called method java.io.File.delete()<br/>At TestContainerLogsPage.java:[line 198]<br/>Another occurrence at TestContainerLogsPage.java:[line 201]<br/>Another occurrence at TestContainerLogsPage.java:[line 204]<br/>Another occurrence at TestContainerLogsPage.java:[line 207]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N256122');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage.testContainerLogPageAccess()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N256122" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage.testContainerLogPageAccess()<br/>Called method java.io.File.mkdir()<br/>At TestContainerLogsPage.java:[line 124]<br/>Another occurrence at TestContainerLogsPage.java:[line 157]<br/>Another occurrence at TestContainerLogsPage.java:[line 159]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N256440');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N256440" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer.setup()<br/>Called method java.io.File.mkdir()<br/>At TestNMWebServer.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N256510');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N256510" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer.setup()<br/>Called method java.io.File.mkdirs()<br/>At TestNMWebServer.java:[line 69]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N256580');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer.writeContainerLogs(Context, ContainerId, LocalDirsHandlerService)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N256580" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer.writeContainerLogs(Context, ContainerId, LocalDirsHandlerService)<br/>Called method java.io.File.mkdirs()<br/>At TestNMWebServer.java:[line 228]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N256719');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N256719" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices.setUp()<br/>Called method java.io.File.mkdir()<br/>At TestNMWebServices.java:[line 161]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N256789');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N256789" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestNMWebServices.java:[line 160]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N256859');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesApps.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N256859" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesApps<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesApps.setUp()<br/>Called method java.io.File.mkdir()<br/>At TestNMWebServicesApps.java:[line 155]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N256929');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesApps.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N256929" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesApps<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesApps.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestNMWebServicesApps.java:[line 154]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N256999');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesContainers.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N256999" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesContainers<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesContainers.setUp()<br/>Called method java.io.File.mkdir()<br/>At TestNMWebServicesContainers.java:[line 161]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N257069');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesContainers.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N257069" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesContainers<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServicesContainers.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestNMWebServicesContainers.java:[line 160]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N269268');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerEventLog.tearDown()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N269268" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerEventLog<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerEventLog.tearDown()<br/>Called method java.io.File.delete()<br/>At TestFairSchedulerEventLog.java:[line 70]<br/>Another occurrence at TestFairSchedulerEventLog.java:[line 71]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N259501');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService.tearDown()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N259501" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService.tearDown()<br/>Called method java.io.File.delete()<br/>At TestResourceTrackerService.java:[line 642]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N259571');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService.writeToHostsFile(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N259571" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService.writeToHostsFile(String[])<br/>Called method java.io.File.createNewFile()<br/>At TestResourceTrackerService.java:[line 607]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N259641');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService.writeToHostsFile(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N259641" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService.writeToHostsFile(String[])<br/>Called method java.io.File.mkdirs()<br/>At TestResourceTrackerService.java:[line 606]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N258281');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService.testRMInitialsWithFileSystemBasedConfigurationProvider()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N258281" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService.testRMInitialsWithFileSystemBasedConfigurationProvider()<br/>Called method java.io.File.delete()<br/>At TestRMAdminService.java:[line 610]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N258351');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService.testRefreshNodesWithFileSystemBasedConfigurationProvider()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N258351" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService.testRefreshNodesWithFileSystemBasedConfigurationProvider()<br/>Called method java.io.File.delete()<br/>At TestRMAdminService.java:[line 469]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N258421');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService.writeConfigurationXML(Configuration, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N258421" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService.writeConfigurationXML(Configuration, String)<br/>Called method java.io.File.delete()<br/>At TestRMAdminService.java:[line 741]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N259077');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.tearDown()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N259077" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.tearDown()<br/>Called method java.io.File.delete()<br/>At TestRMRestart.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N259147');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.writeToHostsFile(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N259147" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.writeToHostsFile(String[])<br/>Called method java.io.File.createNewFile()<br/>At TestRMRestart.java:[line 1831]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N259217');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.writeToHostsFile(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N259217" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.writeToHostsFile(String[])<br/>Called method java.io.File.mkdirs()<br/>At TestRMRestart.java:[line 1830]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N245563');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.TestContainerManagerSecurity.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N245563" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.TestContainerManagerSecurity<br/>In method org.apache.hadoop.yarn.server.TestContainerManagerSecurity.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestContainerManagerSecurity.java:[line 95]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N245633');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.delete() ignored in org.apache.hadoop.yarn.server.TestContainerManagerSecurity.tearDown()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N245633" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.TestContainerManagerSecurity<br/>In method org.apache.hadoop.yarn.server.TestContainerManagerSecurity.tearDown()<br/>Called method java.io.File.delete()<br/>At TestContainerManagerSecurity.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N245908');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.yarn.server.TestDiskFailures.prepareDirToFail(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N245908" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.TestDiskFailures<br/>In method org.apache.hadoop.yarn.server.TestDiskFailures.prepareDirToFail(String)<br/>Called method java.io.File.createNewFile()<br/>At TestDiskFailures.java:[line 274]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N245978');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.TestDiskFailures.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N245978" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.TestDiskFailures<br/>In method org.apache.hadoop.yarn.server.TestDiskFailures.setup()<br/>Called method java.io.File.mkdirs()<br/>At TestDiskFailures.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N246048');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.server.TestDiskFailures.testDirsFailures(boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N246048" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.TestDiskFailures<br/>In method org.apache.hadoop.yarn.server.TestDiskFailures.testDirsFailures(boolean)<br/>Called method java.io.File.mkdirs()<br/>At TestDiskFailures.java:[line 160]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N273860');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.yarn.util.TestApplicationClassLoader.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N273860" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestApplicationClassLoader<br/>In method org.apache.hadoop.yarn.util.TestApplicationClassLoader.setUp()<br/>Called method java.io.File.mkdirs()<br/>At TestApplicationClassLoader.java:[line 54]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N274201');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.yarn.util.TestFSDownload.createJarFile(FileContext, Path, int, Random, LocalResourceVisibility)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N274201" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestFSDownload<br/>In method org.apache.hadoop.yarn.util.TestFSDownload.createJarFile(FileContext, Path, int, Random, LocalResourceVisibility)<br/>Called method java.io.File.createNewFile()<br/>At TestFSDownload.java:[line 208]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N274271');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.yarn.util.TestFSDownload.createTarFile(FileContext, Path, int, Random, LocalResourceVisibility)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N274271" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestFSDownload<br/>In method org.apache.hadoop.yarn.util.TestFSDownload.createTarFile(FileContext, Path, int, Random, LocalResourceVisibility)<br/>Called method java.io.File.createNewFile()<br/>At TestFSDownload.java:[line 152]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N274341');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.yarn.util.TestFSDownload.createTgzFile(FileContext, Path, int, Random, LocalResourceVisibility)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N274341" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestFSDownload<br/>In method org.apache.hadoop.yarn.util.TestFSDownload.createTgzFile(FileContext, Path, int, Random, LocalResourceVisibility)<br/>Called method java.io.File.createNewFile()<br/>At TestFSDownload.java:[line 180]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N274411');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.createNewFile() ignored in org.apache.hadoop.yarn.util.TestFSDownload.createZipFile(FileContext, Path, int, Random, LocalResourceVisibility)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N274411" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestFSDownload<br/>In method org.apache.hadoop.yarn.util.TestFSDownload.createZipFile(FileContext, Path, int, Random, LocalResourceVisibility)<br/>Called method java.io.File.createNewFile()<br/>At TestFSDownload.java:[line 234]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N275902');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Exceptional return value of java.io.File.mkdir() ignored in org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.setupPidDirs(File, String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N275902" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">Bug type RV_RETURN_VALUE_IGNORED_BAD_PRACTICE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree<br/>In method org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.setupPidDirs(File, String[])<br/>Called method java.io.File.mkdir()<br/>At TestProcfsBasedProcessTree.java:[line 870]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N161488');">
<td>
<span class="priority-2">Se</span>
</td>
<td>org.apache.hadoop.io.serializer.JavaSerializationComparator implements Comparator but not Serializable</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N161488" style="display: none;">
<a href="#SE_COMPARATOR_SHOULD_BE_SERIALIZABLE">Bug type SE_COMPARATOR_SHOULD_BE_SERIALIZABLE (click for details)</a>
<br/>In class org.apache.hadoop.io.serializer.JavaSerializationComparator<br/>At JavaSerializationComparator.java:[lines 37-50]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N168932');">
<td>
<span class="priority-2">Se</span>
</td>
<td>org.apache.hadoop.mapred.MergeSorter implements Comparator but not Serializable</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N168932" style="display: none;">
<a href="#SE_COMPARATOR_SHOULD_BE_SERIALIZABLE">Bug type SE_COMPARATOR_SHOULD_BE_SERIALIZABLE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MergeSorter<br/>At MergeSorter.java:[lines 35-77]</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_CORRECTNESS">Correctness Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N170305');">
<td>
<span class="priority-2">BIT</span>
</td>
<td>Bitwise OR of signed byte value computed in org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testPrototypeInflaterGzip() </td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N170305" style="display: none;">
<a href="#BIT_IOR_OF_SIGNED_BYTE">Bug type BIT_IOR_OF_SIGNED_BYTE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestConcatenatedCompressedInput<br/>In method org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testPrototypeInflaterGzip()<br/>At TestConcatenatedCompressedInput.java:[line 250]<br/>Another occurrence at TestConcatenatedCompressedInput.java:[line 271]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N115337');">
<td>
<span class="priority-2">DMI</span>
</td>
<td>D'oh! A nonsensical invocation of isNullOrEmpty(String) in org.apache.hadoop.hdfs.server.common.TestJspHelper.testPrintMethods()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N115337" style="display: none;">
<a href="#DMI_DOH">Bug type DMI_DOH (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.common.TestJspHelper<br/>In method org.apache.hadoop.hdfs.server.common.TestJspHelper.testPrintMethods()<br/>Called method com.google.common.base.Strings.isNullOrEmpty(String)<br/>Passing String constant as value that should be null checked<br/>String constant ""<br/>At TestJspHelper.java:[line 566]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92911');">
<td>
<span class="priority-2">EC</span>
</td>
<td>Using .equals to compare two byte[]'s, (equivalent to ==) in org.apache.hadoop.ha.TestActiveStandbyElector.testGetActiveData()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92911" style="display: none;">
<a href="#EC_BAD_ARRAY_COMPARE">Bug type EC_BAD_ARRAY_COMPARE (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestActiveStandbyElector<br/>In method org.apache.hadoop.ha.TestActiveStandbyElector.testGetActiveData()<br/>Actual type byte[]<br/>Expected byte[]<br/>Return value of org.apache.hadoop.ha.TestActiveStandbyElector$ActiveStandbyElectorTester.getActiveData() of type byte[]<br/>Value loaded from data<br/>Called method org.junit.Assert.assertEquals(Object, Object)<br/>At TestActiveStandbyElector.java:[line 634]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N115969');">
<td>
<span class="priority-1">EC</span>
</td>
<td>Call to org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.equals(org.apache.hadoop.hdfs.protocol.DatanodeInfo) in org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(BlockRecoveryCommand$RecoveringBlock)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N115969" style="display: none;">
<a href="#EC_UNRELATED_TYPES">Bug type EC_UNRELATED_TYPES (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.DataNode<br/>In method org.apache.hadoop.hdfs.server.datanode.DataNode.recoverBlock(BlockRecoveryCommand$RecoveringBlock)<br/>Actual type org.apache.hadoop.hdfs.protocol.DatanodeInfo<br/>Expected org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration<br/>Value loaded from id<br/>Value loaded from bpReg<br/>org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.equals(Object) used to determine equality<br/>At DataNode.java:[line 2130]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N121121');">
<td>
<span class="priority-2">EC</span>
</td>
<td>Call to org.apache.hadoop.hdfs.protocol.DatanodeInfo.equals(org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration) in org.apache.hadoop.hdfs.server.datanode.TestTransferRbw.testTransferRbw()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N121121" style="display: none;">
<a href="#EC_UNRELATED_TYPES">Bug type EC_UNRELATED_TYPES (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestTransferRbw<br/>In method org.apache.hadoop.hdfs.server.datanode.TestTransferRbw.testTransferRbw()<br/>Actual type org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration<br/>Expected org.apache.hadoop.hdfs.protocol.DatanodeInfo<br/>Value loaded from dnReg<br/>org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.equals(Object) used to determine equality<br/>org.apache.hadoop.hdfs.protocol.DatanodeInfo.equals(Object) used to determine equality<br/>At TestTransferRbw.java:[line 118]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N149066');">
<td>
<span class="priority-2">EC</span>
</td>
<td>Call to org.apache.hadoop.io.ByteWritable.equals(org.apache.hadoop.io.IntWritable) in org.apache.hadoop.io.TestBytesWritable.testObjectCommonMethods()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N149066" style="display: none;">
<a href="#EC_UNRELATED_TYPES">Bug type EC_UNRELATED_TYPES (click for details)</a>
<br/>In class org.apache.hadoop.io.TestBytesWritable<br/>In method org.apache.hadoop.io.TestBytesWritable.testObjectCommonMethods()<br/>Actual type org.apache.hadoop.io.IntWritable<br/>Expected org.apache.hadoop.io.ByteWritable<br/>Return value of new org.apache.hadoop.io.IntWritable(int) of type void<br/>Value loaded from bw<br/>org.apache.hadoop.io.ByteWritable.equals(Object) used to determine equality<br/>At TestBytesWritable.java:[line 152]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N163715');">
<td>
<span class="priority-1">EC</span>
</td>
<td>Call to java.util.regex.Pattern.equals(String) in org.apache.hadoop.ipc.TestSaslRPC.assertAuthEquals(Pattern, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N163715" style="display: none;">
<a href="#EC_UNRELATED_TYPES">Bug type EC_UNRELATED_TYPES (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.assertAuthEquals(Pattern, String)<br/>Actual type String<br/>Expected java.util.regex.Pattern<br/>Value loaded from actual<br/>Value loaded from expect<br/>Object.equals(Object) used to determine equality<br/>Called method org.junit.Assert.assertEquals(Object, Object)<br/>At TestSaslRPC.java:[line 978]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N252035');">
<td>
<span class="priority-1">EC</span>
</td>
<td>Call to String.equals(org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.MockLocalizerStatus) in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.MockLocalizerStatus.equals(Object)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N252035" style="display: none;">
<a href="#EC_UNRELATED_TYPES">Bug type EC_UNRELATED_TYPES (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.MockLocalizerStatus<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.MockLocalizerStatus.equals(Object)<br/>Actual type org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.MockLocalizerStatus<br/>Expected String<br/>Value loaded from o<br/>Return value of org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.MockLocalizerStatus.getLocalizerId() of type String<br/>String.equals(Object) used to determine equality<br/>At MockLocalizerStatus.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N270684');">
<td>
<span class="priority-1">GC</span>
</td>
<td>org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppState is incompatible with expected argument type org.apache.hadoop.yarn.api.records.YarnApplicationState in org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerAppsBlock.render(HtmlBlock$Block)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N270684" style="display: none;">
<a href="#GC_UNRELATED_TYPES">Bug type GC_UNRELATED_TYPES (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerAppsBlock<br/>In method org.apache.hadoop.yarn.server.resourcemanager.webapp.FairSchedulerAppsBlock.render(HtmlBlock$Block)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppState<br/>Expected org.apache.hadoop.yarn.api.records.YarnApplicationState<br/>Called method java.util.Collection.contains(Object)<br/>Invoked on reqAppStates<br/>Enum.equals(Object) used to determine equality<br/>At FairSchedulerAppsBlock.java:[line 95]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N245222');">
<td>
<span class="priority-1">GC</span>
</td>
<td>java.util.List&lt;org.apache.hadoop.yarn.api.records.ContainerId&gt; is incompatible with expected argument type org.apache.hadoop.yarn.api.records.ContainerId in org.apache.hadoop.yarn.server.TestContainerManagerSecurity.stopContainer(YarnRPC, Token, List, ApplicationAttemptId, NodeId)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N245222" style="display: none;">
<a href="#GC_UNRELATED_TYPES">Bug type GC_UNRELATED_TYPES (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.TestContainerManagerSecurity<br/>In method org.apache.hadoop.yarn.server.TestContainerManagerSecurity.stopContainer(YarnRPC, Token, List, ApplicationAttemptId, NodeId)<br/>Actual type java.util.List&lt;org.apache.hadoop.yarn.api.records.ContainerId&gt;<br/>Expected org.apache.hadoop.yarn.api.records.ContainerId<br/>Called method java.util.Map.containsKey(Object)<br/>containerId passed as argument<br/>java.util.List.equals(Object) used to determine equality<br/>At TestContainerManagerSecurity.java:[line 434]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N245331');">
<td>
<span class="priority-1">GC</span>
</td>
<td>java.util.List&lt;org.apache.hadoop.yarn.api.records.ContainerId&gt; is incompatible with expected argument type org.apache.hadoop.yarn.api.records.ContainerId in org.apache.hadoop.yarn.server.TestContainerManagerSecurity.stopContainer(YarnRPC, Token, List, ApplicationAttemptId, NodeId)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N245331" style="display: none;">
<a href="#GC_UNRELATED_TYPES">Bug type GC_UNRELATED_TYPES (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.TestContainerManagerSecurity<br/>In method org.apache.hadoop.yarn.server.TestContainerManagerSecurity.stopContainer(YarnRPC, Token, List, ApplicationAttemptId, NodeId)<br/>Actual type java.util.List&lt;org.apache.hadoop.yarn.api.records.ContainerId&gt;<br/>Expected org.apache.hadoop.yarn.api.records.ContainerId<br/>Called method java.util.Map.get(Object)<br/>containerId passed as argument<br/>java.util.List.equals(Object) used to determine equality<br/>At TestContainerManagerSecurity.java:[line 436]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N222791');">
<td>
<span class="priority-2">IJU</span>
</td>
<td>TestCase org.apache.hadoop.streaming.TestStreamingBadRecords defines setUp that doesn't call super.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N222791" style="display: none;">
<a href="#IJU_SETUP_NO_SUPER">Bug type IJU_SETUP_NO_SUPER (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamingBadRecords<br/>In method org.apache.hadoop.streaming.TestStreamingBadRecords.setUp()<br/>Overrides org.apache.hadoop.mapred.ClusterMapReduceTestCase.setUp()<br/>At TestStreamingBadRecords.java:[line 72]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N253414');">
<td>
<span class="priority-1">IL</span>
</td>
<td>There is an apparent infinite loop in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.verifyContainerLogs(LogAggregationService, ApplicationId, ContainerId[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N253414" style="display: none;">
<a href="#IL_INFINITE_LOOP">Bug type IL_INFINITE_LOOP (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.verifyContainerLogs(LogAggregationService, ApplicationId, ContainerId[])<br/>At TestLogAggregationService.java:[line 706]<br/>Loop bottom at TestLogAggregationService.java:[line 739]<br/>Local variable named valueStream<br/>Last changed at TestLogAggregationService.java:[line 744]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N94855');">
<td>
<span class="priority-1">INT</span>
</td>
<td>Bad comparison of nonnegative value with -1 in org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream$ReaderStrategy, int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N94855" style="display: none;">
<a href="#INT_BAD_COMPARISON_WITH_NONNEGATIVE_VALUE">Bug type INT_BAD_COMPARISON_WITH_NONNEGATIVE_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.DFSInputStream<br/>In method org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream$ReaderStrategy, int, int)<br/>Value -1<br/>Local variable named result<br/>At DFSInputStream.java:[line 804]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N65900');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Null passed for non-null parameter of set(String, String) in org.apache.hadoop.conf.Configuration.setPattern(String, Pattern)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N65900" style="display: none;">
<a href="#NP_NULL_PARAM_DEREF_ALL_TARGETS_DANGEROUS">Bug type NP_NULL_PARAM_DEREF_ALL_TARGETS_DANGEROUS (click for details)</a>
<br/>In class org.apache.hadoop.conf.Configuration<br/>In method org.apache.hadoop.conf.Configuration.setPattern(String, Pattern)<br/>Called method org.apache.hadoop.conf.Configuration.set(String, String)<br/>At Configuration.java:[line 1445]<br/>Argument 2 is definitely null but must not be null<br/>Definite null passed to dangerous method call target org.apache.hadoop.conf.Configuration.set(String, String)</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73520');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Null passed for non-null parameter of qualifiedPath(String, FileContext) in org.apache.hadoop.fs.FileContextURIBase.testCreateFileWithNullName()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73520" style="display: none;">
<a href="#NP_NULL_PARAM_DEREF_ALL_TARGETS_DANGEROUS">Bug type NP_NULL_PARAM_DEREF_ALL_TARGETS_DANGEROUS (click for details)</a>
<br/>In class org.apache.hadoop.fs.FileContextURIBase<br/>In method org.apache.hadoop.fs.FileContextURIBase.testCreateFileWithNullName()<br/>Called method org.apache.hadoop.fs.FileContextURIBase.qualifiedPath(String, FileContext)<br/>At FileContextURIBase.java:[line 114]<br/>Value loaded from fileName<br/>Argument 1 is definitely null but must not be null<br/>Definite null passed to dangerous method call target org.apache.hadoop.fs.FileContextURIBase.qualifiedPath(String, FileContext)</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N84295');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Null passed for non-null parameter of org.apache.hadoop.conf.Configuration.set(String, String) in org.apache.hadoop.fs.ftp.FTPFileSystem.initialize(URI, Configuration)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N84295" style="display: none;">
<a href="#NP_NULL_PARAM_DEREF_ALL_TARGETS_DANGEROUS">Bug type NP_NULL_PARAM_DEREF_ALL_TARGETS_DANGEROUS (click for details)</a>
<br/>In class org.apache.hadoop.fs.ftp.FTPFileSystem<br/>In method org.apache.hadoop.fs.ftp.FTPFileSystem.initialize(URI, Configuration)<br/>Called method org.apache.hadoop.conf.Configuration.set(String, String)<br/>At FTPFileSystem.java:[line 103]<br/>Argument 2 is definitely null but must not be null<br/>Definite null passed to dangerous method call target org.apache.hadoop.conf.Configuration.set(String, String)</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N116182');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of bpos in org.apache.hadoop.hdfs.server.datanode.DataNodeTestUtils.spyOnBposToNN(DataNode, NameNode)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N116182" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH">Bug type NP_NULL_ON_SOME_PATH (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.DataNodeTestUtils<br/>In method org.apache.hadoop.hdfs.server.datanode.DataNodeTestUtils.spyOnBposToNN(DataNode, NameNode)<br/>Value loaded from bpos<br/>Dereferenced at DataNodeTestUtils.java:[line 92]<br/>Null value at DataNodeTestUtils.java:[line 81]<br/>Known null at DataNodeTestUtils.java:[line 82]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N116266');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of bpsa in org.apache.hadoop.hdfs.server.datanode.DataNodeTestUtils.spyOnBposToNN(DataNode, NameNode)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N116266" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH">Bug type NP_NULL_ON_SOME_PATH (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.DataNodeTestUtils<br/>In method org.apache.hadoop.hdfs.server.datanode.DataNodeTestUtils.spyOnBposToNN(DataNode, NameNode)<br/>Value loaded from bpsa<br/>Dereferenced at DataNodeTestUtils.java:[line 101]<br/>Null value at DataNodeTestUtils.java:[line 91]<br/>Known null at DataNodeTestUtils.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N122017');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Null passed for non-null parameter of ReplicaMap.add(String, ReplicaInfo) in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReplicaMap.testAdd()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N122017" style="display: none;">
<a href="#NP_NULL_PARAM_DEREF_ALL_TARGETS_DANGEROUS">Bug type NP_NULL_PARAM_DEREF_ALL_TARGETS_DANGEROUS (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReplicaMap<br/>In method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReplicaMap.testAdd()<br/>Called method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReplicaMap.add(String, ReplicaInfo)<br/>At TestReplicaMap.java:[line 77]<br/>Argument 2 is definitely null but must not be null<br/>Definite null passed to dangerous method call target org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReplicaMap.add(String, ReplicaInfo)</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N122120');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Null passed for non-null parameter of ReplicaMap.get(String, Block) in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReplicaMap.testGet()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N122120" style="display: none;">
<a href="#NP_NULL_PARAM_DEREF_ALL_TARGETS_DANGEROUS">Bug type NP_NULL_PARAM_DEREF_ALL_TARGETS_DANGEROUS (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReplicaMap<br/>In method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestReplicaMap.testGet()<br/>Called method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReplicaMap.get(String, Block)<br/>At TestReplicaMap.java:[line 49]<br/>Argument 2 is definitely null but must not be null<br/>Definite null passed to dangerous method call target org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.ReplicaMap.get(String, Block)</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N117327');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of streams in org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery.testNotMatchedReplicaID() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N117327" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery.testNotMatchedReplicaID()<br/>Value loaded from streams<br/>Dereferenced at TestBlockRecovery.java:[line 572]<br/>Null value at TestBlockRecovery.java:[line 555]<br/>Known null at TestBlockRecovery.java:[line 557]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N118051');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of pipeline in org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetrics.testRoundTripAckMetric()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N118051" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH">Bug type NP_NULL_ON_SOME_PATH (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetrics<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDataNodeMetrics.testRoundTripAckMetric()<br/>Value loaded from pipeline<br/>Dereferenced at TestDataNodeMetrics.java:[line 164]<br/>Known null at TestDataNodeMetrics.java:[line 157]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N137400');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of cluster in org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.testHarUriWithHaUriWithNoPort() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N137400" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.testHarUriWithHaUriWithNoPort()<br/>Value loaded from cluster<br/>Dereferenced at TestHarFileSystemWithHA.java:[line 60]<br/>Null value at TestHarFileSystemWithHA.java:[line 44]<br/>Known null at TestHarFileSystemWithHA.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N127209');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fileSys in org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.doSecondaryFailsToReturnImage() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N127209" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckpoint<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.doSecondaryFailsToReturnImage()<br/>Value loaded from fileSys<br/>Dereferenced at TestCheckpoint.java:[line 626]<br/>Null value at TestCheckpoint.java:[line 587]<br/>Known null at TestCheckpoint.java:[line 591]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N127305');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fileSys in org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.doSendFailTest(String) on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N127305" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckpoint<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.doSendFailTest(String)<br/>Value loaded from fileSys<br/>Dereferenced at TestCheckpoint.java:[line 722]<br/>Null value at TestCheckpoint.java:[line 685]<br/>Known null at TestCheckpoint.java:[line 688]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N127401');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fileSys in org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testCheckpoint() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N127401" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckpoint<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testCheckpoint()<br/>Value loaded from fileSys<br/>Dereferenced at TestCheckpoint.java:[line 1061]<br/>Null value at TestCheckpoint.java:[line 1028]<br/>Known null at TestCheckpoint.java:[line 1031]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N127497');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fileSys in org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryNamenodeError1() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N127497" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckpoint<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryNamenodeError1()<br/>Value loaded from fileSys<br/>Dereferenced at TestCheckpoint.java:[line 386]<br/>Null value at TestCheckpoint.java:[line 355]<br/>Known null at TestCheckpoint.java:[line 358]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N127593');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fileSys in org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryNamenodeError2() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N127593" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckpoint<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryNamenodeError2()<br/>Value loaded from fileSys<br/>Dereferenced at TestCheckpoint.java:[line 457]<br/>Null value at TestCheckpoint.java:[line 426]<br/>Known null at TestCheckpoint.java:[line 429]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N127689');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fileSys in org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryNamenodeError3() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N127689" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckpoint<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testSecondaryNamenodeError3()<br/>Value loaded from fileSys<br/>Dereferenced at TestCheckpoint.java:[line 536]<br/>Null value at TestCheckpoint.java:[line 497]<br/>Known null at TestCheckpoint.java:[line 500]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N128851');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of streams in org.apache.hadoop.hdfs.server.namenode.TestEditLog.testEditLogFailOverFromCorrupt() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N128851" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestEditLog<br/>In method org.apache.hadoop.hdfs.server.namenode.TestEditLog.testEditLogFailOverFromCorrupt()<br/>Value loaded from streams<br/>Dereferenced at TestEditLog.java:[line 1444]<br/>Null value at TestEditLog.java:[line 1436]<br/>Known null at TestEditLog.java:[line 1438]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N128944');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of streams in org.apache.hadoop.hdfs.server.namenode.TestEditLog.testEditLogFailOverFromMissing() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N128944" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestEditLog<br/>In method org.apache.hadoop.hdfs.server.namenode.TestEditLog.testEditLogFailOverFromMissing()<br/>Value loaded from streams<br/>Dereferenced at TestEditLog.java:[line 1395]<br/>Null value at TestEditLog.java:[line 1387]<br/>Known null at TestEditLog.java:[line 1389]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N133068');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of secondary in org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testCheckPointDirsAreTrimmed() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N133068" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testCheckPointDirsAreTrimmed()<br/>Value loaded from secondary<br/>Dereferenced at TestNameEditsConfigs.java:[line 621]<br/>Null value at TestNameEditsConfigs.java:[line 591]<br/>Known null at TestNameEditsConfigs.java:[line 609]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N133164');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of cluster in org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N133164" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure()<br/>Value loaded from cluster<br/>Dereferenced at TestNameEditsConfigs.java:[line 461]<br/>Null value at TestNameEditsConfigs.java:[line 429]<br/>Known null at TestNameEditsConfigs.java:[line 445]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N133260');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of cluster in org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N133260" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure()<br/>Value loaded from cluster<br/>Dereferenced at TestNameEditsConfigs.java:[line 580]<br/>Known null at TestNameEditsConfigs.java:[line 563]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N133342');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fileSys in org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N133342" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.testNameEditsConfigsFailure()<br/>Value loaded from fileSys<br/>Dereferenced at TestNameEditsConfigs.java:[line 460]<br/>Null value at TestNameEditsConfigs.java:[line 431]<br/>Known null at TestNameEditsConfigs.java:[line 445]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N104794');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of cluster in org.apache.hadoop.hdfs.TestDistributedFileSystem.testEmptyDelegationToken() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N104794" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDistributedFileSystem<br/>In method org.apache.hadoop.hdfs.TestDistributedFileSystem.testEmptyDelegationToken()<br/>Value loaded from cluster<br/>Dereferenced at TestDistributedFileSystem.java:[line 119]<br/>Null value at TestDistributedFileSystem.java:[line 113]<br/>Known null at TestDistributedFileSystem.java:[line 115]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N106465');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fs in org.apache.hadoop.hdfs.TestFileCreationDelete.testFileCreationDeleteParent() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N106465" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileCreationDelete<br/>In method org.apache.hadoop.hdfs.TestFileCreationDelete.testFileCreationDeleteParent()<br/>Value loaded from fs<br/>Dereferenced at TestFileCreationDelete.java:[line 100]<br/>Null value at TestFileCreationDelete.java:[line 52]<br/>Known null at TestFileCreationDelete.java:[line 54]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N108496');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fs in org.apache.hadoop.hdfs.TestRenameWhileOpen.testWhileOpenRenameParent() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N108496" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestRenameWhileOpen<br/>In method org.apache.hadoop.hdfs.TestRenameWhileOpen.testWhileOpenRenameParent()<br/>Value loaded from fs<br/>Dereferenced at TestRenameWhileOpen.java:[line 129]<br/>Null value at TestRenameWhileOpen.java:[line 64]<br/>Known null at TestRenameWhileOpen.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N108592');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fs in org.apache.hadoop.hdfs.TestRenameWhileOpen.testWhileOpenRenameParentToNonexistentDir() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N108592" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestRenameWhileOpen<br/>In method org.apache.hadoop.hdfs.TestRenameWhileOpen.testWhileOpenRenameParentToNonexistentDir()<br/>Value loaded from fs<br/>Dereferenced at TestRenameWhileOpen.java:[line 203]<br/>Null value at TestRenameWhileOpen.java:[line 150]<br/>Known null at TestRenameWhileOpen.java:[line 152]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N108688');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fs in org.apache.hadoop.hdfs.TestRenameWhileOpen.testWhileOpenRenameToExistentDirectory() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N108688" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestRenameWhileOpen<br/>In method org.apache.hadoop.hdfs.TestRenameWhileOpen.testWhileOpenRenameToExistentDirectory()<br/>Value loaded from fs<br/>Dereferenced at TestRenameWhileOpen.java:[line 269]<br/>Null value at TestRenameWhileOpen.java:[line 225]<br/>Known null at TestRenameWhileOpen.java:[line 227]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N108784');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fs in org.apache.hadoop.hdfs.TestRenameWhileOpen.testWhileOpenRenameToNonExistentDirectory() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N108784" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestRenameWhileOpen<br/>In method org.apache.hadoop.hdfs.TestRenameWhileOpen.testWhileOpenRenameToNonExistentDirectory()<br/>Value loaded from fs<br/>Dereferenced at TestRenameWhileOpen.java:[line 333]<br/>Null value at TestRenameWhileOpen.java:[line 290]<br/>Known null at TestRenameWhileOpen.java:[line 292]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N142171');">
<td>
<span class="priority-1">NP</span>
</td>
<td>Possible null pointer dereference of commandLine in org.apache.hadoop.hdfs.tools.JMXGet.main(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N142171" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH">Bug type NP_NULL_ON_SOME_PATH (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.JMXGet<br/>In method org.apache.hadoop.hdfs.tools.JMXGet.main(String[])<br/>Value loaded from commandLine<br/>Dereferenced at JMXGet.java:[line 304]<br/>Null value at JMXGet.java:[line 295]<br/>Known null at JMXGet.java:[line 297]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N148628');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fs in org.apache.hadoop.io.TestArrayFile.main(String[]) on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N148628" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.io.TestArrayFile<br/>In method org.apache.hadoop.io.TestArrayFile.main(String[])<br/>Value loaded from fs<br/>Dereferenced at TestArrayFile.java:[line 209]<br/>Null value at TestArrayFile.java:[line 174]<br/>Known null at TestArrayFile.java:[line 176]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N150656');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fs in org.apache.hadoop.io.TestSequenceFile.main(String[]) on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N150656" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.io.TestSequenceFile<br/>In method org.apache.hadoop.io.TestSequenceFile.main(String[])<br/>Value loaded from fs<br/>Dereferenced at TestSequenceFile.java:[line 723]<br/>Null value at TestSequenceFile.java:[line 644]<br/>Known null at TestSequenceFile.java:[line 646]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N150822');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of fs in org.apache.hadoop.io.TestSetFile.main(String[]) on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N150822" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.io.TestSetFile<br/>In method org.apache.hadoop.io.TestSetFile.main(String[])<br/>Value loaded from fs<br/>Dereferenced at TestSetFile.java:[line 189]<br/>Null value at TestSetFile.java:[line 150]<br/>Known null at TestSetFile.java:[line 152]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N165506');">
<td>
<span class="priority-1">NP</span>
</td>
<td>Non-virtual method call in org.apache.hadoop.lib.util.TestCheck.notEmptyElementsNullList() passes null for non-null parameter of Check.notEmptyElements(List, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N165506" style="display: none;">
<a href="#NP_NULL_PARAM_DEREF_NONVIRTUAL">Bug type NP_NULL_PARAM_DEREF_NONVIRTUAL (click for details)</a>
<br/>In class org.apache.hadoop.lib.util.TestCheck<br/>In method org.apache.hadoop.lib.util.TestCheck.notEmptyElementsNullList()<br/>Called method org.apache.hadoop.lib.util.Check.notEmptyElements(List, String)<br/>At TestCheck.java:[line 66]<br/>Argument 1 is definitely null but must not be null</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N165593');">
<td>
<span class="priority-1">NP</span>
</td>
<td>Non-virtual method call in org.apache.hadoop.lib.util.TestCheck.notNullElementsNullList() passes null for non-null parameter of Check.notNullElements(List, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N165593" style="display: none;">
<a href="#NP_NULL_PARAM_DEREF_NONVIRTUAL">Bug type NP_NULL_PARAM_DEREF_NONVIRTUAL (click for details)</a>
<br/>In class org.apache.hadoop.lib.util.TestCheck<br/>In method org.apache.hadoop.lib.util.TestCheck.notNullElementsNullList()<br/>Called method org.apache.hadoop.lib.util.Check.notNullElements(List, String)<br/>At TestCheck.java:[line 50]<br/>Argument 1 is definitely null but must not be null</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N185448');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of dfs in org.apache.hadoop.mapred.pipes.TestPipes.testPipes() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N185448" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipes<br/>In method org.apache.hadoop.mapred.pipes.TestPipes.testPipes()<br/>Value loaded from dfs<br/>Dereferenced at TestPipes.java:[line 97]<br/>Null value at TestPipes.java:[line 75]<br/>Known null at TestPipes.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N185544');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of mr in org.apache.hadoop.mapred.pipes.TestPipes.testPipes() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N185544" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipes<br/>In method org.apache.hadoop.mapred.pipes.TestPipes.testPipes()<br/>Value loaded from mr<br/>Dereferenced at TestPipes.java:[line 96]<br/>Null value at TestPipes.java:[line 76]<br/>Known null at TestPipes.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N190847');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Null passed for non-null parameter of org.apache.hadoop.conf.Configuration.set(String, String) in org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat.setBoundingQuery(Configuration, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N190847" style="display: none;">
<a href="#NP_NULL_PARAM_DEREF">Bug type NP_NULL_PARAM_DEREF (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat.setBoundingQuery(Configuration, String)<br/>Called method org.apache.hadoop.conf.Configuration.set(String, String)<br/>Argument 2 might be null but must not be null<br/>Value loaded from query<br/>Method invoked at DataDrivenDBInputFormat.java:[line 274]<br/>Known null at DataDrivenDBInputFormat.java:[line 266]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N194898');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of jobHistoryServer in org.apache.hadoop.mapreduce.security.TestJHSSecurity.testDelegationToken() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N194898" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.TestJHSSecurity<br/>In method org.apache.hadoop.mapreduce.security.TestJHSSecurity.testDelegationToken()<br/>Value loaded from jobHistoryServer<br/>Dereferenced at TestJHSSecurity.java:[line 220]<br/>Null value at TestJHSSecurity.java:[line 83]<br/>Known null at TestJHSSecurity.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N196809');">
<td>
<span class="priority-2">NP</span>
</td>
<td>shexec is null guaranteed to be dereferenced in org.apache.hadoop.mapreduce.util.ProcessTree.isSetsidSupported() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N196809" style="display: none;">
<a href="#NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH">Bug type NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.ProcessTree<br/>In method org.apache.hadoop.mapreduce.util.ProcessTree.isSetsidSupported()<br/>Value loaded from shexec<br/>Dereferenced at ProcessTree.java:[line 64]<br/>Dereferenced at ProcessTree.java:[line 64]<br/>Null value at ProcessTree.java:[line 54]<br/>Known null at ProcessTree.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N196913');">
<td>
<span class="priority-2">NP</span>
</td>
<td>shexec is null guaranteed to be dereferenced in org.apache.hadoop.mapreduce.util.ProcessTree.sendSignal(String, int, String) on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N196913" style="display: none;">
<a href="#NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH">Bug type NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.ProcessTree<br/>In method org.apache.hadoop.mapreduce.util.ProcessTree.sendSignal(String, int, String)<br/>Value loaded from shexec<br/>Dereferenced at ProcessTree.java:[line 139]<br/>Dereferenced at ProcessTree.java:[line 136]<br/>Dereferenced at ProcessTree.java:[line 139]<br/>Dereferenced at ProcessTree.java:[line 136]<br/>Null value at ProcessTree.java:[line 127]<br/>Known null at ProcessTree.java:[line 129]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N197039');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of shexec in org.apache.hadoop.mapreduce.util.ProcessTree.isAlive(String) on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N197039" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.ProcessTree<br/>In method org.apache.hadoop.mapreduce.util.ProcessTree.isAlive(String)<br/>Value loaded from shexec<br/>Dereferenced at ProcessTree.java:[line 298]<br/>Null value at ProcessTree.java:[line 290]<br/>Known null at ProcessTree.java:[line 293]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N197126');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of shexec in org.apache.hadoop.mapreduce.util.ProcessTree.isProcessGroupAlive(String) on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N197126" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.ProcessTree<br/>In method org.apache.hadoop.mapreduce.util.ProcessTree.isProcessGroupAlive(String)<br/>Value loaded from shexec<br/>Dereferenced at ProcessTree.java:[line 323]<br/>Null value at ProcessTree.java:[line 315]<br/>Known null at ProcessTree.java:[line 318]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N199164');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of server in org.apache.hadoop.mapreduce.v2.TestRPCFactories.testPbClientFactory() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N199164" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestRPCFactories<br/>In method org.apache.hadoop.mapreduce.v2.TestRPCFactories.testPbClientFactory()<br/>Value loaded from server<br/>Dereferenced at TestRPCFactories.java:[line 122]<br/>Null value at TestRPCFactories.java:[line 101]<br/>Known null at TestRPCFactories.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N199260');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of server in org.apache.hadoop.mapreduce.v2.TestRPCFactories.testPbServerFactory() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N199260" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestRPCFactories<br/>In method org.apache.hadoop.mapreduce.v2.TestRPCFactories.testPbServerFactory()<br/>Value loaded from server<br/>Dereferenced at TestRPCFactories.java:[line 91]<br/>Null value at TestRPCFactories.java:[line 81]<br/>Known null at TestRPCFactories.java:[line 83]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N210293');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Null passed for non-null parameter of String.contains(CharSequence) in org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspath()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N210293" style="display: none;">
<a href="#NP_NULL_PARAM_DEREF">Bug type NP_NULL_PARAM_DEREF (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.util.TestMRApps<br/>In method org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspath()<br/>Called method String.contains(CharSequence)<br/>Argument 1 might be null but must not be null<br/>Value loaded from mrAppClasspath<br/>Method invoked at TestMRApps.java:[line 216]<br/>Known null at TestMRApps.java:[line 211]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N210387');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Null passed for non-null parameter of String.contains(CharSequence) in org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspath()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N210387" style="display: none;">
<a href="#NP_NULL_PARAM_DEREF">Bug type NP_NULL_PARAM_DEREF (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.util.TestMRApps<br/>In method org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspath()<br/>Called method String.contains(CharSequence)<br/>Argument 1 might be null but must not be null<br/>Value loaded from yarnAppClasspath<br/>Method invoked at TestMRApps.java:[line 206]<br/>Known null at TestMRApps.java:[line 201]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N210481');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Null passed for non-null parameter of String.contains(CharSequence) in org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspathWithArchives()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N210481" style="display: none;">
<a href="#NP_NULL_PARAM_DEREF">Bug type NP_NULL_PARAM_DEREF (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.util.TestMRApps<br/>In method org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspathWithArchives()<br/>Called method String.contains(CharSequence)<br/>Argument 1 might be null but must not be null<br/>Value loaded from confClasspath<br/>Method invoked at TestMRApps.java:[line 245]<br/>Known null at TestMRApps.java:[line 241]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N225868');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of in in org.apache.hadoop.tools.DistCh.checkDuplication(FileSystem, Path, Path, Configuration) on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N225868" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.tools.DistCh<br/>In method org.apache.hadoop.tools.DistCh.checkDuplication(FileSystem, Path, Path, Configuration)<br/>Value loaded from in<br/>Dereferenced at DistCh.java:[line 516]<br/>Null value at DistCh.java:[line 499]<br/>Known null at DistCh.java:[line 501]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N225964');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of opWriter in org.apache.hadoop.tools.DistCh.setup(List, Path) on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N225964" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.tools.DistCh<br/>In method org.apache.hadoop.tools.DistCh.setup(List, Path)<br/>Value loaded from opWriter<br/>Dereferenced at DistCh.java:[line 483]<br/>Null value at DistCh.java:[line 452]<br/>Known null at DistCh.java:[line 454]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N226198');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of input in org.apache.hadoop.tools.DistTool.readFile(Configuration, Path) on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N226198" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.tools.DistTool<br/>In method org.apache.hadoop.tools.DistTool.readFile(Configuration, Path)<br/>Value loaded from input<br/>Dereferenced at DistTool.java:[line 106]<br/>Null value at DistTool.java:[line 99]<br/>Known null at DistTool.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N247461');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of pw in org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService.writeNodeHealthScriptFile(String, boolean) on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N247461" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService.writeNodeHealthScriptFile(String, boolean)<br/>Value loaded from pw<br/>Dereferenced at TestNodeHealthService.java:[line 90]<br/>Null value at TestNodeHealthService.java:[line 82]<br/>Known null at TestNodeHealthService.java:[line 84]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N255243');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of in in org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler.parseMtab() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N255243" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler<br/>In method org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler.parseMtab()<br/>Value loaded from in<br/>Dereferenced at CgroupsLCEResourcesHandler.java:[line 299]<br/>Null value at CgroupsLCEResourcesHandler.java:[line 274]<br/>Known null at CgroupsLCEResourcesHandler.java:[line 277]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N261018');">
<td>
<span class="priority-1">NP</span>
</td>
<td>Null pointer dereference of TestNMReconnect.rmNodeEvent in org.apache.hadoop.yarn.server.resourcemanager.resourcetracker.TestNMReconnect.testReconnect()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N261018" style="display: none;">
<a href="#NP_ALWAYS_NULL">Bug type NP_ALWAYS_NULL (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.resourcetracker.TestNMReconnect<br/>In method org.apache.hadoop.yarn.server.resourcemanager.resourcetracker.TestNMReconnect.testReconnect()<br/>Value loaded from field org.apache.hadoop.yarn.server.resourcemanager.resourcetracker.TestNMReconnect.rmNodeEvent<br/>Dereferenced at TestNMReconnect.java:[line 116]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N236528');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of server in org.apache.hadoop.yarn.TestYSCRPCFactories.testPbClientFactory() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N236528" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.TestYSCRPCFactories<br/>In method org.apache.hadoop.yarn.TestYSCRPCFactories.testPbClientFactory()<br/>Value loaded from server<br/>Dereferenced at TestYSCRPCFactories.java:[line 98]<br/>Null value at TestYSCRPCFactories.java:[line 77]<br/>Known null at TestYSCRPCFactories.java:[line 79]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N236624');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference of server in org.apache.hadoop.yarn.TestYSCRPCFactories.testPbServerFactory() on exception path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N236624" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_EXCEPTION">Bug type NP_NULL_ON_SOME_PATH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.TestYSCRPCFactories<br/>In method org.apache.hadoop.yarn.TestYSCRPCFactories.testPbServerFactory()<br/>Value loaded from server<br/>Dereferenced at TestYSCRPCFactories.java:[line 67]<br/>Null value at TestYSCRPCFactories.java:[line 57]<br/>Known null at TestYSCRPCFactories.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N275688');">
<td>
<span class="priority-2">NP</span>
</td>
<td>shexec is null guaranteed to be dereferenced in org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.isSetsidAvailable() on exception path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N275688" style="display: none;">
<a href="#NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH">Bug type NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree<br/>In method org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.isSetsidAvailable()<br/>Value loaded from shexec<br/>Dereferenced at TestProcfsBasedProcessTree.java:[line 791]<br/>Dereferenced at TestProcfsBasedProcessTree.java:[line 791]<br/>Null value at TestProcfsBasedProcessTree.java:[line 781]<br/>Known null at TestProcfsBasedProcessTree.java:[line 784]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N131737');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Nullcheck of fs at line 149 of value previously dereferenced in org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N131737" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE">Bug type RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsck()<br/>Value loaded from fs<br/>Return value of org.apache.hadoop.hdfs.MiniDFSCluster.getFileSystem() of type org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestFsck.java:[line 149]<br/>Redundant null check at TestFsck.java:[line 157]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N131825');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Nullcheck of fs at line 548 of value previously dereferenced in org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckMoveAndDelete()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N131825" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE">Bug type RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckMoveAndDelete()<br/>Value loaded from fs<br/>Return value of org.apache.hadoop.hdfs.MiniDFSCluster.getFileSystem() of type org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestFsck.java:[line 548]<br/>Redundant null check at TestFsck.java:[line 549]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N131913');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Nullcheck of fs at line 577 of value previously dereferenced in org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckOpenFiles()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N131913" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE">Bug type RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckOpenFiles()<br/>Value loaded from fs<br/>Return value of org.apache.hadoop.hdfs.MiniDFSCluster.getFileSystem() of type org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestFsck.java:[line 577]<br/>Redundant null check at TestFsck.java:[line 601]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N132001');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Nullcheck of logger at line 196 of value previously dereferenced in org.apache.hadoop.hdfs.server.namenode.TestFsck.verifyAuditLogs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N132001" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE">Bug type RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.verifyAuditLogs()<br/>Value loaded from logger<br/>Return value of org.apache.commons.logging.impl.Log4JLogger.getLogger() of type org.apache.log4j.Logger<br/>At TestFsck.java:[line 196]<br/>Redundant null check at TestFsck.java:[line 217]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N134771');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Nullcheck of cluster at line 611 of value previously dereferenced in org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithDanglingLease()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N134771" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE">Bug type RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace<br/>In method org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithDanglingLease()<br/>Value loaded from cluster<br/>Return value of org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build() of type org.apache.hadoop.hdfs.MiniDFSCluster<br/>At TestSaveNamespace.java:[line 611]<br/>Redundant null check at TestSaveNamespace.java:[line 619]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N134853');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Nullcheck of cluster at line 508 of value previously dereferenced in org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N134853" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE">Bug type RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace<br/>In method org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.testSaveNamespaceWithRenamedLease()<br/>Value loaded from cluster<br/>Return value of org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build() of type org.apache.hadoop.hdfs.MiniDFSCluster<br/>At TestSaveNamespace.java:[line 508]<br/>Redundant null check at TestSaveNamespace.java:[line 521]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N104887');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Nullcheck of cluster at line 929 of value previously dereferenced in org.apache.hadoop.hdfs.TestDistributedFileSystem.testFileCloseStatus()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N104887" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE">Bug type RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDistributedFileSystem<br/>In method org.apache.hadoop.hdfs.TestDistributedFileSystem.testFileCloseStatus()<br/>Value loaded from cluster<br/>Return value of org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build() of type org.apache.hadoop.hdfs.MiniDFSCluster<br/>At TestDistributedFileSystem.java:[line 929]<br/>Redundant null check at TestDistributedFileSystem.java:[line 941]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N151723');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Nullcheck of in at line 43 of value previously dereferenced in new org.apache.hadoop.io.compress.DecompressorStream(InputStream, Decompressor, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N151723" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE">Bug type RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.DecompressorStream<br/>In method new org.apache.hadoop.io.compress.DecompressorStream(InputStream, Decompressor, int)<br/>Value loaded from in<br/>At DecompressorStream.java:[line 41]<br/>Redundant null check at DecompressorStream.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N225079');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Nullcheck of MiniDFSClusterManager.dfs at line 157 of value previously dereferenced in org.apache.hadoop.test.MiniDFSClusterManager.start()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N225079" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE">Bug type RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE (click for details)</a>
<br/>In class org.apache.hadoop.test.MiniDFSClusterManager<br/>In method org.apache.hadoop.test.MiniDFSClusterManager.start()<br/>Value loaded from field org.apache.hadoop.test.MiniDFSClusterManager.dfs<br/>At MiniDFSClusterManager.java:[line 144]<br/>Redundant null check at MiniDFSClusterManager.java:[line 157]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N229134');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Nullcheck of value at line 154 of value previously dereferenced in new org.apache.hadoop.tools.rumen.ParsedConfigFile(String, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N229134" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE">Bug type RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE (click for details)</a>
<br/>In class org.apache.hadoop.tools.rumen.ParsedConfigFile<br/>In method new org.apache.hadoop.tools.rumen.ParsedConfigFile(String, String)<br/>Value loaded from value<br/>At ParsedConfigFile.java:[line 152]<br/>Redundant null check at ParsedConfigFile.java:[line 154]<br/>Another occurrence at ParsedConfigFile.java:[line 167]<br/>Another occurrence at ParsedConfigFile.java:[line 171]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N121947');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of String.startsWith(String) ignored in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestInterDatanodeProtocol.testInitReplicaRecovery()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N121947" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED">Bug type RV_RETURN_VALUE_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestInterDatanodeProtocol<br/>In method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestInterDatanodeProtocol.testInitReplicaRecovery()<br/>Called method String.startsWith(String)<br/>At TestInterDatanodeProtocol.java:[line 312]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N117423');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of String.startsWith(String) ignored in org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery.testFailedReplicaUpdate()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N117423" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED">Bug type RV_RETURN_VALUE_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery.testFailedReplicaUpdate()<br/>Called method String.startsWith(String)<br/>At TestBlockRecovery.java:[line 517]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N117493');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of String.startsWith(String) ignored in org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery.testNoReplicaUnderRecovery()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N117493" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED">Bug type RV_RETURN_VALUE_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery.testNoReplicaUnderRecovery()<br/>Called method String.startsWith(String)<br/>At TestBlockRecovery.java:[line 536]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N117563');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of String.startsWith(String) ignored in org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery.testNotMatchedReplicaID()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N117563" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED">Bug type RV_RETURN_VALUE_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBlockRecovery.testNotMatchedReplicaID()<br/>Called method String.startsWith(String)<br/>At TestBlockRecovery.java:[line 565]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N135707');">
<td>
<span class="priority-1">RV</span>
</td>
<td>Return value of String.trim() ignored in org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.testDfsAdminCmd()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N135707" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED">Bug type RV_RETURN_VALUE_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestStorageRestore<br/>In method org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.testDfsAdminCmd()<br/>Called method String.trim()<br/>At TestStorageRestore.java:[line 296]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N253638');">
<td>
<span class="priority-1">RV</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testLogAggregationCreateDirsFailsWithoutKillingNM() uses generates a random value from 0 to 1 and then coerces that value to the integer 0</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N253638" style="display: none;">
<a href="#RV_01_TO_INT">Bug type RV_01_TO_INT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testLogAggregationCreateDirsFailsWithoutKillingNM()<br/>At TestLogAggregationService.java:[line 641]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N253692');">
<td>
<span class="priority-1">RV</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testLogAggregationInitAppFailsWithoutKillingNM() uses generates a random value from 0 to 1 and then coerces that value to the integer 0</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N253692" style="display: none;">
<a href="#RV_01_TO_INT">Bug type RV_01_TO_INT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testLogAggregationInitAppFailsWithoutKillingNM()<br/>At TestLogAggregationService.java:[line 589]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N253746');">
<td>
<span class="priority-1">RV</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testVerifyAndCreateRemoteDirsFailure() uses generates a random value from 0 to 1 and then coerces that value to the integer 0</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N253746" style="display: none;">
<a href="#RV_01_TO_INT">Bug type RV_01_TO_INT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testVerifyAndCreateRemoteDirsFailure()<br/>At TestLogAggregationService.java:[line 446]<br/>Another occurrence at TestLogAggregationService.java:[line 465]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N272111');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of java.util.concurrent.CountDownLatch.await(long, TimeUnit) ignored in org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner.testDualTask()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N272111" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED">Bug type RV_RETURN_VALUE_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner<br/>In method org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner.testDualTask()<br/>Called method java.util.concurrent.CountDownLatch.await(long, TimeUnit)<br/>At TestTaskRunner.java:[line 114]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N272181');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of java.util.concurrent.CountDownLatch.await(long, TimeUnit) ignored in org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner.testMultiTask()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N272181" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED">Bug type RV_RETURN_VALUE_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner<br/>In method org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner.testMultiTask()<br/>Called method java.util.concurrent.CountDownLatch.await(long, TimeUnit)<br/>At TestTaskRunner.java:[line 202]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N272251');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of java.util.concurrent.CountDownLatch.await(long, TimeUnit) ignored in org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner.testPreStartQueueing()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N272251" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED">Bug type RV_RETURN_VALUE_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner<br/>In method org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner.testPreStartQueueing()<br/>Called method java.util.concurrent.CountDownLatch.await(long, TimeUnit)<br/>At TestTaskRunner.java:[line 241]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N272321');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of java.util.concurrent.CountDownLatch.await(long, TimeUnit) ignored in org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner.testSingleTask()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N272321" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED">Bug type RV_RETURN_VALUE_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner<br/>In method org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner.testSingleTask()<br/>Called method java.util.concurrent.CountDownLatch.await(long, TimeUnit)<br/>At TestTaskRunner.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N272391');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of java.util.concurrent.CountDownLatch.await(long, TimeUnit) ignored in org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner.testTriTask()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N272391" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED">Bug type RV_RETURN_VALUE_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner<br/>In method org.apache.hadoop.yarn.sls.scheduler.TestTaskRunner.testTriTask()<br/>Called method java.util.concurrent.CountDownLatch.await(long, TimeUnit)<br/>At TestTaskRunner.java:[line 159]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N114699');">
<td>
<span class="priority-2">SA</span>
</td>
<td>Self comparison of CacheReplicationMonitor.scanCount with itself in org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.waitForRescanIfNeeded()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N114699" style="display: none;">
<a href="#SA_FIELD_SELF_COMPARISON">Bug type SA_FIELD_SELF_COMPARISON (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor<br/>In method org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.waitForRescanIfNeeded()<br/>Field org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor.scanCount<br/>At CacheReplicationMonitor.java:[line 237]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N87120');">
<td>
<span class="priority-1">USELESS_STRING</span>
</td>
<td>Invocation of toString on LoadGenerator.writeProbs in org.apache.hadoop.fs.loadGenerator.LoadGenerator.run(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N87120" style="display: none;">
<a href="#DMI_INVOKING_TOSTRING_ON_ARRAY">Bug type DMI_INVOKING_TOSTRING_ON_ARRAY (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.LoadGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.LoadGenerator.run(String[])<br/>Value loaded from field org.apache.hadoop.fs.loadGenerator.LoadGenerator.writeProbs<br/>At LoadGenerator.java:[line 349]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77874');">
<td>
<span class="priority-1">USELESS_STRING</span>
</td>
<td>Invocation of toString on bytes in org.apache.hadoop.fs.TestDFVariations.testDFInvalidPath()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77874" style="display: none;">
<a href="#DMI_INVOKING_TOSTRING_ON_ARRAY">Bug type DMI_INVOKING_TOSTRING_ON_ARRAY (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestDFVariations<br/>In method org.apache.hadoop.fs.TestDFVariations.testDFInvalidPath()<br/>Local variable named bytes<br/>At TestDFVariations.java:[line 72]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N194631');">
<td>
<span class="priority-2">USELESS_STRING</span>
</td>
<td>Invocation of toString on secretValue in org.apache.hadoop.mapreduce.security.CredentialsTestJob.checkSecrets(Credentials)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N194631" style="display: none;">
<a href="#DMI_INVOKING_TOSTRING_ON_ARRAY">Bug type DMI_INVOKING_TOSTRING_ON_ARRAY (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.CredentialsTestJob<br/>In method org.apache.hadoop.mapreduce.security.CredentialsTestJob.checkSecrets(Credentials)<br/>Local variable named secretValue<br/>At CredentialsTestJob.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N231617');">
<td>
<span class="priority-2">USELESS_STRING</span>
</td>
<td>Invocation of toString on arr in org.apache.hadoop.util.TestGenericsUtil.testWithEmptyList()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N231617" style="display: none;">
<a href="#DMI_INVOKING_TOSTRING_ON_ARRAY">Bug type DMI_INVOKING_TOSTRING_ON_ARRAY (click for details)</a>
<br/>In class org.apache.hadoop.util.TestGenericsUtil<br/>In method org.apache.hadoop.util.TestGenericsUtil.testWithEmptyList()<br/>Local variable named arr<br/>At TestGenericsUtil.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N234484');">
<td>
<span class="priority-1">USELESS_STRING</span>
</td>
<td>Invocation of toString on b in org.apache.hadoop.util.TestWinUtils.readFile(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N234484" style="display: none;">
<a href="#DMI_INVOKING_TOSTRING_ON_ARRAY">Bug type DMI_INVOKING_TOSTRING_ON_ARRAY (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.readFile(File)<br/>Local variable named b<br/>At TestWinUtils.java:[line 73]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N212009');">
<td>
<span class="priority-2">UwF</span>
</td>
<td>Field only ever set to null: org.apache.hadoop.metrics2.lib.MutableQuantiles.previousSnapshot</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N212009" style="display: none;">
<a href="#UWF_NULL_FIELD">Bug type UWF_NULL_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.lib.MutableQuantiles<br/>Field org.apache.hadoop.metrics2.lib.MutableQuantiles.previousSnapshot<br/>In MutableQuantiles.java</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_EXPERIMENTAL">Experimental Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N84708');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.http.client.BaseTestHttpFSWith.createHttpFSServer() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N84708" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.client.BaseTestHttpFSWith<br/>In method org.apache.hadoop.fs.http.client.BaseTestHttpFSWith.createHttpFSServer()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at BaseTestHttpFSWith.java:[line 91] is not discharged<br/>Path continues at BaseTestHttpFSWith.java:[line 92]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84796');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.http.client.BaseTestHttpFSWith.createHttpFSServer() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84796" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.client.BaseTestHttpFSWith<br/>In method org.apache.hadoop.fs.http.client.BaseTestHttpFSWith.createHttpFSServer()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at BaseTestHttpFSWith.java:[line 82] is not discharged<br/>Path continues at BaseTestHttpFSWith.java:[line 83]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86235');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.http.server.TestHttpFSServer.createHttpFSServer(boolean) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86235" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSServer<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSServer.createHttpFSServer(boolean)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestHttpFSServer.java:[line 132] is not discharged<br/>Path continues at TestHttpFSServer.java:[line 133]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N86323');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.http.server.TestHttpFSServer.createHttpFSServer(boolean) may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N86323" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSServer<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSServer.createHttpFSServer(boolean)<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestHttpFSServer.java:[line 121] is not discharged<br/>Path continues at TestHttpFSServer.java:[line 122]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86550');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.http.server.TestHttpFSWithKerberos.createHttpFSServer() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86550" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSWithKerberos<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSWithKerberos.createHttpFSServer()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestHttpFSWithKerberos.java:[line 87] is not discharged<br/>Path continues at TestHttpFSWithKerberos.java:[line 88]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N86638');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.http.server.TestHttpFSWithKerberos.createHttpFSServer() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N86638" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSWithKerberos<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSWithKerberos.createHttpFSServer()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestHttpFSWithKerberos.java:[line 75] is not discharged<br/>Path continues at TestHttpFSWithKerberos.java:[line 76]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N87644');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.loadGenerator.TestLoadGenerator.testLoadGenerator() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N87644" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.TestLoadGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.TestLoadGenerator.testLoadGenerator()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestLoadGenerator.java:[line 142] is not discharged<br/>Path continues at TestLoadGenerator.java:[line 143]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N89181');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.shell.TestTextCommand.createAvroFile(byte[]) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N89181" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.shell.TestTextCommand<br/>In method org.apache.hadoop.fs.shell.TestTextCommand.createAvroFile(byte[])<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestTextCommand.java:[line 93] is not discharged<br/>Path continues at TestTextCommand.java:[line 94]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N90254');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.slive.TestSlive.testDataWriting() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N90254" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.TestSlive<br/>In method org.apache.hadoop.fs.slive.TestSlive.testDataWriting()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestSlive.java:[line 254] is not discharged<br/>Path continues at TestSlive.java:[line 255]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90670');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.swift.snative.SwiftNativeOutputStream.uploadFileAttempt(Path, int) may fail to clean up java.io.InputStream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90670" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION">Bug type OBL_UNSATISFIED_OBLIGATION (click for details)</a>
<br/>In class org.apache.hadoop.fs.swift.snative.SwiftNativeOutputStream<br/>In method org.apache.hadoop.fs.swift.snative.SwiftNativeOutputStream.uploadFileAttempt(Path, int)<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at SwiftNativeOutputStream.java:[line 179] is not discharged<br/>Path continues at SwiftNativeOutputStream.java:[line 182]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N90758');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.swift.snative.SwiftNativeOutputStream.uploadFilePartAttempt(int) may fail to clean up java.io.InputStream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N90758" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION">Bug type OBL_UNSATISFIED_OBLIGATION (click for details)</a>
<br/>In class org.apache.hadoop.fs.swift.snative.SwiftNativeOutputStream<br/>In method org.apache.hadoop.fs.swift.snative.SwiftNativeOutputStream.uploadFilePartAttempt(int)<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at SwiftNativeOutputStream.java:[line 331] is not discharged<br/>Path continues at SwiftNativeOutputStream.java:[line 335]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N79075');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.TestFileUtil.testSymlink() may fail to clean up java.io.InputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N79075" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testSymlink()<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestFileUtil.java:[line 865] is not discharged<br/>Path continues at TestFileUtil.java:[line 866]<br/>Path continues at TestFileUtil.java:[line 867]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N79174');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.TestFileUtil.testSymlink() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N79174" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testSymlink()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestFileUtil.java:[line 853] is not discharged<br/>Path continues at TestFileUtil.java:[line 854]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N79262');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.TestFileUtil.testSymlinkLength() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N79262" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testSymlinkLength()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestFileUtil.java:[line 944] is not discharged<br/>Path continues at TestFileUtil.java:[line 945]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N82276');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.TestHardLink.appendToFile(File, String) may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N82276" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestHardLink<br/>In method org.apache.hadoop.fs.TestHardLink.appendToFile(File, String)<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestHardLink.java:[line 194] is not discharged<br/>Path continues at TestHardLink.java:[line 195]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N82364');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.TestHardLink.fetchFileContents(File) may fail to clean up java.io.Reader on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N82364" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestHardLink<br/>In method org.apache.hadoop.fs.TestHardLink.fetchFileContents(File)<br/>Reference type java.io.Reader<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestHardLink.java:[line 202] is not discharged<br/>Path continues at TestHardLink.java:[line 203]<br/>Remaining obligations: {Reader x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N82452');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.fs.TestHardLink.makeNonEmptyFile(File, String) may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N82452" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestHardLink<br/>In method org.apache.hadoop.fs.TestHardLink.makeNonEmptyFile(File, String)<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestHardLink.java:[line 187] is not discharged<br/>Path continues at TestHardLink.java:[line 188]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N94300');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.hdfs.BenchmarkThroughput.readLocalFile(Path, String, Configuration) may fail to clean up java.io.InputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N94300" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.BenchmarkThroughput<br/>In method org.apache.hadoop.hdfs.BenchmarkThroughput.readLocalFile(Path, String, Configuration)<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at BenchmarkThroughput.java:[line 83] is not discharged<br/>Path continues at BenchmarkThroughput.java:[line 84]<br/>Path continues at BenchmarkThroughput.java:[line 85]<br/>Path continues at BenchmarkThroughput.java:[line 86]<br/>Path continues at BenchmarkThroughput.java:[line 87]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94421');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.hdfs.BenchmarkThroughput.writeLocalFile(String, Configuration, long) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94421" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.BenchmarkThroughput<br/>In method org.apache.hadoop.hdfs.BenchmarkThroughput.writeLocalFile(String, Configuration, long)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at BenchmarkThroughput.java:[line 68] is not discharged<br/>Path continues at BenchmarkThroughput.java:[line 69]<br/>Path continues at BenchmarkThroughput.java:[line 70]<br/>Path continues at BenchmarkThroughput.java:[line 71]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N121446');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.saveDfsUsed() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N121446" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice<br/>In method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.saveDfsUsed()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at BlockPoolSlice.java:[line 213] is not discharged<br/>Path continues at BlockPoolSlice.java:[line 215]<br/>Path continues at BlockPoolSlice.java:[line 220]<br/>Path continues at BlockPoolSlice.java:[line 223]<br/>Path continues at BlockPoolSlice.java:[line 225]<br/>Path continues at BlockPoolSlice.java:[line 226]<br/>Path continues at BlockPoolSlice.java:[line 227]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N124396');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil.corruptVersionFile(File, String, String) may fail to clean up java.io.OutputStream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N124396" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION">Bug type OBL_UNSATISFIED_OBLIGATION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil<br/>In method org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil.corruptVersionFile(File, String, String)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at FSImageTestUtil.java:[line 518] is not discharged<br/>Path continues at FSImageTestUtil.java:[line 519]<br/>Path continues at FSImageTestUtil.java:[line 522]<br/>Path continues at FSImageTestUtil.java:[line 523]<br/>Path continues at FSImageTestUtil.java:[line 524]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N136174');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testImageUploadTimeout() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N136174" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage<br/>In method org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testImageUploadTimeout()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestTransferFsImage.java:[line 166] is not discharged<br/>Path continues at TestTransferFsImage.java:[line 167]<br/>Path continues at TestTransferFsImage.java:[line 183]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98672');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.hdfs.TestBlockReaderLocal.runBlockReaderLocalTest(TestBlockReaderLocal$BlockReaderLocalTest, boolean, long) may fail to clean up java.io.InputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98672" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockReaderLocal<br/>In method org.apache.hadoop.hdfs.TestBlockReaderLocal.runBlockReaderLocalTest(TestBlockReaderLocal$BlockReaderLocalTest, boolean, long)<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestBlockReaderLocal.java:[line 171] is not discharged<br/>Obligation to clean up resource created at TestBlockReaderLocal.java:[line 171] is not discharged<br/>Path continues at TestBlockReaderLocal.java:[line 175]<br/>Path continues at TestBlockReaderLocal.java:[line 176]<br/>Path continues at TestBlockReaderLocal.java:[line 177]<br/>Path continues at TestBlockReaderLocal.java:[line 179]<br/>Path continues at TestBlockReaderLocal.java:[line 204]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N102004');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.hdfs.TestDFSShell.createLocalFileWithRandomData(int, File) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N102004" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.createLocalFileWithRandomData(int, File)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestDFSShell.java:[line 102] is not discharged<br/>Path continues at TestDFSShell.java:[line 103]<br/>Path continues at TestDFSShell.java:[line 104]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N143166');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.hdfs.tools.offlineImageViewer.FileDistributionCalculator.visit(RandomAccessFile) may fail to clean up java.io.InputStream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N143166" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION">Bug type OBL_UNSATISFIED_OBLIGATION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.FileDistributionCalculator<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.FileDistributionCalculator.visit(RandomAccessFile)<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at FileDistributionCalculator.java:[line 101] is not discharged<br/>Path continues at FileDistributionCalculator.java:[line 102]<br/>Path continues at FileDistributionCalculator.java:[line 115]<br/>Path continues at FileDistributionCalculator.java:[line 116]<br/>Path continues at FileDistributionCalculator.java:[line 117]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N144822');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.hdfs.util.TestAtomicFileOutputStream.testFailToFlush() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N144822" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestAtomicFileOutputStream<br/>In method org.apache.hadoop.hdfs.util.TestAtomicFileOutputStream.testFailToFlush()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestAtomicFileOutputStream.java:[line 102] is not discharged<br/>Path continues at TestAtomicFileOutputStream.java:[line 103]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N145754');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.hdfs.util.TestMD5FileUtils.setup() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N145754" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestMD5FileUtils<br/>In method org.apache.hadoop.hdfs.util.TestMD5FileUtils.setup()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestMD5FileUtils.java:[line 52] is not discharged<br/>Path continues at TestMD5FileUtils.java:[line 53]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N152290');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.io.compress.TestCodec.testGzipCodecWrite(boolean) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N152290" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.TestCodec<br/>In method org.apache.hadoop.io.compress.TestCodec.testGzipCodecWrite(boolean)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestCodec.java:[line 877] is not discharged<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N160524');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.io.nativeio.TestNativeIO.testFDDoesntLeak() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N160524" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestNativeIO<br/>In method org.apache.hadoop.io.nativeio.TestNativeIO.testFDDoesntLeak()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestNativeIO.java:[line 393] is not discharged<br/>Path continues at TestNativeIO.java:[line 394]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N160612');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.io.nativeio.TestNativeIO.testFstat() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N160612" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestNativeIO<br/>In method org.apache.hadoop.io.nativeio.TestNativeIO.testFstat()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestNativeIO.java:[line 74] is not discharged<br/>Path continues at TestNativeIO.java:[line 76]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N160700');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.io.nativeio.TestNativeIO.testMultiThreadedFstat() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N160700" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestNativeIO<br/>In method org.apache.hadoop.io.nativeio.TestNativeIO.testMultiThreadedFstat()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestNativeIO.java:[line 110] is not discharged<br/>Path continues at TestNativeIO.java:[line 113]<br/>Path continues at TestNativeIO.java:[line 115]<br/>Path continues at TestNativeIO.java:[line 116]<br/>Path continues at TestNativeIO.java:[line 139]<br/>Path continues at TestNativeIO.java:[line 140]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N160832');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.io.nativeio.TestNativeIO.testOpenWithCreate() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N160832" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestNativeIO<br/>In method org.apache.hadoop.io.nativeio.TestNativeIO.testOpenWithCreate()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestNativeIO.java:[line 359] is not discharged<br/>Path continues at TestNativeIO.java:[line 360]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N161102');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory.createTempFile(String) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N161102" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory<br/>In method org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory.createTempFile(String)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestSharedFileDescriptorFactory.java:[line 66] is not discharged<br/>Path continues at TestSharedFileDescriptorFactory.java:[line 67]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N161190');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory.testReadAndWrite() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N161190" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory<br/>In method org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory.testReadAndWrite()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestSharedFileDescriptorFactory.java:[line 56] is not discharged<br/>Path continues at TestSharedFileDescriptorFactory.java:[line 57]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N150288');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.io.TestSecureIOUtils.makeTestFile() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N150288" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.io.TestSecureIOUtils<br/>In method org.apache.hadoop.io.TestSecureIOUtils.makeTestFile()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestSecureIOUtils.java:[line 59] is not discharged<br/>Path continues at TestSecureIOUtils.java:[line 60]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N165083');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.createHadoopConf(Configuration) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N165083" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService<br/>In method org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.createHadoopConf(Configuration)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestFileSystemAccessService.java:[line 53] is not discharged<br/>Path continues at TestFileSystemAccessService.java:[line 54]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N165171');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.serviceHadoopConfCustomDir() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N165171" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService<br/>In method org.apache.hadoop.lib.service.hadoop.TestFileSystemAccessService.serviceHadoopConfCustomDir()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestFileSystemAccessService.java:[line 183] is not discharged<br/>Path continues at TestFileSystemAccessService.java:[line 184]<br/>Path continues at TestFileSystemAccessService.java:[line 185]<br/>Path continues at TestFileSystemAccessService.java:[line 186]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N183822');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator.configure(String, int) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N183822" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator<br/>In method org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator.configure(String, int)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestKeyFieldBasedComparator.java:[line 83] is not discharged<br/>Path continues at TestKeyFieldBasedComparator.java:[line 84]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N184970');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N184970" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestPipeApplication.java:[line 530] is not discharged<br/>Path continues at TestPipeApplication.java:[line 531]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N185058');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.pipes.TestPipeApplication.readFile(File) may fail to clean up java.io.InputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N185058" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.readFile(File)<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestPipeApplication.java:[line 485] is not discharged<br/>Path continues at TestPipeApplication.java:[line 486]<br/>Path continues at TestPipeApplication.java:[line 487]<br/>Path continues at TestPipeApplication.java:[line 488]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N170438');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testBuiltInGzipDecompressor() may fail to clean up java.io.InputStream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N170438" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION">Bug type OBL_UNSATISFIED_OBLIGATION (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestConcatenatedCompressedInput<br/>In method org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testBuiltInGzipDecompressor()<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestConcatenatedCompressedInput.java:[line 334] is not discharged<br/>Path continues at TestConcatenatedCompressedInput.java:[line 335]<br/>Obligation to clean up resource created at TestConcatenatedCompressedInput.java:[line 335] is not discharged<br/>Path continues at TestConcatenatedCompressedInput.java:[line 336]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 337]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 339]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 340]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 341]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 343]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 344]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 348]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 349]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 351]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 355]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 360]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 361]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N170680');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testMoreBzip2() may fail to clean up java.io.InputStream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N170680" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION">Bug type OBL_UNSATISFIED_OBLIGATION (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestConcatenatedCompressedInput<br/>In method org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testMoreBzip2()<br/>Reference type java.io.InputStream<br/>2 instances of obligation remaining<br/>Obligation to clean up resource created at TestConcatenatedCompressedInput.java:[line 541] is not discharged<br/>Path continues at TestConcatenatedCompressedInput.java:[line 542]<br/>Obligation to clean up resource created at TestConcatenatedCompressedInput.java:[line 542] is not discharged<br/>Path continues at TestConcatenatedCompressedInput.java:[line 543]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 544]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 578]<br/>Path continues at TestConcatenatedCompressedInput.java:[line 582]<br/>Remaining obligations: {InputStream x 2}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N170823');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testPrototypeInflaterGzip() may fail to clean up java.io.InputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N170823" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestConcatenatedCompressedInput<br/>In method org.apache.hadoop.mapred.TestConcatenatedCompressedInput.testPrototypeInflaterGzip()<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestConcatenatedCompressedInput.java:[line 233] is not discharged<br/>Path continues at TestConcatenatedCompressedInput.java:[line 234]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N175170');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestMultiFileSplit.testgetLocations() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N175170" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMultiFileSplit<br/>In method org.apache.hadoop.mapred.TestMultiFileSplit.testgetLocations()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestMultiFileSplit.java:[line 78] is not discharged<br/>Path continues at TestMultiFileSplit.java:[line 79]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N176741');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestShuffleHandler.createMapOutputFile(File, Configuration) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N176741" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.createMapOutputFile(File, Configuration)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestShuffleHandler.java:[line 622] is not discharged<br/>Path continues at TestShuffleHandler.java:[line 623]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N177935');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestTextOutputFormat.testCompress() may fail to clean up java.io.InputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N177935" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextOutputFormat<br/>In method org.apache.hadoop.mapred.TestTextOutputFormat.testCompress()<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestTextOutputFormat.java:[line 216] is not discharged<br/>Path continues at TestTextOutputFormat.java:[line 217]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N178368');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestYARNRunner.testAMAdminCommandOpts() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N178368" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestYARNRunner<br/>In method org.apache.hadoop.mapred.TestYARNRunner.testAMAdminCommandOpts()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestYARNRunner.java:[line 401] is not discharged<br/>Path continues at TestYARNRunner.java:[line 402]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N178456');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestYARNRunner.testJobSubmissionFailure() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N178456" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestYARNRunner<br/>In method org.apache.hadoop.mapred.TestYARNRunner.testJobSubmissionFailure()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestYARNRunner.java:[line 188] is not discharged<br/>Path continues at TestYARNRunner.java:[line 189]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N178544');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.TestYARNRunner.testWarnCommandOpts() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N178544" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestYARNRunner<br/>In method org.apache.hadoop.mapred.TestYARNRunner.testWarnCommandOpts()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestYARNRunner.java:[line 467] is not discharged<br/>Path continues at TestYARNRunner.java:[line 468]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N178772');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapred.UtilsForTests.setUpConfigFile(Properties, File) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N178772" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.UtilsForTests<br/>In method org.apache.hadoop.mapred.UtilsForTests.setUpConfigFile(Properties, File)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at UtilsForTests.java:[line 772] is not discharged<br/>Path continues at UtilsForTests.java:[line 774]<br/>Path continues at UtilsForTests.java:[line 779]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N190941');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat.getSplits(JobContext) may fail to clean up java.sql.Statement on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N190941" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.db.DataDrivenDBInputFormat.getSplits(JobContext)<br/>Reference type java.sql.Statement<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at DataDrivenDBInputFormat.java:[line 183] is not discharged<br/>Path continues at DataDrivenDBInputFormat.java:[line 185]<br/>Path continues at DataDrivenDBInputFormat.java:[line 186]<br/>Path continues at DataDrivenDBInputFormat.java:[line 198]<br/>Path continues at DataDrivenDBInputFormat.java:[line 199]<br/>Path continues at DataDrivenDBInputFormat.java:[line 202]<br/>Path continues at DataDrivenDBInputFormat.java:[line 203]<br/>Path continues at DataDrivenDBInputFormat.java:[line 204]<br/>Path continues at DataDrivenDBInputFormat.java:[line 206]<br/>Path continues at DataDrivenDBInputFormat.java:[line 207]<br/>Remaining obligations: {Statement x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N186144');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapreduce.MiniHadoopClusterManager.start() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N186144" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.MiniHadoopClusterManager<br/>In method org.apache.hadoop.mapreduce.MiniHadoopClusterManager.start()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at MiniHadoopClusterManager.java:[line 180] is not discharged<br/>Path continues at MiniHadoopClusterManager.java:[line 181]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N186232');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapreduce.MiniHadoopClusterManager.start() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N186232" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.MiniHadoopClusterManager<br/>In method org.apache.hadoop.mapreduce.MiniHadoopClusterManager.start()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at MiniHadoopClusterManager.java:[line 194] is not discharged<br/>Path continues at MiniHadoopClusterManager.java:[line 195]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N195359');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.startCluster(Configuration) may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N195359" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle<br/>In method org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.startCluster(Configuration)<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestEncryptedShuffle.java:[line 110] is not discharged<br/>Path continues at TestEncryptedShuffle.java:[line 111]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N195063');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapreduce.security.TestMRCredentials.createKeysAsJson(String) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N195063" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.TestMRCredentials<br/>In method org.apache.hadoop.mapreduce.security.TestMRCredentials.createKeysAsJson(String)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestMRCredentials.java:[line 97] is not discharged<br/>Path continues at TestMRCredentials.java:[line 98]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N195919');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapreduce.task.reduce.InMemoryReader.dumpOnError() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N195919" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.InMemoryReader<br/>In method org.apache.hadoop.mapreduce.task.reduce.InMemoryReader.dumpOnError()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at InMemoryReader.java:[line 83] is not discharged<br/>Path continues at InMemoryReader.java:[line 84]<br/>Path continues at InMemoryReader.java:[line 86]<br/>Path continues at InMemoryReader.java:[line 87]<br/>Path continues at InMemoryReader.java:[line 89]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N210575');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspathWithArchives() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N210575" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.util.TestMRApps<br/>In method org.apache.hadoop.mapreduce.v2.util.TestMRApps.testSetClasspathWithArchives()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestMRApps.java:[line 222] is not discharged<br/>Path continues at TestMRApps.java:[line 223]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N219813');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.security.ssl.TestReloadingX509TrustManager.testLoadCorruptTrustStore() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N219813" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.security.ssl.TestReloadingX509TrustManager<br/>In method org.apache.hadoop.security.ssl.TestReloadingX509TrustManager.testLoadCorruptTrustStore()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestReloadingX509TrustManager.java:[line 70] is not discharged<br/>Path continues at TestReloadingX509TrustManager.java:[line 71]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N217284');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.security.TestAuthenticationFilter.testConfiguration() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N217284" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.security.TestAuthenticationFilter<br/>In method org.apache.hadoop.security.TestAuthenticationFilter.testConfiguration()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestAuthenticationFilter.java:[line 45] is not discharged<br/>Path continues at TestAuthenticationFilter.java:[line 46]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N217774');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.security.TestLdapGroupsMapping.testExtractPassword() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N217774" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.security.TestLdapGroupsMapping<br/>In method org.apache.hadoop.security.TestLdapGroupsMapping.testExtractPassword()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestLdapGroupsMapping.java:[line 149] is not discharged<br/>Path continues at TestLdapGroupsMapping.java:[line 150]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N222496');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.streaming.TestStreamingBackground.setUp() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N222496" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamingBackground<br/>In method org.apache.hadoop.streaming.TestStreamingBackground.setUp()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestStreamingBackground.java:[line 65] is not discharged<br/>Path continues at TestStreamingBackground.java:[line 66]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N222929');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.streaming.TestStreamingExitStatus.setUp() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N222929" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamingExitStatus<br/>In method org.apache.hadoop.streaming.TestStreamingExitStatus.setUp()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestStreamingExitStatus.java:[line 70] is not discharged<br/>Path continues at TestStreamingExitStatus.java:[line 71]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N223367');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.streaming.TestStreamingStderr.setupInput(String, boolean) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N223367" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamingStderr<br/>In method org.apache.hadoop.streaming.TestStreamingStderr.setupInput(String, boolean)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestStreamingStderr.java:[line 61] is not discharged<br/>Path continues at TestStreamingStderr.java:[line 62]<br/>Path continues at TestStreamingStderr.java:[line 63]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N222317');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.streaming.TestStreamXmlRecordReader.createInput() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N222317" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamXmlRecordReader<br/>In method org.apache.hadoop.streaming.TestStreamXmlRecordReader.createInput()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestStreamXmlRecordReader.java:[line 44] is not discharged<br/>Path continues at TestStreamXmlRecordReader.java:[line 45]<br/>Path continues at TestStreamXmlRecordReader.java:[line 46]<br/>Path continues at TestStreamXmlRecordReader.java:[line 47]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N224903');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.test.MiniDFSClusterManager.start() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N224903" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.test.MiniDFSClusterManager<br/>In method org.apache.hadoop.test.MiniDFSClusterManager.start()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at MiniDFSClusterManager.java:[line 150] is not discharged<br/>Path continues at MiniDFSClusterManager.java:[line 151]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N224991');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.test.MiniDFSClusterManager.start() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N224991" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.test.MiniDFSClusterManager<br/>In method org.apache.hadoop.test.MiniDFSClusterManager.start()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at MiniDFSClusterManager.java:[line 161] is not discharged<br/>Path continues at MiniDFSClusterManager.java:[line 162]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N225298');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.test.SysPropsForTestsLoader.&lt;static initializer for SysPropsForTestsLoader&gt;() may fail to clean up java.io.Reader</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N225298" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION">Bug type OBL_UNSATISFIED_OBLIGATION (click for details)</a>
<br/>In class org.apache.hadoop.test.SysPropsForTestsLoader<br/>In method org.apache.hadoop.test.SysPropsForTestsLoader.&lt;static initializer for SysPropsForTestsLoader&gt;()<br/>Reference type java.io.Reader<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at SysPropsForTestsLoader.java:[line 48] is not discharged<br/>Path continues at SysPropsForTestsLoader.java:[line 49]<br/>Path continues at SysPropsForTestsLoader.java:[line 54]<br/>Path continues at SysPropsForTestsLoader.java:[line 64]<br/>Path continues at SysPropsForTestsLoader.java:[line 65]<br/>Remaining obligations: {Reader x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N232242');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithCommentsOnly() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N232242" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestHostsFileReader<br/>In method org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithCommentsOnly()<br/>Reference type java.io.Writer<br/>2 instances of obligation remaining<br/>Obligation to clean up resource created at TestHostsFileReader.java:[line 171] is not discharged<br/>Path continues at TestHostsFileReader.java:[line 172]<br/>Obligation to clean up resource created at TestHostsFileReader.java:[line 172] is not discharged<br/>Path continues at TestHostsFileReader.java:[line 174]<br/>Remaining obligations: {Writer x 2}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N232352');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithNull() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N232352" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestHostsFileReader<br/>In method org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithNull()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestHostsFileReader.java:[line 143] is not discharged<br/>Path continues at TestHostsFileReader.java:[line 144]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N232440');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithSpaces() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N232440" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestHostsFileReader<br/>In method org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithSpaces()<br/>Reference type java.io.Writer<br/>2 instances of obligation remaining<br/>Obligation to clean up resource created at TestHostsFileReader.java:[line 199] is not discharged<br/>Path continues at TestHostsFileReader.java:[line 200]<br/>Obligation to clean up resource created at TestHostsFileReader.java:[line 200] is not discharged<br/>Path continues at TestHostsFileReader.java:[line 202]<br/>Remaining obligations: {Writer x 2}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N232550');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithTabs() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N232550" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestHostsFileReader<br/>In method org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithTabs()<br/>Reference type java.io.Writer<br/>2 instances of obligation remaining<br/>Obligation to clean up resource created at TestHostsFileReader.java:[line 235] is not discharged<br/>Path continues at TestHostsFileReader.java:[line 236]<br/>Obligation to clean up resource created at TestHostsFileReader.java:[line 236] is not discharged<br/>Path continues at TestHostsFileReader.java:[line 238]<br/>Remaining obligations: {Writer x 2}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N232660');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.util.TestHostsFileReader.testHostsFileReader() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N232660" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestHostsFileReader<br/>In method org.apache.hadoop.util.TestHostsFileReader.testHostsFileReader()<br/>Reference type java.io.Writer<br/>2 instances of obligation remaining<br/>Obligation to clean up resource created at TestHostsFileReader.java:[line 64] is not discharged<br/>Path continues at TestHostsFileReader.java:[line 65]<br/>Obligation to clean up resource created at TestHostsFileReader.java:[line 65] is not discharged<br/>Path continues at TestHostsFileReader.java:[line 67]<br/>Remaining obligations: {Writer x 2}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N232770');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.util.TestHostsFileReader.testRefreshHostFileReaderWithNonexistentFile() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N232770" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestHostsFileReader<br/>In method org.apache.hadoop.util.TestHostsFileReader.testRefreshHostFileReaderWithNonexistentFile()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestHostsFileReader.java:[line 121] is not discharged<br/>Path continues at TestHostsFileReader.java:[line 122]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N233247');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.util.TestJarFinder.testExistingManifest() may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N233247" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestJarFinder<br/>In method org.apache.hadoop.util.TestJarFinder.testExistingManifest()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestJarFinder.java:[line 91] is not discharged<br/>Path continues at TestJarFinder.java:[line 92]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N233335');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.util.TestJarFinder.testExistingManifest() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N233335" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestJarFinder<br/>In method org.apache.hadoop.util.TestJarFinder.testExistingManifest()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestJarFinder.java:[line 96] is not discharged<br/>Path continues at TestJarFinder.java:[line 97]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N233423');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.util.TestJarFinder.testNoManifest() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N233423" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestJarFinder<br/>In method org.apache.hadoop.util.TestJarFinder.testNoManifest()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestJarFinder.java:[line 115] is not discharged<br/>Path continues at TestJarFinder.java:[line 116]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N233742');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.util.TestMRCJCRunJar.makeTestJar() may fail to clean up java.io.InputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N233742" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestMRCJCRunJar<br/>In method org.apache.hadoop.util.TestMRCJCRunJar.makeTestJar()<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestMRCJCRunJar.java:[line 64] is not discharged<br/>Path continues at TestMRCJCRunJar.java:[line 66]<br/>Path continues at TestMRCJCRunJar.java:[line 67]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N234759');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.util.TestWinUtils.readFile(File) may fail to clean up java.io.InputStream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N234759" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION">Bug type OBL_UNSATISFIED_OBLIGATION (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.readFile(File)<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestWinUtils.java:[line 70] is not discharged<br/>Path continues at TestWinUtils.java:[line 71]<br/>Path continues at TestWinUtils.java:[line 72]<br/>Path continues at TestWinUtils.java:[line 73]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N234869');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.util.TestWinUtils.writeFile(File, String) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N234869" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.writeFile(File, String)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestWinUtils.java:[line 63] is not discharged<br/>Path continues at TestWinUtils.java:[line 64]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N237039');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.yarn.applications.distributedshell.Log4jPropertyHelper.updateLog4jConfiguration(Class, String) may fail to clean up java.io.InputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N237039" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.distributedshell.Log4jPropertyHelper<br/>In method org.apache.hadoop.yarn.applications.distributedshell.Log4jPropertyHelper.updateLog4jConfiguration(Class, String)<br/>Reference type java.io.InputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at Log4jPropertyHelper.java:[line 39] is not discharged<br/>Path continues at Log4jPropertyHelper.java:[line 40]<br/>Obligation to clean up resource created at Log4jPropertyHelper.java:[line 40] is not discharged<br/>Path continues at Log4jPropertyHelper.java:[line 41]<br/>Path continues at Log4jPropertyHelper.java:[line 51]<br/>Remaining obligations: {InputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N244941');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.writeLog(String, String) may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N244941" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock<br/>In method org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.writeLog(String, String)<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestAggregatedLogsBlock.java:[line 248] is not discharged<br/>Path continues at TestAggregatedLogsBlock.java:[line 249]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N253496');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.writeContainerLogs(File, ContainerId) may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N253496" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.writeContainerLogs(File, ContainerId)<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestLogAggregationService.java:[line 682] is not discharged<br/>Path continues at TestLogAggregationService.java:[line 683]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N247554');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService.testNodeHealthScriptShouldRun() may fail to clean up java.io.OutputStream</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N247554" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION">Bug type OBL_UNSATISFIED_OBLIGATION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService.testNodeHealthScriptShouldRun()<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestNodeHealthService.java:[line 107] is not discharged<br/>Path continues at TestNodeHealthService.java:[line 108]<br/>Path continues at TestNodeHealthService.java:[line 109]<br/>Path continues at TestNodeHealthService.java:[line 112]<br/>Path continues at TestNodeHealthService.java:[line 114]<br/>Path continues at TestNodeHealthService.java:[line 115]<br/>Path continues at TestNodeHealthService.java:[line 117]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N256352');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer.writeContainerLogs(Context, ContainerId, LocalDirsHandlerService) may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N256352" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer.writeContainerLogs(Context, ContainerId, LocalDirsHandlerService)<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestNMWebServer.java:[line 230] is not discharged<br/>Path continues at TestNMWebServer.java:[line 231]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N272774');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.yarn.state.Graph.save(String) may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N272774" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.state.Graph<br/>In method org.apache.hadoop.yarn.state.Graph.save(String)<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at Graph.java:[line 189] is not discharged<br/>Path continues at Graph.java:[line 190]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N274113');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.yarn.util.TestFSDownload.createJar(FileContext, Path, LocalResourceVisibility) may fail to clean up java.io.OutputStream on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N274113" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestFSDownload<br/>In method org.apache.hadoop.yarn.util.TestFSDownload.createJar(FileContext, Path, LocalResourceVisibility)<br/>Reference type java.io.OutputStream<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestFSDownload.java:[line 129] is not discharged<br/>Path continues at TestFSDownload.java:[line 130]<br/>Remaining obligations: {OutputStream x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N274810');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.parsingProcMemFile() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N274810" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin<br/>In method org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.parsingProcMemFile()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestLinuxResourceCalculatorPlugin.java:[line 223] is not discharged<br/>Path continues at TestLinuxResourceCalculatorPlugin.java:[line 224]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N274898');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.parsingProcStatAndCpuFile() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N274898" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin<br/>In method org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.parsingProcStatAndCpuFile()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestLinuxResourceCalculatorPlugin.java:[line 159] is not discharged<br/>Path continues at TestLinuxResourceCalculatorPlugin.java:[line 160]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N274986');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.updateStatFile(long, long, long) may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N274986" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin<br/>In method org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.updateStatFile(long, long, long)<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestLinuxResourceCalculatorPlugin.java:[line 205] is not discharged<br/>Path continues at TestLinuxResourceCalculatorPlugin.java:[line 206]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N275792');">
<td>
<span class="priority-2">OBL</span>
</td>
<td>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree() may fail to clean up java.io.Writer on checked exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N275792" style="display: none;">
<a href="#OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">Bug type OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree<br/>In method org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree()<br/>Reference type java.io.Writer<br/>1 instances of obligation remaining<br/>Obligation to clean up resource created at TestProcfsBasedProcessTree.java:[line 148] is not discharged<br/>Path continues at TestProcfsBasedProcessTree.java:[line 149]<br/>Path continues at TestProcfsBasedProcessTree.java:[line 154]<br/>Path continues at TestProcfsBasedProcessTree.java:[line 155]<br/>Remaining obligations: {Writer x 1}</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_I18N">Internationalization Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N65682');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.cli.util.CommandExecutor.executeCommand(String): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N65682" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.cli.util.CommandExecutor<br/>In method org.apache.hadoop.cli.util.CommandExecutor.executeCommand(String)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At CommandExecutor.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N65751');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.cli.util.CommandExecutor.executeCommand(String): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N65751" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.cli.util.CommandExecutor<br/>In method org.apache.hadoop.cli.util.CommandExecutor.executeCommand(String)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At CommandExecutor.java:[line 74]<br/>Another occurrence at CommandExecutor.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N65831');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.Configuration.getConfResourceAsReader(String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N65831" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.Configuration<br/>In method org.apache.hadoop.conf.Configuration.getConfResourceAsReader(String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At Configuration.java:[line 2082]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N66362');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testBooleanValues(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N66362" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testBooleanValues()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 586]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66431');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testCommentsInValue(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66431" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testCommentsInValue()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 294]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N66500');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testDoubleValues(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N66500" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testDoubleValues()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 633]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66569');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testDumpConfiguratioWithoutDefaults(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66569" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testDumpConfiguratioWithoutDefaults()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 1106]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N66638');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testDumpConfiguration(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N66638" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testDumpConfiguration()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 1016]<br/>Another occurrence at TestConfiguration.java:[line 1036]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66718');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testFinalParam(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66718" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testFinalParam()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 184]<br/>Another occurrence at TestConfiguration.java:[line 193]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N66798');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testFloatValues(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N66798" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testFloatValues()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 610]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66867');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testGetClass(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66867" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testGetClass()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 656]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N66936');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testGetClasses(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N66936" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testGetClasses()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 668]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67005');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testGetFinalParameters(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67005" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testGetFinalParameters()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 1188]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N67074');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testHexValues(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N67074" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testHexValues()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 504]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67143');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testHumanReadableValues(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67143" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testHumanReadableValues()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 566]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N67212');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testIncludes(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N67212" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testIncludes()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 388]<br/>Another occurrence at TestConfiguration.java:[line 394]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67292');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testInputStreamResource(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67292" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testInputStreamResource()<br/>Called method String.getBytes()<br/>At TestConfiguration.java:[line 104]<br/>Another occurrence at TestConfiguration.java:[line 108]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N67372');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testIntegerValues(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N67372" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testIntegerValues()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 535]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67441');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testMultiplePropertySource(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67441" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testMultiplePropertySource()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 824]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N67510');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testOverlay(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N67510" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testOverlay()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 260]<br/>Another occurrence at TestConfiguration.java:[line 268]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67590');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testPattern(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67590" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testPattern()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 774]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N67659');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testPropertySource(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N67659" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testPropertySource()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 801]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67728');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testRelativeIncludes(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67728" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testRelativeIncludes()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 417]<br/>Another occurrence at TestConfiguration.java:[line 422]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N67808');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testReload(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N67808" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testReload()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 896]<br/>Another occurrence at TestConfiguration.java:[line 904]<br/>Another occurrence at TestConfiguration.java:[line 922]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N67899');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testToString(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N67899" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testToString()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 363]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N67968');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testTrim(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N67968" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testTrim()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 305]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68037');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testVariableSubstitution(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68037" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testVariableSubstitution()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfiguration.java:[line 149]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N68106');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfiguration.testWriteXml(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N68106" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testWriteXml()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestConfiguration.java:[line 379]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68440');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfigurationDeprecation.testDeprecation(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68440" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfigurationDeprecation<br/>In method org.apache.hadoop.conf.TestConfigurationDeprecation.testDeprecation()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfigurationDeprecation.java:[line 124]<br/>Another occurrence at TestConfigurationDeprecation.java:[line 146]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N68520');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestConfigurationDeprecation.testDeprecationForFinalParameters(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N68520" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfigurationDeprecation<br/>In method org.apache.hadoop.conf.TestConfigurationDeprecation.testDeprecationForFinalParameters()<br/>Called method new java.io.FileWriter(String)<br/>At TestConfigurationDeprecation.java:[line 190]<br/>Another occurrence at TestConfigurationDeprecation.java:[line 218]<br/>Another occurrence at TestConfigurationDeprecation.java:[line 241]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68773');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestDeprecatedKeys.testReadWriteWithDeprecatedKeys(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68773" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestDeprecatedKeys<br/>In method org.apache.hadoop.conf.TestDeprecatedKeys.testReadWriteWithDeprecatedKeys()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestDeprecatedKeys.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N68842');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestNoDefaultsJobConf.testNoDefaults(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N68842" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestNoDefaultsJobConf<br/>In method org.apache.hadoop.conf.TestNoDefaultsJobConf.testNoDefaults()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestNoDefaultsJobConf.java:[line 89]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N68911');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.conf.TestNoDefaultsJobConf.testNoDefaults(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N68911" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestNoDefaultsJobConf<br/>In method org.apache.hadoop.conf.TestNoDefaultsJobConf.testNoDefaults()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestNoDefaultsJobConf.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69120');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.contrib.bkjournal.BookKeeperJournalManager.recoverLastTxId(EditLogLedgerMetadata, boolean): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69120" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.BookKeeperJournalManager<br/>In method org.apache.hadoop.contrib.bkjournal.BookKeeperJournalManager.recoverLastTxId(EditLogLedgerMetadata, boolean)<br/>Called method String.getBytes()<br/>At BookKeeperJournalManager.java:[line 733]<br/>Another occurrence at BookKeeperJournalManager.java:[line 737]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69200');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.contrib.bkjournal.BookKeeperJournalManager.selectInputStreams(Collection, long, boolean): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69200" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.BookKeeperJournalManager<br/>In method org.apache.hadoop.contrib.bkjournal.BookKeeperJournalManager.selectInputStreams(Collection, long, boolean)<br/>Called method String.getBytes()<br/>At BookKeeperJournalManager.java:[line 524]<br/>Another occurrence at BookKeeperJournalManager.java:[line 527]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69280');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.contrib.bkjournal.BookKeeperJournalManager.startLogSegment(long, int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69280" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.BookKeeperJournalManager<br/>In method org.apache.hadoop.contrib.bkjournal.BookKeeperJournalManager.startLogSegment(long, int)<br/>Called method String.getBytes()<br/>At BookKeeperJournalManager.java:[line 386]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69906');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.contrib.bkjournal.TestBookKeeperEditLogStreams.testEmptyInputStream(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69906" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestBookKeeperEditLogStreams<br/>In method org.apache.hadoop.contrib.bkjournal.TestBookKeeperEditLogStreams.testEmptyInputStream()<br/>Called method String.getBytes()<br/>At TestBookKeeperEditLogStreams.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70042');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.contrib.bkjournal.TestBookKeeperJournalManager.testCorruptInprogressNode(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70042" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestBookKeeperJournalManager<br/>In method org.apache.hadoop.contrib.bkjournal.TestBookKeeperJournalManager.testCorruptInprogressNode()<br/>Called method String.getBytes()<br/>At TestBookKeeperJournalManager.java:[line 602]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72426');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72426" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.DFSCIOTest<br/>In method org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At DFSCIOTest.java:[line 501]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N72495');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N72495" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.DFSCIOTest<br/>In method org.apache.hadoop.fs.DFSCIOTest.analyzeResult(FileSystem, int, long, String)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At DFSCIOTest.java:[line 538]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72749');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72749" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.DistributedFSCheck<br/>In method org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At DistributedFSCheck.java:[line 289]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N72818');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N72818" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.DistributedFSCheck<br/>In method org.apache.hadoop.fs.DistributedFSCheck.analyzeResult(long, String, boolean)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At DistributedFSCheck.java:[line 346]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N73630');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.FileContextUtilBase.testFcCopy(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N73630" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.FileContextUtilBase<br/>In method org.apache.hadoop.fs.FileContextUtilBase.testFcCopy()<br/>Called method String.getBytes()<br/>At FileContextUtilBase.java:[line 75]<br/>Another occurrence at FileContextUtilBase.java:[line 82]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73710');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.FileContextUtilBase.testRecursiveFcCopy(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73710" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.FileContextUtilBase<br/>In method org.apache.hadoop.fs.FileContextUtilBase.testRecursiveFcCopy()<br/>Called method String.getBytes()<br/>At FileContextUtilBase.java:[line 95]<br/>Another occurrence at FileContextUtilBase.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74097');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.FileSystemTestHelper.readFile(FileSystem, Path, int): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74097" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.FileSystemTestHelper<br/>In method org.apache.hadoop.fs.FileSystemTestHelper.readFile(FileSystem, Path, int)<br/>Called method new String(byte[], int, int)<br/>At FileSystemTestHelper.java:[line 202]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N74166');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.FileSystemTestHelper.writeFile(FileSystem, Path, int): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N74166" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.FileSystemTestHelper<br/>In method org.apache.hadoop.fs.FileSystemTestHelper.writeFile(FileSystem, Path, int)<br/>Called method new String(byte[])<br/>At FileSystemTestHelper.java:[line 189]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74235');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.HardLink.createHardLink(File, File): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74235" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.HardLink<br/>In method org.apache.hadoop.fs.HardLink.createHardLink(File, File)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At HardLink.java:[line 385]<br/>Another occurrence at HardLink.java:[line 388]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N74315');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.HardLink.createHardLinkMult(File, String[], File, int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N74315" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.HardLink<br/>In method org.apache.hadoop.fs.HardLink.createHardLinkMult(File, String[], File, int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At HardLink.java:[line 473]<br/>Another occurrence at HardLink.java:[line 476]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74395');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.HardLink.getLinkCount(File): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74395" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.HardLink<br/>In method org.apache.hadoop.fs.HardLink.getLinkCount(File)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At HardLink.java:[line 512]<br/>Another occurrence at HardLink.java:[line 515]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84639');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.http.client.BaseTestHttpFSWith.createHttpFSServer(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84639" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.client.BaseTestHttpFSWith<br/>In method org.apache.hadoop.fs.http.client.BaseTestHttpFSWith.createHttpFSServer()<br/>Called method new java.io.FileWriter(File)<br/>At BaseTestHttpFSWith.java:[line 82]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N85044');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.http.client.HttpFSUtils.jsonParse(HttpURLConnection): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N85044" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.client.HttpFSUtils<br/>In method org.apache.hadoop.fs.http.client.HttpFSUtils.jsonParse(HttpURLConnection)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At HttpFSUtils.java:[line 149]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85490');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.http.server.HttpFSAuthenticationFilter.getConfiguration(String, FilterConfig): new java.io.FileReader(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85490" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.HttpFSAuthenticationFilter<br/>In method org.apache.hadoop.fs.http.server.HttpFSAuthenticationFilter.getConfiguration(String, FilterConfig)<br/>Called method new java.io.FileReader(String)<br/>At HttpFSAuthenticationFilter.java:[line 79]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N85760');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.http.server.TestHttpFSServer.createHttpFSServer(boolean): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N85760" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSServer<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSServer.createHttpFSServer(boolean)<br/>Called method new java.io.FileWriter(File)<br/>At TestHttpFSServer.java:[line 121]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85829');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.http.server.TestHttpFSServer.instrumentation(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85829" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSServer<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSServer.instrumentation()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestHttpFSServer.java:[line 184]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N85898');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.http.server.TestHttpFSServer.testDelegationTokenOperations(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N85898" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSServer<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSServer.testDelegationTokenOperations()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestHttpFSServer.java:[line 313]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85967');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.http.server.TestHttpFSServer.testDelegationTokenOperations(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85967" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSServer<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSServer.testDelegationTokenOperations()<br/>Called method String.getBytes()<br/>At TestHttpFSServer.java:[line 294]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86036');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.http.server.TestHttpFSServer.testGlobFilter(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86036" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSServer<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSServer.testGlobFilter()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestHttpFSServer.java:[line 229]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N86105');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.http.server.TestHttpFSServer.testHdfsAccess(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N86105" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSServer<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSServer.testHdfsAccess()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestHttpFSServer.java:[line 208]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86481');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.http.server.TestHttpFSWithKerberos.createHttpFSServer(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86481" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSWithKerberos<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSWithKerberos.createHttpFSServer()<br/>Called method new java.io.FileWriter(File)<br/>At TestHttpFSWithKerberos.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N74652');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.JHLogAnalyzer.analyzeResult(FileSystem, int, long, Path): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N74652" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.JHLogAnalyzer<br/>In method org.apache.hadoop.fs.JHLogAnalyzer.analyzeResult(FileSystem, int, long, Path)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At JHLogAnalyzer.java:[line 1093]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74721');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.JHLogAnalyzer.analyzeResult(FileSystem, int, long, Path): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74721" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.JHLogAnalyzer<br/>In method org.apache.hadoop.fs.JHLogAnalyzer.analyzeResult(FileSystem, int, long, Path)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At JHLogAnalyzer.java:[line 1084]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N86796');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.loadGenerator.DataGenerator.genDirStructure(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N86796" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.DataGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.DataGenerator.genDirStructure()<br/>Called method new java.io.FileReader(File)<br/>At DataGenerator.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86865');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.loadGenerator.DataGenerator.genFiles(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86865" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.DataGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.DataGenerator.genFiles()<br/>Called method new java.io.FileReader(File)<br/>At DataGenerator.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87188');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.loadGenerator.LoadGenerator.loadScriptFile(String): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87188" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.LoadGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.LoadGenerator.loadScriptFile(String)<br/>Called method new java.io.FileReader(File)<br/>At LoadGenerator.java:[line 531]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N87324');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.loadGenerator.StructureGenerator.output(File): new java.io.PrintStream(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N87324" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.StructureGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.StructureGenerator.output(File)<br/>Called method new java.io.PrintStream(File)<br/>At StructureGenerator.java:[line 285]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87393');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.loadGenerator.StructureGenerator.outputFiles(File): new java.io.PrintStream(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87393" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.StructureGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.StructureGenerator.outputFiles(File)<br/>Called method new java.io.PrintStream(File)<br/>At StructureGenerator.java:[line 294]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N87462');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.loadGenerator.TestLoadGenerator.testLoadGenerator(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N87462" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.TestLoadGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.TestLoadGenerator.testLoadGenerator()<br/>Called method new java.io.FileWriter(File)<br/>At TestLoadGenerator.java:[line 142]<br/>Another occurrence at TestLoadGenerator.java:[line 147]<br/>Another occurrence at TestLoadGenerator.java:[line 220]<br/>Another occurrence at TestLoadGenerator.java:[line 234]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87564');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.loadGenerator.TestLoadGenerator.testStructureGenerator(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87564" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.TestLoadGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.TestLoadGenerator.testStructureGenerator()<br/>Called method new java.io.FileReader(File)<br/>At TestLoadGenerator.java:[line 79]<br/>Another occurrence at TestLoadGenerator.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N87996');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.permission.TestStickyBit.confirmCanAppend(Configuration, Path): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N87996" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.permission.TestStickyBit<br/>In method org.apache.hadoop.fs.permission.TestStickyBit.confirmCanAppend(Configuration, Path)<br/>Called method String.getBytes()<br/>At TestStickyBit.java:[line 114]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N88065');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.permission.TestStickyBit.writeFile(FileSystem, Path): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N88065" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.permission.TestStickyBit<br/>In method org.apache.hadoop.fs.permission.TestStickyBit.writeFile(FileSystem, Path)<br/>Called method String.getBytes()<br/>At TestStickyBit.java:[line 383]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89990');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.slive.SliveTest.writeReport(ConfigExtractor): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89990" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.SliveTest<br/>In method org.apache.hadoop.fs.slive.SliveTest.writeReport(ConfigExtractor)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At SliveTest.java:[line 232]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90059');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.slive.SliveTest.writeReport(ConfigExtractor): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90059" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.SliveTest<br/>In method org.apache.hadoop.fs.slive.SliveTest.writeReport(ConfigExtractor)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At SliveTest.java:[line 264]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N90532');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystemStore.getObjectLocation(Path): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N90532" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystemStore<br/>In method org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystemStore.getObjectLocation(Path)<br/>Called method new String(byte[])<br/>At SwiftNativeFileSystemStore.java:[line 449]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90601');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystemStore.listDirectory(SwiftObjectPath, boolean, boolean): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90601" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystemStore<br/>In method org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystemStore.listDirectory(SwiftObjectPath, boolean, boolean)<br/>Called method new String(byte[])<br/>At SwiftNativeFileSystemStore.java:[line 354]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75716');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestAvroFSInput.testAFSInput(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75716" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestAvroFSInput<br/>In method org.apache.hadoop.fs.TestAvroFSInput.testAFSInput()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestAvroFSInput.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N75785');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestChecksumFileSystem.testCorruptedChecksum(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N75785" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestChecksumFileSystem<br/>In method org.apache.hadoop.fs.TestChecksumFileSystem.testCorruptedChecksum()<br/>Called method String.getBytes()<br/>At TestChecksumFileSystem.java:[line 179]<br/>Another occurrence at TestChecksumFileSystem.java:[line 186]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75865');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestChecksumFileSystem.testMultiChunkFile(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75865" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestChecksumFileSystem<br/>In method org.apache.hadoop.fs.TestChecksumFileSystem.testMultiChunkFile()<br/>Called method String.getBytes()<br/>At TestChecksumFileSystem.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N75934');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestChecksumFileSystem.testTruncatedChecksum(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N75934" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestChecksumFileSystem<br/>In method org.apache.hadoop.fs.TestChecksumFileSystem.testTruncatedChecksum()<br/>Called method String.getBytes()<br/>At TestChecksumFileSystem.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76003');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestChecksumFileSystem.testVerifyChecksum(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76003" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestChecksumFileSystem<br/>In method org.apache.hadoop.fs.TestChecksumFileSystem.testVerifyChecksum()<br/>Called method String.getBytes()<br/>At TestChecksumFileSystem.java:[line 58]<br/>Another occurrence at TestChecksumFileSystem.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77624');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestDFSIO.analyzeResult(FileSystem, TestDFSIO$TestType, long, String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77624" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestDFSIO<br/>In method org.apache.hadoop.fs.TestDFSIO.analyzeResult(FileSystem, TestDFSIO$TestType, long, String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestDFSIO.java:[line 817]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N77693');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestDFSIO.analyzeResult(FileSystem, TestDFSIO$TestType, long, String): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N77693" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestDFSIO<br/>In method org.apache.hadoop.fs.TestDFSIO.analyzeResult(FileSystem, TestDFSIO$TestType, long, String)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestDFSIO.java:[line 853]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N78708');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFileUtil.createFile(File, String, String): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N78708" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.createFile(File, String, String)<br/>Called method new java.io.PrintWriter(File)<br/>At TestFileUtil.java:[line 129]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78777');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFileUtil.testCopy5(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78777" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testCopy5()<br/>Called method String.getBytes()<br/>At TestFileUtil.java:[line 767]<br/>Another occurrence at TestFileUtil.java:[line 777]<br/>Another occurrence at TestFileUtil.java:[line 792]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N78868');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFileUtil.testCopyMergeSingleDirectory(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N78868" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testCopyMergeSingleDirectory()<br/>Called method new java.io.FileReader(File)<br/>At TestFileUtil.java:[line 511]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78937');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFileUtil.testSymlink(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78937" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testSymlink()<br/>Called method String.getBytes()<br/>At TestFileUtil.java:[line 847]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N79006');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFileUtil.testSymlinkLength(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N79006" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testSymlinkLength()<br/>Called method String.getBytes()<br/>At TestFileUtil.java:[line 938]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81110');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFsShellCopy.createFile(Path[]): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81110" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFsShellCopy<br/>In method org.apache.hadoop.fs.TestFsShellCopy.createFile(Path[])<br/>Called method String.getBytes()<br/>At TestFsShellCopy.java:[line 491]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N81179');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFsShellCopy.readFile(String): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N81179" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFsShellCopy<br/>In method org.apache.hadoop.fs.TestFsShellCopy.readFile(String)<br/>Called method new String(byte[])<br/>At TestFsShellCopy.java:[line 504]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81248');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFsShellReturnCode.testGetWithInvalidSourcePathShouldNotDisplayNullInConsole(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81248" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFsShellReturnCode<br/>In method org.apache.hadoop.fs.TestFsShellReturnCode.testGetWithInvalidSourcePathShouldNotDisplayNullInConsole()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestFsShellReturnCode.java:[line 304]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N81317');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFsShellReturnCode.testGetWithInvalidSourcePathShouldNotDisplayNullInConsole(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N81317" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFsShellReturnCode<br/>In method org.apache.hadoop.fs.TestFsShellReturnCode.testGetWithInvalidSourcePathShouldNotDisplayNullInConsole()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestFsShellReturnCode.java:[line 289]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81386');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFsShellReturnCode.testInvalidDefaultFS(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81386" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFsShellReturnCode<br/>In method org.apache.hadoop.fs.TestFsShellReturnCode.testInvalidDefaultFS()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestFsShellReturnCode.java:[line 375]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N81455');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFsShellReturnCode.testInvalidDefaultFS(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N81455" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFsShellReturnCode<br/>In method org.apache.hadoop.fs.TestFsShellReturnCode.testInvalidDefaultFS()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestFsShellReturnCode.java:[line 369]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81524');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFsShellReturnCode.testRmForceWithNonexistentGlob(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81524" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFsShellReturnCode<br/>In method org.apache.hadoop.fs.TestFsShellReturnCode.testRmForceWithNonexistentGlob()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestFsShellReturnCode.java:[line 347]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N81593');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFsShellReturnCode.testRmForceWithNonexistentGlob(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N81593" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFsShellReturnCode<br/>In method org.apache.hadoop.fs.TestFsShellReturnCode.testRmForceWithNonexistentGlob()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestFsShellReturnCode.java:[line 341]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81662');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFsShellReturnCode.testRmWithNonexistentGlob(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81662" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFsShellReturnCode<br/>In method org.apache.hadoop.fs.TestFsShellReturnCode.testRmWithNonexistentGlob()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestFsShellReturnCode.java:[line 327]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N81731');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestFsShellReturnCode.testRmWithNonexistentGlob(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N81731" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFsShellReturnCode<br/>In method org.apache.hadoop.fs.TestFsShellReturnCode.testRmWithNonexistentGlob()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestFsShellReturnCode.java:[line 320]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N81923');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestHardLink.appendToFile(File, String): new java.io.FileWriter(File, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N81923" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestHardLink<br/>In method org.apache.hadoop.fs.TestHardLink.appendToFile(File, String)<br/>Called method new java.io.FileWriter(File, boolean)<br/>At TestHardLink.java:[line 194]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N81992');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestHardLink.fetchFileContents(File): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N81992" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestHardLink<br/>In method org.apache.hadoop.fs.TestHardLink.fetchFileContents(File)<br/>Called method new java.io.FileReader(File)<br/>At TestHardLink.java:[line 202]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N82061');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestHardLink.makeNonEmptyFile(File, String): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N82061" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestHardLink<br/>In method org.apache.hadoop.fs.TestHardLink.makeNonEmptyFile(File, String)<br/>Called method new java.io.FileWriter(File)<br/>At TestHardLink.java:[line 187]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N82794');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestJHLA.setUp(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N82794" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestJHLA<br/>In method org.apache.hadoop.fs.TestJHLA.setUp()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestJHLA.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83583');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestLocalFileSystem.testWorkingDirectory(): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83583" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestLocalFileSystem<br/>In method org.apache.hadoop.fs.TestLocalFileSystem.testWorkingDirectory()<br/>Called method new String(byte[], int, int)<br/>At TestLocalFileSystem.java:[line 119]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84157');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestTrash.trashShell(Configuration, Path, FileSystem, Path): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84157" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestTrash<br/>In method org.apache.hadoop.fs.TestTrash.trashShell(Configuration, Path, FileSystem, Path)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestTrash.java:[line 431]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N84226');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.TestTrash.trashShell(Configuration, Path, FileSystem, Path): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N84226" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestTrash<br/>In method org.apache.hadoop.fs.TestTrash.trashShell(Configuration, Path, FileSystem, Path)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestTrash.java:[line 422]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91452');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.fs.viewfs.TestViewfsFileStatus.testFileStatusSerialziation(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91452" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.TestViewfsFileStatus<br/>In method org.apache.hadoop.fs.viewfs.TestViewfsFileStatus.testFileStatusSerialziation()<br/>Called method String.getBytes()<br/>At TestViewfsFileStatus.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92187');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.ha.ClientBaseWithFixes.send4LetterWord(String, int, String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92187" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.ha.ClientBaseWithFixes<br/>In method org.apache.hadoop.ha.ClientBaseWithFixes.send4LetterWord(String, int, String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At ClientBaseWithFixes.java:[line 244]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N92256');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.ha.ClientBaseWithFixes.send4LetterWord(String, int, String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N92256" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.ha.ClientBaseWithFixes<br/>In method org.apache.hadoop.ha.ClientBaseWithFixes.send4LetterWord(String, int, String)<br/>Called method String.getBytes()<br/>At ClientBaseWithFixes.java:[line 239]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92842');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.ha.StreamPumper.pump(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92842" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.ha.StreamPumper<br/>In method org.apache.hadoop.ha.StreamPumper.pump()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At StreamPumper.java:[line 79]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93618');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.ha.TestHAAdmin.setup(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93618" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestHAAdmin<br/>In method org.apache.hadoop.ha.TestHAAdmin.setup()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestHAAdmin.java:[line 57]<br/>Another occurrence at TestHAAdmin.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N95209');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.DFSTestUtil.appendFile(FileSystem, Path, String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N95209" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.DFSTestUtil<br/>In method org.apache.hadoop.hdfs.DFSTestUtil.appendFile(FileSystem, Path, String)<br/>Called method String.getBytes()<br/>At DFSTestUtil.java:[line 701]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95278');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.DFSTestUtil.readFile(File): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95278" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.DFSTestUtil<br/>In method org.apache.hadoop.hdfs.DFSTestUtil.readFile(File)<br/>Called method new java.io.FileReader(File)<br/>At DFSTestUtil.java:[line 680]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N95347');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.DFSTestUtil.readFile(FileSystem, Path): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N95347" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.DFSTestUtil<br/>In method org.apache.hadoop.hdfs.DFSTestUtil.readFile(FileSystem, Path)<br/>Called method new String(byte[], int, int)<br/>At DFSTestUtil.java:[line 245]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95416');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.DFSTestUtil.runOperations(MiniDFSCluster, DistributedFileSystem, Configuration, long, int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95416" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.DFSTestUtil<br/>In method org.apache.hadoop.hdfs.DFSTestUtil.runOperations(MiniDFSCluster, DistributedFileSystem, Configuration, long, int)<br/>Called method String.getBytes()<br/>At DFSTestUtil.java:[line 1115]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N95485');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.DFSTestUtil.writeFile(FileSystem, Path, String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N95485" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.DFSTestUtil<br/>In method org.apache.hadoop.hdfs.DFSTestUtil.writeFile(FileSystem, Path, String)<br/>Called method String.getBytes()<br/>At DFSTestUtil.java:[line 692]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95806');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.MiniDFSCluster.addToFile(String, String): new java.io.FileWriter(File, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95806" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.MiniDFSCluster<br/>In method org.apache.hadoop.hdfs.MiniDFSCluster.addToFile(String, String)<br/>Called method new java.io.FileWriter(File, boolean)<br/>At MiniDFSCluster.java:[line 2503]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N95875');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlock(File): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N95875" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.MiniDFSCluster<br/>In method org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlock(File)<br/>Called method String.getBytes()<br/>At MiniDFSCluster.java:[line 1725]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N110895');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.listPaths(DFSClient, String, byte[]): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N110895" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3<br/>In method org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.listPaths(DFSClient, String, byte[])<br/>Called method new String(byte[])<br/>At RpcProgramNfs3.java:[line 1328]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N110964');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.readdir(XDR, SecurityHandler, InetAddress): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N110964" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3<br/>In method org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.readdir(XDR, SecurityHandler, InetAddress)<br/>Called method String.getBytes()<br/>At RpcProgramNfs3.java:[line 1418]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N111033');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.readdirplus(XDR, SecurityHandler, InetAddress): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N111033" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3<br/>In method org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.readdirplus(XDR, SecurityHandler, InetAddress)<br/>Called method String.getBytes()<br/>At RpcProgramNfs3.java:[line 1560]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N111102');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.readlink(XDR, SecurityHandler, InetAddress): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N111102" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3<br/>In method org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.readlink(XDR, SecurityHandler, InetAddress)<br/>Called method String.getBytes()<br/>At RpcProgramNfs3.java:[line 555]<br/>Another occurrence at RpcProgramNfs3.java:[line 556]<br/>Another occurrence at RpcProgramNfs3.java:[line 562]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N96568');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.NNBench.analyzeResults(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N96568" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>In method org.apache.hadoop.hdfs.NNBench.analyzeResults()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At NNBench.java:[line 319]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N96637');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.NNBench.analyzeResults(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N96637" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>In method org.apache.hadoop.hdfs.NNBench.analyzeResults()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At NNBench.java:[line 446]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N113170');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.protocolPB.TestPBHelper.createLocatedBlock(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N113170" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocolPB.TestPBHelper<br/>In method org.apache.hadoop.hdfs.protocolPB.TestPBHelper.createLocatedBlock()<br/>Called method String.getBytes()<br/>At TestPBHelper.java:[line 451]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N113239');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.protocolPB.TestPBHelper.createLocatedBlockNoStorageMedia(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N113239" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocolPB.TestPBHelper<br/>In method org.apache.hadoop.hdfs.protocolPB.TestPBHelper.createLocatedBlockNoStorageMedia()<br/>Called method String.getBytes()<br/>At TestPBHelper.java:[line 468]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N113308');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.protocolPB.TestPBHelper.getBlockKey(int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N113308" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocolPB.TestPBHelper<br/>In method org.apache.hadoop.hdfs.protocolPB.TestPBHelper.getBlockKey(int)<br/>Called method String.getBytes()<br/>At TestPBHelper.java:[line 211]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N113377');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.protocolPB.TestPBHelper.testConvertBlockToken(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N113377" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocolPB.TestPBHelper<br/>In method org.apache.hadoop.hdfs.protocolPB.TestPBHelper.testConvertBlockToken()<br/>Called method String.getBytes()<br/>At TestPBHelper.java:[line 387]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N113446');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.protocolPB.TestPBHelper.testConvertText(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N113446" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocolPB.TestPBHelper<br/>In method org.apache.hadoop.hdfs.protocolPB.TestPBHelper.testConvertText()<br/>Called method String.getBytes()<br/>At TestPBHelper.java:[line 379]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N114194');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser.testWebHdfsDoAs(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N114194" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser<br/>In method org.apache.hadoop.hdfs.security.TestDelegationTokenForProxyUser.testWebHdfsDoAs()<br/>Called method String.getBytes()<br/>At TestDelegationTokenForProxyUser.java:[line 166]<br/>Another occurrence at TestDelegationTokenForProxyUser.java:[line 176]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N115623');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(DataOutputStream, DataInputStream, DataOutputStream, String, DataTransferThrottler, DatanodeInfo[]): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N115623" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.BlockReceiver<br/>In method org.apache.hadoop.hdfs.server.datanode.BlockReceiver.receiveBlock(DataOutputStream, DataInputStream, DataOutputStream, String, DataTransferThrottler, DatanodeInfo[])<br/>Called method new java.io.FileWriter(File)<br/>At BlockReceiver.java:[line 760]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N121239');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.addToReplicasMap(ReplicaMap, File, boolean): new java.util.Scanner(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N121239" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice<br/>In method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.addToReplicasMap(ReplicaMap, File, boolean)<br/>Called method new java.util.Scanner(File)<br/>At BlockPoolSlice.java:[line 295]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N121308');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.loadDfsUsed(): new java.util.Scanner(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N121308" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice<br/>In method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.loadDfsUsed()<br/>Called method new java.util.Scanner(File)<br/>At BlockPoolSlice.java:[line 168]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N121377');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.saveDfsUsed(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N121377" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice<br/>In method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice.saveDfsUsed()<br/>Called method new java.io.FileWriter(File)<br/>At BlockPoolSlice.java:[line 213]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N124664');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.FSImageUtil.&lt;static initializer for FSImageUtil&gt;(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N124664" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSImageUtil<br/>In method org.apache.hadoop.hdfs.server.namenode.FSImageUtil.&lt;static initializer for FSImageUtil&gt;()<br/>Called method String.getBytes()<br/>At FSImageUtil.java:[line 35]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N124785');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(String, byte[], boolean): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N124785" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSNamesystem<br/>In method org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListingInt(String, byte[], boolean)<br/>Called method new String(byte[])<br/>At FSNamesystem.java:[line 4165]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N136477');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencing.doMetasave(NameNode): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N136477" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencing<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestDNFencing.doMetasave(NameNode)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestDNFencing.java:[line 538]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N137054');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.ha.TestHAFsck.runFsck(Configuration): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N137054" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestHAFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestHAFsck.runFsck(Configuration)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestHAFsck.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N137123');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.ha.TestHAFsck.runFsck(Configuration): new java.io.PrintStream(OutputStream, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N137123" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestHAFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestHAFsck.runFsck(Configuration)<br/>Called method new java.io.PrintStream(OutputStream, boolean)<br/>At TestHAFsck.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N137331');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.createEmptyHarArchive(FileSystem, Path): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N137331" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestHarFileSystemWithHA.createEmptyHarArchive(FileSystem, Path)<br/>Called method String.getBytes()<br/>At TestHarFileSystemWithHA.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N137192');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.testOpenFileWhenNNAndClientCrashAfterAddBlock(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N137192" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestHASafeMode.testOpenFileWhenNNAndClientCrashAfterAddBlock()<br/>Called method String.getBytes()<br/>At TestHASafeMode.java:[line 820]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N137635');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotTestHelper.compareDumpedTreeInFile(File, File, boolean, boolean): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N137635" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotTestHelper<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotTestHelper.compareDumpedTreeInFile(File, File, boolean, boolean)<br/>Called method new java.io.FileReader(File)<br/>At SnapshotTestHelper.java:[line 207]<br/>Another occurrence at SnapshotTestHelper.java:[line 208]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N137715');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotTestHelper.dumpTree2File(FSDirectory, File): new java.io.FileWriter(File, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N137715" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotTestHelper<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotTestHelper.dumpTree2File(FSDirectory, File)<br/>Called method new java.io.FileWriter(File, boolean)<br/>At SnapshotTestHelper.java:[line 272]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N137784');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotTestHelper.printFile(File): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N137784" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotTestHelper<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotTestHelper.printFile(File)<br/>Called method new java.io.FileReader(File)<br/>At SnapshotTestHelper.java:[line 261]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N138539');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.existsInDiffReport(List, SnapshotDiffReport$DiffType, String): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N138539" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.existsInDiffReport(List, SnapshotDiffReport$DiffType, String)<br/>Called method new String(byte[])<br/>At TestRenameWithSnapshots.java:[line 174]<br/>Another occurrence at TestRenameWithSnapshots.java:[line 176]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N139453');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.testDeleteSnapshotCommandWithIllegalArguments(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N139453" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.testDeleteSnapshotCommandWithIllegalArguments()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestSnapshotDeletion.java:[line 989]<br/>Another occurrence at TestSnapshotDeletion.java:[line 996]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N139533');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.testDeleteSnapshotCommandWithIllegalArguments(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N139533" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotDeletion.testDeleteSnapshotCommandWithIllegalArguments()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestSnapshotDeletion.java:[line 980]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N139602');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength.testSnapshotFileLengthWithCatCommand(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N139602" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength.testSnapshotFileLengthWithCatCommand()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestSnapshotFileLength.java:[line 164]<br/>Another occurrence at TestSnapshotFileLength.java:[line 165]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N140510');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotRename.testRenameSnapshotCommandWithIllegalArguments(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N140510" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotRename<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotRename.testRenameSnapshotCommandWithIllegalArguments()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestSnapshotRename.java:[line 246]<br/>Another occurrence at TestSnapshotRename.java:[line 253]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N140590');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotRename.testRenameSnapshotCommandWithIllegalArguments(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N140590" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotRename<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotRename.testRenameSnapshotCommandWithIllegalArguments()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestSnapshotRename.java:[line 237]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N126311');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestAuditLogs.verifyAuditLogsRepeat(boolean, int): new java.io.FileReader(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N126311" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestAuditLogs<br/>In method org.apache.hadoop.hdfs.server.namenode.TestAuditLogs.verifyAuditLogsRepeat(boolean, int)<br/>Called method new java.io.FileReader(String)<br/>At TestAuditLogs.java:[line 313]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N127140');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testNamespaceVerifiedOnFileTransfer(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N127140" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckpoint<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testNamespaceVerifiedOnFileTransfer()<br/>Called method String.getBytes()<br/>At TestCheckpoint.java:[line 1976]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N128211');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithEmptyClusterIdOption(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N128211" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestClusterId<br/>In method org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithEmptyClusterIdOption()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestClusterId.java:[line 286]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N128280');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithInvalidClusterIdOption(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N128280" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestClusterId<br/>In method org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithInvalidClusterIdOption()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestClusterId.java:[line 233]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N128349');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithNoClusterIdOption(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N128349" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestClusterId<br/>In method org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithNoClusterIdOption()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestClusterId.java:[line 259]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N128418');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithoutForceEnterNo(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N128418" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestClusterId<br/>In method org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithoutForceEnterNo()<br/>Called method String.getBytes()<br/>At TestClusterId.java:[line 432]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N128487');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithoutForceEnterYes(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N128487" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestClusterId<br/>In method org.apache.hadoop.hdfs.server.namenode.TestClusterId.testFormatWithoutForceEnterYes()<br/>Called method String.getBytes()<br/>At TestClusterId.java:[line 395]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N130154');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.&lt;static initializer for TestFavoredNodesEndToEnd&gt;(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N130154" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.&lt;static initializer for TestFavoredNodesEndToEnd&gt;()<br/>Called method String.getBytes()<br/>At TestFavoredNodesEndToEnd.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N131275');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestFsck.runFsck(Configuration, int, boolean, String[]): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N131275" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.runFsck(Configuration, int, boolean, String[])<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestFsck.java:[line 127]<br/>Another occurrence at TestFsck.java:[line 128]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N131355');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestFsck.runFsck(Configuration, int, boolean, String[]): new java.io.PrintStream(OutputStream, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N131355" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.runFsck(Configuration, int, boolean, String[])<br/>Called method new java.io.PrintStream(OutputStream, boolean)<br/>At TestFsck.java:[line 120]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N131424');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestFsck.testCorruptBlock(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N131424" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.testCorruptBlock()<br/>Called method String.getBytes()<br/>At TestFsck.java:[line 645]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N131493');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckOpenFiles(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N131493" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckOpenFiles()<br/>Called method String.getBytes()<br/>At TestFsck.java:[line 580]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N131562');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestFsck.verifyAuditLogs(): new java.io.FileReader(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N131562" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.verifyAuditLogs()<br/>Called method new java.io.FileReader(String)<br/>At TestFsck.java:[line 201]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N132333');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestINodeFile.testFilesInGetListingOps(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N132333" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestINodeFile<br/>In method org.apache.hadoop.hdfs.server.namenode.TestINodeFile.testFilesInGetListingOps()<br/>Called method String.getBytes()<br/>At TestINodeFile.java:[line 1010]<br/>Another occurrence at TestINodeFile.java:[line 1015]<br/>Another occurrence at TestINodeFile.java:[line 1022]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N132662');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestMetaSave.testMetaSave(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N132662" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestMetaSave<br/>In method org.apache.hadoop.hdfs.server.namenode.TestMetaSave.testMetaSave()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMetaSave.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N132731');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestMetaSave.testMetaSaveOverwrite(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N132731" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestMetaSave<br/>In method org.apache.hadoop.hdfs.server.namenode.TestMetaSave.testMetaSaveOverwrite()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMetaSave.java:[line 181]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N132800');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestMetaSave.testMetasaveAfterDelete(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N132800" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestMetaSave<br/>In method org.apache.hadoop.hdfs.server.namenode.TestMetaSave.testMetasaveAfterDelete()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMetaSave.java:[line 148]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N135585');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestStartupProgressServlet.setUp(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N135585" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestStartupProgressServlet<br/>In method org.apache.hadoop.hdfs.server.namenode.TestStartupProgressServlet.setUp()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestStartupProgressServlet.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N136105');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testImageUploadTimeout(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N136105" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage<br/>In method org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testImageUploadTimeout()<br/>Called method String.getBytes()<br/>At TestTransferFsImage.java:[line 167]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98966');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestClientReportBadBlock.runFsck(Configuration, int, boolean, String[]): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98966" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestClientReportBadBlock<br/>In method org.apache.hadoop.hdfs.TestClientReportBadBlock.runFsck(Configuration, int, boolean, String[])<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestClientReportBadBlock.java:[line 349]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99035');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestClientReportBadBlock.runFsck(Configuration, int, boolean, String[]): new java.io.PrintStream(OutputStream, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99035" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestClientReportBadBlock<br/>In method org.apache.hadoop.hdfs.TestClientReportBadBlock.runFsck(Configuration, int, boolean, String[])<br/>Called method new java.io.PrintStream(OutputStream, boolean)<br/>At TestClientReportBadBlock.java:[line 345]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99305');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestClose.testWriteAfterClose(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99305" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestClose<br/>In method org.apache.hadoop.hdfs.TestClose.testWriteAfterClose()<br/>Called method String.getBytes()<br/>At TestClose.java:[line 41]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N103401');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDataTransferKeepalive.assertXceiverCount(int): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N103401" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDataTransferKeepalive<br/>In method org.apache.hadoop.hdfs.TestDataTransferKeepalive.assertXceiverCount(int)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestDataTransferKeepalive.java:[line 249]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N103470');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDataTransferProtocol.sendRecvData(String, boolean): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N103470" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDataTransferProtocol<br/>In method org.apache.hadoop.hdfs.TestDataTransferProtocol.sendRecvData(String, boolean)<br/>Called method new String(byte[])<br/>At TestDataTransferProtocol.java:[line 129]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100824');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSShell.corrupt(List): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100824" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.corrupt(List)<br/>Called method new java.io.PrintWriter(File)<br/>At TestDFSShell.java:[line 1396]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N100893');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSShell.createLocalFile(File): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N100893" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.createLocalFile(File)<br/>Called method new java.io.PrintWriter(File)<br/>At TestDFSShell.java:[line 89]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100962');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSShell.runCount(String, long, long, FsShell): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100962" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.runCount(String, long, long, FsShell)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestDFSShell.java:[line 829]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N101031');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSShell.runCount(String, long, long, FsShell): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N101031" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.runCount(String, long, long, FsShell)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestDFSShell.java:[line 822]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N101100');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSShell.runLsr(FsShell, String, int): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N101100" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.runLsr(FsShell, String, int)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestDFSShell.java:[line 1582]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N101169');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSShell.runLsr(FsShell, String, int): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N101169" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.runLsr(FsShell, String, int)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestDFSShell.java:[line 1574]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N101238');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSShell.testDu(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N101238" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testDu()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestDFSShell.java:[line 217]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N101307');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSShell.testDu(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N101307" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testDu()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestDFSShell.java:[line 190]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N101376');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSShell.testErrOutPut(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N101376" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testErrOutPut()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestDFSShell.java:[line 347]<br/>Another occurrence at TestDFSShell.java:[line 357]<br/>Another occurrence at TestDFSShell.java:[line 365]<br/>Another occurrence at TestDFSShell.java:[line 372]<br/>Another occurrence at TestDFSShell.java:[line 379]<br/>Another occurrence at TestDFSShell.java:[line 386]<br/>Another occurrence at TestDFSShell.java:[line 399]<br/>Another occurrence at TestDFSShell.java:[line 411]<br/>Another occurrence at TestDFSShell.java:[line 423]<br/>Another occurrence at TestDFSShell.java:[line 440]<br/>Another occurrence at TestDFSShell.java:[line 448]<br/>Another occurrence at TestDFSShell.java:[line 456]<br/>Another occurrence at TestDFSShell.java:[line 466]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N101577');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSShell.testErrOutPut(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N101577" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testErrOutPut()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestDFSShell.java:[line 340]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N101646');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSShell.testErrOutPut(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N101646" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testErrOutPut()<br/>Called method String.getBytes()<br/>At TestDFSShell.java:[line 417]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N101715');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSShell.textTest(Path, Configuration): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N101715" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.textTest(Path, Configuration)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestDFSShell.java:[line 611]<br/>Another occurrence at TestDFSShell.java:[line 631]<br/>Another occurrence at TestDFSShell.java:[line 648]<br/>Another occurrence at TestDFSShell.java:[line 670]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N101817');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSShell.textTest(Path, Configuration): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N101817" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.textTest(Path, Configuration)<br/>Called method String.getBytes()<br/>At TestDFSShell.java:[line 637]<br/>Another occurrence at TestDFSShell.java:[line 644]<br/>Another occurrence at TestDFSShell.java:[line 666]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N102902');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSShellGenericOptions.testConfOption(String[], String): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N102902" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShellGenericOptions<br/>In method org.apache.hadoop.hdfs.TestDFSShellGenericOptions.testConfOption(String[], String)<br/>Called method new java.io.PrintWriter(File)<br/>At TestDFSShellGenericOptions.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N103125');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSUpgradeFromImage.unpackStorage(String): new java.io.FileReader(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N103125" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSUpgradeFromImage<br/>In method org.apache.hadoop.hdfs.TestDFSUpgradeFromImage.unpackStorage(String)<br/>Called method new java.io.FileReader(String)<br/>At TestDFSUpgradeFromImage.java:[line 108]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N103194');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestDFSUpgradeFromImage.verifyDir(DistributedFileSystem, Path, CRC32): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N103194" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSUpgradeFromImage<br/>In method org.apache.hadoop.hdfs.TestDFSUpgradeFromImage.verifyDir(DistributedFileSystem, Path, CRC32)<br/>Called method String.getBytes()<br/>At TestDFSUpgradeFromImage.java:[line 196]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N105117');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestEncryptedTransfer.writeTestDataToFile(FileSystem): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N105117" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestEncryptedTransfer<br/>In method org.apache.hadoop.hdfs.TestEncryptedTransfer.writeTestDataToFile(FileSystem)<br/>Called method String.getBytes()<br/>At TestEncryptedTransfer.java:[line 484]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N105966');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestFileAppend4.testAppendInsufficientLocations(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N105966" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileAppend4<br/>In method org.apache.hadoop.hdfs.TestFileAppend4.testAppendInsufficientLocations()<br/>Called method String.getBytes()<br/>At TestFileAppend4.java:[line 358]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N106035');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestFileAppend4.testUpdateNeededReplicationsForAppendedFile(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N106035" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileAppend4<br/>In method org.apache.hadoop.hdfs.TestFileAppend4.testUpdateNeededReplicationsForAppendedFile()<br/>Called method String.getBytes()<br/>At TestFileAppend4.java:[line 315]<br/>Another occurrence at TestFileAppend4.java:[line 320]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N106189');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestFileCreation.testFsClose(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N106189" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileCreation<br/>In method org.apache.hadoop.hdfs.TestFileCreation.testFsClose()<br/>Called method String.getBytes()<br/>At TestFileCreation.java:[line 1023]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N106258');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestFileCreation.testFsCloseAfterClusterShutdown(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N106258" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileCreation<br/>In method org.apache.hadoop.hdfs.TestFileCreation.testFsCloseAfterClusterShutdown()<br/>Called method String.getBytes()<br/>At TestFileCreation.java:[line 1055]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N106327');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestFileCreation.testLeaseExpireHardLimit(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N106327" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileCreation<br/>In method org.apache.hadoop.hdfs.TestFileCreation.testLeaseExpireHardLimit()<br/>Called method new java.io.FileReader(File)<br/>At TestFileCreation.java:[line 988]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N106396');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestFileCreation.testLeaseExpireHardLimit(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N106396" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileCreation<br/>In method org.apache.hadoop.hdfs.TestFileCreation.testLeaseExpireHardLimit()<br/>Called method String.getBytes()<br/>At TestFileCreation.java:[line 962]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N107660');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestLocalDFS.readFile(FileSystem, Path): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N107660" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestLocalDFS<br/>In method org.apache.hadoop.hdfs.TestLocalDFS.readFile(FileSystem, Path)<br/>Called method new String(byte[], int, int)<br/>At TestLocalDFS.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N110221');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestSnapshotCommands.toolRun(Tool, String, int, String): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N110221" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestSnapshotCommands<br/>In method org.apache.hadoop.hdfs.TestSnapshotCommands.toolRun(Tool, String, int, String)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestSnapshotCommands.java:[line 110]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N110290');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.TestSnapshotCommands.toolRun(Tool, String, int, String): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N110290" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestSnapshotCommands<br/>In method org.apache.hadoop.hdfs.TestSnapshotCommands.toolRun(Tool, String, int, String)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestSnapshotCommands.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N143962');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.tools.offlineImageViewer.OfflineImageViewerPB.run(String[]): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N143962" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.OfflineImageViewerPB<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.OfflineImageViewerPB.run(String[])<br/>Called method new java.io.PrintWriter(File)<br/>At OfflineImageViewerPB.java:[line 151]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N144031');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.tools.offlineImageViewer.OfflineImageViewerPB.run(String[]): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N144031" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.OfflineImageViewerPB<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.OfflineImageViewerPB.run(String[])<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At OfflineImageViewerPB.java:[line 151]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N144318');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.tools.offlineImageViewer.TestDelimitedImageVisitor.testDelimitedImageVisistor(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N144318" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.TestDelimitedImageVisitor<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.TestDelimitedImageVisitor.testDelimitedImageVisistor()<br/>Called method new java.io.FileReader(File)<br/>At TestDelimitedImageVisitor.java:[line 82]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N142255');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.tools.TestDFSHAAdmin.setup(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N142255" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.TestDFSHAAdmin<br/>In method org.apache.hadoop.hdfs.tools.TestDFSHAAdmin.setup()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestDFSHAAdmin.java:[line 137]<br/>Another occurrence at TestDFSHAAdmin.java:[line 138]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N142335');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.tools.TestDFSHAAdmin.setupConfirmationOnSystemIn(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N142335" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.TestDFSHAAdmin<br/>In method org.apache.hadoop.hdfs.tools.TestDFSHAAdmin.setupConfirmationOnSystemIn()<br/>Called method String.getBytes()<br/>At TestDFSHAAdmin.java:[line 236]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N142404');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.tools.TestDFSHAAdminMiniCluster.setup(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N142404" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.TestDFSHAAdminMiniCluster<br/>In method org.apache.hadoop.hdfs.tools.TestDFSHAAdminMiniCluster.setup()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestDFSHAAdminMiniCluster.java:[line 76]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N142543');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.tools.TestGetConf.runTool(HdfsConfiguration, String[], boolean): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N142543" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.TestGetConf<br/>In method org.apache.hadoop.hdfs.tools.TestGetConf.runTool(HdfsConfiguration, String[], boolean)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestGetConf.java:[line 142]<br/>Another occurrence at TestGetConf.java:[line 143]<br/>Another occurrence at TestGetConf.java:[line 147]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N142634');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.tools.TestGetConf.runTool(HdfsConfiguration, String[], boolean): new java.io.PrintStream(OutputStream, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N142634" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.TestGetConf<br/>In method org.apache.hadoop.hdfs.tools.TestGetConf.runTool(HdfsConfiguration, String[], boolean)<br/>Called method new java.io.PrintStream(OutputStream, boolean)<br/>At TestGetConf.java:[line 138]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N110413');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.UpgradeUtilities.corruptFile(File, byte[], byte[]): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N110413" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.UpgradeUtilities<br/>In method org.apache.hadoop.hdfs.UpgradeUtilities.corruptFile(File, byte[], byte[])<br/>Called method new String(byte[])<br/>At UpgradeUtilities.java:[line 507]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N144604');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.util.TestAtomicFileOutputStream.testFailToFlush(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N144604" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestAtomicFileOutputStream<br/>In method org.apache.hadoop.hdfs.util.TestAtomicFileOutputStream.testFailToFlush()<br/>Called method String.getBytes()<br/>At TestAtomicFileOutputStream.java:[line 103]<br/>Another occurrence at TestAtomicFileOutputStream.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N144684');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.util.TestAtomicFileOutputStream.testOverwriteFile(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N144684" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestAtomicFileOutputStream<br/>In method org.apache.hadoop.hdfs.util.TestAtomicFileOutputStream.testOverwriteFile()<br/>Called method String.getBytes()<br/>At TestAtomicFileOutputStream.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N144753');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.util.TestAtomicFileOutputStream.testWriteNewFile(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N144753" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestAtomicFileOutputStream<br/>In method org.apache.hadoop.hdfs.util.TestAtomicFileOutputStream.testWriteNewFile()<br/>Called method String.getBytes()<br/>At TestAtomicFileOutputStream.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N144980');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.util.TestExactSizeInputStream.byteStream(String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N144980" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestExactSizeInputStream<br/>In method org.apache.hadoop.hdfs.util.TestExactSizeInputStream.byteStream(String)<br/>Called method String.getBytes()<br/>At TestExactSizeInputStream.java:[line 127]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N145685');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.util.TestMD5FileUtils.testVerifyMD5FileBadFormat(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N145685" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestMD5FileUtils<br/>In method org.apache.hadoop.hdfs.util.TestMD5FileUtils.testVerifyMD5FileBadFormat()<br/>Called method new java.io.FileWriter(File)<br/>At TestMD5FileUtils.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N146186');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract.testCaseInsensitive(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N146186" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract<br/>In method org.apache.hadoop.hdfs.web.TestWebHdfsFileSystemContract.testCaseInsensitive()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestWebHdfsFileSystemContract.java:[line 171]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N146047');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.web.TestWebHDFSForHA.testFailoverAfterOpen(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N146047" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.web.TestWebHDFSForHA<br/>In method org.apache.hadoop.hdfs.web.TestWebHDFSForHA.testFailoverAfterOpen()<br/>Called method String.getBytes()<br/>At TestWebHDFSForHA.java:[line 129]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N146399');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes.testRedirect(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N146399" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes<br/>In method org.apache.hadoop.hdfs.web.TestWebHdfsWithMultipleNameNodes.testRedirect()<br/>Called method String.getBytes()<br/>At TestWebHdfsWithMultipleNameNodes.java:[line 131]<br/>Another occurrence at TestWebHdfsWithMultipleNameNodes.java:[line 153]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N146479');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.http.HtmlQuoting.&lt;static initializer for HtmlQuoting&gt;(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N146479" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.http.HtmlQuoting<br/>In method org.apache.hadoop.http.HtmlQuoting.&lt;static initializer for HtmlQuoting&gt;()<br/>Called method String.getBytes()<br/>At HtmlQuoting.java:[line 28]<br/>Another occurrence at HtmlQuoting.java:[line 29]<br/>Another occurrence at HtmlQuoting.java:[line 30]<br/>Another occurrence at HtmlQuoting.java:[line 31]<br/>Another occurrence at HtmlQuoting.java:[line 32]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N146592');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.http.HtmlQuoting.needsQuoting(String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N146592" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.http.HtmlQuoting<br/>In method org.apache.hadoop.http.HtmlQuoting.needsQuoting(String)<br/>Called method String.getBytes()<br/>At HtmlQuoting.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N146661');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.http.HtmlQuoting.quoteHtmlChars(String): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N146661" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.http.HtmlQuoting<br/>In method org.apache.hadoop.http.HtmlQuoting.quoteHtmlChars(String)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At HtmlQuoting.java:[line 109]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N146730');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.http.HtmlQuoting.quoteHtmlChars(String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N146730" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.http.HtmlQuoting<br/>In method org.apache.hadoop.http.HtmlQuoting.quoteHtmlChars(String)<br/>Called method String.getBytes()<br/>At HtmlQuoting.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N146799');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.http.HttpServerFunctionalTest.readOutput(URL): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N146799" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.http.HttpServerFunctionalTest<br/>In method org.apache.hadoop.http.HttpServerFunctionalTest.readOutput(URL)<br/>Called method new String(byte[], int, int)<br/>At HttpServerFunctionalTest.java:[line 225]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N146868');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.http.TestGlobalFilter.access(String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N146868" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.http.TestGlobalFilter<br/>In method org.apache.hadoop.http.TestGlobalFilter.access(String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestGlobalFilter.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N147061');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.http.TestPathFilter.access(String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N147061" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.http.TestPathFilter<br/>In method org.apache.hadoop.http.TestPathFilter.access(String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestPathFilter.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N147323');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.http.TestServletFilter.access(String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N147323" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.http.TestServletFilter<br/>In method org.apache.hadoop.http.TestServletFilter.access(String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestServletFilter.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N147184');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.http.TestSSLHttpServer.readOut(URL): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N147184" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.http.TestSSLHttpServer<br/>In method org.apache.hadoop.http.TestSSLHttpServer.readOut(URL)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestSSLHttpServer.java:[line 115]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N151865');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.compress.TestCodec.testGzipCodecRead(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N151865" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.TestCodec<br/>In method org.apache.hadoop.io.compress.TestCodec.testGzipCodecRead()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestCodec.java:[line 757]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N151934');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.compress.TestCodec.testGzipCodecRead(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N151934" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.TestCodec<br/>In method org.apache.hadoop.io.compress.TestCodec.testGzipCodecRead()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestCodec.java:[line 743]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N152003');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.compress.TestCodec.testGzipCodecWrite(boolean): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N152003" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.TestCodec<br/>In method org.apache.hadoop.io.compress.TestCodec.testGzipCodecWrite(boolean)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestCodec.java:[line 868]<br/>Another occurrence at TestCodec.java:[line 877]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N152083');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.compress.TestCodec.testGzipLongOverflow(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N152083" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.TestCodec<br/>In method org.apache.hadoop.io.compress.TestCodec.testGzipLongOverflow()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestCodec.java:[line 814]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N152152');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.compress.TestCodec.testGzipLongOverflow(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N152152" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.TestCodec<br/>In method org.apache.hadoop.io.compress.TestCodec.testGzipLongOverflow()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestCodec.java:[line 795]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N152221');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.compress.TestCodec.verifyGzipFile(String, String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N152221" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.TestCodec<br/>In method org.apache.hadoop.io.compress.TestCodec.verifyGzipFile(String, String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestCodec.java:[line 764]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N147983');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.DefaultStringifier.toString(Object): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N147983" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.DefaultStringifier<br/>In method org.apache.hadoop.io.DefaultStringifier.toString(Object)<br/>Called method new String(byte[])<br/>At DefaultStringifier.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N155202');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFile.getSomeKey(int): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N155202" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFile<br/>In method org.apache.hadoop.io.file.tfile.TestTFile.getSomeKey(int)<br/>Called method String.getBytes()<br/>At TestTFile.java:[line 250]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N155271');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFile.readAndCheckbytes(TFile$Reader$Scanner, int, int): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N155271" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFile<br/>In method org.apache.hadoop.io.file.tfile.TestTFile.readAndCheckbytes(TFile$Reader$Scanner, int, int)<br/>Called method new String(byte[])<br/>At TestTFile.java:[line 107]<br/>Another occurrence at TestTFile.java:[line 109]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N155351');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFile.readAndCheckbytes(TFile$Reader$Scanner, int, int): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N155351" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFile<br/>In method org.apache.hadoop.io.file.tfile.TestTFile.readAndCheckbytes(TFile$Reader$Scanner, int, int)<br/>Called method String.getBytes()<br/>At TestTFile.java:[line 107]<br/>Another occurrence at TestTFile.java:[line 109]<br/>Another occurrence at TestTFile.java:[line 115]<br/>Another occurrence at TestTFile.java:[line 117]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N155453');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFile.readLargeRecords(TFile$Reader$Scanner, int, int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N155453" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFile<br/>In method org.apache.hadoop.io.file.tfile.TestTFile.readLargeRecords(TFile$Reader$Scanner, int, int)<br/>Called method String.getBytes()<br/>At TestTFile.java:[line 144]<br/>Another occurrence at TestTFile.java:[line 148]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N155533');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFile.readNumMetablocks(TFile$Reader, int): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N155533" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFile<br/>In method org.apache.hadoop.io.file.tfile.TestTFile.readNumMetablocks(TFile$Reader, int)<br/>Called method String.getBytes()<br/>At TestTFile.java:[line 389]<br/>Another occurrence at TestTFile.java:[line 394]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N155613');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFile.readPrepWithKnownLength(TFile$Reader$Scanner, int, int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N155613" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFile<br/>In method org.apache.hadoop.io.file.tfile.TestTFile.readPrepWithKnownLength(TFile$Reader$Scanner, int, int)<br/>Called method String.getBytes()<br/>At TestTFile.java:[line 204]<br/>Another occurrence at TestTFile.java:[line 207]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N155693');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFile.readPrepWithUnknownLength(TFile$Reader$Scanner, int, int): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N155693" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFile<br/>In method org.apache.hadoop.io.file.tfile.TestTFile.readPrepWithUnknownLength(TFile$Reader$Scanner, int, int)<br/>Called method String.getBytes()<br/>At TestTFile.java:[line 233]<br/>Another occurrence at TestTFile.java:[line 242]<br/>Another occurrence at TestTFile.java:[line 243]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N155784');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFile.writeLargeRecords(TFile$Writer, int, int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N155784" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFile<br/>In method org.apache.hadoop.io.file.tfile.TestTFile.writeLargeRecords(TFile$Writer, int, int)<br/>Called method String.getBytes()<br/>At TestTFile.java:[line 131]<br/>Another occurrence at TestTFile.java:[line 132]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N155864');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFile.writeNumMetablocks(TFile$Writer, String, int): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N155864" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFile<br/>In method org.apache.hadoop.io.file.tfile.TestTFile.writeNumMetablocks(TFile$Writer, String, int)<br/>Called method String.getBytes()<br/>At TestTFile.java:[line 367]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N155933');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFile.writePrepWithKnownLength(TFile$Writer, int, int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N155933" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFile<br/>In method org.apache.hadoop.io.file.tfile.TestTFile.writePrepWithKnownLength(TFile$Writer, int, int)<br/>Called method String.getBytes()<br/>At TestTFile.java:[line 183]<br/>Another occurrence at TestTFile.java:[line 185]<br/>Another occurrence at TestTFile.java:[line 189]<br/>Another occurrence at TestTFile.java:[line 193]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N156035');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFile.writePrepWithUnkownLength(TFile$Writer, int, int): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N156035" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFile<br/>In method org.apache.hadoop.io.file.tfile.TestTFile.writePrepWithUnkownLength(TFile$Writer, int, int)<br/>Called method String.getBytes()<br/>At TestTFile.java:[line 218]<br/>Another occurrence at TestTFile.java:[line 222]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N156115');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFile.writeSomeRecords(TFile$Writer, int, int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N156115" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFile<br/>In method org.apache.hadoop.io.file.tfile.TestTFile.writeSomeRecords(TFile$Writer, int, int)<br/>Called method String.getBytes()<br/>At TestTFile.java:[line 92]<br/>Another occurrence at TestTFile.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N156429');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.checkBlockIndex(int, int): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N156429" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.checkBlockIndex(int, int)<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 649]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N156498');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readKeyManyTimes(int): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N156498" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readKeyManyTimes(int)<br/>Called method new String(byte[], int, int)<br/>At TestTFileByteArrays.java:[line 746]<br/>Another occurrence at TestTFileByteArrays.java:[line 751]<br/>Another occurrence at TestTFileByteArrays.java:[line 756]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N156589');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readKeyManyTimes(int): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N156589" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readKeyManyTimes(int)<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 738]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N156658');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readKeyWithoutValue(int): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N156658" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readKeyWithoutValue(int)<br/>Called method new String(byte[], int, int)<br/>At TestTFileByteArrays.java:[line 693]<br/>Another occurrence at TestTFileByteArrays.java:[line 701]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N156738');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readKeyWithoutValue(int): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N156738" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readKeyWithoutValue(int)<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 684]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N156807');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(FileSystem, Path, int, Configuration): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N156807" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readRecords(FileSystem, Path, int, Configuration)<br/>Called method new String(byte[], int, int)<br/>At TestTFileByteArrays.java:[line 629]<br/>Another occurrence at TestTFileByteArrays.java:[line 635]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N156887');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readValueBeforeKey(int): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N156887" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readValueBeforeKey(int)<br/>Called method new String(byte[], int, int)<br/>At TestTFileByteArrays.java:[line 668]<br/>Another occurrence at TestTFileByteArrays.java:[line 673]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N156967');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readValueBeforeKey(int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N156967" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readValueBeforeKey(int)<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 660]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N157036');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readValueWithoutKey(int): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N157036" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readValueWithoutKey(int)<br/>Called method new String(byte[], int, int)<br/>At TestTFileByteArrays.java:[line 721]<br/>Another occurrence at TestTFileByteArrays.java:[line 727]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N157116');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readValueWithoutKey(int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N157116" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.readValueWithoutKey(int)<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 714]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N157185');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N157185" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureGetNonExistentMetaBlock()<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 293]<br/>Another occurrence at TestTFileByteArrays.java:[line 299]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N157265');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureKeyLongerThan64K(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N157265" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureKeyLongerThan64K()<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 426]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N157334');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeLength(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N157334" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeLength()<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 487]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N157403');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeLength_2(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N157403" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeLength_2()<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 504]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N157472');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeLength_3(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N157472" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeLength_3()<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 527]<br/>Another occurrence at TestTFileByteArrays.java:[line 535]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N157552');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeOffset(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N157552" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeOffset()<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 454]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N157621');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeOffset_2(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N157621" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureNegativeOffset_2()<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 471]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N157690');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOutOfOrderKeys(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N157690" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureOutOfOrderKeys()<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 438]<br/>Another occurrence at TestTFileByteArrays.java:[line 439]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N157770');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureReadValueManyTimes(): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N157770" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureReadValueManyTimes()<br/>Called method new String(byte[], int, int)<br/>At TestTFileByteArrays.java:[line 350]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N157839');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteMetaBlocksWithSameName(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N157839" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteMetaBlocksWithSameName()<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 271]<br/>Another occurrence at TestTFileByteArrays.java:[line 277]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N157919');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteRecordAfterMetaBlock(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N157919" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testFailureWriteRecordAfterMetaBlock()<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 321]<br/>Another occurrence at TestTFileByteArrays.java:[line 326]<br/>Another occurrence at TestTFileByteArrays.java:[line 330]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N158010');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testLocate(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N158010" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.testLocate()<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 241]<br/>Another occurrence at TestTFileByteArrays.java:[line 242]<br/>Another occurrence at TestTFileByteArrays.java:[line 243]<br/>Another occurrence at TestTFileByteArrays.java:[line 244]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N158112');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TFile$Writer, int): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N158112" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileByteArrays.writeRecords(TFile$Writer, int)<br/>Called method String.getBytes()<br/>At TestTFileByteArrays.java:[line 590]<br/>Another occurrence at TestTFileByteArrays.java:[line 591]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N158192');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileComparator2.testSortedLongWritable(): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N158192" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileComparator2<br/>In method org.apache.hadoop.io.file.tfile.TestTFileComparator2.testSortedLongWritable()<br/>Called method new String(byte[], int, int)<br/>At TestTFileComparator2.java:[line 95]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N158261');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileComparator2.testSortedLongWritable(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N158261" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileComparator2<br/>In method org.apache.hadoop.io.file.tfile.TestTFileComparator2.testSortedLongWritable()<br/>Called method String.getBytes()<br/>At TestTFileComparator2.java:[line 73]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N158718');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileSplit.createFile(int, String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N158718" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileSplit<br/>In method org.apache.hadoop.io.file.tfile.TestTFileSplit.createFile(int, String)<br/>Called method String.getBytes()<br/>At TestTFileSplit.java:[line 60]<br/>Another occurrence at TestTFileSplit.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N158798');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureAddKeyWithoutValue(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N158798" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileStreams<br/>In method org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureAddKeyWithoutValue()<br/>Called method String.getBytes()<br/>At TestTFileStreams.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N158867');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureAddValueWithoutKey(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N158867" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileStreams<br/>In method org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureAddValueWithoutKey()<br/>Called method String.getBytes()<br/>At TestTFileStreams.java:[line 160]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N158936');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureCloseKeyStreamManyTimesInWriter(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N158936" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileStreams<br/>In method org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureCloseKeyStreamManyTimesInWriter()<br/>Called method String.getBytes()<br/>At TestTFileStreams.java:[line 276]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N159005');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureKeyTooLong(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N159005" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileStreams<br/>In method org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureKeyTooLong()<br/>Called method String.getBytes()<br/>At TestTFileStreams.java:[line 200]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N159074');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureKeyTooShort(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N159074" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileStreams<br/>In method org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureKeyTooShort()<br/>Called method String.getBytes()<br/>At TestTFileStreams.java:[line 215]<br/>Another occurrence at TestTFileStreams.java:[line 219]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N159154');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureOneEntryKnownLength(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N159154" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileStreams<br/>In method org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureOneEntryKnownLength()<br/>Called method String.getBytes()<br/>At TestTFileStreams.java:[line 178]<br/>Another occurrence at TestTFileStreams.java:[line 188]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N159234');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureValueTooLong(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N159234" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileStreams<br/>In method org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureValueTooLong()<br/>Called method String.getBytes()<br/>At TestTFileStreams.java:[line 234]<br/>Another occurrence at TestTFileStreams.java:[line 238]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N159314');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureValueTooShort(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N159314" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileStreams<br/>In method org.apache.hadoop.io.file.tfile.TestTFileStreams.testFailureValueTooShort()<br/>Called method String.getBytes()<br/>At TestTFileStreams.java:[line 260]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N159383');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(int, boolean, boolean, boolean): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N159383" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileStreams<br/>In method org.apache.hadoop.io.file.tfile.TestTFileStreams.writeRecords(int, boolean, boolean, boolean)<br/>Called method String.getBytes()<br/>At TestTFileStreams.java:[line 388]<br/>Another occurrence at TestTFileStreams.java:[line 393]<br/>Another occurrence at TestTFileStreams.java:[line 395]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N159474');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.setUp(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N159474" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.setUp()<br/>Called method String.getBytes()<br/>At TestTFileUnsortedByteArrays.java:[line 71]<br/>Another occurrence at TestTFileUnsortedByteArrays.java:[line 72]<br/>Another occurrence at TestTFileUnsortedByteArrays.java:[line 73]<br/>Another occurrence at TestTFileUnsortedByteArrays.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N159576');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testFailureScannerWithKeys(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N159576" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testFailureScannerWithKeys()<br/>Called method String.getBytes()<br/>At TestTFileUnsortedByteArrays.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N159645');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testFailureSeek(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N159645" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testFailureSeek()<br/>Called method String.getBytes()<br/>At TestTFileUnsortedByteArrays.java:[line 193]<br/>Another occurrence at TestTFileUnsortedByteArrays.java:[line 204]<br/>Another occurrence at TestTFileUnsortedByteArrays.java:[line 215]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N159736');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testScan(): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N159736" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testScan()<br/>Called method new String(byte[], int, int)<br/>At TestTFileUnsortedByteArrays.java:[line 118]<br/>Another occurrence at TestTFileUnsortedByteArrays.java:[line 123]<br/>Another occurrence at TestTFileUnsortedByteArrays.java:[line 131]<br/>Another occurrence at TestTFileUnsortedByteArrays.java:[line 136]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N159838');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testScanRange(): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N159838" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays<br/>In method org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.testScanRange()<br/>Called method new String(byte[], int, int)<br/>At TestTFileUnsortedByteArrays.java:[line 159]<br/>Another occurrence at TestTFileUnsortedByteArrays.java:[line 164]<br/>Another occurrence at TestTFileUnsortedByteArrays.java:[line 172]<br/>Another occurrence at TestTFileUnsortedByteArrays.java:[line 177]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N154837');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.file.tfile.TFileDumper.dumpInfo(String, PrintStream, Configuration): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N154837" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TFileDumper<br/>In method org.apache.hadoop.io.file.tfile.TFileDumper.dumpInfo(String, PrintStream, Configuration)<br/>Called method new String(byte[], int, int)<br/>At TFileDumper.java:[line 236]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N160179');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.nativeio.TestNativeIO.testFDDoesntLeak(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N160179" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestNativeIO<br/>In method org.apache.hadoop.io.nativeio.TestNativeIO.testFDDoesntLeak()<br/>Called method String.getBytes()<br/>At TestNativeIO.java:[line 394]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N160248');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.nativeio.TestNativeIO.testOpenWithCreate(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N160248" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestNativeIO<br/>In method org.apache.hadoop.io.nativeio.TestNativeIO.testOpenWithCreate()<br/>Called method String.getBytes()<br/>At TestNativeIO.java:[line 360]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N160317');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.nativeio.TestNativeIO.testSetFilePointer(): new java.io.FileReader(FileDescriptor)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N160317" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestNativeIO<br/>In method org.apache.hadoop.io.nativeio.TestNativeIO.testSetFilePointer()<br/>Called method new java.io.FileReader(FileDescriptor)<br/>At TestNativeIO.java:[line 196]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N160386');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.nativeio.TestNativeIO.testSetFilePointer(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N160386" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestNativeIO<br/>In method org.apache.hadoop.io.nativeio.TestNativeIO.testSetFilePointer()<br/>Called method new java.io.FileWriter(File)<br/>At TestNativeIO.java:[line 174]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N160455');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.nativeio.TestNativeIO.testSyncFileRange(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N160455" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestNativeIO<br/>In method org.apache.hadoop.io.nativeio.TestNativeIO.testSyncFileRange()<br/>Called method String.getBytes()<br/>At TestNativeIO.java:[line 475]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N148790');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.TestBytesWritable.testCompare(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N148790" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.TestBytesWritable<br/>In method org.apache.hadoop.io.TestBytesWritable.testCompare()<br/>Called method String.getBytes()<br/>At TestBytesWritable.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N148859');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.TestBytesWritable.testHash(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N148859" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.TestBytesWritable<br/>In method org.apache.hadoop.io.TestBytesWritable.testHash()<br/>Called method String.getBytes()<br/>At TestBytesWritable.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N148928');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.TestBytesWritable.testSizeChange(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N148928" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.TestBytesWritable<br/>In method org.apache.hadoop.io.TestBytesWritable.testSizeChange()<br/>Called method String.getBytes()<br/>At TestBytesWritable.java:[line 32]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N148997');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.TestBytesWritable.testZeroCopy(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N148997" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.TestBytesWritable<br/>In method org.apache.hadoop.io.TestBytesWritable.testZeroCopy()<br/>Called method String.getBytes()<br/>At TestBytesWritable.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N150219');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.TestMapWritable.testMapWritable(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N150219" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.TestMapWritable<br/>In method org.apache.hadoop.io.TestMapWritable.testMapWritable()<br/>Called method String.getBytes()<br/>At TestMapWritable.java:[line 41]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N150046');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.TestMD5Hash.testFactoryReturnsClearedHashes(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N150046" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.TestMD5Hash<br/>In method org.apache.hadoop.io.TestMD5Hash.testFactoryReturnsClearedHashes()<br/>Called method String.getBytes()<br/>At TestMD5Hash.java:[line 121]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N150918');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.TestSortedMapWritable.testEqualsAndHashCode(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N150918" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.TestSortedMapWritable<br/>In method org.apache.hadoop.io.TestSortedMapWritable.testEqualsAndHashCode()<br/>Called method String.getBytes()<br/>At TestSortedMapWritable.java:[line 135]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N150987');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.TestSortedMapWritable.testSortedMapWritable(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N150987" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.TestSortedMapWritable<br/>In method org.apache.hadoop.io.TestSortedMapWritable.testSortedMapWritable()<br/>Called method String.getBytes()<br/>At TestSortedMapWritable.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N151056');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.TestText.testFindAfterUpdatingContents(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N151056" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.TestText<br/>In method org.apache.hadoop.io.TestText.testFindAfterUpdatingContents()<br/>Called method String.getBytes()<br/>At TestText.java:[line 232]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N151125');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.TestText.testReadWriteOperations(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N151125" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.TestText<br/>In method org.apache.hadoop.io.TestText.testReadWriteOperations()<br/>Called method String.getBytes()<br/>At TestText.java:[line 344]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N151194');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.io.TestText.testTextText(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N151194" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.io.TestText<br/>In method org.apache.hadoop.io.TestText.testTextText()<br/>Called method String.getBytes()<br/>At TestText.java:[line 274]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N161731');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.ipc.RpcConstants.&lt;static initializer for RpcConstants&gt;(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N161731" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.ipc.RpcConstants<br/>In method org.apache.hadoop.ipc.RpcConstants.&lt;static initializer for RpcConstants&gt;()<br/>Called method String.getBytes()<br/>At RpcConstants.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N161800');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.ipc.Server.&lt;static initializer for Server&gt;(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N161800" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.ipc.Server<br/>In method org.apache.hadoop.ipc.Server.&lt;static initializer for Server&gt;()<br/>Called method String.getBytes()<br/>At Server.java:[line 176]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N161869');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.ipc.TestIPC.testHttpGetResponse(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N161869" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestIPC<br/>In method org.apache.hadoop.ipc.TestIPC.testHttpGetResponse()<br/>Called method String.getBytes()<br/>At TestIPC.java:[line 953]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N163646');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.ipc.TestSaslRPC.internalGetAuthMethod(SaslRpcServer$AuthMethod, SaslRpcServer$AuthMethod, TestSaslRPC$UseToken): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N163646" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.internalGetAuthMethod(SaslRpcServer$AuthMethod, SaslRpcServer$AuthMethod, TestSaslRPC$UseToken)<br/>Called method String.getBytes()<br/>At TestSaslRPC.java:[line 926]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N165680');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.lib.util.TestConfigurationUtils.constructors(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N165680" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.lib.util.TestConfigurationUtils<br/>In method org.apache.hadoop.lib.util.TestConfigurationUtils.constructors()<br/>Called method String.getBytes()<br/>At TestConfigurationUtils.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N165749');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.lib.util.TestConfigurationUtils.constructorsFail3(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N165749" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.lib.util.TestConfigurationUtils<br/>In method org.apache.hadoop.lib.util.TestConfigurationUtils.constructorsFail3()<br/>Called method String.getBytes()<br/>At TestConfigurationUtils.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N165818');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.lib.wsrs.JSONMapProvider.writeTo(Map, Class, Type, Annotation[], MediaType, MultivaluedMap, OutputStream): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N165818" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.lib.wsrs.JSONMapProvider<br/>In method org.apache.hadoop.lib.wsrs.JSONMapProvider.writeTo(Map, Class, Type, Annotation[], MediaType, MultivaluedMap, OutputStream)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At JSONMapProvider.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N165887');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.lib.wsrs.JSONProvider.writeTo(JSONStreamAware, Class, Type, Annotation[], MediaType, MultivaluedMap, OutputStream): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N165887" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.lib.wsrs.JSONProvider<br/>In method org.apache.hadoop.lib.wsrs.JSONProvider.writeTo(JSONStreamAware, Class, Type, Annotation[], MediaType, MultivaluedMap, OutputStream)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At JSONProvider.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N165956');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.lib.wsrs.TestInputStreamEntity.test(): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N165956" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.lib.wsrs.TestInputStreamEntity<br/>In method org.apache.hadoop.lib.wsrs.TestInputStreamEntity.test()<br/>Called method new String(byte[])<br/>At TestInputStreamEntity.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N166025');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.lib.wsrs.TestInputStreamEntity.test(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N166025" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.lib.wsrs.TestInputStreamEntity<br/>In method org.apache.hadoop.lib.wsrs.TestInputStreamEntity.test()<br/>Called method String.getBytes()<br/>At TestInputStreamEntity.java:[line 33]<br/>Another occurrence at TestInputStreamEntity.java:[line 40]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N166105');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.lib.wsrs.TestJSONMapProvider.test(): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N166105" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.lib.wsrs.TestJSONMapProvider<br/>In method org.apache.hadoop.lib.wsrs.TestJSONMapProvider.test()<br/>Called method new String(byte[])<br/>At TestJSONMapProvider.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N166174');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.lib.wsrs.TestJSONProvider.test(): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N166174" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.lib.wsrs.TestJSONProvider<br/>In method org.apache.hadoop.lib.wsrs.TestJSONProvider.test()<br/>Called method new String(byte[])<br/>At TestJSONProvider.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N166294');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.log.LogLevel.process(String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N166294" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.log.LogLevel<br/>In method org.apache.hadoop.log.LogLevel.process(String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At LogLevel.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N166363');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.log.TestLogLevel.testDynamicLogLevel(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N166363" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.log.TestLogLevel<br/>In method org.apache.hadoop.log.TestLogLevel.testDynamicLogLevel()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestLogLevel.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N179146');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.gridmix.DistributedCacheEmulator.writeDistCacheFilesList(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N179146" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.DistributedCacheEmulator<br/>In method org.apache.hadoop.mapred.gridmix.DistributedCacheEmulator.writeDistCacheFilesList()<br/>Called method String.getBytes()<br/>At DistributedCacheEmulator.java:[line 440]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N180962');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testFileQueueDecompression(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N180962" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils<br/>In method org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testFileQueueDecompression()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestCompressionEmulationUtils.java:[line 544]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N181031');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testFileQueueDecompression(): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N181031" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils<br/>In method org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testFileQueueDecompression()<br/>Called method new String(byte[])<br/>At TestCompressionEmulationUtils.java:[line 557]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N181100');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testFileQueueDecompression(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N181100" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils<br/>In method org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testFileQueueDecompression()<br/>Called method String.getBytes()<br/>At TestCompressionEmulationUtils.java:[line 554]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N181169');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testPossiblyCompressedDecompressedStreams(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N181169" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils<br/>In method org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testPossiblyCompressedDecompressedStreams()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestCompressionEmulationUtils.java:[line 457]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N181238');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testPossiblyCompressedDecompressedStreams(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N181238" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils<br/>In method org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testPossiblyCompressedDecompressedStreams()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestCompressionEmulationUtils.java:[line 448]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N181307');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testRandomCompressedTextDataGenerator(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N181307" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils<br/>In method org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testRandomCompressedTextDataGenerator()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestCompressionEmulationUtils.java:[line 129]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N181376');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testRandomCompressedTextDataGenerator(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N181376" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils<br/>In method org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.testRandomCompressedTextDataGenerator()<br/>Called method String.getBytes()<br/>At TestCompressionEmulationUtils.java:[line 132]<br/>Another occurrence at TestCompressionEmulationUtils.java:[line 138]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N181671');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.doValidateSetupGenDC(RecordReader, FileSystem, long[]): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N181671" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation<br/>In method org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.doValidateSetupGenDC(RecordReader, FileSystem, long[])<br/>Called method new String(byte[], int, int)<br/>At TestDistCacheEmulation.java:[line 332]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N182310');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testMain(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N182310" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestGridmixSubmission<br/>In method org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testMain()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestGridmixSubmission.java:[line 194]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N182379');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testMain(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N182379" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestGridmixSubmission<br/>In method org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testMain()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestGridmixSubmission.java:[line 179]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N166963');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.JobClientUnitTest.testShowJob(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N166963" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At JobClientUnitTest.java:[line 150]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N167032');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.JobClientUnitTest.testShowJob(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N167032" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At JobClientUnitTest.java:[line 149]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N183317');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.join.TestTupleWritable.makeRandomWritables(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N183317" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.join.TestTupleWritable<br/>In method org.apache.hadoop.mapred.join.TestTupleWritable.makeRandomWritables()<br/>Called method String.getBytes()<br/>At TestTupleWritable.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N183386');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.join.TestTupleWritable.testIterable(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N183386" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.join.TestTupleWritable<br/>In method org.apache.hadoop.mapred.join.TestTupleWritable.testIterable()<br/>Called method String.getBytes()<br/>At TestTupleWritable.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N183455');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.join.TestTupleWritable.testNestedIterable(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N183455" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.join.TestTupleWritable<br/>In method org.apache.hadoop.mapred.join.TestTupleWritable.testNestedIterable()<br/>Called method String.getBytes()<br/>At TestTupleWritable.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N183524');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.join.TestTupleWritable.testWritable(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N183524" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.join.TestTupleWritable<br/>In method org.apache.hadoop.mapred.join.TestTupleWritable.testWritable()<br/>Called method String.getBytes()<br/>At TestTupleWritable.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N183593');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in new org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N183593" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator<br/>In method new org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator()<br/>Called method String.getBytes()<br/>At TestKeyFieldBasedComparator.java:[line 137]<br/>Another occurrence at TestKeyFieldBasedComparator.java:[line 138]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N183673');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator.configure(String, int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N183673" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator<br/>In method org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator.configure(String, int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestKeyFieldBasedComparator.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N183742');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator.configure(String, int): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N183742" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator<br/>In method org.apache.hadoop.mapred.lib.TestKeyFieldBasedComparator.configure(String, int)<br/>Called method String.getBytes()<br/>At TestKeyFieldBasedComparator.java:[line 84]<br/>Another occurrence at TestKeyFieldBasedComparator.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N183980');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.lib.TestLineInputFormat.testFormat(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N183980" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestLineInputFormat<br/>In method org.apache.hadoop.mapred.lib.TestLineInputFormat.testFormat()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestLineInputFormat.java:[line 63]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N184049');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.lib.TestMultipleOutputs._testMOWithJavaSerialization(boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N184049" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestMultipleOutputs<br/>In method org.apache.hadoop.mapred.lib.TestMultipleOutputs._testMOWithJavaSerialization(boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMultipleOutputs.java:[line 151]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N184118');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.lib.TestMultipleOutputs._testMultipleOutputs(boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N184118" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.lib.TestMultipleOutputs<br/>In method org.apache.hadoop.mapred.lib.TestMultipleOutputs._testMultipleOutputs(boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMultipleOutputs.java:[line 239]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N168302');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.MRBench.generateTextFile(FileSystem, Path, long, MRBench$Order): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N168302" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRBench<br/>In method org.apache.hadoop.mapred.MRBench.generateTextFile(FileSystem, Path, long, MRBench$Order)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At MRBench.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N168654');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.MRCaching.launchMRCache(String, String, String, JobConf, String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N168654" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRCaching<br/>In method org.apache.hadoop.mapred.MRCaching.launchMRCache(String, String, String, JobConf, String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At MRCaching.java:[line 275]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N184187');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.CommonStub.initSoket(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N184187" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.CommonStub<br/>In method org.apache.hadoop.mapred.pipes.CommonStub.initSoket()<br/>Called method String.getBytes()<br/>At CommonStub.java:[line 121]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N184256');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N184256" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.getFileCommand(String)<br/>Called method String.getBytes()<br/>At TestPipeApplication.java:[line 531]<br/>Another occurrence at TestPipeApplication.java:[line 533]<br/>Another occurrence at TestPipeApplication.java:[line 535]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N184347');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.TestPipeApplication.readFile(File): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N184347" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.readFile(File)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestPipeApplication.java:[line 494]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N184416');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.TestPipeApplication.testApplication(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N184416" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.testApplication()<br/>Called method String.getBytes()<br/>At TestPipeApplication.java:[line 171]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N184485');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.TestPipeApplication.testPipesReduser(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N184485" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.testPipesReduser()<br/>Called method String.getBytes()<br/>At TestPipeApplication.java:[line 392]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N184554');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.TestPipeApplication.testRunner(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N184554" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.testRunner()<br/>Called method String.getBytes()<br/>At TestPipeApplication.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N184623');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.TestPipeApplication.testSubmitter(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N184623" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.testSubmitter()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestPipeApplication.java:[line 278]<br/>Another occurrence at TestPipeApplication.java:[line 279]<br/>Another occurrence at TestPipeApplication.java:[line 280]<br/>Another occurrence at TestPipeApplication.java:[line 281]<br/>Another occurrence at TestPipeApplication.java:[line 283]<br/>Another occurrence at TestPipeApplication.java:[line 284]<br/>Another occurrence at TestPipeApplication.java:[line 286]<br/>Another occurrence at TestPipeApplication.java:[line 287]<br/>Another occurrence at TestPipeApplication.java:[line 289]<br/>Another occurrence at TestPipeApplication.java:[line 291]<br/>Another occurrence at TestPipeApplication.java:[line 293]<br/>Another occurrence at TestPipeApplication.java:[line 295]<br/>Another occurrence at TestPipeApplication.java:[line 297]<br/>Another occurrence at TestPipeApplication.java:[line 300]<br/>Another occurrence at TestPipeApplication.java:[line 304]<br/>Another occurrence at TestPipeApplication.java:[line 306]<br/>Another occurrence at TestPipeApplication.java:[line 308]<br/>Another occurrence at TestPipeApplication.java:[line 310]<br/>Another occurrence at TestPipeApplication.java:[line 314]<br/>Another occurrence at TestPipeApplication.java:[line 318]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N184901');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.pipes.TestPipeApplication.testSubmitter(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N184901" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.pipes.TestPipeApplication<br/>In method org.apache.hadoop.mapred.pipes.TestPipeApplication.testSubmitter()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestPipeApplication.java:[line 273]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N169581');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestBadRecords.createInput(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N169581" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestBadRecords<br/>In method org.apache.hadoop.mapred.TestBadRecords.createInput()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestBadRecords.java:[line 104]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N169650');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestBadRecords.validateOutput(JobConf, RunningJob, List, List): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N169650" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestBadRecords<br/>In method org.apache.hadoop.mapred.TestBadRecords.validateOutput(JobConf, RunningJob, List, List)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestBadRecords.java:[line 180]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N169719');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestClusterMapReduceTestCase._testMapReduce(boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N169719" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestClusterMapReduceTestCase<br/>In method org.apache.hadoop.mapred.TestClusterMapReduceTestCase._testMapReduce(boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestClusterMapReduceTestCase.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N169788');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestClusterMapReduceTestCase._testMapReduce(boolean): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N169788" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestClusterMapReduceTestCase<br/>In method org.apache.hadoop.mapred.TestClusterMapReduceTestCase._testMapReduce(boolean)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestClusterMapReduceTestCase.java:[line 35]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N169857');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testDFSRestart(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N169857" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestClusterMapReduceTestCase<br/>In method org.apache.hadoop.mapred.TestClusterMapReduceTestCase.testDFSRestart()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestClusterMapReduceTestCase.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N169926');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestCombineFileInputFormat.writeFile(FileSystem, Path, String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N169926" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestCombineFileInputFormat<br/>In method org.apache.hadoop.mapred.TestCombineFileInputFormat.writeFile(FileSystem, Path, String)<br/>Called method String.getBytes()<br/>At TestCombineFileInputFormat.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N169995');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestCombineTextInputFormat.createFiles(int, int, Random): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N169995" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestCombineTextInputFormat<br/>In method org.apache.hadoop.mapred.TestCombineTextInputFormat.createFiles(int, int, Random)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestCombineTextInputFormat.java:[line 165]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N170064');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestCombineTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N170064" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestCombineTextInputFormat<br/>In method org.apache.hadoop.mapred.TestCombineTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String)<br/>Called method String.getBytes()<br/>At TestCombineTextInputFormat.java:[line 187]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N170133');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestCommandLineJobSubmission.testJobShell(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N170133" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestCommandLineJobSubmission<br/>In method org.apache.hadoop.mapred.TestCommandLineJobSubmission.testJobShell()<br/>Called method String.getBytes()<br/>At TestCommandLineJobSubmission.java:[line 57]<br/>Another occurrence at TestCommandLineJobSubmission.java:[line 64]<br/>Another occurrence at TestCommandLineJobSubmission.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N170369');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestConcatenatedCompressedInput.writeFile(FileSystem, Path, CompressionCodec, String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N170369" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestConcatenatedCompressedInput<br/>In method org.apache.hadoop.mapred.TestConcatenatedCompressedInput.writeFile(FileSystem, Path, CompressionCodec, String)<br/>Called method String.getBytes()<br/>At TestConcatenatedCompressedInput.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N171292');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestFileInputFormatPathFilter.createFile(String): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N171292" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFileInputFormatPathFilter<br/>In method org.apache.hadoop.mapred.TestFileInputFormatPathFilter.createFile(String)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestFileInputFormatPathFilter.java:[line 72]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N171431');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestFixedLengthInputFormat.createFile(Path, CompressionCodec, int, int): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N171431" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFixedLengthInputFormat<br/>In method org.apache.hadoop.mapred.TestFixedLengthInputFormat.createFile(Path, CompressionCodec, int, int)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestFixedLengthInputFormat.java:[line 236]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N171500');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestFixedLengthInputFormat.readSplit(FixedLengthInputFormat, InputSplit, JobConf): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N171500" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFixedLengthInputFormat<br/>In method org.apache.hadoop.mapred.TestFixedLengthInputFormat.readSplit(FixedLengthInputFormat, InputSplit, JobConf)<br/>Called method new String(byte[], int, int)<br/>At TestFixedLengthInputFormat.java:[line 376]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N171569');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestFixedLengthInputFormat.runRandomTests(CompressionCodec): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N171569" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFixedLengthInputFormat<br/>In method org.apache.hadoop.mapred.TestFixedLengthInputFormat.runRandomTests(CompressionCodec)<br/>Called method new String(byte[], int, int)<br/>At TestFixedLengthInputFormat.java:[line 337]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N171638');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestFixedLengthInputFormat.writeFile(FileSystem, Path, CompressionCodec, String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N171638" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFixedLengthInputFormat<br/>In method org.apache.hadoop.mapred.TestFixedLengthInputFormat.writeFile(FileSystem, Path, CompressionCodec, String)<br/>Called method String.getBytes()<br/>At TestFixedLengthInputFormat.java:[line 363]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N171920');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJavaSerialization.cleanAndCreateInput(FileSystem): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N171920" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJavaSerialization<br/>In method org.apache.hadoop.mapred.TestJavaSerialization.cleanAndCreateInput(FileSystem)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestJavaSerialization.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N171989');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJavaSerialization.testMapReduceJob(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N171989" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJavaSerialization<br/>In method org.apache.hadoop.mapred.TestJavaSerialization.testMapReduceJob()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestJavaSerialization.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N172680');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJobName.testComplexName(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N172680" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobName<br/>In method org.apache.hadoop.mapred.TestJobName.testComplexName()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestJobName.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N172749');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJobName.testComplexName(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N172749" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobName<br/>In method org.apache.hadoop.mapred.TestJobName.testComplexName()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestJobName.java:[line 37]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N172818');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N172818" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobName<br/>In method org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestJobName.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N172887');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N172887" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobName<br/>In method org.apache.hadoop.mapred.TestJobName.testComplexNameWithRegex()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestJobName.java:[line 71]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N172956');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJobQueueClient.testPrintJobQueueInfo(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N172956" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobQueueClient<br/>In method org.apache.hadoop.mapred.TestJobQueueClient.testPrintJobQueueInfo()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestJobQueueClient.java:[line 50]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N173025');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestJobQueueClient.testPrintJobQueueInfo(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N173025" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobQueueClient<br/>In method org.apache.hadoop.mapred.TestJobQueueClient.testPrintJobQueueInfo()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestJobQueueClient.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N173164');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestKeyValueTextInputFormat.testFormat(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N173164" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapred.TestKeyValueTextInputFormat.testFormat()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestKeyValueTextInputFormat.java:[line 72]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N173233');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestKeyValueTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N173233" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapred.TestKeyValueTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String)<br/>Called method String.getBytes()<br/>At TestKeyValueTextInputFormat.java:[line 191]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N173372');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestLazyOutput.createInput(FileSystem, int): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N173372" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestLazyOutput<br/>In method org.apache.hadoop.mapred.TestLazyOutput.createInput(FileSystem, int)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestLazyOutput.java:[line 127]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N173441');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestLineRecordReaderJobs.createInputFile(Configuration): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N173441" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestLineRecordReaderJobs<br/>In method org.apache.hadoop.mapred.TestLineRecordReaderJobs.createInputFile(Configuration)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestLineRecordReaderJobs.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N173510');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestLocalDistributedCacheManager.testDownload(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N173510" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestLocalDistributedCacheManager<br/>In method org.apache.hadoop.mapred.TestLocalDistributedCacheManager.testDownload()<br/>Called method String.getBytes()<br/>At TestLocalDistributedCacheManager.java:[line 152]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N173579');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestLocalDistributedCacheManager.testDuplicateDownload(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N173579" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestLocalDistributedCacheManager<br/>In method org.apache.hadoop.mapred.TestLocalDistributedCacheManager.testDuplicateDownload()<br/>Called method String.getBytes()<br/>At TestLocalDistributedCacheManager.java:[line 259]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N173785');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestLocalModeWithNewApis.readOutput(Path, Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N173785" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestLocalModeWithNewApis<br/>In method org.apache.hadoop.mapred.TestLocalModeWithNewApis.readOutput(Path, Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestLocalModeWithNewApis.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N174275');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMapRed.isSequenceFile(FileSystem, Path): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N174275" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMapRed<br/>In method org.apache.hadoop.mapred.TestMapRed.isSequenceFile(FileSystem, Path)<br/>Called method String.getBytes()<br/>At TestMapRed.java:[line 683]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N174344');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMapRed.launch(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N174344" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMapRed<br/>In method org.apache.hadoop.mapred.TestMapRed.launch()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMapRed.java:[line 648]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N174413');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMapRed.printTextFile(FileSystem, Path): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N174413" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMapRed<br/>In method org.apache.hadoop.mapred.TestMapRed.printTextFile(FileSystem, Path)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMapRed.java:[line 660]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N174670');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMerge.createInput(FileSystem): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N174670" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMerge<br/>In method org.apache.hadoop.mapred.TestMerge.createInput(FileSystem)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMerge.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N174878');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMiniMRClasspath.launchExternal(URI, JobConf, String, int, int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N174878" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMiniMRClasspath<br/>In method org.apache.hadoop.mapred.TestMiniMRClasspath.launchExternal(URI, JobConf, String, int, int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMiniMRClasspath.java:[line 147]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N174947');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMiniMRClasspath.launchWordCount(URI, JobConf, String, int, int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N174947" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMiniMRClasspath<br/>In method org.apache.hadoop.mapred.TestMiniMRClasspath.launchWordCount(URI, JobConf, String, int, int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMiniMRClasspath.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N173997');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMRCJCJobClient.runJob(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N173997" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMRCJCJobClient<br/>In method org.apache.hadoop.mapred.TestMRCJCJobClient.runJob()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMRCJCJobClient.java:[line 39]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N174136');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMRWithDistributedCache.makeJar(Path, int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N174136" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMRWithDistributedCache<br/>In method org.apache.hadoop.mapred.TestMRWithDistributedCache.makeJar(Path, int)<br/>Called method String.getBytes()<br/>At TestMRWithDistributedCache.java:[line 220]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N175101');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestMultiFileSplit.testgetLocations(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N175101" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMultiFileSplit<br/>In method org.apache.hadoop.mapred.TestMultiFileSplit.testgetLocations()<br/>Called method String.getBytes()<br/>At TestMultiFileSplit.java:[line 79]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N175328');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestNetworkedJob.testJobQueueClient(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N175328" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestNetworkedJob<br/>In method org.apache.hadoop.mapred.TestNetworkedJob.testJobQueueClient()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestNetworkedJob.java:[line 348]<br/>Another occurrence at TestNetworkedJob.java:[line 349]<br/>Another occurrence at TestNetworkedJob.java:[line 354]<br/>Another occurrence at TestNetworkedJob.java:[line 355]<br/>Another occurrence at TestNetworkedJob.java:[line 357]<br/>Another occurrence at TestNetworkedJob.java:[line 366]<br/>Another occurrence at TestNetworkedJob.java:[line 367]<br/>Another occurrence at TestNetworkedJob.java:[line 368]<br/>Another occurrence at TestNetworkedJob.java:[line 375]<br/>Another occurrence at TestNetworkedJob.java:[line 376]<br/>Another occurrence at TestNetworkedJob.java:[line 377]<br/>Another occurrence at TestNetworkedJob.java:[line 378]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N175518');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestNetworkedJob.testJobQueueClient(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N175518" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestNetworkedJob<br/>In method org.apache.hadoop.mapred.TestNetworkedJob.testJobQueueClient()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestNetworkedJob.java:[line 345]<br/>Another occurrence at TestNetworkedJob.java:[line 351]<br/>Another occurrence at TestNetworkedJob.java:[line 363]<br/>Another occurrence at TestNetworkedJob.java:[line 372]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N175620');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestOldCombinerGrouping.testCombiner(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N175620" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestOldCombinerGrouping<br/>In method org.apache.hadoop.mapred.TestOldCombinerGrouping.testCombiner()<br/>Called method new java.io.FileReader(File)<br/>At TestOldCombinerGrouping.java:[line 167]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N175689');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestOldCombinerGrouping.testCombiner(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N175689" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestOldCombinerGrouping<br/>In method org.apache.hadoop.mapred.TestOldCombinerGrouping.testCombiner()<br/>Called method new java.io.FileWriter(File)<br/>At TestOldCombinerGrouping.java:[line 129]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N175758');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestQueue.writeFile(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N175758" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestQueue<br/>In method org.apache.hadoop.mapred.TestQueue.writeFile()<br/>Called method new java.io.FileWriter(File)<br/>At TestQueue.java:[line 241]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N176465');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N176465" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.createIndexFile(File, Configuration)<br/>Called method String.getBytes()<br/>At TestShuffleHandler.java:[line 643]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N176534');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestShuffleHandler.createMapOutputFile(File, Configuration): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N176534" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.createMapOutputFile(File, Configuration)<br/>Called method String.getBytes()<br/>At TestShuffleHandler.java:[line 623]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N176603');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess(): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N176603" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess()<br/>Called method new String(byte[])<br/>At TestShuffleHandler.java:[line 594]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N176672');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N176672" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestShuffleHandler<br/>In method org.apache.hadoop.mapred.TestShuffleHandler.testMapFileAccess()<br/>Called method String.getBytes()<br/>At TestShuffleHandler.java:[line 558]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N177171');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestTaskLog.readTaskLog(TaskLog$LogName, TaskAttemptID, boolean): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N177171" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTaskLog<br/>In method org.apache.hadoop.mapred.TestTaskLog.readTaskLog(TaskLog$LogName, TaskAttemptID, boolean)<br/>Called method new String(byte[])<br/>At TestTaskLog.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N177590');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestTextInputFormat.testFormat(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N177590" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextInputFormat<br/>In method org.apache.hadoop.mapred.TestTextInputFormat.testFormat()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestTextInputFormat.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N177659');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestTextInputFormat.testMaxLineLength(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N177659" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextInputFormat<br/>In method org.apache.hadoop.mapred.TestTextInputFormat.testMaxLineLength()<br/>Called method String.getBytes()<br/>At TestTextInputFormat.java:[line 316]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N177728');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestTextInputFormat.testNewLines(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N177728" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextInputFormat<br/>In method org.apache.hadoop.mapred.TestTextInputFormat.testNewLines()<br/>Called method String.getBytes()<br/>At TestTextInputFormat.java:[line 276]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N177797');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestTextInputFormat.testSplitableCodecs(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N177797" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextInputFormat<br/>In method org.apache.hadoop.mapred.TestTextInputFormat.testSplitableCodecs()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestTextInputFormat.java:[line 182]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N177866');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N177866" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextInputFormat<br/>In method org.apache.hadoop.mapred.TestTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String)<br/>Called method String.getBytes()<br/>At TestTextInputFormat.java:[line 388]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N178076');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestUserDefinedCounters.cleanAndCreateInput(FileSystem): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N178076" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestUserDefinedCounters<br/>In method org.apache.hadoop.mapred.TestUserDefinedCounters.cleanAndCreateInput(FileSystem)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestUserDefinedCounters.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N178145');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestUserDefinedCounters.testMapReduceJob(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N178145" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestUserDefinedCounters<br/>In method org.apache.hadoop.mapred.TestUserDefinedCounters.testMapReduceJob()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestUserDefinedCounters.java:[line 109]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N178299');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapred.TestYARNRunner.testWarnCommandOpts(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N178299" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestYARNRunner<br/>In method org.apache.hadoop.mapred.TestYARNRunner.testWarnCommandOpts()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestYARNRunner.java:[line 483]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N185640');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.FailJob.run(String[]): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N185640" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.FailJob<br/>In method org.apache.hadoop.mapreduce.FailJob.run(String[])<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At FailJob.java:[line 124]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N191904');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader.testProgressIsReportedIfInputASeriesOfEmptyFiles(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N191904" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader<br/>In method org.apache.hadoop.mapreduce.lib.input.TestCombineFileRecordReader.testProgressIsReportedIfInputASeriesOfEmptyFiles()<br/>Called method new java.io.FileWriter(File)<br/>At TestCombineFileRecordReader.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N192250');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testFormat(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N192250" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testFormat()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMRKeyValueTextInputFormat.java:[line 90]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N192319');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testSplitableCodecs(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N192319" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.testSplitableCodecs()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMRKeyValueTextInputFormat.java:[line 189]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N192388');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N192388" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRKeyValueTextInputFormat.writeFile(FileSystem, Path, CompressionCodec, String)<br/>Called method String.getBytes()<br/>At TestMRKeyValueTextInputFormat.java:[line 303]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N192673');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.input.TestNLineInputFormat.testFormat(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N192673" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestNLineInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestNLineInputFormat.testFormat()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestNLineInputFormat.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N192742');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.makeRandomWritables(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N192742" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable<br/>In method org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.makeRandomWritables()<br/>Called method String.getBytes()<br/>At TestJoinTupleWritable.java:[line 63]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N192811');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.testIterable(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N192811" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable<br/>In method org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.testIterable()<br/>Called method String.getBytes()<br/>At TestJoinTupleWritable.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N192880');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.testNestedIterable(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N192880" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable<br/>In method org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.testNestedIterable()<br/>Called method String.getBytes()<br/>At TestJoinTupleWritable.java:[line 123]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N192949');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.testWritable(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N192949" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable<br/>In method org.apache.hadoop.mapreduce.lib.join.TestJoinTupleWritable.testWritable()<br/>Called method String.getBytes()<br/>At TestJoinTupleWritable.java:[line 141]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N193601');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.output.TestMRMultipleOutputs._testMOWithJavaSerialization(boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N193601" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.TestMRMultipleOutputs<br/>In method org.apache.hadoop.mapreduce.lib.output.TestMRMultipleOutputs._testMOWithJavaSerialization(boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRMultipleOutputs.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N193670');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.output.TestMRMultipleOutputs._testMultipleOutputs(boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N193670" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.TestMRMultipleOutputs<br/>In method org.apache.hadoop.mapreduce.lib.output.TestMRMultipleOutputs._testMultipleOutputs(boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRMultipleOutputs.java:[line 200]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N194041');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper.testGetWordLengths(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N194041" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper<br/>In method org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper.testGetWordLengths()<br/>Called method String.getBytes()<br/>At TestKeyFieldHelper.java:[line 220]<br/>Another occurrence at TestKeyFieldHelper.java:[line 228]<br/>Another occurrence at TestKeyFieldHelper.java:[line 234]<br/>Another occurrence at TestKeyFieldHelper.java:[line 240]<br/>Another occurrence at TestKeyFieldHelper.java:[line 245]<br/>Another occurrence at TestKeyFieldHelper.java:[line 249]<br/>Another occurrence at TestKeyFieldHelper.java:[line 253]<br/>Another occurrence at TestKeyFieldHelper.java:[line 257]<br/>Another occurrence at TestKeyFieldHelper.java:[line 261]<br/>Another occurrence at TestKeyFieldHelper.java:[line 266]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N194209');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper.testKeySpecs(String, String, KeyFieldHelper, int, int): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N194209" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper<br/>In method org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper.testKeySpecs(String, String, KeyFieldHelper, int, int)<br/>Called method new String(byte[])<br/>At TestKeyFieldHelper.java:[line 404]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N194278');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper.testKeySpecs(String, String, KeyFieldHelper, int, int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N194278" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper<br/>In method org.apache.hadoop.mapreduce.lib.partition.TestKeyFieldHelper.testKeySpecs(String, String, KeyFieldHelper, int, int)<br/>Called method String.getBytes()<br/>At TestKeyFieldHelper.java:[line 379]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N194347');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in new org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedComparator(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N194347" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedComparator<br/>In method new org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedComparator()<br/>Called method String.getBytes()<br/>At TestMRKeyFieldBasedComparator.java:[line 117]<br/>Another occurrence at TestMRKeyFieldBasedComparator.java:[line 118]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N194427');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedComparator.testComparator(String, int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N194427" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedComparator<br/>In method org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedComparator.testComparator(String, int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRKeyFieldBasedComparator.java:[line 76]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N194496');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedPartitioner.testEmptyKey(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N194496" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedPartitioner<br/>In method org.apache.hadoop.mapreduce.lib.partition.TestMRKeyFieldBasedPartitioner.testEmptyKey()<br/>Called method String.getBytes()<br/>At TestMRKeyFieldBasedPartitioner.java:[line 56]<br/>Another occurrence at TestMRKeyFieldBasedPartitioner.java:[line 68]<br/>Another occurrence at TestMRKeyFieldBasedPartitioner.java:[line 80]<br/>Another occurrence at TestMRKeyFieldBasedPartitioner.java:[line 101]<br/>Another occurrence at TestMRKeyFieldBasedPartitioner.java:[line 104]<br/>Another occurrence at TestMRKeyFieldBasedPartitioner.java:[line 116]<br/>Another occurrence at TestMRKeyFieldBasedPartitioner.java:[line 119]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N185937');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.MapReduceTestUtil.readOutput(Path, Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N185937" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.MapReduceTestUtil<br/>In method org.apache.hadoop.mapreduce.MapReduceTestUtil.readOutput(Path, Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At MapReduceTestUtil.java:[line 414]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N186006');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.MapReduceTestUtil.readTaskLog(TaskLog$LogName, TaskAttemptID, boolean): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N186006" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.MapReduceTestUtil<br/>In method org.apache.hadoop.mapreduce.MapReduceTestUtil.readTaskLog(TaskLog$LogName, TaskAttemptID, boolean)<br/>Called method new String(byte[])<br/>At MapReduceTestUtil.java:[line 454]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N186075');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.MiniHadoopClusterManager.start(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N186075" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.MiniHadoopClusterManager<br/>In method org.apache.hadoop.mapreduce.MiniHadoopClusterManager.start()<br/>Called method new java.io.FileWriter(File)<br/>At MiniHadoopClusterManager.java:[line 194]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N194691');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.security.CredentialsTestJob.checkSecrets(Credentials): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N194691" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.CredentialsTestJob<br/>In method org.apache.hadoop.mapreduce.security.CredentialsTestJob.checkSecrets(Credentials)<br/>Called method new String(byte[])<br/>At CredentialsTestJob.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N194760');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.security.SecureShuffleUtils.toHex(byte[]): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N194760" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.SecureShuffleUtils<br/>In method org.apache.hadoop.mapreduce.security.SecureShuffleUtils.toHex(byte[])<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At SecureShuffleUtils.java:[line 148]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N194829');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.security.SecureShuffleUtils.toHex(byte[]): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N194829" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.SecureShuffleUtils<br/>In method org.apache.hadoop.mapreduce.security.SecureShuffleUtils.toHex(byte[])<br/>Called method new java.io.PrintStream(OutputStream)<br/>At SecureShuffleUtils.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N195221');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(boolean): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N195221" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle<br/>In method org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.encryptedShuffleWithCerts(boolean)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestEncryptedShuffle.java:[line 142]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N195290');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.startCluster(Configuration): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N195290" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle<br/>In method org.apache.hadoop.mapreduce.security.ssl.TestEncryptedShuffle.startCluster(Configuration)<br/>Called method new java.io.FileWriter(String)<br/>At TestEncryptedShuffle.java:[line 110]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N194994');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.security.TestMRCredentials.createKeysAsJson(String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N194994" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.security.TestMRCredentials<br/>In method org.apache.hadoop.mapreduce.security.TestMRCredentials.createKeysAsJson(String)<br/>Called method String.getBytes()<br/>At TestMRCredentials.java:[line 98]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N196158');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostBogusHeader(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N196158" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestFetcher<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostBogusHeader()<br/>Called method String.getBytes()<br/>At TestFetcher.java:[line 174]<br/>Another occurrence at TestFetcher.java:[line 183]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N196238');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostCompressFailure(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N196238" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestFetcher<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostCompressFailure()<br/>Called method String.getBytes()<br/>At TestFetcher.java:[line 275]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N196307');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostIncompatibleShuffleVersion(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N196307" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestFetcher<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostIncompatibleShuffleVersion()<br/>Called method String.getBytes()<br/>At TestFetcher.java:[line 202]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N196376');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostWait(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N196376" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestFetcher<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testCopyFromHostWait()<br/>Called method String.getBytes()<br/>At TestFetcher.java:[line 236]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N196445');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptInMemory(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N196445" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestFetcher<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptInMemory()<br/>Called method String.getBytes()<br/>At TestFetcher.java:[line 314]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N196514');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptOnDisk(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N196514" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestFetcher<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testInterruptOnDisk()<br/>Called method String.getBytes()<br/>At TestFetcher.java:[line 362]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N196583');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testReduceOutOfDiskSpace(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N196583" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestFetcher<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestFetcher.testReduceOutOfDiskSpace()<br/>Called method String.getBytes()<br/>At TestFetcher.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N186957');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestJobMonitorAndPrint.testJobMonitorAndPrint(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N186957" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestJobMonitorAndPrint<br/>In method org.apache.hadoop.mapreduce.TestJobMonitorAndPrint.testJobMonitorAndPrint()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestJobMonitorAndPrint.java:[line 108]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N187241');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestLocalRunner.createInputFile(Path, int, int): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N187241" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestLocalRunner<br/>In method org.apache.hadoop.mapreduce.TestLocalRunner.createInputFile(Path, int, int)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestLocalRunner.java:[line 156]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N187310');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestLocalRunner.makeNumberFile(int, int): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N187310" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestLocalRunner<br/>In method org.apache.hadoop.mapreduce.TestLocalRunner.makeNumberFile(int, int)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestLocalRunner.java:[line 453]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N187379');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestLocalRunner.verifyNumberJob(int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N187379" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestLocalRunner<br/>In method org.apache.hadoop.mapreduce.TestLocalRunner.verifyNumberJob(int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestLocalRunner.java:[line 494]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N187448');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestLocalRunner.verifyOutput(Path): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N187448" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestLocalRunner<br/>In method org.apache.hadoop.mapreduce.TestLocalRunner.verifyOutput(Path)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestLocalRunner.java:[line 227]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N188813');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMapperReducerCleanup.createInputFile(Path, int, int): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N188813" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMapperReducerCleanup<br/>In method org.apache.hadoop.mapreduce.TestMapperReducerCleanup.createInputFile(Path, int, int)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMapperReducerCleanup.java:[line 190]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N188537');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMapReduce.isSequenceFile(FileSystem, Path): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N188537" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMapReduce<br/>In method org.apache.hadoop.mapreduce.TestMapReduce.isSequenceFile(FileSystem, Path)<br/>Called method String.getBytes()<br/>At TestMapReduce.java:[line 456]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N188606');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMapReduce.launch(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N188606" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMapReduce<br/>In method org.apache.hadoop.mapreduce.TestMapReduce.launch()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMapReduce.java:[line 420]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N188675');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMapReduce.printTextFile(FileSystem, Path): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N188675" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMapReduce<br/>In method org.apache.hadoop.mapreduce.TestMapReduce.printTextFile(FileSystem, Path)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMapReduce.java:[line 433]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N188744');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.createInput(FileSystem, int): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N188744" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMapReduceLazyOutput<br/>In method org.apache.hadoop.mapreduce.TestMapReduceLazyOutput.createInput(FileSystem, int)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMapReduceLazyOutput.java:[line 117]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N187571');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.runTool(Configuration, Tool, String[], OutputStream): new java.io.PrintStream(OutputStream, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N187571" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.runTool(Configuration, Tool, String[], OutputStream)<br/>Called method new java.io.PrintStream(OutputStream, boolean)<br/>At TestMRJobClient.java:[line 84]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N187640');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.startStop(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N187640" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.startStop()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestMRJobClient.java:[line 255]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N187709');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.startStop(): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N187709" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.startStop()<br/>Called method new String(byte[])<br/>At TestMRJobClient.java:[line 270]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N187778');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testAllJobList(String, Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N187778" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testAllJobList(String, Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 466]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N187847');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testGetCounter(String, Configuration): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N187847" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testGetCounter(String, Configuration)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestMRJobClient.java:[line 449]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N187916');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testJobEvents(String, Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N187916" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testJobEvents(String, Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 396]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N187985');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testJobHistory(Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N187985" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testJobHistory(Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 372]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N188054');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testJobStatus(String, Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N188054" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testJobStatus(String, Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 421]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N188123');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testListAttemptIds(String, Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N188123" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testListAttemptIds(String, Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 321]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N188192');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testListBlackList(Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N188192" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testListBlackList(Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 299]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N188261');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testListTrackers(Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N188261" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testListTrackers(Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 342]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N188330');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testSubmit(Configuration): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N188330" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testSubmit(Configuration)<br/>Called method new String(byte[])<br/>At TestMRJobClient.java:[line 245]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N188399');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.testSubmittedJobList(Configuration): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N188399" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.testSubmittedJobList(Configuration)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 489]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N188468');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestMRJobClient.verifyJobPriority(String, String, Configuration, CLI): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N188468" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMRJobClient<br/>In method org.apache.hadoop.mapreduce.TestMRJobClient.verifyJobPriority(String, String, Configuration, CLI)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobClient.java:[line 509]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N188984');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestNewCombinerGrouping.testCombiner(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N188984" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestNewCombinerGrouping<br/>In method org.apache.hadoop.mapreduce.TestNewCombinerGrouping.testCombiner()<br/>Called method new java.io.FileReader(File)<br/>At TestNewCombinerGrouping.java:[line 154]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N189053');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestNewCombinerGrouping.testCombiner(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N189053" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestNewCombinerGrouping<br/>In method org.apache.hadoop.mapreduce.TestNewCombinerGrouping.testCombiner()<br/>Called method new java.io.FileWriter(File)<br/>At TestNewCombinerGrouping.java:[line 115]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N189332');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestValueIterReset.createInput(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N189332" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestValueIterReset<br/>In method org.apache.hadoop.mapreduce.TestValueIterReset.createInput()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestValueIterReset.java:[line 515]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N189401');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestValueIterReset.validateOutput(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N189401" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestValueIterReset<br/>In method org.apache.hadoop.mapreduce.TestValueIterReset.validateOutput()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestValueIterReset.java:[line 557]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N189543');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N189543" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider<br/>In method org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken()<br/>Called method String.getBytes()<br/>At TestYarnClientProtocolProvider.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N200986');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.job.impl.TestShuffleProvider.testShuffleProviders(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N200986" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.job.impl.TestShuffleProvider<br/>In method org.apache.hadoop.mapreduce.v2.app.job.impl.TestShuffleProvider.testShuffleProviders()<br/>Called method String.getBytes()<br/>At TestShuffleProvider.java:[line 95]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N201055');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttemptContainerRequest.testAttemptContainerRequest(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N201055" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttemptContainerRequest<br/>In method org.apache.hadoop.mapreduce.v2.app.job.impl.TestTaskAttemptContainerRequest.testAttemptContainerRequest()<br/>Called method String.getBytes()<br/>At TestTaskAttemptContainerRequest.java:[line 75]<br/>Another occurrence at TestTaskAttemptContainerRequest.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N201135');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncher.testSlowNM(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N201135" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncher<br/>In method org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncher.testSlowNM()<br/>Called method String.getBytes()<br/>At TestContainerLauncher.java:[line 249]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N201204');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncherImpl.createNewContainerToken(ContainerId, String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N201204" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncherImpl<br/>In method org.apache.hadoop.mapreduce.v2.app.launcher.TestContainerLauncherImpl.createNewContainerToken(ContainerId, String)<br/>Called method String.getBytes()<br/>At TestContainerLauncherImpl.java:[line 401]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N199524');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.MRApp.initJobCredentialsAndUGI(Configuration): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N199524" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MRApp<br/>In method org.apache.hadoop.mapreduce.v2.app.MRApp.initJobCredentialsAndUGI(Configuration)<br/>Called method String.getBytes()<br/>At MRApp.java:[line 167]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N200198');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterCredentials(): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N200198" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster<br/>In method org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterCredentials()<br/>Called method new String(byte[])<br/>At TestMRAppMaster.java:[line 420]<br/>Another occurrence at TestMRAppMaster.java:[line 428]<br/>Another occurrence at TestMRAppMaster.java:[line 437]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N200289');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterCredentials(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N200289" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster<br/>In method org.apache.hadoop.mapreduce.v2.app.TestMRAppMaster.testMRAppMasterCredentials()<br/>Called method String.getBytes()<br/>At TestMRAppMaster.java:[line 355]<br/>Another occurrence at TestMRAppMaster.java:[line 356]<br/>Another occurrence at TestMRAppMaster.java:[line 371]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N203073');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in new org.apache.hadoop.mapreduce.v2.app.webapp.AppControllerForTest(App, Configuration, Controller$RequestContext): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N203073" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.AppControllerForTest<br/>In method new org.apache.hadoop.mapreduce.v2.app.webapp.AppControllerForTest(App, Configuration, Controller$RequestContext)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At AppControllerForTest.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N203142');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.webapp.AppControllerForTest.getData(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N203142" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.AppControllerForTest<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.AppControllerForTest.getData()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At AppControllerForTest.java:[line 106]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N203211');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.webapp.AppControllerForTest.writer(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N203211" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.AppControllerForTest<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.AppControllerForTest.writer()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At AppControllerForTest.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N203386');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebApp.testMRWebAppSSLDisabled(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N203386" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebApp<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebApp.testMRWebAppSSLDisabled()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestAMWebApp.java:[line 195]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N206277');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerFileSystemStateStoreService.testTokenStore(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N206277" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerFileSystemStateStoreService<br/>In method org.apache.hadoop.mapreduce.v2.hs.TestHistoryServerFileSystemStateStoreService.testTokenStore()<br/>Called method String.getBytes()<br/>At TestHistoryServerFileSystemStateStoreService.java:[line 85]<br/>Another occurrence at TestHistoryServerFileSystemStateStoreService.java:[line 128]<br/>Another occurrence at TestHistoryServerFileSystemStateStoreService.java:[line 129]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N206610');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.checkHistoryParsing(int, int, int): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N206610" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing<br/>In method org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.checkHistoryParsing(int, int, int)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestJobHistoryParsing.java:[line 368]<br/>Another occurrence at TestJobHistoryParsing.java:[line 369]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N206690');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.checkHistoryParsing(int, int, int): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N206690" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing<br/>In method org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryParsing.checkHistoryParsing(int, int, int)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestJobHistoryParsing.java:[line 353]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N206837');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks.testAttemptsBlock(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N206837" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks.testAttemptsBlock()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestBlocks.java:[line 185]<br/>Another occurrence at TestBlocks.java:[line 186]<br/>Another occurrence at TestBlocks.java:[line 187]<br/>Another occurrence at TestBlocks.java:[line 189]<br/>Another occurrence at TestBlocks.java:[line 190]<br/>Another occurrence at TestBlocks.java:[line 191]<br/>Another occurrence at TestBlocks.java:[line 192]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N206972');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks.testAttemptsBlock(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N206972" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks.testAttemptsBlock()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestBlocks.java:[line 179]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N207041');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks.testHsJobsBlock(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N207041" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks.testHsJobsBlock()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestBlocks.java:[line 212]<br/>Another occurrence at TestBlocks.java:[line 213]<br/>Another occurrence at TestBlocks.java:[line 214]<br/>Another occurrence at TestBlocks.java:[line 215]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N207143');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks.testHsJobsBlock(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N207143" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks.testHsJobsBlock()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestBlocks.java:[line 207]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N207212');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks.testHsTasksBlock(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N207212" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks.testHsTasksBlock()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestBlocks.java:[line 109]<br/>Another occurrence at TestBlocks.java:[line 110]<br/>Another occurrence at TestBlocks.java:[line 111]<br/>Another occurrence at TestBlocks.java:[line 112]<br/>Another occurrence at TestBlocks.java:[line 113]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N207325');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks.testHsTasksBlock(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N207325" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestBlocks.testHsTasksBlock()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestBlocks.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N198769');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N198769" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser<br/>In method org.apache.hadoop.mapreduce.v2.TestMiniMRProxyUser.mrRun()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestMiniMRProxyUser.java:[line 109]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N197911');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.TestMRJobs.makeJar(Path, int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N197911" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobs<br/>In method org.apache.hadoop.mapreduce.v2.TestMRJobs.makeJar(Path, int)<br/>Called method String.getBytes()<br/>At TestMRJobs.java:[line 785]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N198492');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.testProfiler(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N198492" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler<br/>In method org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.testProfiler()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMRJobsWithProfiler.java:[line 184]<br/>Another occurrence at TestMRJobsWithProfiler.java:[line 211]<br/>Another occurrence at TestMRJobsWithProfiler.java:[line 226]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N210733');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.metrics.ganglia.GangliaContext.xdr_string(String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N210733" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.metrics.ganglia.GangliaContext<br/>In method org.apache.hadoop.metrics.ganglia.GangliaContext.xdr_string(String)<br/>Called method String.getBytes()<br/>At GangliaContext.java:[line 227]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N211091');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.metrics2.impl.MetricsConfig.toString(Configuration): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N211091" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.impl.MetricsConfig<br/>In method org.apache.hadoop.metrics2.impl.MetricsConfig.toString(Configuration)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At MetricsConfig.java:[line 282]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N211160');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.metrics2.impl.MetricsConfig.toString(Configuration): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N211160" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.impl.MetricsConfig<br/>In method org.apache.hadoop.metrics2.impl.MetricsConfig.toString(Configuration)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At MetricsConfig.java:[line 275]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N211282');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.metrics2.impl.TestGangliaMetrics.checkMetrics(List, int): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N211282" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.impl.TestGangliaMetrics<br/>In method org.apache.hadoop.metrics2.impl.TestGangliaMetrics.checkMetrics(List, int)<br/>Called method new String(byte[])<br/>At TestGangliaMetrics.java:[line 147]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N212107');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.metrics2.sink.FileSink.init(SubsetConfiguration): new java.io.FileWriter(File, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N212107" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.sink.FileSink<br/>In method org.apache.hadoop.metrics2.sink.FileSink.init(SubsetConfiguration)<br/>Called method new java.io.FileWriter(File, boolean)<br/>At FileSink.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N212176');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.metrics2.sink.FileSink.init(SubsetConfiguration): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N212176" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.sink.FileSink<br/>In method org.apache.hadoop.metrics2.sink.FileSink.init(SubsetConfiguration)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At FileSink.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N212385');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink.xdr_string(String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N212385" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink<br/>In method org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink.xdr_string(String)<br/>Called method String.getBytes()<br/>At AbstractGangliaSink.java:[line 224]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N212582');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.minikdc.MiniKdc.initKDCServer(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N212582" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.minikdc.MiniKdc<br/>In method org.apache.hadoop.minikdc.MiniKdc.initKDCServer()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At MiniKdc.java:[line 433]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N212651');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.minikdc.MiniKdc.main(String[]): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N212651" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.minikdc.MiniKdc<br/>In method org.apache.hadoop.minikdc.MiniKdc.main(String[])<br/>Called method new java.io.FileReader(File)<br/>At MiniKdc.java:[line 131]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N212793');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.mount.MountResponse.writeExportList(XDR, int, List, List): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N212793" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.mount.MountResponse<br/>In method org.apache.hadoop.mount.MountResponse.writeExportList(XDR, int, List, List)<br/>Called method String.getBytes()<br/>At MountResponse.java:[line 79]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N213331');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.net.TestSocketIOWithTimeout.testSocketIOWithTimeout(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N213331" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.net.TestSocketIOWithTimeout<br/>In method org.apache.hadoop.net.TestSocketIOWithTimeout.testSocketIOWithTimeout()<br/>Called method String.getBytes()<br/>At TestSocketIOWithTimeout.java:[line 94]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N214022');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in new org.apache.hadoop.nfs.nfs3.FileHandle(String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N214022" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.nfs.nfs3.FileHandle<br/>In method new org.apache.hadoop.nfs.nfs3.FileHandle(String)<br/>Called method String.getBytes()<br/>At FileHandle.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N214091');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.nfs.nfs3.IdUserGroup.updateMapInternal(BiMap, String, String, String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N214091" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.nfs.nfs3.IdUserGroup<br/>In method org.apache.hadoop.nfs.nfs3.IdUserGroup.updateMapInternal(BiMap, String, String, String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At IdUserGroup.java:[line 145]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N214286');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.nfs.nfs3.request.CREATE3Request.serialize(XDR): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N214286" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.nfs.nfs3.request.CREATE3Request<br/>In method org.apache.hadoop.nfs.nfs3.request.CREATE3Request.serialize(XDR)<br/>Called method String.getBytes()<br/>At CREATE3Request.java:[line 80]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N214355');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.nfs.nfs3.request.LOOKUP3Request.serialize(XDR): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N214355" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.nfs.nfs3.request.LOOKUP3Request<br/>In method org.apache.hadoop.nfs.nfs3.request.LOOKUP3Request.serialize(XDR)<br/>Called method String.getBytes()<br/>At LOOKUP3Request.java:[line 55]<br/>Another occurrence at LOOKUP3Request.java:[line 56]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N214573');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.oncrpc.security.CredentialsSys.write(XDR): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N214573" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.oncrpc.security.CredentialsSys<br/>In method org.apache.hadoop.oncrpc.security.CredentialsSys.write(XDR)<br/>Called method String.getBytes()<br/>At CredentialsSys.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N214435');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.oncrpc.XDR.readString(): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N214435" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.oncrpc.XDR<br/>In method org.apache.hadoop.oncrpc.XDR.readString()<br/>Called method new String(byte[])<br/>At XDR.java:[line 168]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N214504');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.oncrpc.XDR.writeString(String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N214504" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.oncrpc.XDR<br/>In method org.apache.hadoop.oncrpc.XDR.writeString(String)<br/>Called method String.getBytes()<br/>At XDR.java:[line 172]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N214860');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.record.compiler.CGenerator.genCode(String, ArrayList, ArrayList, String, ArrayList): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N214860" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.CGenerator<br/>In method org.apache.hadoop.record.compiler.CGenerator.genCode(String, ArrayList, ArrayList, String, ArrayList)<br/>Called method new java.io.FileWriter(String)<br/>At CGenerator.java:[line 45]<br/>Another occurrence at CGenerator.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N214940');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.record.compiler.CppGenerator.genCode(String, ArrayList, ArrayList, String, ArrayList): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N214940" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.CppGenerator<br/>In method org.apache.hadoop.record.compiler.CppGenerator.genCode(String, ArrayList, ArrayList, String, ArrayList)<br/>Called method new java.io.FileWriter(String)<br/>At CppGenerator.java:[line 46]<br/>Another occurrence at CppGenerator.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N215223');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.record.compiler.generated.Rcc.Include(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N215223" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.Rcc<br/>In method org.apache.hadoop.record.compiler.generated.Rcc.Include()<br/>Called method new java.io.FileReader(File)<br/>At Rcc.java:[line 163]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N215292');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.record.compiler.generated.Rcc.driver(String[]): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N215292" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.Rcc<br/>In method org.apache.hadoop.record.compiler.generated.Rcc.driver(String[])<br/>Called method new java.io.FileReader(File)<br/>At Rcc.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N216326');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in new org.apache.hadoop.record.compiler.generated.SimpleCharStream(InputStream, int, int, int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N216326" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.SimpleCharStream<br/>In method new org.apache.hadoop.record.compiler.generated.SimpleCharStream(InputStream, int, int, int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At SimpleCharStream.java:[line 310]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N216395');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in new org.apache.hadoop.record.compiler.generated.SimpleCharStream(InputStream, String, int, int, int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N216395" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.SimpleCharStream<br/>In method new org.apache.hadoop.record.compiler.generated.SimpleCharStream(InputStream, String, int, int, int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At SimpleCharStream.java:[line 304]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N216464');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.record.compiler.generated.SimpleCharStream.ReInit(InputStream, int, int, int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N216464" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.SimpleCharStream<br/>In method org.apache.hadoop.record.compiler.generated.SimpleCharStream.ReInit(InputStream, int, int, int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At SimpleCharStream.java:[line 344]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N216533');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.record.compiler.generated.SimpleCharStream.ReInit(InputStream, String, int, int, int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N216533" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.SimpleCharStream<br/>In method org.apache.hadoop.record.compiler.generated.SimpleCharStream.ReInit(InputStream, String, int, int, int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At SimpleCharStream.java:[line 338]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N218738');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.authentication.client.AuthenticatorTestCase._testAuthentication(Authenticator, boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N218738" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.authentication.client.AuthenticatorTestCase<br/>In method org.apache.hadoop.security.authentication.client.AuthenticatorTestCase._testAuthentication(Authenticator, boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At AuthenticatorTestCase.java:[line 153]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N218807');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.authentication.client.AuthenticatorTestCase._testAuthentication(Authenticator, boolean): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N218807" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.authentication.client.AuthenticatorTestCase<br/>In method org.apache.hadoop.security.authentication.client.AuthenticatorTestCase._testAuthentication(Authenticator, boolean)<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At AuthenticatorTestCase.java:[line 147]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N218942');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.authentication.examples.WhoClient.main(String[]): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N218942" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.authentication.examples.WhoClient<br/>In method org.apache.hadoop.security.authentication.examples.WhoClient.main(String[])<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At WhoClient.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N219011');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(FilterConfig): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N219011" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.authentication.server.AuthenticationFilter<br/>In method org.apache.hadoop.security.authentication.server.AuthenticationFilter.init(FilterConfig)<br/>Called method String.getBytes()<br/>At AuthenticationFilter.java:[line 164]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N219080');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.authentication.util.Signer.computeSignature(String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N219080" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.authentication.util.Signer<br/>In method org.apache.hadoop.security.authentication.util.Signer.computeSignature(String)<br/>Called method String.getBytes()<br/>At Signer.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N219149');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.authentication.util.TestSigner.testInvalidSignedText(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N219149" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.authentication.util.TestSigner<br/>In method org.apache.hadoop.security.authentication.util.TestSigner.testInvalidSignedText()<br/>Called method String.getBytes()<br/>At TestSigner.java:[line 73]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N219218');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.authentication.util.TestSigner.testNullAndEmptyString(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N219218" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.authentication.util.TestSigner<br/>In method org.apache.hadoop.security.authentication.util.TestSigner.testNullAndEmptyString()<br/>Called method String.getBytes()<br/>At TestSigner.java:[line 33]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N219287');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.authentication.util.TestSigner.testSignature(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N219287" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.authentication.util.TestSigner<br/>In method org.apache.hadoop.security.authentication.util.TestSigner.testSignature()<br/>Called method String.getBytes()<br/>At TestSigner.java:[line 54]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N219356');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.authentication.util.TestSigner.testTampering(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N219356" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.authentication.util.TestSigner<br/>In method org.apache.hadoop.security.authentication.util.TestSigner.testTampering()<br/>Called method String.getBytes()<br/>At TestSigner.java:[line 86]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N219425');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.authentication.util.TestSigner.testVerify(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N219425" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.authentication.util.TestSigner<br/>In method org.apache.hadoop.security.authentication.util.TestSigner.testVerify()<br/>Called method String.getBytes()<br/>At TestSigner.java:[line 64]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N216751');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.AuthenticationFilterInitializer.initFilter(FilterContainer, Configuration): new java.io.FileReader(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N216751" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.AuthenticationFilterInitializer<br/>In method org.apache.hadoop.security.AuthenticationFilterInitializer.initFilter(FilterContainer, Configuration)<br/>Called method new java.io.FileReader(String)<br/>At AuthenticationFilterInitializer.java:[line 84]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N216820');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.LdapGroupsMapping.extractPassword(String): new java.io.FileReader(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N216820" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.LdapGroupsMapping<br/>In method org.apache.hadoop.security.LdapGroupsMapping.extractPassword(String)<br/>Called method new java.io.FileReader(String)<br/>At LdapGroupsMapping.java:[line 351]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N217008');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.SaslRpcServer.decodeIdentifier(String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N217008" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.SaslRpcServer<br/>In method org.apache.hadoop.security.SaslRpcServer.decodeIdentifier(String)<br/>Called method String.getBytes()<br/>At SaslRpcServer.java:[line 194]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N217077');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.SaslRpcServer.encodeIdentifier(byte[]): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N217077" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.SaslRpcServer<br/>In method org.apache.hadoop.security.SaslRpcServer.encodeIdentifier(byte[])<br/>Called method new String(byte[])<br/>At SaslRpcServer.java:[line 190]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N217146');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.SaslRpcServer.encodePassword(byte[]): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N217146" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.SaslRpcServer<br/>In method org.apache.hadoop.security.SaslRpcServer.encodePassword(byte[])<br/>Called method new String(byte[])<br/>At SaslRpcServer.java:[line 212]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N219630');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.ssl.KeyStoreTestUtil.saveConfig(File, Configuration): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N219630" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.ssl.KeyStoreTestUtil<br/>In method org.apache.hadoop.security.ssl.KeyStoreTestUtil.saveConfig(File, Configuration)<br/>Called method new java.io.FileWriter(File)<br/>At KeyStoreTestUtil.java:[line 355]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N217215');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.TestAuthenticationFilter.testConfiguration(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N217215" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.TestAuthenticationFilter<br/>In method org.apache.hadoop.security.TestAuthenticationFilter.testConfiguration()<br/>Called method new java.io.FileWriter(File)<br/>At TestAuthenticationFilter.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N217705');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.TestLdapGroupsMapping.testExtractPassword(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N217705" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.TestLdapGroupsMapping<br/>In method org.apache.hadoop.security.TestLdapGroupsMapping.testExtractPassword()<br/>Called method new java.io.FileWriter(File)<br/>At TestLdapGroupsMapping.java:[line 149]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N218002');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.TestProxyUserFromEnv.testProxyUserFromEnvironment(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N218002" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.TestProxyUserFromEnv<br/>In method org.apache.hadoop.security.TestProxyUserFromEnv.testProxyUserFromEnvironment()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestProxyUserFromEnv.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N218191');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.TestRefreshUserMappings.addNewConfigResource(String, String, String, String, String): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N218191" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.TestRefreshUserMappings<br/>In method org.apache.hadoop.security.TestRefreshUserMappings.addNewConfigResource(String, String, String, String, String)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestRefreshUserMappings.java:[line 239]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N218330');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.TestUserGroupInformation.testGetServerSideGroups(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N218330" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.TestUserGroupInformation<br/>In method org.apache.hadoop.security.TestUserGroupInformation.testGetServerSideGroups()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestUserGroupInformation.java:[line 188]<br/>Another occurrence at TestUserGroupInformation.java:[line 204]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N218410');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.TestUserGroupInformation.testPrivateTokenExclusion(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N218410" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.TestUserGroupInformation<br/>In method org.apache.hadoop.security.TestUserGroupInformation.testPrivateTokenExclusion()<br/>Called method String.getBytes()<br/>At TestUserGroupInformation.java:[line 788]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N220181');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.security.token.TestToken.testEncodeWritable(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N220181" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.security.token.TestToken<br/>In method org.apache.hadoop.security.token.TestToken.testEncodeWritable()<br/>Called method String.getBytes()<br/>At TestToken.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N220829');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.DelayEchoApp.go(int): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N220829" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.DelayEchoApp<br/>In method org.apache.hadoop.streaming.DelayEchoApp.go(int)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At DelayEchoApp.java:[line 33]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N220898');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in new org.apache.hadoop.streaming.Environment(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N220898" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.Environment<br/>In method new org.apache.hadoop.streaming.Environment()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At Environment.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N220967');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.FailApp.go(boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N220967" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.FailApp<br/>In method org.apache.hadoop.streaming.FailApp.go(boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At FailApp.java:[line 35]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N221308');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.RawBytesMapApp.go(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N221308" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.RawBytesMapApp<br/>In method org.apache.hadoop.streaming.RawBytesMapApp.go()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At RawBytesMapApp.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N221377');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.StderrApp.go(int, int, int, boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N221377" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.StderrApp<br/>In method org.apache.hadoop.streaming.StderrApp.go(int, int, int, boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At StderrApp.java:[line 39]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N221446');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.StreamAggregate.go(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N221446" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.StreamAggregate<br/>In method org.apache.hadoop.streaming.StreamAggregate.go()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At StreamAggregate.java:[line 40]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N221515');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.TestAutoInputFormat.testFormat(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N221515" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestAutoInputFormat<br/>In method org.apache.hadoop.streaming.TestAutoInputFormat.testFormat()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestAutoInputFormat.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N221584');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.TestDumpTypedBytes.testDumping(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N221584" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestDumpTypedBytes<br/>In method org.apache.hadoop.streaming.TestDumpTypedBytes.testDumping()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestDumpTypedBytes.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N221653');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.TestDumpTypedBytes.testDumping(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N221653" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestDumpTypedBytes<br/>In method org.apache.hadoop.streaming.TestDumpTypedBytes.testDumping()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestDumpTypedBytes.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N221807');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N221807" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestMultipleCachefiles<br/>In method org.apache.hadoop.streaming.TestMultipleCachefiles.testMultipleCachefiles()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestMultipleCachefiles.java:[line 137]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N222427');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.TestStreamingBackground.setUp(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N222427" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamingBackground<br/>In method org.apache.hadoop.streaming.TestStreamingBackground.setUp()<br/>Called method String.getBytes()<br/>At TestStreamingBackground.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N222584');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.TestStreamingBadRecords.createInput(): new java.io.OutputStreamWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N222584" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamingBadRecords<br/>In method org.apache.hadoop.streaming.TestStreamingBadRecords.createInput()<br/>Called method new java.io.OutputStreamWriter(OutputStream)<br/>At TestStreamingBadRecords.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N222653');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.TestStreamingBadRecords.createInput(): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N222653" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamingBadRecords<br/>In method org.apache.hadoop.streaming.TestStreamingBadRecords.createInput()<br/>Called method new String(byte[])<br/>At TestStreamingBadRecords.java:[line 83]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N222722');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.TestStreamingBadRecords.validateOutput(RunningJob, boolean): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N222722" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamingBadRecords<br/>In method org.apache.hadoop.streaming.TestStreamingBadRecords.validateOutput(RunningJob, boolean)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestStreamingBadRecords.java:[line 134]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N222860');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.TestStreamingExitStatus.setUp(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N222860" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamingExitStatus<br/>In method org.apache.hadoop.streaming.TestStreamingExitStatus.setUp()<br/>Called method String.getBytes()<br/>At TestStreamingExitStatus.java:[line 71]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N223298');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.TestStreamingStderr.setupInput(String, boolean): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N223298" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamingStderr<br/>In method org.apache.hadoop.streaming.TestStreamingStderr.setupInput(String, boolean)<br/>Called method String.getBytes()<br/>At TestStreamingStderr.java:[line 63]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N223466');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.TestSymLink.testSymLink(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N223466" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestSymLink<br/>In method org.apache.hadoop.streaming.TestSymLink.testSymLink()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestSymLink.java:[line 124]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N223913');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.TrApp.go(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N223913" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TrApp<br/>In method org.apache.hadoop.streaming.TrApp.go()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TrApp.java:[line 84]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N223982');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.TrAppReduce.go(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N223982" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TrAppReduce<br/>In method org.apache.hadoop.streaming.TrAppReduce.go()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TrAppReduce.java:[line 84]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N224051');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.UniqApp.go(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N224051" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.UniqApp<br/>In method org.apache.hadoop.streaming.UniqApp.go()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At UniqApp.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N224120');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.streaming.UtilTest.redirectIfAntJunit(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N224120" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.UtilTest<br/>In method org.apache.hadoop.streaming.UtilTest.redirectIfAntJunit()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At UtilTest.java:[line 82]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N224834');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.test.MiniDFSClusterManager.start(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N224834" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.test.MiniDFSClusterManager<br/>In method org.apache.hadoop.test.MiniDFSClusterManager.start()<br/>Called method new java.io.FileWriter(File)<br/>At MiniDFSClusterManager.java:[line 161]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N225229');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.test.SysPropsForTestsLoader.&lt;static initializer for SysPropsForTestsLoader&gt;(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N225229" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.test.SysPropsForTestsLoader<br/>In method org.apache.hadoop.test.SysPropsForTestsLoader.&lt;static initializer for SysPropsForTestsLoader&gt;()<br/>Called method new java.io.FileReader(File)<br/>At SysPropsForTestsLoader.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N225485');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.test.TestHFSTestCase.testJetty(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N225485" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.test.TestHFSTestCase<br/>In method org.apache.hadoop.test.TestHFSTestCase.testJetty()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestHFSTestCase.java:[line 177]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N225554');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.test.TestHTestCase.testJetty(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N225554" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.test.TestHTestCase<br/>In method org.apache.hadoop.test.TestHTestCase.testJetty()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestHTestCase.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N225623');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in new org.apache.hadoop.test.TimedOutTestsListener(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N225623" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.test.TimedOutTestsListener<br/>In method new org.apache.hadoop.test.TimedOutTestsListener()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TimedOutTestsListener.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N226060');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.DistCpV1.fetchFileList(Configuration, Path): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N226060" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.DistCpV1<br/>In method org.apache.hadoop.tools.DistCpV1.fetchFileList(Configuration, Path)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At DistCpV1.java:[line 702]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N226129');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.DistTool.readFile(Configuration, Path): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N226129" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.DistTool<br/>In method org.apache.hadoop.tools.DistTool.readFile(Configuration, Path)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At DistTool.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N226425');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.FileBasedCopyListing.fetchFileList(Path): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N226425" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.FileBasedCopyListing<br/>In method org.apache.hadoop.tools.FileBasedCopyListing.fetchFileList(Path)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At FileBasedCopyListing.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N226494');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.GetGroupsTestBase.runTool(Configuration, String[], boolean): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N226494" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.GetGroupsTestBase<br/>In method org.apache.hadoop.tools.GetGroupsTestBase.runTool(Configuration, String[], boolean)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At GetGroupsTestBase.java:[line 121]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N226563');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.GetGroupsTestBase.runTool(Configuration, String[], boolean): new java.io.PrintStream(OutputStream, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N226563" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.GetGroupsTestBase<br/>In method org.apache.hadoop.tools.GetGroupsTestBase.runTool(Configuration, String[], boolean)<br/>Called method new java.io.PrintStream(OutputStream, boolean)<br/>At GetGroupsTestBase.java:[line 117]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N228729');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.mapred.TestCopyMapper.testFailCopyWithAccessControlException(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N228729" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.mapred.TestCopyMapper<br/>In method org.apache.hadoop.tools.mapred.TestCopyMapper.testFailCopyWithAccessControlException()<br/>Called method String.getBytes()<br/>At TestCopyMapper.java:[line 606]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N229065');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in new org.apache.hadoop.tools.rumen.ParsedConfigFile(String, String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N229065" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.rumen.ParsedConfigFile<br/>In method new org.apache.hadoop.tools.rumen.ParsedConfigFile(String, String)<br/>Called method String.getBytes()<br/>At ParsedConfigFile.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N229228');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.rumen.RandomSeedGenerator.getSeed(String, long): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N229228" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.rumen.RandomSeedGenerator<br/>In method org.apache.hadoop.tools.rumen.RandomSeedGenerator.getSeed(String, long)<br/>Called method String.getBytes()<br/>At RandomSeedGenerator.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N226895');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestCopyFiles.execCmd(FsShell, String[]): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N226895" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestCopyFiles<br/>In method org.apache.hadoop.tools.TestCopyFiles.execCmd(FsShell, String[])<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestCopyFiles.java:[line 1106]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N226964');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestCopyFiles.execCmd(FsShell, String[]): new java.io.PrintStream(OutputStream, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N226964" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestCopyFiles<br/>In method org.apache.hadoop.tools.TestCopyFiles.execCmd(FsShell, String[])<br/>Called method new java.io.PrintStream(OutputStream, boolean)<br/>At TestCopyFiles.java:[line 1100]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N227033');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestCopyListing.testBuildListing(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N227033" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestCopyListing<br/>In method org.apache.hadoop.tools.TestCopyListing.testBuildListing()<br/>Called method String.getBytes()<br/>At TestCopyListing.java:[line 173]<br/>Another occurrence at TestCopyListing.java:[line 177]<br/>Another occurrence at TestCopyListing.java:[line 181]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N227201');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestDelegationTokenRemoteFetcher.createToken(URI): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N227201" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestDelegationTokenRemoteFetcher<br/>In method org.apache.hadoop.tools.TestDelegationTokenRemoteFetcher.createToken(URI)<br/>Called method String.getBytes()<br/>At TestDelegationTokenRemoteFetcher.java:[line 217]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N227270');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestDistCh.runLsr(FsShell, String, int): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N227270" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestDistCh<br/>In method org.apache.hadoop.tools.TestDistCh.runLsr(FsShell, String, int)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestDistCh.java:[line 213]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N227339');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestDistCh.runLsr(FsShell, String, int): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N227339" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestDistCh<br/>In method org.apache.hadoop.tools.TestDistCh.runLsr(FsShell, String, int)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestDistCh.java:[line 205]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N227478');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestDistCpViewFs.addEntries(Path, String[]): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N227478" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestDistCpViewFs<br/>In method org.apache.hadoop.tools.TestDistCpViewFs.addEntries(Path, String[])<br/>Called method String.getBytes()<br/>At TestDistCpViewFs.java:[line 428]<br/>Another occurrence at TestDistCpViewFs.java:[line 429]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N227558');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestDistCpViewFs.createFiles(String[]): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N227558" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestDistCpViewFs<br/>In method org.apache.hadoop.tools.TestDistCpViewFs.createFiles(String[])<br/>Called method String.getBytes()<br/>At TestDistCpViewFs.java:[line 449]<br/>Another occurrence at TestDistCpViewFs.java:[line 450]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N227638');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestExternalCall.createFile(String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N227638" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestExternalCall<br/>In method org.apache.hadoop.tools.TestExternalCall.createFile(String)<br/>Called method String.getBytes()<br/>At TestExternalCall.java:[line 100]<br/>Another occurrence at TestExternalCall.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N227852');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestFileBasedCopyListing.addEntries(Path, String[]): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N227852" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestFileBasedCopyListing<br/>In method org.apache.hadoop.tools.TestFileBasedCopyListing.addEntries(Path, String[])<br/>Called method String.getBytes()<br/>At TestFileBasedCopyListing.java:[line 484]<br/>Another occurrence at TestFileBasedCopyListing.java:[line 485]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N227932');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestFileBasedCopyListing.createFiles(String[]): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N227932" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestFileBasedCopyListing<br/>In method org.apache.hadoop.tools.TestFileBasedCopyListing.createFiles(String[])<br/>Called method String.getBytes()<br/>At TestFileBasedCopyListing.java:[line 496]<br/>Another occurrence at TestFileBasedCopyListing.java:[line 497]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N228064');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestHadoopArchives.lsr(FsShell, String): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N228064" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestHadoopArchives<br/>In method org.apache.hadoop.tools.TestHadoopArchives.lsr(FsShell, String)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestHadoopArchives.java:[line 200]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N228133');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestHadoopArchives.lsr(FsShell, String): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N228133" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestHadoopArchives<br/>In method org.apache.hadoop.tools.TestHadoopArchives.lsr(FsShell, String)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestHadoopArchives.java:[line 192]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N228202');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestIntegration.addEntries(Path, String[]): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N228202" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestIntegration<br/>In method org.apache.hadoop.tools.TestIntegration.addEntries(Path, String[])<br/>Called method String.getBytes()<br/>At TestIntegration.java:[line 501]<br/>Another occurrence at TestIntegration.java:[line 502]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N228282');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestIntegration.createFiles(String[]): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N228282" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestIntegration<br/>In method org.apache.hadoop.tools.TestIntegration.createFiles(String[])<br/>Called method String.getBytes()<br/>At TestIntegration.java:[line 513]<br/>Another occurrence at TestIntegration.java:[line 514]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N228362');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestIntegration.testOverwrite(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N228362" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestIntegration<br/>In method org.apache.hadoop.tools.TestIntegration.testOverwrite()<br/>Called method String.getBytes()<br/>At TestIntegration.java:[line 348]<br/>Another occurrence at TestIntegration.java:[line 349]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N228442');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestJMXGet.checkPrintAllValues(JMXGet): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N228442" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestJMXGet<br/>In method org.apache.hadoop.tools.TestJMXGet.checkPrintAllValues(JMXGet)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestJMXGet.java:[line 137]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N228511');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestJMXGet.checkPrintAllValues(JMXGet): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N228511" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestJMXGet<br/>In method org.apache.hadoop.tools.TestJMXGet.checkPrintAllValues(JMXGet)<br/>Called method new String(byte[])<br/>At TestJMXGet.java:[line 145]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N228580');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestTools.checkOutput(String[], String, PrintStream, Class): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N228580" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestTools<br/>In method org.apache.hadoop.tools.TestTools.checkOutput(String[], String, PrintStream, Class)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestTools.java:[line 110]<br/>Another occurrence at TestTools.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N228660');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.tools.TestTools.checkOutput(String[], String, PrintStream, Class): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N228660" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestTools<br/>In method org.apache.hadoop.tools.TestTools.checkOutput(String[], String, PrintStream, Class)<br/>Called method new String(byte[])<br/>At TestTools.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N235945');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.bloom.TestBloomFilters.checkOnAbsentFalsePositive(int, int, RetouchedBloomFilter, TestBloomFilters$Digits, short): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N235945" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.bloom.TestBloomFilters<br/>In method org.apache.hadoop.util.bloom.TestBloomFilters.checkOnAbsentFalsePositive(int, int, RetouchedBloomFilter, TestBloomFilters$Digits, short)<br/>Called method String.getBytes()<br/>At TestBloomFilters.java:[line 194]<br/>Another occurrence at TestBloomFilters.java:[line 202]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N236025');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.hash.TestHash.testHash(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N236025" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.hash.TestHash<br/>In method org.apache.hadoop.util.hash.TestHash.testHash()<br/>Called method String.getBytes()<br/>At TestHash.java:[line 58]<br/>Another occurrence at TestHash.java:[line 60]<br/>Another occurrence at TestHash.java:[line 65]<br/>Another occurrence at TestHash.java:[line 67]<br/>Another occurrence at TestHash.java:[line 73]<br/>Another occurrence at TestHash.java:[line 75]<br/>Another occurrence at TestHash.java:[line 81]<br/>Another occurrence at TestHash.java:[line 83]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N229639');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.Hello.main(String[]): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N229639" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.Hello<br/>In method org.apache.hadoop.util.Hello.main(String[])<br/>Called method String.getBytes()<br/>At Hello.java:[line 33]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N229708');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.HostsFileReader.readFileToSetWithFileInputStream(String, String, InputStream, Set): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N229708" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.HostsFileReader<br/>In method org.apache.hadoop.util.HostsFileReader.readFileToSetWithFileInputStream(String, String, InputStream, Set)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At HostsFileReader.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N230741');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.ReflectionUtils.logThreadInfo(Log, String, long): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N230741" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.ReflectionUtils<br/>In method org.apache.hadoop.util.ReflectionUtils.logThreadInfo(Log, String, long)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At ReflectionUtils.java:[line 220]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N230810');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.ReflectionUtils.logThreadInfo(Log, String, long): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N230810" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.ReflectionUtils<br/>In method org.apache.hadoop.util.ReflectionUtils.logThreadInfo(Log, String, long)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At ReflectionUtils.java:[line 219]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N230956');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.Shell.runCommand(): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N230956" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.Shell<br/>In method org.apache.hadoop.util.Shell.runCommand()<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At Shell.java:[line 458]<br/>Another occurrence at Shell.java:[line 461]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N231478');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.TestGenericOptionsParser.testTokenCacheOption(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N231478" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.TestGenericOptionsParser<br/>In method org.apache.hadoop.util.TestGenericOptionsParser.testTokenCacheOption()<br/>Called method String.getBytes()<br/>At TestGenericOptionsParser.java:[line 178]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N231762');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithCommentsOnly(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N231762" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.TestHostsFileReader<br/>In method org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithCommentsOnly()<br/>Called method new java.io.FileWriter(String)<br/>At TestHostsFileReader.java:[line 171]<br/>Another occurrence at TestHostsFileReader.java:[line 172]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N231842');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithNull(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N231842" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.TestHostsFileReader<br/>In method org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithNull()<br/>Called method new java.io.FileWriter(String)<br/>At TestHostsFileReader.java:[line 143]<br/>Another occurrence at TestHostsFileReader.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N231922');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithSpaces(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N231922" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.TestHostsFileReader<br/>In method org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithSpaces()<br/>Called method new java.io.FileWriter(String)<br/>At TestHostsFileReader.java:[line 199]<br/>Another occurrence at TestHostsFileReader.java:[line 200]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N232002');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithTabs(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N232002" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.TestHostsFileReader<br/>In method org.apache.hadoop.util.TestHostsFileReader.testHostFileReaderWithTabs()<br/>Called method new java.io.FileWriter(String)<br/>At TestHostsFileReader.java:[line 235]<br/>Another occurrence at TestHostsFileReader.java:[line 236]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N232082');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.TestHostsFileReader.testHostsFileReader(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N232082" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.TestHostsFileReader<br/>In method org.apache.hadoop.util.TestHostsFileReader.testHostsFileReader()<br/>Called method new java.io.FileWriter(String)<br/>At TestHostsFileReader.java:[line 64]<br/>Another occurrence at TestHostsFileReader.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N232162');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.TestHostsFileReader.testRefreshHostFileReaderWithNonexistentFile(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N232162" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.TestHostsFileReader<br/>In method org.apache.hadoop.util.TestHostsFileReader.testRefreshHostFileReaderWithNonexistentFile()<br/>Called method new java.io.FileWriter(String)<br/>At TestHostsFileReader.java:[line 121]<br/>Another occurrence at TestHostsFileReader.java:[line 122]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N233109');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.TestJarFinder.testExistingManifest(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N233109" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.TestJarFinder<br/>In method org.apache.hadoop.util.TestJarFinder.testExistingManifest()<br/>Called method new java.io.FileWriter(File)<br/>At TestJarFinder.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N233178');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.TestJarFinder.testNoManifest(): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N233178" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.TestJarFinder<br/>In method org.apache.hadoop.util.TestJarFinder.testNoManifest()<br/>Called method new java.io.FileWriter(File)<br/>At TestJarFinder.java:[line 115]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N233662');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.TestLineReader.testCustomDelimiter(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N233662" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.TestLineReader<br/>In method org.apache.hadoop.util.TestLineReader.testCustomDelimiter()<br/>Called method String.getBytes()<br/>At TestLineReader.java:[line 90]<br/>Another occurrence at TestLineReader.java:[line 119]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N234186');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.TestShell.testShellCommandTimeout(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N234186" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.TestShell<br/>In method org.apache.hadoop.util.TestShell.testShellCommandTimeout()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestShell.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N234544');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.TestWinUtils.writeFile(File, String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N234544" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.writeFile(File, String)<br/>Called method String.getBytes()<br/>At TestWinUtils.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N235652');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.util.TestZKUtil.testGoodAuths(): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N235652" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.util.TestZKUtil<br/>In method org.apache.hadoop.util.TestZKUtil.testGoodAuths()<br/>Called method new String(byte[])<br/>At TestZKUtil.java:[line 120]<br/>Another occurrence at TestZKUtil.java:[line 124]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N236717');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.api.TestContainerResourceIncrease.testResourceIncreaseContext(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N236717" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.api.TestContainerResourceIncrease<br/>In method org.apache.hadoop.yarn.api.TestContainerResourceIncrease.testResourceIncreaseContext()<br/>Called method String.getBytes()<br/>At TestContainerResourceIncrease.java:[line 39]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N237214');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithCustomLogPropertyFile(): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N237214" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell<br/>In method org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithCustomLogPropertyFile()<br/>Called method new java.io.PrintWriter(File)<br/>At TestDistributedShell.java:[line 257]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N237283');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithShellScript(): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N237283" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell<br/>In method org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.testDSShellWithShellScript()<br/>Called method new java.io.PrintWriter(File)<br/>At TestDistributedShell.java:[line 386]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N237352');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyContainerLog(int, List, boolean, String): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N237352" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell<br/>In method org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyContainerLog(int, List, boolean, String)<br/>Called method new java.io.FileReader(File)<br/>At TestDistributedShell.java:[line 664]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N238172');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.applications.unmanagedamlauncher.UnmanagedAMLauncher.launchAM(ApplicationAttemptId): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N238172" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.unmanagedamlauncher.UnmanagedAMLauncher<br/>In method org.apache.hadoop.yarn.applications.unmanagedamlauncher.UnmanagedAMLauncher.launchAM(ApplicationAttemptId)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At UnmanagedAMLauncher.java:[line 234]<br/>Another occurrence at UnmanagedAMLauncher.java:[line 237]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N239441');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.ApplicationCLI.listApplicationAttempts(String): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N239441" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.ApplicationCLI<br/>In method org.apache.hadoop.yarn.client.cli.ApplicationCLI.listApplicationAttempts(String)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At ApplicationCLI.java:[line 493]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N239510');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.ApplicationCLI.listApplications(Set, EnumSet): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N239510" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.ApplicationCLI<br/>In method org.apache.hadoop.yarn.client.cli.ApplicationCLI.listApplications(Set, EnumSet)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At ApplicationCLI.java:[line 338]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N239579');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.ApplicationCLI.listContainers(String): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N239579" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.ApplicationCLI<br/>In method org.apache.hadoop.yarn.client.cli.ApplicationCLI.listContainers(String)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At ApplicationCLI.java:[line 519]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N239648');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.ApplicationCLI.printApplicationAttemptReport(String): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N239648" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.ApplicationCLI<br/>In method org.apache.hadoop.yarn.client.cli.ApplicationCLI.printApplicationAttemptReport(String)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At ApplicationCLI.java:[line 262]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N239717');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.ApplicationCLI.printApplicationReport(String): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N239717" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.ApplicationCLI<br/>In method org.apache.hadoop.yarn.client.cli.ApplicationCLI.printApplicationReport(String)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At ApplicationCLI.java:[line 432]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N239786');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.ApplicationCLI.printContainerReport(String): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N239786" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.ApplicationCLI<br/>In method org.apache.hadoop.yarn.client.cli.ApplicationCLI.printContainerReport(String)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At ApplicationCLI.java:[line 301]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N239855');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.NodeCLI.listClusterNodes(Set): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N239855" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.NodeCLI<br/>In method org.apache.hadoop.yarn.client.cli.NodeCLI.listClusterNodes(Set)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At NodeCLI.java:[line 141]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N239924');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.NodeCLI.printNodeStatus(String): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N239924" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.NodeCLI<br/>In method org.apache.hadoop.yarn.client.cli.NodeCLI.printNodeStatus(String)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At NodeCLI.java:[line 167]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N240370');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestLogsCLI.setUp(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N240370" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestLogsCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestLogsCLI.setUp()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestLogsCLI.java:[line 57]<br/>Another occurrence at TestLogsCLI.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N240450');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestLogsCLI.testHelpMessage(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N240450" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestLogsCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestLogsCLI.testHelpMessage()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestLogsCLI.java:[line 138]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N240519');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestLogsCLI.testHelpMessage(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N240519" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestLogsCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestLogsCLI.testHelpMessage()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestLogsCLI.java:[line 124]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N240588');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestLogsCLI.testInvalidApplicationId(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N240588" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestLogsCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestLogsCLI.testInvalidApplicationId()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestLogsCLI.java:[line 95]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N240657');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestLogsCLI.testUnknownApplicationId(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N240657" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestLogsCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestLogsCLI.testUnknownApplicationId()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestLogsCLI.java:[line 110]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N241015');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.createApplicationAttemptCLIHelpMessage(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N241015" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.createApplicationAttemptCLIHelpMessage()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestYarnCLI.java:[line 1247]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N241084');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.createApplicationCLIHelpMessage(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N241084" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.createApplicationCLIHelpMessage()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestYarnCLI.java:[line 1216]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N241153');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.createContainerCLIHelpMessage(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N241153" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.createContainerCLIHelpMessage()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestYarnCLI.java:[line 1261]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N241222');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.createNodeCLIHelpMessage(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N241222" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.createNodeCLIHelpMessage()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestYarnCLI.java:[line 1273]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N241291');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.setup(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N241291" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.setup()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestYarnCLI.java:[line 80]<br/>Another occurrence at TestYarnCLI.java:[line 82]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N241371');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testAppAttemptsHelpCommand(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N241371" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testAppAttemptsHelpCommand()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestYarnCLI.java:[line 707]<br/>Another occurrence at TestYarnCLI.java:[line 716]<br/>Another occurrence at TestYarnCLI.java:[line 726]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N241462');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testAppsHelpCommand(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N241462" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testAppsHelpCommand()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestYarnCLI.java:[line 680]<br/>Another occurrence at TestYarnCLI.java:[line 688]<br/>Another occurrence at TestYarnCLI.java:[line 696]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N241553');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testContainersHelpCommand(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N241553" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testContainersHelpCommand()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestYarnCLI.java:[line 737]<br/>Another occurrence at TestYarnCLI.java:[line 747]<br/>Another occurrence at TestYarnCLI.java:[line 755]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N241644');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplicationAttemptReport(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N241644" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplicationAttemptReport()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestYarnCLI.java:[line 153]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N241713');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplicationAttemptReport(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N241713" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplicationAttemptReport()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestYarnCLI.java:[line 142]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N241782');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplicationAttempts(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N241782" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplicationAttempts()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestYarnCLI.java:[line 199]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N241851');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplicationAttempts(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N241851" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplicationAttempts()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestYarnCLI.java:[line 183]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N241920');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplicationReport(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N241920" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplicationReport()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestYarnCLI.java:[line 119]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N241989');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplicationReport(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N241989" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplicationReport()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestYarnCLI.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N242058');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplications(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N242058" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplications()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestYarnCLI.java:[line 406]<br/>Another occurrence at TestYarnCLI.java:[line 446]<br/>Another occurrence at TestYarnCLI.java:[line 486]<br/>Another occurrence at TestYarnCLI.java:[line 524]<br/>Another occurrence at TestYarnCLI.java:[line 546]<br/>Another occurrence at TestYarnCLI.java:[line 604]<br/>Another occurrence at TestYarnCLI.java:[line 639]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N242193');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplications(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N242193" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetApplications()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestYarnCLI.java:[line 376]<br/>Another occurrence at TestYarnCLI.java:[line 431]<br/>Another occurrence at TestYarnCLI.java:[line 466]<br/>Another occurrence at TestYarnCLI.java:[line 509]<br/>Another occurrence at TestYarnCLI.java:[line 534]<br/>Another occurrence at TestYarnCLI.java:[line 564]<br/>Another occurrence at TestYarnCLI.java:[line 624]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N242328');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetContainerReport(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N242328" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetContainerReport()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestYarnCLI.java:[line 230]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N242397');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetContainerReport(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N242397" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetContainerReport()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestYarnCLI.java:[line 219]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N242466');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetContainers(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N242466" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetContainers()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestYarnCLI.java:[line 257]<br/>Another occurrence at TestYarnCLI.java:[line 281]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N242546');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetContainers(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N242546" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testGetContainers()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestYarnCLI.java:[line 259]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N242615');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testListClusterNodes(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N242615" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testListClusterNodes()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestYarnCLI.java:[line 899]<br/>Another occurrence at TestYarnCLI.java:[line 922]<br/>Another occurrence at TestYarnCLI.java:[line 928]<br/>Another occurrence at TestYarnCLI.java:[line 949]<br/>Another occurrence at TestYarnCLI.java:[line 970]<br/>Another occurrence at TestYarnCLI.java:[line 991]<br/>Another occurrence at TestYarnCLI.java:[line 1012]<br/>Another occurrence at TestYarnCLI.java:[line 1045]<br/>Another occurrence at TestYarnCLI.java:[line 1080]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N242772');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testListClusterNodes(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N242772" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testListClusterNodes()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestYarnCLI.java:[line 891]<br/>Another occurrence at TestYarnCLI.java:[line 912]<br/>Another occurrence at TestYarnCLI.java:[line 941]<br/>Another occurrence at TestYarnCLI.java:[line 962]<br/>Another occurrence at TestYarnCLI.java:[line 983]<br/>Another occurrence at TestYarnCLI.java:[line 1004]<br/>Another occurrence at TestYarnCLI.java:[line 1029]<br/>Another occurrence at TestYarnCLI.java:[line 1060]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N242918');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testMissingArguments(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N242918" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testMissingArguments()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestYarnCLI.java:[line 1162]<br/>Another occurrence at TestYarnCLI.java:[line 1168]<br/>Another occurrence at TestYarnCLI.java:[line 1174]<br/>Another occurrence at TestYarnCLI.java:[line 1184]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N243020');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testNodeStatus(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N243020" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testNodeStatus()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestYarnCLI.java:[line 1110]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N243089');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testNodesHelpCommand(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N243089" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testNodesHelpCommand()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestYarnCLI.java:[line 766]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N238299');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.TestRMAdminCLI.testError(String[], String, ByteArrayOutputStream, int): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N238299" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.TestRMAdminCLI<br/>In method org.apache.hadoop.yarn.client.TestRMAdminCLI.testError(String[], String, ByteArrayOutputStream, int)<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestRMAdminCLI.java:[line 366]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N238368');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.TestRMAdminCLI.testException(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N238368" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.TestRMAdminCLI<br/>In method org.apache.hadoop.yarn.client.TestRMAdminCLI.testException()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestRMAdminCLI.java:[line 357]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N238437');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.TestRMAdminCLI.testException(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N238437" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.TestRMAdminCLI<br/>In method org.apache.hadoop.yarn.client.TestRMAdminCLI.testException()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestRMAdminCLI.java:[line 349]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N238506');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.TestRMAdminCLI.testHelp(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N238506" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.TestRMAdminCLI<br/>In method org.apache.hadoop.yarn.client.TestRMAdminCLI.testHelp()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestRMAdminCLI.java:[line 247]<br/>Another occurrence at TestRMAdminCLI.java:[line 251]<br/>Another occurrence at TestRMAdminCLI.java:[line 258]<br/>Another occurrence at TestRMAdminCLI.java:[line 263]<br/>Another occurrence at TestRMAdminCLI.java:[line 268]<br/>Another occurrence at TestRMAdminCLI.java:[line 270]<br/>Another occurrence at TestRMAdminCLI.java:[line 275]<br/>Another occurrence at TestRMAdminCLI.java:[line 280]<br/>Another occurrence at TestRMAdminCLI.java:[line 285]<br/>Another occurrence at TestRMAdminCLI.java:[line 329]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N238674');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.client.TestRMAdminCLI.testHelp(): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N238674" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.TestRMAdminCLI<br/>In method org.apache.hadoop.yarn.client.TestRMAdminCLI.testHelp()<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestRMAdminCLI.java:[line 241]<br/>Another occurrence at TestRMAdminCLI.java:[line 242]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N243736');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.lib.TestZKClient.send4LetterWord(String, int, String): new java.io.InputStreamReader(InputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N243736" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.lib.TestZKClient<br/>In method org.apache.hadoop.yarn.lib.TestZKClient.send4LetterWord(String, int, String)<br/>Called method new java.io.InputStreamReader(InputStream)<br/>At TestZKClient.java:[line 64]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N243805');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.lib.TestZKClient.send4LetterWord(String, int, String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N243805" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.lib.TestZKClient<br/>In method org.apache.hadoop.yarn.lib.TestZKClient.send4LetterWord(String, int, String)<br/>Called method String.getBytes()<br/>At TestZKClient.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N244047');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.lib.ZKClient.getServiceData(String): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N244047" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.lib.ZKClient<br/>In method org.apache.hadoop.yarn.lib.ZKClient.getServiceData(String)<br/>Called method new String(byte[])<br/>At ZKClient.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N244116');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.lib.ZKClient.registerService(String, String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N244116" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.lib.ZKClient<br/>In method org.apache.hadoop.yarn.lib.ZKClient.registerService(String, String)<br/>Called method String.getBytes()<br/>At ZKClient.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N244185');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat.testContainerLogsFileAccess(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N244185" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat<br/>In method org.apache.hadoop.yarn.logaggregation.TestAggregatedLogFormat.testContainerLogsFileAccess()<br/>Called method new java.io.FileReader(File)<br/>At TestAggregatedLogFormat.java:[line 290]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N244320');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testAccessDenied(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N244320" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock<br/>In method org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testAccessDenied()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestAggregatedLogsBlock.java:[line 83]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N244389');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testAccessDenied(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N244389" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock<br/>In method org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testAccessDenied()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestAggregatedLogsBlock.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N244458');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testAggregatedLogsBlock(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N244458" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock<br/>In method org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testAggregatedLogsBlock()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestAggregatedLogsBlock.java:[line 143]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N244527');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testAggregatedLogsBlock(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N244527" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock<br/>In method org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testAggregatedLogsBlock()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestAggregatedLogsBlock.java:[line 137]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N244596');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testBadLogs(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N244596" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock<br/>In method org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testBadLogs()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestAggregatedLogsBlock.java:[line 113]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N244665');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testBadLogs(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N244665" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock<br/>In method org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testBadLogs()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestAggregatedLogsBlock.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N244734');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testNoLogs(): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N244734" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock<br/>In method org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testNoLogs()<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestAggregatedLogsBlock.java:[line 175]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N244803');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testNoLogs(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N244803" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock<br/>In method org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.testNoLogs()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestAggregatedLogsBlock.java:[line 169]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N244872');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.writeLog(String, String): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N244872" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock<br/>In method org.apache.hadoop.yarn.logaggregation.TestAggregatedLogsBlock.writeLog(String, String)<br/>Called method new java.io.FileWriter(File)<br/>At TestAggregatedLogsBlock.java:[line 248]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N246352');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.applicationhistoryservice.timeline.LeveldbTimelineStore.&lt;static initializer for LeveldbTimelineStore&gt;(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N246352" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.applicationhistoryservice.timeline.LeveldbTimelineStore<br/>In method org.apache.hadoop.yarn.server.applicationhistoryservice.timeline.LeveldbTimelineStore.&lt;static initializer for LeveldbTimelineStore&gt;()<br/>Called method String.getBytes()<br/>At LeveldbTimelineStore.java:[line 125]<br/>Another occurrence at LeveldbTimelineStore.java:[line 126]<br/>Another occurrence at LeveldbTimelineStore.java:[line 127]<br/>Another occurrence at LeveldbTimelineStore.java:[line 129]<br/>Another occurrence at LeveldbTimelineStore.java:[line 130]<br/>Another occurrence at LeveldbTimelineStore.java:[line 131]<br/>Another occurrence at LeveldbTimelineStore.java:[line 132]<br/>Another occurrence at LeveldbTimelineStore.java:[line 133]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N246498');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.applicationhistoryservice.timeline.LeveldbTimelineStore.parseRemainingKey(byte[], int): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N246498" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.applicationhistoryservice.timeline.LeveldbTimelineStore<br/>In method org.apache.hadoop.yarn.server.applicationhistoryservice.timeline.LeveldbTimelineStore.parseRemainingKey(byte[], int)<br/>Called method new String(byte[], int, int)<br/>At LeveldbTimelineStore.java:[line 1185]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N250593');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.writeLaunchEnv(OutputStream, Map, Map, List): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N250593" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.writeLaunchEnv(OutputStream, Map, Map, List)<br/>Called method new java.io.PrintStream(OutputStream)<br/>At ContainerLaunch.java:[line 752]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N250728');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.internalKillTest(boolean): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N250728" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.internalKillTest(boolean)<br/>Called method new java.io.FileReader(File)<br/>At TestContainerLaunch.java:[line 727]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N250797');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.internalKillTest(boolean): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N250797" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.internalKillTest(boolean)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestContainerLaunch.java:[line 636]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N250866');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testAuxiliaryServiceHelper(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N250866" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testAuxiliaryServiceHelper()<br/>Called method String.getBytes()<br/>At TestContainerLaunch.java:[line 615]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N250935');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerEnvVariables(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N250935" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerEnvVariables()<br/>Called method new java.io.FileReader(File)<br/>At TestContainerLaunch.java:[line 510]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N251004');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerEnvVariables(): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N251004" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerEnvVariables()<br/>Called method new java.io.PrintWriter(File)<br/>At TestContainerLaunch.java:[line 395]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N251073');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerEnvVariables(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N251073" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerEnvVariables()<br/>Called method String.getBytes()<br/>At TestContainerLaunch.java:[line 536]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N251142');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerLaunchStdoutAndStderrDiagnostics(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N251142" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerLaunchStdoutAndStderrDiagnostics()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestContainerLaunch.java:[line 325]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N251211');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testInvalidSymlinkDiagnostics(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N251211" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testInvalidSymlinkDiagnostics()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestContainerLaunch.java:[line 185]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N251280');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testSpecialCharSymlinks(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N251280" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testSpecialCharSymlinks()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestContainerLaunch.java:[line 117]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N252488');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestContainerLocalizer.createFakeCredentials(Random, int): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N252488" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestContainerLocalizer<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestContainerLocalizer.createFakeCredentials(Random, int)<br/>Called method String.getBytes()<br/>At TestContainerLocalizer.java:[line 391]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N252611');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.getToken(int): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N252611" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.getToken(int)<br/>Called method String.getBytes()<br/>At TestResourceLocalizationService.java:[line 1443]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N253085');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testLogAggregationForRealContainerLaunch(): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N253085" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.testLogAggregationForRealContainerLaunch()<br/>Called method new java.io.PrintWriter(File)<br/>At TestLogAggregationService.java:[line 777]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N253154');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.verifyContainerLogs(LogAggregationService, ApplicationId, ContainerId[]): java.io.ByteArrayOutputStream.toString()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N253154" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.verifyContainerLogs(LogAggregationService, ApplicationId, ContainerId[])<br/>Called method java.io.ByteArrayOutputStream.toString()<br/>At TestLogAggregationService.java:[line 717]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N253223');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.verifyContainerLogs(LogAggregationService, ApplicationId, ContainerId[]): new java.io.PrintStream(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N253223" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.verifyContainerLogs(LogAggregationService, ApplicationId, ContainerId[])<br/>Called method new java.io.PrintStream(OutputStream)<br/>At TestLogAggregationService.java:[line 714]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N253292');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.writeContainerLogs(File, ContainerId): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N253292" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.writeContainerLogs(File, ContainerId)<br/>Called method new java.io.FileWriter(File)<br/>At TestLogAggregationService.java:[line 682]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N254779');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerKillOnMemoryOverflow(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N254779" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerKillOnMemoryOverflow()<br/>Called method new java.io.FileReader(File)<br/>At TestContainersMonitor.java:[line 256]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N254848');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerKillOnMemoryOverflow(): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N254848" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerKillOnMemoryOverflow()<br/>Called method new java.io.PrintWriter(File)<br/>At TestContainersMonitor.java:[line 193]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N249535');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesMeta(): new String(byte[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N249535" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.TestAuxServices.testAuxServicesMeta()<br/>Called method new String(byte[])<br/>At TestAuxServices.java:[line 263]<br/>Another occurrence at TestAuxServices.java:[line 264]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N249615');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerLaunchAndExit(int): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N249615" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerLaunchAndExit(int)<br/>Called method new java.io.PrintWriter(File)<br/>At TestContainerManager.java:[line 364]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N249684');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerLaunchAndStop(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N249684" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerLaunchAndStop()<br/>Called method new java.io.FileReader(File)<br/>At TestContainerManager.java:[line 322]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N249753');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerLaunchAndStop(): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N249753" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerLaunchAndStop()<br/>Called method new java.io.PrintWriter(File)<br/>At TestContainerManager.java:[line 262]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N249822');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerSetup(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N249822" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerSetup()<br/>Called method new java.io.FileReader(File)<br/>At TestContainerManager.java:[line 251]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N249891');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerSetup(): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N249891" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerSetup()<br/>Called method new java.io.PrintWriter(File)<br/>At TestContainerManager.java:[line 185]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N249960');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testLocalFilesCleanup(): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N249960" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testLocalFilesCleanup()<br/>Called method new java.io.PrintWriter(File)<br/>At TestContainerManager.java:[line 473]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N250029');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testStartContainerFailureWithUnknownAuxService(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N250029" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testStartContainerFailureWithUnknownAuxService()<br/>Called method String.getBytes()<br/>At TestContainerManager.java:[line 769]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N246992');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutor.writeScriptFile(String[]): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N246992" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutor<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutor.writeScriptFile(String[])<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestLinuxContainerExecutor.java:[line 154]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N247061');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutorWithMocks.readMockParams(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N247061" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutorWithMocks<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestLinuxContainerExecutorWithMocks.readMockParams()<br/>Called method new java.io.FileReader(File)<br/>At TestLinuxContainerExecutorWithMocks.java:[line 71]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N247340');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService.writeNodeHealthScriptFile(String, boolean): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N247340" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService.writeNodeHealthScriptFile(String, boolean)<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestNodeHealthService.java:[line 86]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N248090');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.createUnhaltingScriptFile(ContainerId, File, File): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N248090" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.createUnhaltingScriptFile(ContainerId, File, File)<br/>Called method new java.io.PrintWriter(File)<br/>At TestNodeManagerShutdown.java:[line 256]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N248159');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.testKillContainersOnShutdown(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N248159" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerShutdown.testKillContainersOnShutdown()<br/>Called method new java.io.FileReader(File)<br/>At TestNodeManagerShutdown.java:[line 139]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N255105');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler.parseMtab(): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N255105" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler<br/>In method org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler.parseMtab()<br/>Called method new java.io.FileReader(File)<br/>At CgroupsLCEResourcesHandler.java:[line 277]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N255174');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler.updateCgroup(String, String, String, String): new java.io.FileWriter(String, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N255174" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler<br/>In method org.apache.hadoop.yarn.server.nodemanager.util.CgroupsLCEResourcesHandler.updateCgroup(String, String, String, String)<br/>Called method new java.io.FileWriter(String, boolean)<br/>At CgroupsLCEResourcesHandler.java:[line 160]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N255339');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.util.ProcessIdFileReader.getProcessId(Path): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N255339" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.util.ProcessIdFileReader<br/>In method org.apache.hadoop.yarn.server.nodemanager.util.ProcessIdFileReader.getProcessId(Path)<br/>Called method new java.io.FileReader(File)<br/>At ProcessIdFileReader.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N255408');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.util.TestProcessIdFileReader.testComplexGet(): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N255408" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.util.TestProcessIdFileReader<br/>In method org.apache.hadoop.yarn.server.nodemanager.util.TestProcessIdFileReader.testComplexGet()<br/>Called method new java.io.PrintWriter(File)<br/>At TestProcessIdFileReader.java:[line 88]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N255477');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.util.TestProcessIdFileReader.testSimpleGet(): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N255477" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.util.TestProcessIdFileReader<br/>In method org.apache.hadoop.yarn.server.nodemanager.util.TestProcessIdFileReader.testSimpleGet()<br/>Called method new java.io.PrintWriter(File)<br/>At TestProcessIdFileReader.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N255733');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in new org.apache.hadoop.yarn.server.nodemanager.webapp.MockContainer(ApplicationAttemptId, Dispatcher, Configuration, String, ApplicationId, int): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N255733" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.MockContainer<br/>In method new org.apache.hadoop.yarn.server.nodemanager.webapp.MockContainer(ApplicationAttemptId, Dispatcher, Configuration, String, ApplicationId, int)<br/>Called method String.getBytes()<br/>At MockContainer.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N255880');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage.testContainerLogPageAccess(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N255880" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestContainerLogsPage.testContainerLogPageAccess()<br/>Called method String.getBytes()<br/>At TestContainerLogsPage.java:[line 164]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N256214');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer.testNMWebApp(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N256214" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer.testNMWebApp()<br/>Called method String.getBytes()<br/>At TestNMWebServer.java:[line 194]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N256283');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer.writeContainerLogs(Context, ContainerId, LocalDirsHandlerService): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N256283" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServer.writeContainerLogs(Context, ContainerId, LocalDirsHandlerService)<br/>Called method new java.io.FileWriter(File)<br/>At TestNMWebServer.java:[line 230]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N256650');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices.testContainerLogs(): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N256650" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.TestNMWebServices.testContainerLogs()<br/>Called method new java.io.PrintWriter(File)<br/>At TestNMWebServices.java:[line 337]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N260169');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreTestBase.testRMDTSecretManagerStateStore(RMStateStoreTestBase$RMStateStoreHelper): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N260169" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreTestBase<br/>In method org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreTestBase.testRMDTSecretManagerStateStore(RMStateStoreTestBase$RMStateStoreHelper)<br/>Called method String.getBytes()<br/>At RMStateStoreTestBase.java:[line 402]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N260334');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore.testFSRMStateStore(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N260334" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore<br/>In method org.apache.hadoop.yarn.server.resourcemanager.recovery.TestFSRMStateStore.testFSRMStateStore()<br/>Called method String.getBytes()<br/>At TestFSRMStateStore.java:[line 153]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N260403');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStoreZKClientConnections.testZKClientDisconnectAndReconnect(): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N260403" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStoreZKClientConnections<br/>In method org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStoreZKClientConnections.testZKClientDisconnectAndReconnect()<br/>Called method new String(byte[])<br/>At TestZKRMStateStoreZKClientConnections.java:[line 206]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N260472');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStoreZKClientConnections.testZKClientDisconnectAndReconnect(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N260472" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStoreZKClientConnections<br/>In method org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStoreZKClientConnections.testZKClientDisconnectAndReconnect()<br/>Called method String.getBytes()<br/>At TestZKRMStateStoreZKClientConnections.java:[line 183]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N260541');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStoreZKClientConnections.testZKSessionTimeout(): new String(byte[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N260541" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStoreZKClientConnections<br/>In method org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStoreZKClientConnections.testZKSessionTimeout()<br/>Called method new String(byte[])<br/>At TestZKRMStateStoreZKClientConnections.java:[line 235]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N260610');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStoreZKClientConnections.testZKSessionTimeout(): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N260610" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStoreZKClientConnections<br/>In method org.apache.hadoop.yarn.server.resourcemanager.recovery.TestZKRMStateStoreZKClientConnections.testZKSessionTimeout()<br/>Called method String.getBytes()<br/>At TestZKRMStateStoreZKClientConnections.java:[line 228]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N260679');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createConnection(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N260679" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<br/>In method org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.createConnection()<br/>Called method String.getBytes()<br/>At ZKRMStateStore.java:[line 1018]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N266676');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService.testAllocationFileParsing(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N266676" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService.testAllocationFileParsing()<br/>Called method new java.io.FileWriter(String)<br/>At TestAllocationFileLoaderService.java:[line 148]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N266745');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService.testBackwardsCompatibleAllocationFileParsing(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N266745" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService.testBackwardsCompatibleAllocationFileParsing()<br/>Called method new java.io.FileWriter(String)<br/>At TestAllocationFileLoaderService.java:[line 272]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N266814');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService.testQueueAlongsideRoot(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N266814" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService.testQueueAlongsideRoot()<br/>Called method new java.io.FileWriter(String)<br/>At TestAllocationFileLoaderService.java:[line 407]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N266883');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService.testReload(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N266883" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService.testReload()<br/>Called method new java.io.FileWriter(String)<br/>At TestAllocationFileLoaderService.java:[line 70]<br/>Another occurrence at TestAllocationFileLoaderService.java:[line 109]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N266963');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService.testSimplePlacementPolicyFromConf(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N266963" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestAllocationFileLoaderService.testSimplePlacementPolicyFromConf()<br/>Called method new java.io.FileWriter(String)<br/>At TestAllocationFileLoaderService.java:[line 377]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N268286');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testAclSubmitApplication(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N268286" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testAclSubmitApplication()<br/>Called method new java.io.FileWriter(String)<br/>At TestFairScheduler.java:[line 1520]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N268355');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChoiceOfPreemptedContainers(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N268355" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChoiceOfPreemptedContainers()<br/>Called method new java.io.FileWriter(String)<br/>At TestFairScheduler.java:[line 1089]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N268424');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testConfigureRootQueue(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N268424" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testConfigureRootQueue()<br/>Called method new java.io.FileWriter(String)<br/>At TestFairScheduler.java:[line 935]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N268493');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testDontAllowUndeclaredPools(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N268493" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testDontAllowUndeclaredPools()<br/>Called method new java.io.FileWriter(String)<br/>At TestFairScheduler.java:[line 2438]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N268562');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testFairShareWithMinAlloc(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N268562" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testFairShareWithMinAlloc()<br/>Called method new java.io.FileWriter(String)<br/>At TestFairScheduler.java:[line 774]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N268631');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testHierarchicalQueueAllocationFileParsing(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N268631" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testHierarchicalQueueAllocationFileParsing()<br/>Called method new java.io.FileWriter(String)<br/>At TestFairScheduler.java:[line 900]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N268700');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testIsStarvedForFairShare(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N268700" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testIsStarvedForFairShare()<br/>Called method new java.io.FileWriter(String)<br/>At TestFairScheduler.java:[line 1022]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N268769');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testIsStarvedForMinShare(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N268769" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testIsStarvedForMinShare()<br/>Called method new java.io.FileWriter(String)<br/>At TestFairScheduler.java:[line 965]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N268838');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testMaxRunningAppsHierarchicalQueues(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N268838" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testMaxRunningAppsHierarchicalQueues()<br/>Called method new java.io.FileWriter(String)<br/>At TestFairScheduler.java:[line 2291]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N268907');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testNotAllowSubmitApplication(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N268907" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testNotAllowSubmitApplication()<br/>Called method new java.io.FileWriter(String)<br/>At TestFairScheduler.java:[line 1755]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N268976');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N268976" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()<br/>Called method new java.io.FileWriter(String)<br/>At TestFairScheduler.java:[line 1247]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N269045');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testUserAndQueueMaxRunningApps(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N269045" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testUserAndQueueMaxRunningApps()<br/>Called method new java.io.FileWriter(String)<br/>At TestFairScheduler.java:[line 2239]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N269114');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testUserMaxRunningApps(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N269114" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testUserMaxRunningApps()<br/>Called method new java.io.FileWriter(String)<br/>At TestFairScheduler.java:[line 1404]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N269349');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerQueueACLs.createConfiguration(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N269349" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerQueueACLs<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairSchedulerQueueACLs.createConfiguration()<br/>Called method new java.io.FileWriter(String)<br/>At TestFairSchedulerQueueACLs.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N270208');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.testAppSubmissionWithInvalidDelegationToken(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N270208" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer<br/>In method org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.testAppSubmissionWithInvalidDelegationToken()<br/>Called method String.getBytes()<br/>At TestDelegationTokenRenewer.java:[line 742]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N259421');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService.writeToHostsFile(String[]): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N259421" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService.writeToHostsFile(String[])<br/>Called method String.getBytes()<br/>At TestResourceTrackerService.java:[line 613]<br/>Another occurrence at TestResourceTrackerService.java:[line 614]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N258089');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService.testRMInitialsWithFileSystemBasedConfigurationProvider(): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N258089" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService.testRMInitialsWithFileSystemBasedConfigurationProvider()<br/>Called method new java.io.PrintWriter(File)<br/>At TestRMAdminService.java:[line 615]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N258158');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService.testRefreshNodesWithFileSystemBasedConfigurationProvider(): new java.io.PrintWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N258158" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService.testRefreshNodesWithFileSystemBasedConfigurationProvider()<br/>Called method new java.io.PrintWriter(File)<br/>At TestRMAdminService.java:[line 474]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N258997');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.writeToHostsFile(String[]): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N258997" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.writeToHostsFile(String[])<br/>Called method String.getBytes()<br/>At TestRMRestart.java:[line 1837]<br/>Another occurrence at TestRMRestart.java:[line 1838]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N271661');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.sls.RumenToSLSConverter.generateSLSLoadFile(String, String): new java.io.FileReader(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N271661" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.RumenToSLSConverter<br/>In method org.apache.hadoop.yarn.sls.RumenToSLSConverter.generateSLSLoadFile(String, String)<br/>Called method new java.io.FileReader(String)<br/>At RumenToSLSConverter.java:[line 118]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N271730');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.sls.RumenToSLSConverter.generateSLSLoadFile(String, String): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N271730" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.RumenToSLSConverter<br/>In method org.apache.hadoop.yarn.sls.RumenToSLSConverter.generateSLSLoadFile(String, String)<br/>Called method new java.io.FileWriter(String)<br/>At RumenToSLSConverter.java:[line 120]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N271799');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.sls.RumenToSLSConverter.generateSLSNodeFile(String): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N271799" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.RumenToSLSConverter<br/>In method org.apache.hadoop.yarn.sls.RumenToSLSConverter.generateSLSNodeFile(String)<br/>Called method new java.io.FileWriter(String)<br/>At RumenToSLSConverter.java:[line 141]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N272042');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.sls.scheduler.ResourceSchedulerWrapper.initMetrics(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N272042" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.scheduler.ResourceSchedulerWrapper<br/>In method org.apache.hadoop.yarn.sls.scheduler.ResourceSchedulerWrapper.initMetrics()<br/>Called method new java.io.FileWriter(String)<br/>At ResourceSchedulerWrapper.java:[line 478]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N271868');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.sls.SLSRunner.startAMFromSLSTraces(Resource, int): new java.io.FileReader(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N271868" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.SLSRunner<br/>In method org.apache.hadoop.yarn.sls.SLSRunner.startAMFromSLSTraces(Resource, int)<br/>Called method new java.io.FileReader(String)<br/>At SLSRunner.java:[line 262]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N272461');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.sls.utils.SLSUtils.parseNodesFromNodeFile(String): new java.io.FileReader(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N272461" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.utils.SLSUtils<br/>In method org.apache.hadoop.yarn.sls.utils.SLSUtils.parseNodesFromNodeFile(String)<br/>Called method new java.io.FileReader(String)<br/>At SLSUtils.java:[line 115]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N272530');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.sls.utils.SLSUtils.parseNodesFromSLSTrace(String): new java.io.FileReader(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N272530" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.utils.SLSUtils<br/>In method org.apache.hadoop.yarn.sls.utils.SLSUtils.parseNodesFromSLSTrace(String)<br/>Called method new java.io.FileReader(String)<br/>At SLSUtils.java:[line 88]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N272705');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.state.Graph.save(String): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N272705" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.state.Graph<br/>In method org.apache.hadoop.yarn.state.Graph.save(String)<br/>Called method new java.io.FileWriter(String)<br/>At Graph.java:[line 189]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N236171');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.TestContainerLaunchRPC.testRPCTimeout(String): String.getBytes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N236171" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.TestContainerLaunchRPC<br/>In method org.apache.hadoop.yarn.TestContainerLaunchRPC.testRPCTimeout(String)<br/>Called method String.getBytes()<br/>At TestContainerLaunchRPC.java:[line 106]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N236240');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.TestRPC.test(String): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N236240" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.TestRPC<br/>In method org.apache.hadoop.yarn.TestRPC.test(String)<br/>Called method String.getBytes()<br/>At TestRPC.java:[line 133]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N273225');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin.readProcCpuInfoFile(): new java.io.FileReader(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N273225" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin<br/>In method org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin.readProcCpuInfoFile()<br/>Called method new java.io.FileReader(String)<br/>At LinuxResourceCalculatorPlugin.java:[line 211]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N273294');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin.readProcMemInfoFile(boolean): new java.io.FileReader(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N273294" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin<br/>In method org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin.readProcMemInfoFile(boolean)<br/>Called method new java.io.FileReader(String)<br/>At LinuxResourceCalculatorPlugin.java:[line 152]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N273363');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin.readProcStatFile(): new java.io.FileReader(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N273363" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin<br/>In method org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin.readProcStatFile()<br/>Called method new java.io.FileReader(String)<br/>At LinuxResourceCalculatorPlugin.java:[line 258]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N273432');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.constructProcessInfo(ProcfsBasedProcessTree$ProcessInfo, String): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N273432" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.ProcfsBasedProcessTree<br/>In method org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.constructProcessInfo(ProcfsBasedProcessTree$ProcessInfo, String)<br/>Called method new java.io.FileReader(File)<br/>At ProcfsBasedProcessTree.java:[line 496]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N273501');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.constructProcessSMAPInfo(ProcfsBasedProcessTree$ProcessTreeSmapMemInfo, String): new java.io.FileReader(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N273501" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.ProcfsBasedProcessTree<br/>In method org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.constructProcessSMAPInfo(ProcfsBasedProcessTree$ProcessTreeSmapMemInfo, String)<br/>Called method new java.io.FileReader(File)<br/>At ProcfsBasedProcessTree.java:[line 736]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N273791');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.util.TestApplicationClassLoader.makeTestJar(): String.getBytes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N273791" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestApplicationClassLoader<br/>In method org.apache.hadoop.yarn.util.TestApplicationClassLoader.makeTestJar()<br/>Called method String.getBytes()<br/>At TestApplicationClassLoader.java:[line 130]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N274603');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.parsingProcMemFile(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N274603" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin<br/>In method org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.parsingProcMemFile()<br/>Called method new java.io.FileWriter(String)<br/>At TestLinuxResourceCalculatorPlugin.java:[line 223]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N274672');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.parsingProcStatAndCpuFile(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N274672" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin<br/>In method org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.parsingProcStatAndCpuFile()<br/>Called method new java.io.FileWriter(String)<br/>At TestLinuxResourceCalculatorPlugin.java:[line 159]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N274741');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.updateStatFile(long, long, long): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N274741" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin<br/>In method org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.updateStatFile(long, long, long)<br/>Called method new java.io.FileWriter(String)<br/>At TestLinuxResourceCalculatorPlugin.java:[line 205]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N275349');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.getPidFromPidFile(String): new java.io.FileReader(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N275349" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree<br/>In method org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.getPidFromPidFile(String)<br/>Called method new java.io.FileReader(String)<br/>At TestProcfsBasedProcessTree.java:[line 262]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N275418');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree(): new java.io.FileWriter(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N275418" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree<br/>In method org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.testProcessTree()<br/>Called method new java.io.FileWriter(String)<br/>At TestProcfsBasedProcessTree.java:[line 148]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N275487');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.writeCmdLineFiles(File, String[], String[]): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N275487" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree<br/>In method org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.writeCmdLineFiles(File, String[], String[])<br/>Called method new java.io.FileWriter(File)<br/>At TestProcfsBasedProcessTree.java:[line 944]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N275556');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.writeStatFiles(File, String[], TestProcfsBasedProcessTree$ProcessStatInfo[], ProcfsBasedProcessTree$ProcessTreeSmapMemInfo[]): new java.io.FileWriter(File)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N275556" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree<br/>In method org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.writeStatFiles(File, String[], TestProcfsBasedProcessTree$ProcessStatInfo[], ProcfsBasedProcessTree$ProcessTreeSmapMemInfo[])<br/>Called method new java.io.FileWriter(File)<br/>At TestProcfsBasedProcessTree.java:[line 903]<br/>Another occurrence at TestProcfsBasedProcessTree.java:[line 920]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N276254');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.webapp.hamlet.TestHamlet.newHamlet(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N276254" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.webapp.hamlet.TestHamlet<br/>In method org.apache.hadoop.yarn.webapp.hamlet.TestHamlet.newHamlet()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestHamlet.java:[line 163]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N276323');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.webapp.hamlet.TestHamletImpl.testGeneric(): new java.io.PrintWriter(OutputStream)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N276323" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.webapp.hamlet.TestHamletImpl<br/>In method org.apache.hadoop.yarn.webapp.hamlet.TestHamletImpl.testGeneric()<br/>Called method new java.io.PrintWriter(OutputStream)<br/>At TestHamletImpl.java:[line 35]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N276185');">
<td>
<span class="priority-1">Dm</span>
</td>
<td>Found reliance on default encoding in org.apache.hadoop.yarn.webapp.TestWebApp.getContent(String): new String(byte[], int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N276185" style="display: none;">
<a href="#DM_DEFAULT_ENCODING">Bug type DM_DEFAULT_ENCODING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.webapp.TestWebApp<br/>In method org.apache.hadoop.yarn.webapp.TestWebApp.getContent(String)<br/>Called method new String(byte[], int, int)<br/>At TestWebApp.java:[line 297]</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_MALICIOUS_CODE">Malicious code vulnerability Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N71411');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.fs.BlockLocation.getCachedHosts() may expose internal representation by returning BlockLocation.cachedHosts</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N71411" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.fs.BlockLocation<br/>In method org.apache.hadoop.fs.BlockLocation.getCachedHosts()<br/>Field org.apache.hadoop.fs.BlockLocation.cachedHosts<br/>At BlockLocation.java:[line 134]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71479');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.fs.BlockLocation.getHosts() may expose internal representation by returning BlockLocation.hosts</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71479" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.fs.BlockLocation<br/>In method org.apache.hadoop.fs.BlockLocation.getHosts()<br/>Field org.apache.hadoop.fs.BlockLocation.hosts<br/>At BlockLocation.java:[line 127]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N71547');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.fs.BlockLocation.getNames() may expose internal representation by returning BlockLocation.names</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N71547" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.fs.BlockLocation<br/>In method org.apache.hadoop.fs.BlockLocation.getNames()<br/>Field org.apache.hadoop.fs.BlockLocation.names<br/>At BlockLocation.java:[line 141]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71615');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.fs.BlockLocation.getTopologyPaths() may expose internal representation by returning BlockLocation.topologyPaths</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71615" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.fs.BlockLocation<br/>In method org.apache.hadoop.fs.BlockLocation.getTopologyPaths()<br/>Field org.apache.hadoop.fs.BlockLocation.topologyPaths<br/>At BlockLocation.java:[line 149]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72283');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.fs.BlockStorageLocation.getVolumeIds() may expose internal representation by returning BlockStorageLocation.volumeIds</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72283" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.fs.BlockStorageLocation<br/>In method org.apache.hadoop.fs.BlockStorageLocation.getVolumeIds()<br/>Field org.apache.hadoop.fs.BlockStorageLocation.volumeIds<br/>At BlockStorageLocation.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N74790');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.fs.LocatedFileStatus.getBlockLocations() may expose internal representation by returning LocatedFileStatus.locations</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N74790" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.fs.LocatedFileStatus<br/>In method org.apache.hadoop.fs.LocatedFileStatus.getBlockLocations()<br/>Field org.apache.hadoop.fs.LocatedFileStatus.locations<br/>At LocatedFileStatus.java:[line 84]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N88134');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.fs.s3.INode.getBlocks() may expose internal representation by returning INode.blocks</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N88134" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.fs.s3.INode<br/>In method org.apache.hadoop.fs.s3.INode.getBlocks()<br/>Field org.apache.hadoop.fs.s3.INode.blocks<br/>At INode.java:[line 63]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95668');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.HDFSPolicyProvider.getServices() may expose internal representation by returning HDFSPolicyProvider.hdfsServices</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95668" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.HDFSPolicyProvider<br/>In method org.apache.hadoop.hdfs.HDFSPolicyProvider.getServices()<br/>Field org.apache.hadoop.hdfs.HDFSPolicyProvider.hdfsServices<br/>At HDFSPolicyProvider.java:[line 72]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N95944');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.MiniDFSCluster.getNameNodeInfos() may expose internal representation by returning MiniDFSCluster.nameNodes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N95944" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.MiniDFSCluster<br/>In method org.apache.hadoop.hdfs.MiniDFSCluster.getNameNodeInfos()<br/>Field org.apache.hadoop.hdfs.MiniDFSCluster.nameNodes<br/>At MiniDFSCluster.java:[line 895]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N111363');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.protocol.BlockListAsLongs.getBlockListAsLongs() may expose internal representation by returning BlockListAsLongs.blockList</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N111363" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.BlockListAsLongs<br/>In method org.apache.hadoop.hdfs.protocol.BlockListAsLongs.getBlockListAsLongs()<br/>Field org.apache.hadoop.hdfs.protocol.BlockListAsLongs.blockList<br/>At BlockListAsLongs.java:[line 133]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N111506');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.protocol.CorruptFileBlocks.getFiles() may expose internal representation by returning CorruptFileBlocks.files</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N111506" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.CorruptFileBlocks<br/>In method org.apache.hadoop.hdfs.protocol.CorruptFileBlocks.getFiles()<br/>Field org.apache.hadoop.hdfs.protocol.CorruptFileBlocks.files<br/>At CorruptFileBlocks.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N111649');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.protocol.DirectoryListing.getPartialListing() may expose internal representation by returning DirectoryListing.partialListing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N111649" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.DirectoryListing<br/>In method org.apache.hadoop.hdfs.protocol.DirectoryListing.getPartialListing()<br/>Field org.apache.hadoop.hdfs.protocol.DirectoryListing.partialListing<br/>At DirectoryListing.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N111792');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.protocol.HdfsBlocksMetadata.getBlockIds() may expose internal representation by returning HdfsBlocksMetadata.blockIds</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N111792" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.HdfsBlocksMetadata<br/>In method org.apache.hadoop.hdfs.protocol.HdfsBlocksMetadata.getBlockIds()<br/>Field org.apache.hadoop.hdfs.protocol.HdfsBlocksMetadata.blockIds<br/>At HdfsBlocksMetadata.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N112039');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.protocol.HdfsFileStatus.getLocalNameInBytes() may expose internal representation by returning HdfsFileStatus.path</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N112039" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.HdfsFileStatus<br/>In method org.apache.hadoop.hdfs.protocol.HdfsFileStatus.getLocalNameInBytes()<br/>Field org.apache.hadoop.hdfs.protocol.HdfsFileStatus.path<br/>At HdfsFileStatus.java:[line 191]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N112107');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.protocol.HdfsFileStatus.getSymlinkInBytes() may expose internal representation by returning HdfsFileStatus.symlink</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N112107" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.HdfsFileStatus<br/>In method org.apache.hadoop.hdfs.protocol.HdfsFileStatus.getSymlinkInBytes()<br/>Field org.apache.hadoop.hdfs.protocol.HdfsFileStatus.symlink<br/>At HdfsFileStatus.java:[line 234]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N112325');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.protocol.LocatedBlock.getCachedLocations() may expose internal representation by returning LocatedBlock.cachedLocs</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N112325" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.LocatedBlock<br/>In method org.apache.hadoop.hdfs.protocol.LocatedBlock.getCachedLocations()<br/>Field org.apache.hadoop.hdfs.protocol.LocatedBlock.cachedLocs<br/>At LocatedBlock.java:[line 180]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N112393');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.protocol.LocatedBlock.getLocations() may expose internal representation by returning LocatedBlock.locs</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N112393" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.LocatedBlock<br/>In method org.apache.hadoop.hdfs.protocol.LocatedBlock.getLocations()<br/>Field org.apache.hadoop.hdfs.protocol.LocatedBlock.locs<br/>At LocatedBlock.java:[line 122]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N112461');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.protocol.LocatedBlock.getStorageIDs() may expose internal representation by returning LocatedBlock.storageIDs</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N112461" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.LocatedBlock<br/>In method org.apache.hadoop.hdfs.protocol.LocatedBlock.getStorageIDs()<br/>Field org.apache.hadoop.hdfs.protocol.LocatedBlock.storageIDs<br/>At LocatedBlock.java:[line 130]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N112529');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.protocol.LocatedBlock.getStorageTypes() may expose internal representation by returning LocatedBlock.storageTypes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N112529" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.LocatedBlock<br/>In method org.apache.hadoop.hdfs.protocol.LocatedBlock.getStorageTypes()<br/>Field org.apache.hadoop.hdfs.protocol.LocatedBlock.storageTypes<br/>At LocatedBlock.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N112897');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.getParentFullPath() may expose internal representation by returning SnapshottableDirectoryStatus.parentFullPath</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N112897" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus<br/>In method org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.getParentFullPath()<br/>Field org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.parentFullPath<br/>At SnapshottableDirectoryStatus.java:[line 88]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N114274');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.getBytes() may expose internal representation by returning BlockTokenIdentifier.cache</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N114274" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier<br/>In method org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.getBytes()<br/>Field org.apache.hadoop.hdfs.security.token.block.BlockTokenIdentifier.cache<br/>At BlockTokenIdentifier.java:[line 176]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N114492');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys.getAllKeys() may expose internal representation by returning ExportedBlockKeys.allKeys</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N114492" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys<br/>In method org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys.getAllKeys()<br/>Field org.apache.hadoop.hdfs.security.token.block.ExportedBlockKeys.allKeys<br/>At ExportedBlockKeys.java:[line 72]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N123996');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.getClientId() may expose internal representation by returning FSEditLogOp.rpcClientId</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N123996" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp<br/>In method org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.getClientId()<br/>Field org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.rpcClientId<br/>At FSEditLogOp.java:[line 242]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N125059');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.INodeFile.getBlocks() may expose internal representation by returning INodeFile.blocks</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N125059" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.INodeFile<br/>In method org.apache.hadoop.hdfs.server.namenode.INodeFile.getBlocks()<br/>Field org.apache.hadoop.hdfs.server.namenode.INodeFile.blocks<br/>At INodeFile.java:[line 374]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N125202');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.INodeSymlink.getSymlink() may expose internal representation by returning INodeSymlink.symlink</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N125202" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.INodeSymlink<br/>In method org.apache.hadoop.hdfs.server.namenode.INodeSymlink.getSymlink()<br/>Field org.apache.hadoop.hdfs.server.namenode.INodeSymlink.symlink<br/>At INodeSymlink.java:[line 73]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N125270');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields.getFeatures() may expose internal representation by returning INodeWithAdditionalFields.features</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N125270" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields<br/>In method org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields.getFeatures()<br/>Field org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields.features<br/>At INodeWithAdditionalFields.java:[line 345]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N125338');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields.getLocalNameBytes() may expose internal representation by returning INodeWithAdditionalFields.name</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N125338" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields<br/>In method org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields.getLocalNameBytes()<br/>Field org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields.name<br/>At INodeWithAdditionalFields.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N140952');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.server.protocol.BlockCommand.getBlocks() may expose internal representation by returning BlockCommand.blocks</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N140952" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.BlockCommand<br/>In method org.apache.hadoop.hdfs.server.protocol.BlockCommand.getBlocks()<br/>Field org.apache.hadoop.hdfs.server.protocol.BlockCommand.blocks<br/>At BlockCommand.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N141020');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.server.protocol.BlockCommand.getTargetStorageIDs() may expose internal representation by returning BlockCommand.targetStorageIDs</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N141020" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.BlockCommand<br/>In method org.apache.hadoop.hdfs.server.protocol.BlockCommand.getTargetStorageIDs()<br/>Field org.apache.hadoop.hdfs.server.protocol.BlockCommand.targetStorageIDs<br/>At BlockCommand.java:[line 113]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N141088');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.server.protocol.BlockCommand.getTargets() may expose internal representation by returning BlockCommand.targets</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N141088" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.BlockCommand<br/>In method org.apache.hadoop.hdfs.server.protocol.BlockCommand.getTargets()<br/>Field org.apache.hadoop.hdfs.server.protocol.BlockCommand.targets<br/>At BlockCommand.java:[line 109]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N141381');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.server.protocol.BlockIdCommand.getBlockIds() may expose internal representation by returning BlockIdCommand.blockIds</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N141381" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.BlockIdCommand<br/>In method org.apache.hadoop.hdfs.server.protocol.BlockIdCommand.getBlockIds()<br/>Field org.apache.hadoop.hdfs.server.protocol.BlockIdCommand.blockIds<br/>At BlockIdCommand.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N141524');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.getBlocks() may expose internal representation by returning BlocksWithLocations.blocks</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N141524" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations<br/>In method org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.getBlocks()<br/>Field org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.blocks<br/>At BlocksWithLocations.java:[line 90]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N141667');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.server.protocol.HeartbeatResponse.getCommands() may expose internal representation by returning HeartbeatResponse.commands</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N141667" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.HeartbeatResponse<br/>In method org.apache.hadoop.hdfs.server.protocol.HeartbeatResponse.getCommands()<br/>Field org.apache.hadoop.hdfs.server.protocol.HeartbeatResponse.commands<br/>At HeartbeatResponse.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N141810');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.server.protocol.StorageBlockReport.getBlocks() may expose internal representation by returning StorageBlockReport.blocks</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N141810" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.StorageBlockReport<br/>In method org.apache.hadoop.hdfs.server.protocol.StorageBlockReport.getBlocks()<br/>Field org.apache.hadoop.hdfs.server.protocol.StorageBlockReport.blocks<br/>At StorageBlockReport.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N141953');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks.getBlocks() may expose internal representation by returning StorageReceivedDeletedBlocks.blocks</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N141953" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks<br/>In method org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks.getBlocks()<br/>Field org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks.blocks<br/>At StorageReceivedDeletedBlocks.java:[line 39]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N147513');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.io.ArrayWritable.get() may expose internal representation by returning ArrayWritable.values</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N147513" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.io.ArrayWritable<br/>In method org.apache.hadoop.io.ArrayWritable.get()<br/>Field org.apache.hadoop.io.ArrayWritable.values<br/>At ArrayWritable.java:[line 89]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N147731');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.io.BoundedByteArrayOutputStream.getBuffer() may expose internal representation by returning BoundedByteArrayOutputStream.buffer</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N147731" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.io.BoundedByteArrayOutputStream<br/>In method org.apache.hadoop.io.BoundedByteArrayOutputStream.getBuffer()<br/>Field org.apache.hadoop.io.BoundedByteArrayOutputStream.buffer<br/>At BoundedByteArrayOutputStream.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N147799');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.io.BytesWritable.getBytes() may expose internal representation by returning BytesWritable.bytes</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N147799" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.io.BytesWritable<br/>In method org.apache.hadoop.io.BytesWritable.getBytes()<br/>Field org.apache.hadoop.io.BytesWritable.bytes<br/>At BytesWritable.java:[line 86]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N154620');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.io.file.tfile.ByteArray.buffer() may expose internal representation by returning ByteArray.buffer</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N154620" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.ByteArray<br/>In method org.apache.hadoop.io.file.tfile.ByteArray.buffer()<br/>Field org.apache.hadoop.io.file.tfile.ByteArray.buffer<br/>At ByteArray.java:[line 78]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N148318');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.io.MD5Hash.getDigest() may expose internal representation by returning MD5Hash.digest</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N148318" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.io.MD5Hash<br/>In method org.apache.hadoop.io.MD5Hash.getDigest()<br/>Field org.apache.hadoop.io.MD5Hash.digest<br/>At MD5Hash.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N151263');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.io.Text.getBytes() may expose internal representation by returning Text.bytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N151263" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.io.Text<br/>In method org.apache.hadoop.io.Text.getBytes()<br/>Field org.apache.hadoop.io.Text.bytes<br/>At Text.java:[line 119]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N151437');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.io.TwoDArrayWritable.get() may expose internal representation by returning TwoDArrayWritable.values</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N151437" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.io.TwoDArrayWritable<br/>In method org.apache.hadoop.io.TwoDArrayWritable.get()<br/>Field org.apache.hadoop.io.TwoDArrayWritable.values<br/>At TwoDArrayWritable.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N151655');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.io.UTF8.getBytes() may expose internal representation by returning UTF8.bytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N151655" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.io.UTF8<br/>In method org.apache.hadoop.io.UTF8.getBytes()<br/>Field org.apache.hadoop.io.UTF8.bytes<br/>At UTF8.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N161523');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.ipc.ProtocolSignature.getMethods() may expose internal representation by returning ProtocolSignature.methods</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N161523" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.ipc.ProtocolSignature<br/>In method org.apache.hadoop.ipc.ProtocolSignature.getMethods()<br/>Field org.apache.hadoop.ipc.ProtocolSignature.methods<br/>At ProtocolSignature.java:[line 69]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N166817');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapred.IFileInputStream.getChecksum() may expose internal representation by returning IFileInputStream.csum</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N166817" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapred.IFileInputStream<br/>In method org.apache.hadoop.mapred.IFileInputStream.getChecksum()<br/>Field org.apache.hadoop.mapred.IFileInputStream.csum<br/>At IFileInputStream.java:[line 248]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N168789');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate.getMapTaskCompletionEvents() may expose internal representation by returning MapTaskCompletionEventsUpdate.events</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N168789" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate<br/>In method org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate.getMapTaskCompletionEvents()<br/>Field org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate.events<br/>At MapTaskCompletionEventsUpdate.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N189679');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getClockSplits() may expose internal representation by returning MapAttemptFinishedEvent.clockSplits</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N189679" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getClockSplits()<br/>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.clockSplits<br/>At MapAttemptFinishedEvent.java:[line 209]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N189747');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getCpuUsages() may expose internal representation by returning MapAttemptFinishedEvent.cpuUsages</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N189747" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getCpuUsages()<br/>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.cpuUsages<br/>At MapAttemptFinishedEvent.java:[line 212]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N189815');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getPhysMemKbytes() may expose internal representation by returning MapAttemptFinishedEvent.physMemKbytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N189815" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getPhysMemKbytes()<br/>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.physMemKbytes<br/>At MapAttemptFinishedEvent.java:[line 218]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N189883');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getVMemKbytes() may expose internal representation by returning MapAttemptFinishedEvent.vMemKbytes</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N189883" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.getVMemKbytes()<br/>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.vMemKbytes<br/>At MapAttemptFinishedEvent.java:[line 215]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N190026');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getClockSplits() may expose internal representation by returning ReduceAttemptFinishedEvent.clockSplits</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N190026" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getClockSplits()<br/>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.clockSplits<br/>At ReduceAttemptFinishedEvent.java:[line 214]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N190094');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getCpuUsages() may expose internal representation by returning ReduceAttemptFinishedEvent.cpuUsages</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N190094" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getCpuUsages()<br/>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.cpuUsages<br/>At ReduceAttemptFinishedEvent.java:[line 217]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N190162');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getPhysMemKbytes() may expose internal representation by returning ReduceAttemptFinishedEvent.physMemKbytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N190162" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getPhysMemKbytes()<br/>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.physMemKbytes<br/>At ReduceAttemptFinishedEvent.java:[line 223]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N190230');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getVMemKbytes() may expose internal representation by returning ReduceAttemptFinishedEvent.vMemKbytes</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N190230" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.getVMemKbytes()<br/>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.vMemKbytes<br/>At ReduceAttemptFinishedEvent.java:[line 220]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N190373');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getClockSplits() may expose internal representation by returning TaskAttemptUnsuccessfulCompletionEvent.clockSplits</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N190373" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getClockSplits()<br/>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.clockSplits<br/>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 239]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N190441');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getCpuUsages() may expose internal representation by returning TaskAttemptUnsuccessfulCompletionEvent.cpuUsages</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N190441" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getCpuUsages()<br/>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.cpuUsages<br/>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 242]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N190509');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getPhysMemKbytes() may expose internal representation by returning TaskAttemptUnsuccessfulCompletionEvent.physMemKbytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N190509" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getPhysMemKbytes()<br/>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.physMemKbytes<br/>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 248]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N190577');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getVMemKbytes() may expose internal representation by returning TaskAttemptUnsuccessfulCompletionEvent.vMemKbytes</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N190577" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent<br/>In method org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.getVMemKbytes()<br/>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.vMemKbytes<br/>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 245]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N191414');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getLengths() may expose internal representation by returning CombineFileSplit.lengths</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N191414" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit<br/>In method org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getLengths()<br/>Field org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.lengths<br/>At CombineFileSplit.java:[line 108]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N191482');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getLocations() may expose internal representation by returning CombineFileSplit.locations</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N191482" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit<br/>In method org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getLocations()<br/>Field org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.locations<br/>At CombineFileSplit.java:[line 138]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N191550');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getPaths() may expose internal representation by returning CombineFileSplit.paths</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N191550" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit<br/>In method org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getPaths()<br/>Field org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.paths<br/>At CombineFileSplit.java:[line 133]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N191618');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getStartOffsets() may expose internal representation by returning CombineFileSplit.startoffset</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N191618" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.CombineFileSplit<br/>In method org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.getStartOffsets()<br/>Field org.apache.hadoop.mapreduce.lib.input.CombineFileSplit.startoffset<br/>At CombineFileSplit.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N191686');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.input.FileSplit.getLocations() may expose internal representation by returning FileSplit.hosts</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N191686" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.FileSplit<br/>In method org.apache.hadoop.mapreduce.lib.input.FileSplit.getLocations()<br/>Field org.apache.hadoop.mapreduce.lib.input.FileSplit.hosts<br/>At FileSplit.java:[line 98]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N186320');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.QueueAclsInfo.getOperations() may expose internal representation by returning QueueAclsInfo.operations</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N186320" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.QueueAclsInfo<br/>In method org.apache.hadoop.mapreduce.QueueAclsInfo.getOperations()<br/>Field org.apache.hadoop.mapreduce.QueueAclsInfo.operations<br/>At QueueAclsInfo.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N186463');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.QueueInfo.getJobStatuses() may expose internal representation by returning QueueInfo.stats</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N186463" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.QueueInfo<br/>In method org.apache.hadoop.mapreduce.QueueInfo.getJobStatuses()<br/>Field org.apache.hadoop.mapreduce.QueueInfo.stats<br/>At QueueInfo.java:[line 189]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N186814');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.TaskReport.getDiagnostics() may expose internal representation by returning TaskReport.diagnostics</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N186814" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TaskReport<br/>In method org.apache.hadoop.mapreduce.TaskReport.getDiagnostics()<br/>Field org.apache.hadoop.mapreduce.TaskReport.diagnostics<br/>At TaskReport.java:[line 98]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N201868');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.getHosts() may expose internal representation by returning ContainerRequestEvent.hosts</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N201868" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent<br/>In method org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.getHosts()<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.hosts<br/>At ContainerRequestEvent.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N201936');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.getRacks() may expose internal representation by returning ContainerRequestEvent.racks</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N201936" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent<br/>In method org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.getRacks()<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.racks<br/>At ContainerRequestEvent.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N202650');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.security.authorize.ClientHSPolicyProvider.getServices() may expose internal representation by returning ClientHSPolicyProvider.mrHSServices</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N202650" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.security.authorize.ClientHSPolicyProvider<br/>In method org.apache.hadoop.mapreduce.v2.app.security.authorize.ClientHSPolicyProvider.getServices()<br/>Field org.apache.hadoop.mapreduce.v2.app.security.authorize.ClientHSPolicyProvider.mrHSServices<br/>At ClientHSPolicyProvider.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N202718');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.security.authorize.MRAMPolicyProvider.getServices() may expose internal representation by returning MRAMPolicyProvider.mapReduceApplicationMasterServices</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N202718" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.security.authorize.MRAMPolicyProvider<br/>In method org.apache.hadoop.mapreduce.v2.app.security.authorize.MRAMPolicyProvider.getServices()<br/>Field org.apache.hadoop.mapreduce.v2.app.security.authorize.MRAMPolicyProvider.mapReduceApplicationMasterServices<br/>At MRAMPolicyProvider.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N205786');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo.getSource() may expose internal representation by returning ConfEntryInfo.source</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N205786" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo.getSource()<br/>Field org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo.source<br/>At ConfEntryInfo.java:[line 54]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N214642');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.record.Buffer.get() may expose internal representation by returning Buffer.bytes</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N214642" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.record.Buffer<br/>In method org.apache.hadoop.record.Buffer.get()<br/>Field org.apache.hadoop.record.Buffer.bytes<br/>At Buffer.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N219494');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory.getKeyManagers() may expose internal representation by returning FileBasedKeyStoresFactory.keyManagers</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N219494" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory<br/>In method org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory.getKeyManagers()<br/>Field org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory.keyManagers<br/>At FileBasedKeyStoresFactory.java:[line 239]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N219562');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory.getTrustManagers() may expose internal representation by returning FileBasedKeyStoresFactory.trustManagers</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N219562" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory<br/>In method org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory.getTrustManagers()<br/>Field org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory.trustManagers<br/>At FileBasedKeyStoresFactory.java:[line 249]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N220385');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.security.token.delegation.DelegationKey.getEncodedKey() may expose internal representation by returning DelegationKey.keyBytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N220385" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.security.token.delegation.DelegationKey<br/>In method org.apache.hadoop.security.token.delegation.DelegationKey.getEncodedKey()<br/>Field org.apache.hadoop.security.token.delegation.DelegationKey.keyBytes<br/>At DelegationKey.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N221036');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.streaming.PipeMapper.getFieldSeparator() may expose internal representation by returning PipeMapper.mapOutputFieldSeparator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N221036" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.streaming.PipeMapper<br/>In method org.apache.hadoop.streaming.PipeMapper.getFieldSeparator()<br/>Field org.apache.hadoop.streaming.PipeMapper.mapOutputFieldSeparator<br/>At PipeMapper.java:[line 140]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N221104');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.streaming.PipeMapper.getInputSeparator() may expose internal representation by returning PipeMapper.mapInputFieldSeparator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N221104" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.streaming.PipeMapper<br/>In method org.apache.hadoop.streaming.PipeMapper.getInputSeparator()<br/>Field org.apache.hadoop.streaming.PipeMapper.mapInputFieldSeparator<br/>At PipeMapper.java:[line 135]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N221172');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.streaming.PipeReducer.getFieldSeparator() may expose internal representation by returning PipeReducer.reduceOutFieldSeparator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N221172" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.streaming.PipeReducer<br/>In method org.apache.hadoop.streaming.PipeReducer.getFieldSeparator()<br/>Field org.apache.hadoop.streaming.PipeReducer.reduceOutFieldSeparator<br/>At PipeReducer.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N221240');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.streaming.PipeReducer.getInputSeparator() may expose internal representation by returning PipeReducer.reduceInputFieldSeparator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N221240" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.streaming.PipeReducer<br/>In method org.apache.hadoop.streaming.PipeReducer.getInputSeparator()<br/>Field org.apache.hadoop.streaming.PipeReducer.reduceInputFieldSeparator<br/>At PipeReducer.java:[line 139]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N228997');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.tools.rumen.LoggedJob.getMapperTriesToSucceed() may expose internal representation by returning LoggedJob.mapperTriesToSucceed</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N228997" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.tools.rumen.LoggedJob<br/>In method org.apache.hadoop.tools.rumen.LoggedJob.getMapperTriesToSucceed()<br/>Field org.apache.hadoop.tools.rumen.LoggedJob.mapperTriesToSucceed<br/>At LoggedJob.java:[line 340]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N229501');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.tools.rumen.ZombieJob.getInputSplits() may expose internal representation by returning ZombieJob.splits</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N229501" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.tools.rumen.ZombieJob<br/>In method org.apache.hadoop.tools.rumen.ZombieJob.getInputSplits()<br/>Field org.apache.hadoop.tools.rumen.ZombieJob.splits<br/>At ZombieJob.java:[line 226]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N235802');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.util.bloom.Key.getBytes() may expose internal representation by returning Key.bytes</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N235802" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.util.bloom.Key<br/>In method org.apache.hadoop.util.bloom.Key.getBytes()<br/>Field org.apache.hadoop.util.bloom.Key.bytes<br/>At Key.java:[line 116]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N255037');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.security.authorize.NMPolicyProvider.getServices() may expose internal representation by returning NMPolicyProvider.nodeManagerServices</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N255037" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.security.authorize.NMPolicyProvider<br/>In method org.apache.hadoop.yarn.server.nodemanager.security.authorize.NMPolicyProvider.getServices()<br/>Field org.apache.hadoop.yarn.server.nodemanager.security.authorize.NMPolicyProvider.nodeManagerServices<br/>At NMPolicyProvider.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N270616');">
<td>
<span class="priority-2">EI</span>
</td>
<td>org.apache.hadoop.yarn.server.resourcemanager.security.authorize.RMPolicyProvider.getServices() may expose internal representation by returning RMPolicyProvider.resourceManagerServices</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N270616" style="display: none;">
<a href="#EI_EXPOSE_REP">Bug type EI_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.security.authorize.RMPolicyProvider<br/>In method org.apache.hadoop.yarn.server.resourcemanager.security.authorize.RMPolicyProvider.getServices()<br/>Field org.apache.hadoop.yarn.server.resourcemanager.security.authorize.RMPolicyProvider.resourceManagerServices<br/>At RMPolicyProvider.java:[line 83]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N71683');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.fs.BlockLocation(String[], String[], String[], String[], long, long, boolean) may expose internal representation by storing an externally mutable object into BlockLocation.cachedHosts</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N71683" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.fs.BlockLocation<br/>In method new org.apache.hadoop.fs.BlockLocation(String[], String[], String[], String[], long, long, boolean)<br/>Field org.apache.hadoop.fs.BlockLocation.cachedHosts<br/>Local variable named cachedHosts<br/>At BlockLocation.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71758');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.fs.BlockLocation(String[], String[], String[], String[], long, long, boolean) may expose internal representation by storing an externally mutable object into BlockLocation.hosts</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71758" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.fs.BlockLocation<br/>In method new org.apache.hadoop.fs.BlockLocation(String[], String[], String[], String[], long, long, boolean)<br/>Field org.apache.hadoop.fs.BlockLocation.hosts<br/>Local variable named hosts<br/>At BlockLocation.java:[line 106]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N71833');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.fs.BlockLocation(String[], String[], String[], String[], long, long, boolean) may expose internal representation by storing an externally mutable object into BlockLocation.names</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N71833" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.fs.BlockLocation<br/>In method new org.apache.hadoop.fs.BlockLocation(String[], String[], String[], String[], long, long, boolean)<br/>Field org.apache.hadoop.fs.BlockLocation.names<br/>Local variable named names<br/>At BlockLocation.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71908');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.fs.BlockLocation(String[], String[], String[], String[], long, long, boolean) may expose internal representation by storing an externally mutable object into BlockLocation.topologyPaths</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71908" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.fs.BlockLocation<br/>In method new org.apache.hadoop.fs.BlockLocation(String[], String[], String[], String[], long, long, boolean)<br/>Field org.apache.hadoop.fs.BlockLocation.topologyPaths<br/>Local variable named topologyPaths<br/>At BlockLocation.java:[line 116]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N71983');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.fs.BlockLocation.setCachedHosts(String[]) may expose internal representation by storing an externally mutable object into BlockLocation.cachedHosts</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N71983" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.fs.BlockLocation<br/>In method org.apache.hadoop.fs.BlockLocation.setCachedHosts(String[])<br/>Field org.apache.hadoop.fs.BlockLocation.cachedHosts<br/>Local variable named cachedHosts<br/>At BlockLocation.java:[line 212]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N72058');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.fs.BlockLocation.setHosts(String[]) may expose internal representation by storing an externally mutable object into BlockLocation.hosts</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N72058" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.fs.BlockLocation<br/>In method org.apache.hadoop.fs.BlockLocation.setHosts(String[])<br/>Field org.apache.hadoop.fs.BlockLocation.hosts<br/>Local variable named hosts<br/>At BlockLocation.java:[line 201]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72133');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.fs.BlockLocation.setNames(String[]) may expose internal representation by storing an externally mutable object into BlockLocation.names</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72133" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.fs.BlockLocation<br/>In method org.apache.hadoop.fs.BlockLocation.setNames(String[])<br/>Field org.apache.hadoop.fs.BlockLocation.names<br/>Local variable named names<br/>At BlockLocation.java:[line 223]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N72208');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.fs.BlockLocation.setTopologyPaths(String[]) may expose internal representation by storing an externally mutable object into BlockLocation.topologyPaths</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N72208" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.fs.BlockLocation<br/>In method org.apache.hadoop.fs.BlockLocation.setTopologyPaths(String[])<br/>Field org.apache.hadoop.fs.BlockLocation.topologyPaths<br/>Local variable named topologyPaths<br/>At BlockLocation.java:[line 234]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N72351');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.fs.BlockStorageLocation(BlockLocation, VolumeId[]) may expose internal representation by storing an externally mutable object into BlockStorageLocation.volumeIds</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N72351" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.fs.BlockStorageLocation<br/>In method new org.apache.hadoop.fs.BlockStorageLocation(BlockLocation, VolumeId[])<br/>Field org.apache.hadoop.fs.BlockStorageLocation.volumeIds<br/>Local variable named volumeIds<br/>At BlockStorageLocation.java:[line 40]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N74475');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.fs.HdfsVolumeId(byte[]) may expose internal representation by storing an externally mutable object into HdfsVolumeId.id</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N74475" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.fs.HdfsVolumeId<br/>In method new org.apache.hadoop.fs.HdfsVolumeId(byte[])<br/>Field org.apache.hadoop.fs.HdfsVolumeId.id<br/>Local variable named id<br/>At HdfsVolumeId.java:[line 41]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74858');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.fs.LocatedFileStatus(long, boolean, int, long, long, long, FsPermission, String, String, Path, Path, BlockLocation[]) may expose internal representation by storing an externally mutable object into LocatedFileStatus.locations</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74858" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.fs.LocatedFileStatus<br/>In method new org.apache.hadoop.fs.LocatedFileStatus(long, boolean, int, long, long, long, FsPermission, String, String, Path, Path, BlockLocation[])<br/>Field org.apache.hadoop.fs.LocatedFileStatus.locations<br/>Local variable named locations<br/>At LocatedFileStatus.java:[line 76]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N88202');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.fs.s3.INode(INode$FileType, Block[]) may expose internal representation by storing an externally mutable object into INode.blocks</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N88202" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.fs.s3.INode<br/>In method new org.apache.hadoop.fs.s3.INode(INode$FileType, Block[])<br/>Field org.apache.hadoop.fs.s3.INode.blocks<br/>Local variable named blocks<br/>At INode.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N111431');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.protocol.BlockListAsLongs(long[]) may expose internal representation by storing an externally mutable object into BlockListAsLongs.blockList</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N111431" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.BlockListAsLongs<br/>In method new org.apache.hadoop.hdfs.protocol.BlockListAsLongs(long[])<br/>Field org.apache.hadoop.hdfs.protocol.BlockListAsLongs.blockList<br/>Local variable named iBlockList<br/>At BlockListAsLongs.java:[line 129]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N111574');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.protocol.CorruptFileBlocks(String[], String) may expose internal representation by storing an externally mutable object into CorruptFileBlocks.files</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N111574" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.CorruptFileBlocks<br/>In method new org.apache.hadoop.hdfs.protocol.CorruptFileBlocks(String[], String)<br/>Field org.apache.hadoop.hdfs.protocol.CorruptFileBlocks.files<br/>Local variable named files<br/>At CorruptFileBlocks.java:[line 39]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N111717');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.protocol.DirectoryListing(HdfsFileStatus[], int) may expose internal representation by storing an externally mutable object into DirectoryListing.partialListing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N111717" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.DirectoryListing<br/>In method new org.apache.hadoop.hdfs.protocol.DirectoryListing(HdfsFileStatus[], int)<br/>Field org.apache.hadoop.hdfs.protocol.DirectoryListing.partialListing<br/>Local variable named partialListing<br/>At DirectoryListing.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N111860');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.protocol.HdfsBlocksMetadata(String, long[], List, List) may expose internal representation by storing an externally mutable object into HdfsBlocksMetadata.blockIds</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N111860" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.HdfsBlocksMetadata<br/>In method new org.apache.hadoop.hdfs.protocol.HdfsBlocksMetadata(String, long[], List, List)<br/>Field org.apache.hadoop.hdfs.protocol.HdfsBlocksMetadata.blockIds<br/>Local variable named blockIds<br/>At HdfsBlocksMetadata.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N112175');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.protocol.HdfsFileStatus(long, boolean, int, long, long, long, FsPermission, String, String, byte[], byte[], long, int) may expose internal representation by storing an externally mutable object into HdfsFileStatus.path</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N112175" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.HdfsFileStatus<br/>In method new org.apache.hadoop.hdfs.protocol.HdfsFileStatus(long, boolean, int, long, long, long, FsPermission, String, String, byte[], byte[], long, int)<br/>Field org.apache.hadoop.hdfs.protocol.HdfsFileStatus.path<br/>Local variable named path<br/>At HdfsFileStatus.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N112250');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.protocol.HdfsFileStatus(long, boolean, int, long, long, long, FsPermission, String, String, byte[], byte[], long, int) may expose internal representation by storing an externally mutable object into HdfsFileStatus.symlink</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N112250" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.HdfsFileStatus<br/>In method new org.apache.hadoop.hdfs.protocol.HdfsFileStatus(long, boolean, int, long, long, long, FsPermission, String, String, byte[], byte[], long, int)<br/>Field org.apache.hadoop.hdfs.protocol.HdfsFileStatus.symlink<br/>Local variable named symlink<br/>At HdfsFileStatus.java:[line 84]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N112597');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.protocol.LocatedBlock(ExtendedBlock, DatanodeInfo[], String[], StorageType[], long, boolean, DatanodeInfo[]) may expose internal representation by storing an externally mutable object into LocatedBlock.cachedLocs</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N112597" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.LocatedBlock<br/>In method new org.apache.hadoop.hdfs.protocol.LocatedBlock(ExtendedBlock, DatanodeInfo[], String[], StorageType[], long, boolean, DatanodeInfo[])<br/>Field org.apache.hadoop.hdfs.protocol.LocatedBlock.cachedLocs<br/>Local variable named cachedLocs<br/>At LocatedBlock.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N112672');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.protocol.LocatedBlock(ExtendedBlock, DatanodeInfo[], String[], StorageType[], long, boolean, DatanodeInfo[]) may expose internal representation by storing an externally mutable object into LocatedBlock.locs</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N112672" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.LocatedBlock<br/>In method new org.apache.hadoop.hdfs.protocol.LocatedBlock(ExtendedBlock, DatanodeInfo[], String[], StorageType[], long, boolean, DatanodeInfo[])<br/>Field org.apache.hadoop.hdfs.protocol.LocatedBlock.locs<br/>Local variable named locs<br/>At LocatedBlock.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N112747');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.protocol.LocatedBlock(ExtendedBlock, DatanodeInfo[], String[], StorageType[], long, boolean, DatanodeInfo[]) may expose internal representation by storing an externally mutable object into LocatedBlock.storageIDs</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N112747" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.LocatedBlock<br/>In method new org.apache.hadoop.hdfs.protocol.LocatedBlock(ExtendedBlock, DatanodeInfo[], String[], StorageType[], long, boolean, DatanodeInfo[])<br/>Field org.apache.hadoop.hdfs.protocol.LocatedBlock.storageIDs<br/>Local variable named storageIDs<br/>At LocatedBlock.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N112822');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.protocol.LocatedBlock(ExtendedBlock, DatanodeInfo[], String[], StorageType[], long, boolean, DatanodeInfo[]) may expose internal representation by storing an externally mutable object into LocatedBlock.storageTypes</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N112822" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.LocatedBlock<br/>In method new org.apache.hadoop.hdfs.protocol.LocatedBlock(ExtendedBlock, DatanodeInfo[], String[], StorageType[], long, boolean, DatanodeInfo[])<br/>Field org.apache.hadoop.hdfs.protocol.LocatedBlock.storageTypes<br/>Local variable named storageTypes<br/>At LocatedBlock.java:[line 100]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N112965');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus(long, long, FsPermission, String, String, byte[], long, int, int, int, byte[]) may expose internal representation by storing an externally mutable object into SnapshottableDirectoryStatus.parentFullPath</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N112965" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus<br/>In method new org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus(long, long, FsPermission, String, String, byte[], long, int, int, int, byte[])<br/>Field org.apache.hadoop.hdfs.protocol.SnapshottableDirectoryStatus.parentFullPath<br/>Local variable named parentFullPath<br/>At SnapshottableDirectoryStatus.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N114342');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.security.token.block.DataEncryptionKey(int, String, byte[], byte[], long, String) may expose internal representation by storing an externally mutable object into DataEncryptionKey.encryptionKey</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N114342" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.security.token.block.DataEncryptionKey<br/>In method new org.apache.hadoop.hdfs.security.token.block.DataEncryptionKey(int, String, byte[], byte[], long, String)<br/>Field org.apache.hadoop.hdfs.security.token.block.DataEncryptionKey.encryptionKey<br/>Local variable named encryptionKey<br/>At DataEncryptionKey.java:[line 40]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N114417');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.security.token.block.DataEncryptionKey(int, String, byte[], byte[], long, String) may expose internal representation by storing an externally mutable object into DataEncryptionKey.nonce</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N114417" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.security.token.block.DataEncryptionKey<br/>In method new org.apache.hadoop.hdfs.security.token.block.DataEncryptionKey(int, String, byte[], byte[], long, String)<br/>Field org.apache.hadoop.hdfs.security.token.block.DataEncryptionKey.nonce<br/>Local variable named nonce<br/>At DataEncryptionKey.java:[line 39]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N116569');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.hdfs.server.datanode.ReplicaInPipeline.setLastChecksumAndDataLen(long, byte[]) may expose internal representation by storing an externally mutable object into ReplicaInPipeline.lastChecksum</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N116569" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.ReplicaInPipeline<br/>In method org.apache.hadoop.hdfs.server.datanode.ReplicaInPipeline.setLastChecksumAndDataLen(long, byte[])<br/>Field org.apache.hadoop.hdfs.server.datanode.ReplicaInPipeline.lastChecksum<br/>Local variable named lastChecksum<br/>At ReplicaInPipeline.java:[line 129]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N124064');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.setRpcClientId(byte[]) may expose internal representation by storing an externally mutable object into FSEditLogOp.rpcClientId</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N124064" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp<br/>In method org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.setRpcClientId(byte[])<br/>Field org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.rpcClientId<br/>Local variable named clientId<br/>At FSEditLogOp.java:[line 246]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N125127');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.INodeFile.setBlocks(BlockInfo[]) may expose internal representation by storing an externally mutable object into INodeFile.blocks</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N125127" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.INodeFile<br/>In method org.apache.hadoop.hdfs.server.namenode.INodeFile.setBlocks(BlockInfo[])<br/>Field org.apache.hadoop.hdfs.server.namenode.INodeFile.blocks<br/>Local variable named blocks<br/>At INodeFile.java:[line 424]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N125406');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields.setLocalName(byte[]) may expose internal representation by storing an externally mutable object into INodeWithAdditionalFields.name</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N125406" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields<br/>In method org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields.setLocalName(byte[])<br/>Field org.apache.hadoop.hdfs.server.namenode.INodeWithAdditionalFields.name<br/>Local variable named name<br/>At INodeWithAdditionalFields.java:[line 149]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N141156');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.server.protocol.BlockCommand(int, String, Block[], DatanodeInfo[][], String[][]) may expose internal representation by storing an externally mutable object into BlockCommand.blocks</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N141156" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.BlockCommand<br/>In method new org.apache.hadoop.hdfs.server.protocol.BlockCommand(int, String, Block[], DatanodeInfo[][], String[][])<br/>Field org.apache.hadoop.hdfs.server.protocol.BlockCommand.blocks<br/>Local variable named blocks<br/>At BlockCommand.java:[line 95]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N141231');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.server.protocol.BlockCommand(int, String, Block[], DatanodeInfo[][], String[][]) may expose internal representation by storing an externally mutable object into BlockCommand.targetStorageIDs</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N141231" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.BlockCommand<br/>In method new org.apache.hadoop.hdfs.server.protocol.BlockCommand(int, String, Block[], DatanodeInfo[][], String[][])<br/>Field org.apache.hadoop.hdfs.server.protocol.BlockCommand.targetStorageIDs<br/>Local variable named targetStorageIDs<br/>At BlockCommand.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N141306');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.server.protocol.BlockCommand(int, String, Block[], DatanodeInfo[][], String[][]) may expose internal representation by storing an externally mutable object into BlockCommand.targets</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N141306" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.BlockCommand<br/>In method new org.apache.hadoop.hdfs.server.protocol.BlockCommand(int, String, Block[], DatanodeInfo[][], String[][])<br/>Field org.apache.hadoop.hdfs.server.protocol.BlockCommand.targets<br/>Local variable named targets<br/>At BlockCommand.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N141449');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.server.protocol.BlockIdCommand(int, String, long[]) may expose internal representation by storing an externally mutable object into BlockIdCommand.blockIds</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N141449" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.BlockIdCommand<br/>In method new org.apache.hadoop.hdfs.server.protocol.BlockIdCommand(int, String, long[])<br/>Field org.apache.hadoop.hdfs.server.protocol.BlockIdCommand.blockIds<br/>Local variable named blockIds<br/>At BlockIdCommand.java:[line 40]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N141592');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations(BlocksWithLocations$BlockWithLocations[]) may expose internal representation by storing an externally mutable object into BlocksWithLocations.blocks</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N141592" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations<br/>In method new org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations(BlocksWithLocations$BlockWithLocations[])<br/>Field org.apache.hadoop.hdfs.server.protocol.BlocksWithLocations.blocks<br/>Local variable named blocks<br/>At BlocksWithLocations.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N141735');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.server.protocol.HeartbeatResponse(DatanodeCommand[], NNHAStatusHeartbeat, RollingUpgradeStatus) may expose internal representation by storing an externally mutable object into HeartbeatResponse.commands</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N141735" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.HeartbeatResponse<br/>In method new org.apache.hadoop.hdfs.server.protocol.HeartbeatResponse(DatanodeCommand[], NNHAStatusHeartbeat, RollingUpgradeStatus)<br/>Field org.apache.hadoop.hdfs.server.protocol.HeartbeatResponse.commands<br/>Local variable named cmds<br/>At HeartbeatResponse.java:[line 40]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N141878');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.server.protocol.StorageBlockReport(DatanodeStorage, long[]) may expose internal representation by storing an externally mutable object into StorageBlockReport.blocks</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N141878" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.StorageBlockReport<br/>In method new org.apache.hadoop.hdfs.server.protocol.StorageBlockReport(DatanodeStorage, long[])<br/>Field org.apache.hadoop.hdfs.server.protocol.StorageBlockReport.blocks<br/>Local variable named blocks<br/>At StorageBlockReport.java:[line 30]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N142021');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks(String, ReceivedDeletedBlockInfo[]) may expose internal representation by storing an externally mutable object into StorageReceivedDeletedBlocks.blocks</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N142021" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks<br/>In method new org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks(String, ReceivedDeletedBlockInfo[])<br/>Field org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks.blocks<br/>Local variable named blocks<br/>At StorageReceivedDeletedBlocks.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N142096');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks(DatanodeStorage, ReceivedDeletedBlockInfo[]) may expose internal representation by storing an externally mutable object into StorageReceivedDeletedBlocks.blocks</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N142096" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks<br/>In method new org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks(DatanodeStorage, ReceivedDeletedBlockInfo[])<br/>Field org.apache.hadoop.hdfs.server.protocol.StorageReceivedDeletedBlocks.blocks<br/>Local variable named blocks<br/>At StorageReceivedDeletedBlocks.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N142862');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.hdfs.tools.offlineEditsViewer.TeeOutputStream(OutputStream[]) may expose internal representation by storing an externally mutable object into TeeOutputStream.outs</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N142862" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineEditsViewer.TeeOutputStream<br/>In method new org.apache.hadoop.hdfs.tools.offlineEditsViewer.TeeOutputStream(OutputStream[])<br/>Field org.apache.hadoop.hdfs.tools.offlineEditsViewer.TeeOutputStream.outs<br/>Local variable named outs<br/>At TeeOutputStream.java:[line 30]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N147581');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.io.ArrayWritable(Class, Writable[]) may expose internal representation by storing an externally mutable object into ArrayWritable.values</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N147581" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.ArrayWritable<br/>In method new org.apache.hadoop.io.ArrayWritable(Class, Writable[])<br/>Field org.apache.hadoop.io.ArrayWritable.values<br/>Local variable named values<br/>At ArrayWritable.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N147656');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.io.ArrayWritable.set(Writable[]) may expose internal representation by storing an externally mutable object into ArrayWritable.values</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N147656" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.ArrayWritable<br/>In method org.apache.hadoop.io.ArrayWritable.set(Writable[])<br/>Field org.apache.hadoop.io.ArrayWritable.values<br/>Local variable named values<br/>At ArrayWritable.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N147867');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.io.BytesWritable(byte[], int) may expose internal representation by storing an externally mutable object into BytesWritable.bytes</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N147867" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.BytesWritable<br/>In method new org.apache.hadoop.io.BytesWritable(byte[], int)<br/>Field org.apache.hadoop.io.BytesWritable.bytes<br/>Local variable named bytes<br/>At BytesWritable.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N152804');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.io.compress.bzip2.Bzip2Compressor.setInput(byte[], int, int) may expose internal representation by storing an externally mutable object into Bzip2Compressor.userBuf</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N152804" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.bzip2.Bzip2Compressor<br/>In method org.apache.hadoop.io.compress.bzip2.Bzip2Compressor.setInput(byte[], int, int)<br/>Field org.apache.hadoop.io.compress.bzip2.Bzip2Compressor.userBuf<br/>Local variable named b<br/>At Bzip2Compressor.java:[line 135]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N152879');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.io.compress.bzip2.Bzip2Decompressor.setInput(byte[], int, int) may expose internal representation by storing an externally mutable object into Bzip2Decompressor.userBuf</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N152879" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.bzip2.Bzip2Decompressor<br/>In method org.apache.hadoop.io.compress.bzip2.Bzip2Decompressor.setInput(byte[], int, int)<br/>Field org.apache.hadoop.io.compress.bzip2.Bzip2Decompressor.userBuf<br/>Local variable named b<br/>At Bzip2Decompressor.java:[line 80]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N153021');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.io.compress.lz4.Lz4Compressor.setInput(byte[], int, int) may expose internal representation by storing an externally mutable object into Lz4Compressor.userBuf</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N153021" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.lz4.Lz4Compressor<br/>In method org.apache.hadoop.io.compress.lz4.Lz4Compressor.setInput(byte[], int, int)<br/>Field org.apache.hadoop.io.compress.lz4.Lz4Compressor.userBuf<br/>Local variable named b<br/>At Lz4Compressor.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N153096');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.io.compress.lz4.Lz4Decompressor.setInput(byte[], int, int) may expose internal representation by storing an externally mutable object into Lz4Decompressor.userBuf</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N153096" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.lz4.Lz4Decompressor<br/>In method org.apache.hadoop.io.compress.lz4.Lz4Decompressor.setInput(byte[], int, int)<br/>Field org.apache.hadoop.io.compress.lz4.Lz4Decompressor.userBuf<br/>Local variable named b<br/>At Lz4Decompressor.java:[line 110]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N153171');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(byte[], int, int) may expose internal representation by storing an externally mutable object into SnappyCompressor.userBuf</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N153171" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.snappy.SnappyCompressor<br/>In method org.apache.hadoop.io.compress.snappy.SnappyCompressor.setInput(byte[], int, int)<br/>Field org.apache.hadoop.io.compress.snappy.SnappyCompressor.userBuf<br/>Local variable named b<br/>At SnappyCompressor.java:[line 114]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N153246');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.io.compress.snappy.SnappyDecompressor.setInput(byte[], int, int) may expose internal representation by storing an externally mutable object into SnappyDecompressor.userBuf</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N153246" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.snappy.SnappyDecompressor<br/>In method org.apache.hadoop.io.compress.snappy.SnappyDecompressor.setInput(byte[], int, int)<br/>Field org.apache.hadoop.io.compress.snappy.SnappyDecompressor.userBuf<br/>Local variable named b<br/>At SnappyDecompressor.java:[line 114]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N153792');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.setInput(byte[], int, int) may expose internal representation by storing an externally mutable object into BuiltInGzipDecompressor.userBuf</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N153792" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor<br/>In method org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.setInput(byte[], int, int)<br/>Field org.apache.hadoop.io.compress.zlib.BuiltInGzipDecompressor.userBuf<br/>Local variable named b<br/>At BuiltInGzipDecompressor.java:[line 156]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N154068');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.io.compress.zlib.ZlibCompressor.setInput(byte[], int, int) may expose internal representation by storing an externally mutable object into ZlibCompressor.userBuf</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N154068" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.zlib.ZlibCompressor<br/>In method org.apache.hadoop.io.compress.zlib.ZlibCompressor.setInput(byte[], int, int)<br/>Field org.apache.hadoop.io.compress.zlib.ZlibCompressor.userBuf<br/>Local variable named b<br/>At ZlibCompressor.java:[line 271]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N154143');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.io.compress.zlib.ZlibDecompressor.setInput(byte[], int, int) may expose internal representation by storing an externally mutable object into ZlibDecompressor.userBuf</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N154143" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.zlib.ZlibDecompressor<br/>In method org.apache.hadoop.io.compress.zlib.ZlibDecompressor.setInput(byte[], int, int)<br/>Field org.apache.hadoop.io.compress.zlib.ZlibDecompressor.userBuf<br/>Local variable named b<br/>At ZlibDecompressor.java:[line 131]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N154688');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.io.file.tfile.ByteArray(byte[], int, int) may expose internal representation by storing an externally mutable object into ByteArray.buffer</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N154688" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.ByteArray<br/>In method new org.apache.hadoop.io.file.tfile.ByteArray(byte[], int, int)<br/>Field org.apache.hadoop.io.file.tfile.ByteArray.buffer<br/>Local variable named buffer<br/>At ByteArray.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N148386');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.io.MD5Hash(byte[]) may expose internal representation by storing an externally mutable object into MD5Hash.digest</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N148386" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.MD5Hash<br/>In method new org.apache.hadoop.io.MD5Hash(byte[])<br/>Field org.apache.hadoop.io.MD5Hash.digest<br/>Local variable named digest<br/>At MD5Hash.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N151505');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.io.TwoDArrayWritable(Class, Writable[][]) may expose internal representation by storing an externally mutable object into TwoDArrayWritable.values</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N151505" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.TwoDArrayWritable<br/>In method new org.apache.hadoop.io.TwoDArrayWritable(Class, Writable[][])<br/>Field org.apache.hadoop.io.TwoDArrayWritable.values<br/>Local variable named values<br/>At TwoDArrayWritable.java:[line 40]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N151580');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.io.TwoDArrayWritable.set(Writable[][]) may expose internal representation by storing an externally mutable object into TwoDArrayWritable.values</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N151580" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.io.TwoDArrayWritable<br/>In method org.apache.hadoop.io.TwoDArrayWritable.set(Writable[][])<br/>Field org.apache.hadoop.io.TwoDArrayWritable.values<br/>Local variable named values<br/>At TwoDArrayWritable.java:[line 56]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N161591');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.ipc.ProtocolSignature(long, int[]) may expose internal representation by storing an externally mutable object into ProtocolSignature.methods</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N161591" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.ipc.ProtocolSignature<br/>In method new org.apache.hadoop.ipc.ProtocolSignature(long, int[])<br/>Field org.apache.hadoop.ipc.ProtocolSignature.methods<br/>Local variable named methodHashcodes<br/>At ProtocolSignature.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N163834');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.ipc.TestSaslRPC(SaslRpcServer$QualityOfProtection[], SaslRpcServer$QualityOfProtection, String) may expose internal representation by storing an externally mutable object into TestSaslRPC.qop</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N163834" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method new org.apache.hadoop.ipc.TestSaslRPC(SaslRpcServer$QualityOfProtection[], SaslRpcServer$QualityOfProtection, String)<br/>Field org.apache.hadoop.ipc.TestSaslRPC.qop<br/>Local variable named qop<br/>At TestSaslRPC.java:[line 122]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N168014');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapred.LocatedFileStatusFetcher(Configuration, Path[], boolean, PathFilter, boolean) may expose internal representation by storing an externally mutable object into LocatedFileStatusFetcher.inputDirs</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N168014" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapred.LocatedFileStatusFetcher<br/>In method new org.apache.hadoop.mapred.LocatedFileStatusFetcher(Configuration, Path[], boolean, PathFilter, boolean)<br/>Field org.apache.hadoop.mapred.LocatedFileStatusFetcher.inputDirs<br/>Local variable named dirs<br/>At LocatedFileStatusFetcher.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N168857');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate(TaskCompletionEvent[], boolean) may expose internal representation by storing an externally mutable object into MapTaskCompletionEventsUpdate.events</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N168857" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate<br/>In method new org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate(TaskCompletionEvent[], boolean)<br/>Field org.apache.hadoop.mapred.MapTaskCompletionEventsUpdate.events<br/>Local variable named events<br/>At MapTaskCompletionEventsUpdate.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N189951');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent(TaskAttemptID, TaskType, String, long, long, String, int, String, String, Counters, int[][]) may expose internal representation by storing an externally mutable object into MapAttemptFinishedEvent.allSplits</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N189951" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent<br/>In method new org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent(TaskAttemptID, TaskType, String, long, long, String, int, String, String, Counters, int[][])<br/>Field org.apache.hadoop.mapreduce.jobhistory.MapAttemptFinishedEvent.allSplits<br/>Local variable named allSplits<br/>At MapAttemptFinishedEvent.java:[line 90]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N190298');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent(TaskAttemptID, TaskType, String, long, long, long, String, int, String, String, Counters, int[][]) may expose internal representation by storing an externally mutable object into ReduceAttemptFinishedEvent.allSplits</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N190298" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent<br/>In method new org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent(TaskAttemptID, TaskType, String, long, long, long, String, int, String, String, Counters, int[][])<br/>Field org.apache.hadoop.mapreduce.jobhistory.ReduceAttemptFinishedEvent.allSplits<br/>Local variable named allSplits<br/>At ReduceAttemptFinishedEvent.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N190645');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent(TaskAttemptID, TaskType, String, long, String, int, String, String, Counters, int[][]) may expose internal representation by storing an externally mutable object into TaskAttemptUnsuccessfulCompletionEvent.allSplits</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N190645" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent<br/>In method new org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent(TaskAttemptID, TaskType, String, long, String, int, String, String, Counters, int[][])<br/>Field org.apache.hadoop.mapreduce.jobhistory.TaskAttemptUnsuccessfulCompletionEvent.allSplits<br/>Local variable named allSplits<br/>At TaskAttemptUnsuccessfulCompletionEvent.java:[line 89]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N190772');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.lib.db.DBRecordReader(DBInputFormat$DBInputSplit, Class, Configuration, Connection, DBConfiguration, String, String[], String) may expose internal representation by storing an externally mutable object into DBRecordReader.fieldNames</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N190772" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.db.DBRecordReader<br/>In method new org.apache.hadoop.mapreduce.lib.db.DBRecordReader(DBInputFormat$DBInputSplit, Class, Configuration, Connection, DBConfiguration, String, String[], String)<br/>Field org.apache.hadoop.mapreduce.lib.db.DBRecordReader.fieldNames<br/>Local variable named fields<br/>At DBRecordReader.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N191754');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.lib.input.FileSplit(Path, long, long, String[]) may expose internal representation by storing an externally mutable object into FileSplit.hosts</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N191754" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.FileSplit<br/>In method new org.apache.hadoop.mapreduce.lib.input.FileSplit(Path, long, long, String[])<br/>Field org.apache.hadoop.mapreduce.lib.input.FileSplit.hosts<br/>Local variable named hosts<br/>At FileSplit.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N191829');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.lib.input.LineRecordReader(byte[]) may expose internal representation by storing an externally mutable object into LineRecordReader.recordDelimiterBytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N191829" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.LineRecordReader<br/>In method new org.apache.hadoop.mapreduce.lib.input.LineRecordReader(byte[])<br/>Field org.apache.hadoop.mapreduce.lib.input.LineRecordReader.recordDelimiterBytes<br/>Local variable named recordDelimiter<br/>At LineRecordReader.java:[line 71]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N193018');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.lib.join.TupleWritable(Writable[]) may expose internal representation by storing an externally mutable object into TupleWritable.values</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N193018" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.join.TupleWritable<br/>In method new org.apache.hadoop.mapreduce.lib.join.TupleWritable(Writable[])<br/>Field org.apache.hadoop.mapreduce.lib.join.TupleWritable.values<br/>Local variable named vals<br/>At TupleWritable.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N186388');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.QueueAclsInfo(String, String[]) may expose internal representation by storing an externally mutable object into QueueAclsInfo.operations</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N186388" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.QueueAclsInfo<br/>In method new org.apache.hadoop.mapreduce.QueueAclsInfo(String, String[])<br/>Field org.apache.hadoop.mapreduce.QueueAclsInfo.operations<br/>Local variable named operations<br/>At QueueAclsInfo.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N186531');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.QueueInfo(String, String, QueueState, JobStatus[]) may expose internal representation by storing an externally mutable object into QueueInfo.stats</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N186531" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.QueueInfo<br/>In method new org.apache.hadoop.mapreduce.QueueInfo(String, String, QueueState, JobStatus[])<br/>Field org.apache.hadoop.mapreduce.QueueInfo.stats<br/>Local variable named stats<br/>At QueueInfo.java:[line 94]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N195844');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.task.reduce.InMemoryReader(MergeManagerImpl, TaskAttemptID, byte[], int, int, Configuration) may expose internal representation by storing an externally mutable object into InMemoryReader.buffer</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N195844" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.InMemoryReader<br/>In method new org.apache.hadoop.mapreduce.task.reduce.InMemoryReader(MergeManagerImpl, TaskAttemptID, byte[], int, int, Configuration)<br/>Field org.apache.hadoop.mapreduce.task.reduce.InMemoryReader.buffer<br/>Local variable named data<br/>At InMemoryReader.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N186882');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.TaskReport(TaskID, float, String, String[], TIPStatus, long, long, Counters) may expose internal representation by storing an externally mutable object into TaskReport.diagnostics</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N186882" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TaskReport<br/>In method new org.apache.hadoop.mapreduce.TaskReport(TaskID, float, String, String[], TIPStatus, long, long, Counters)<br/>Field org.apache.hadoop.mapreduce.TaskReport.diagnostics<br/>Local variable named diagnostics<br/>At TaskReport.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N202004');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent(TaskAttemptId, Resource, String[], String[]) may expose internal representation by storing an externally mutable object into ContainerRequestEvent.hosts</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N202004" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent<br/>In method new org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent(TaskAttemptId, Resource, String[], String[])<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.hosts<br/>Local variable named hosts<br/>At ContainerRequestEvent.java:[line 37]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N202079');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent(TaskAttemptId, Resource, String[], String[]) may expose internal representation by storing an externally mutable object into ContainerRequestEvent.racks</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N202079" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent<br/>In method new org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent(TaskAttemptId, Resource, String[], String[])<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.ContainerRequestEvent.racks<br/>Local variable named racks<br/>At ContainerRequestEvent.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N205854');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo(String, String, String[]) may expose internal representation by storing an externally mutable object into ConfEntryInfo.source</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N205854" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo<br/>In method new org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo(String, String, String[])<br/>Field org.apache.hadoop.mapreduce.v2.app.webapp.dao.ConfEntryInfo.source<br/>Local variable named source<br/>At ConfEntryInfo.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N212507');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.metrics2.util.SampleQuantiles(Quantile[]) may expose internal representation by storing an externally mutable object into SampleQuantiles.quantiles</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N212507" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.util.SampleQuantiles<br/>In method new org.apache.hadoop.metrics2.util.SampleQuantiles(Quantile[])<br/>Field org.apache.hadoop.metrics2.util.SampleQuantiles.quantiles<br/>Local variable named quantiles<br/>At SampleQuantiles.java:[line 76]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N214710');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.record.Buffer(byte[]) may expose internal representation by storing an externally mutable object into Buffer.bytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N214710" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.record.Buffer<br/>In method new org.apache.hadoop.record.Buffer(byte[])<br/>Field org.apache.hadoop.record.Buffer.bytes<br/>Local variable named bytes<br/>At Buffer.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N214785');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.record.Buffer.set(byte[]) may expose internal representation by storing an externally mutable object into Buffer.bytes</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N214785" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.record.Buffer<br/>In method org.apache.hadoop.record.Buffer.set(byte[])<br/>Field org.apache.hadoop.record.Buffer.bytes<br/>Local variable named bytes<br/>At Buffer.java:[line 78]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N215020');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.record.compiler.generated.ParseException(Token, int[][], String[]) may expose internal representation by storing an externally mutable object into ParseException.expectedTokenSequences</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N215020" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.ParseException<br/>In method new org.apache.hadoop.record.compiler.generated.ParseException(Token, int[][], String[])<br/>Field org.apache.hadoop.record.compiler.generated.ParseException.expectedTokenSequences<br/>Local variable named expectedTokenSequencesVal<br/>At ParseException.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N215095');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.record.compiler.generated.ParseException(Token, int[][], String[]) may expose internal representation by storing an externally mutable object into ParseException.tokenImage</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N215095" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.ParseException<br/>In method new org.apache.hadoop.record.compiler.generated.ParseException(Token, int[][], String[])<br/>Field org.apache.hadoop.record.compiler.generated.ParseException.tokenImage<br/>Local variable named tokenImageVal<br/>At ParseException.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N220453');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.security.token.delegation.DelegationKey(int, long, byte[]) may expose internal representation by storing an externally mutable object into DelegationKey.keyBytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N220453" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.security.token.delegation.DelegationKey<br/>In method new org.apache.hadoop.security.token.delegation.DelegationKey(int, long, byte[])<br/>Field org.apache.hadoop.security.token.delegation.DelegationKey.keyBytes<br/>Local variable named encodedKey<br/>At DelegationKey.java:[line 63]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N235870');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>org.apache.hadoop.util.bloom.Key.set(byte[], double) may expose internal representation by storing an externally mutable object into Key.bytes</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N235870" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.util.bloom.Key<br/>In method org.apache.hadoop.util.bloom.Key.set(byte[], double)<br/>Field org.apache.hadoop.util.bloom.Key.bytes<br/>Local variable named value<br/>At Key.java:[line 110]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N229920');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.util.LineReader(InputStream, int, byte[]) may expose internal representation by storing an externally mutable object into LineReader.recordDelimiterBytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N229920" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.util.LineReader<br/>In method new org.apache.hadoop.util.LineReader(InputStream, int, byte[])<br/>Field org.apache.hadoop.util.LineReader.recordDelimiterBytes<br/>Local variable named recordDelimiterBytes<br/>At LineReader.java:[line 123]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N229995');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.util.LineReader(InputStream, Configuration, byte[]) may expose internal representation by storing an externally mutable object into LineReader.recordDelimiterBytes</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N229995" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.util.LineReader<br/>In method new org.apache.hadoop.util.LineReader(InputStream, Configuration, byte[])<br/>Field org.apache.hadoop.util.LineReader.recordDelimiterBytes<br/>Local variable named recordDelimiterBytes<br/>At LineReader.java:[line 141]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N230070');">
<td>
<span class="priority-2">EI2</span>
</td>
<td>new org.apache.hadoop.util.LineReader(InputStream, byte[]) may expose internal representation by storing an externally mutable object into LineReader.recordDelimiterBytes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N230070" style="display: none;">
<a href="#EI_EXPOSE_REP2">Bug type EI_EXPOSE_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.util.LineReader<br/>In method new org.apache.hadoop.util.LineReader(InputStream, byte[])<br/>Field org.apache.hadoop.util.LineReader.recordDelimiterBytes<br/>Local variable named recordDelimiterBytes<br/>At LineReader.java:[line 106]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70111');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.contrib.bkjournal.TestBookKeeperJournalManager.conf isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70111" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestBookKeeperJournalManager<br/>Field org.apache.hadoop.contrib.bkjournal.TestBookKeeperJournalManager.conf<br/>At TestBookKeeperJournalManager.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N70617');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.examples.dancing.Pentomino.fourRotations should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N70617" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.examples.dancing.Pentomino<br/>Field org.apache.hadoop.examples.dancing.Pentomino.fourRotations<br/>At Pentomino.java:[line 268]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70669');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.examples.dancing.Pentomino.oneRotation should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70669" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.examples.dancing.Pentomino<br/>Field org.apache.hadoop.examples.dancing.Pentomino.oneRotation<br/>At Pentomino.java:[line 258]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N70721');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.examples.dancing.Pentomino.twoRotations should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N70721" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.examples.dancing.Pentomino<br/>Field org.apache.hadoop.examples.dancing.Pentomino.twoRotations<br/>At Pentomino.java:[line 263]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73086');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.FCStatisticsBaseTest.fc should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73086" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.fs.FCStatisticsBaseTest<br/>Field org.apache.hadoop.fs.FCStatisticsBaseTest.fc<br/>At FCStatisticsBaseTest.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N73138');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.FCStatisticsBaseTest.blockSize isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N73138" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.fs.FCStatisticsBaseTest<br/>Field org.apache.hadoop.fs.FCStatisticsBaseTest.blockSize<br/>At FCStatisticsBaseTest.java:[line 41]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73190');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.FCStatisticsBaseTest.numBlocks isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73190" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.fs.FCStatisticsBaseTest<br/>Field org.apache.hadoop.fs.FCStatisticsBaseTest.numBlocks<br/>At FCStatisticsBaseTest.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N73294');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.FileContextCreateMkdirBaseTest.fc isn't final and can't be protected from malicious code </td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N73294" style="display: none;">
<a href="#MS_CANNOT_BE_FINAL">Bug type MS_CANNOT_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.fs.FileContextCreateMkdirBaseTest<br/>Field org.apache.hadoop.fs.FileContextCreateMkdirBaseTest.fc<br/>In FileContextCreateMkdirBaseTest.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N73342');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.FileContextMainOperationsBaseTest.fc isn't final and can't be protected from malicious code </td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N73342" style="display: none;">
<a href="#MS_CANNOT_BE_FINAL">Bug type MS_CANNOT_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.fs.FileContextMainOperationsBaseTest<br/>Field org.apache.hadoop.fs.FileContextMainOperationsBaseTest.fc<br/>In FileContextMainOperationsBaseTest.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N73242');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.FSMainOperationsBaseTest.data should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N73242" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.fs.FSMainOperationsBaseTest<br/>Field org.apache.hadoop.fs.FSMainOperationsBaseTest.data<br/>At FSMainOperationsBaseTest.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N88277');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.s3.INode.FILE_TYPES should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N88277" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.fs.s3.INode<br/>Field org.apache.hadoop.fs.s3.INode.FILE_TYPES<br/>At INode.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75668');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.SymlinkBaseTest.wrapper should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75668" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.fs.SymlinkBaseTest<br/>Field org.apache.hadoop.fs.SymlinkBaseTest.wrapper<br/>In SymlinkBaseTest.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N82863');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.TestListFiles.TEST_DIR isn't final and can't be protected from malicious code </td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N82863" style="display: none;">
<a href="#MS_CANNOT_BE_FINAL">Bug type MS_CANNOT_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestListFiles<br/>Field org.apache.hadoop.fs.TestListFiles.TEST_DIR<br/>In TestListFiles.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N82911');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.TestListFiles.fs isn't final and can't be protected from malicious code </td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N82911" style="display: none;">
<a href="#MS_CANNOT_BE_FINAL">Bug type MS_CANNOT_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestListFiles<br/>Field org.apache.hadoop.fs.TestListFiles.fs<br/>In TestListFiles.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84013');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.TestSymlinkHdfs.cluster should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84013" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestSymlinkHdfs<br/>Field org.apache.hadoop.fs.TestSymlinkHdfs.cluster<br/>In TestSymlinkHdfs.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N84061');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.TestSymlinkHdfs.dfs should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N84061" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestSymlinkHdfs<br/>Field org.apache.hadoop.fs.TestSymlinkHdfs.dfs<br/>In TestSymlinkHdfs.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84109');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.TestSymlinkHdfs.webhdfs should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84109" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestSymlinkHdfs<br/>Field org.apache.hadoop.fs.TestSymlinkHdfs.webhdfs<br/>In TestSymlinkHdfs.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N91661');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.SupportsBlocks should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N91661" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest<br/>Field org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.SupportsBlocks<br/>At ViewFileSystemBaseTest.java:[line 355]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91947');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.fs.viewfs.ViewFsBaseTest.SupportsBlocks should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91947" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.ViewFsBaseTest<br/>Field org.apache.hadoop.fs.viewfs.ViewFsBaseTest.SupportsBlocks<br/>At ViewFsBaseTest.java:[line 342]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92507');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.ha.ClientBaseWithFixes.CONNECTION_TIMEOUT isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92507" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.ha.ClientBaseWithFixes<br/>Field org.apache.hadoop.ha.ClientBaseWithFixes.CONNECTION_TIMEOUT<br/>At ClientBaseWithFixes.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N94178');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.ha.ZKFailoverController.ZKFC_CONF_KEYS is a mutable array</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N94178" style="display: none;">
<a href="#MS_MUTABLE_ARRAY">Bug type MS_MUTABLE_ARRAY (click for details)</a>
<br/>In class org.apache.hadoop.ha.ZKFailoverController<br/>Field org.apache.hadoop.ha.ZKFailoverController.ZKFC_CONF_KEYS<br/>At ZKFailoverController.java:[line 76]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94803');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.DFSClientFaultInjector.instance should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94803" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.DFSClientFaultInjector<br/>Field org.apache.hadoop.hdfs.DFSClientFaultInjector.instance<br/>At DFSClientFaultInjector.java:[line 31]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N96493');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.MiniDFSClusterWithNodeGroup.setNodeGroups(String[]) may expose internal static state by storing a mutable object into a static field org.apache.hadoop.hdfs.MiniDFSClusterWithNodeGroup.NODE_GROUPS</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N96493" style="display: none;">
<a href="#EI_EXPOSE_STATIC_REP2">Bug type EI_EXPOSE_STATIC_REP2 (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.MiniDFSClusterWithNodeGroup<br/>In method org.apache.hadoop.hdfs.MiniDFSClusterWithNodeGroup.setNodeGroups(String[])<br/>Field org.apache.hadoop.hdfs.MiniDFSClusterWithNodeGroup.NODE_GROUPS<br/>Local variable named nodeGroups<br/>At MiniDFSClusterWithNodeGroup.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N96706');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.baseDir should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N96706" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.baseDir<br/>At NNBench.java:[line 100]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N96758');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.blockSize should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N96758" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.blockSize<br/>At NNBench.java:[line 95]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N96810');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.bytesPerChecksum should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N96810" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.bytesPerChecksum<br/>At NNBench.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N96862');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.bytesToWrite should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N96862" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.bytesToWrite<br/>At NNBench.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N96914');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.numberOfFiles should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N96914" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.numberOfFiles<br/>At NNBench.java:[line 98]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N96966');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.numberOfMaps should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N96966" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.numberOfMaps<br/>At NNBench.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97018');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.numberOfReduces should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97018" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.numberOfReduces<br/>At NNBench.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N97070');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.operation should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N97070" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.operation<br/>At NNBench.java:[line 90]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97122');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.readFileAfterOpen should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97122" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.readFileAfterOpen<br/>At NNBench.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N97174');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.replicationFactorPerFile should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N97174" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.replicationFactorPerFile<br/>At NNBench.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97226');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.startTime should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97226" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.startTime<br/>At NNBench.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N97278');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.CONTROL_DIR_NAME isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N97278" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.CONTROL_DIR_NAME<br/>At NNBench.java:[line 84]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97330');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.DATA_DIR_NAME isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97330" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.DATA_DIR_NAME<br/>At NNBench.java:[line 86]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N97382');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.hdfs.NNBench.OUTPUT_DIR_NAME isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N97382" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>Field org.apache.hadoop.hdfs.NNBench.OUTPUT_DIR_NAME<br/>At NNBench.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N111935');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.hdfs.protocol.HdfsConstants.RESERVED_PATH_COMPONENTS is a mutable array</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N111935" style="display: none;">
<a href="#MS_MUTABLE_ARRAY">Bug type MS_MUTABLE_ARRAY (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.HdfsConstants<br/>Field org.apache.hadoop.hdfs.protocol.HdfsConstants.RESERVED_PATH_COMPONENTS<br/>At HdfsConstants.java:[line 136]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N111987');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.protocol.HdfsConstants.DOT_SNAPSHOT_DIR_BYTES is a mutable array</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N111987" style="display: none;">
<a href="#MS_MUTABLE_ARRAY">Bug type MS_MUTABLE_ARRAY (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.HdfsConstants<br/>Field org.apache.hadoop.hdfs.protocol.HdfsConstants.DOT_SNAPSHOT_DIR_BYTES<br/>At HdfsConstants.java:[line 160]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N113996');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.qjournal.server.JournalFaultInjector.instance isn't final and can't be protected from malicious code </td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N113996" style="display: none;">
<a href="#MS_CANNOT_BE_FINAL">Bug type MS_CANNOT_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.qjournal.server.JournalFaultInjector<br/>Field org.apache.hadoop.hdfs.qjournal.server.JournalFaultInjector.instance<br/>At JournalFaultInjector.java:[line 33]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N115285');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.common.Storage.LAYOUT_VERSIONS_203 is a mutable array</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N115285" style="display: none;">
<a href="#MS_MUTABLE_ARRAY">Bug type MS_MUTABLE_ARRAY (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.common.Storage<br/>Field org.apache.hadoop.hdfs.server.common.Storage.LAYOUT_VERSIONS_203<br/>At Storage.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N116078');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.datanode.DataNodeFaultInjector.instance isn't final and can't be protected from malicious code </td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N116078" style="display: none;">
<a href="#MS_CANNOT_BE_FINAL">Bug type MS_CANNOT_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.DataNodeFaultInjector<br/>Field org.apache.hadoop.hdfs.server.datanode.DataNodeFaultInjector.instance<br/>At DataNodeFaultInjector.java:[line 31]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N116130');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.datanode.DataNodeLayoutVersion.FEATURES is a mutable collection</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N116130" style="display: none;">
<a href="#MS_MUTABLE_COLLECTION">Bug type MS_MUTABLE_COLLECTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.DataNodeLayoutVersion<br/>Field org.apache.hadoop.hdfs.server.datanode.DataNodeLayoutVersion.FEATURES<br/>At DataNodeLayoutVersion.java:[line 32]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N122636');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.cluster isn't final and can't be protected from malicious code </td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N122636" style="display: none;">
<a href="#MS_CANNOT_BE_FINAL">Bug type MS_CANNOT_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest<br/>Field org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.cluster<br/>In FSAclBaseTest.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N122684');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.conf isn't final and can't be protected from malicious code </td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N122684" style="display: none;">
<a href="#MS_CANNOT_BE_FINAL">Bug type MS_CANNOT_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest<br/>Field org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.conf<br/>In FSAclBaseTest.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N122943');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.FSDirectory.DOT_INODES should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N122943" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSDirectory<br/>Field org.apache.hadoop.hdfs.server.namenode.FSDirectory.DOT_INODES<br/>At FSDirectory.java:[line 115]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N122995');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.FSDirectory.DOT_RESERVED should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N122995" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSDirectory<br/>Field org.apache.hadoop.hdfs.server.namenode.FSDirectory.DOT_RESERVED<br/>At FSDirectory.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N124139');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.FSImageFormat.renameReservedMap is a mutable collection which should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N124139" style="display: none;">
<a href="#MS_MUTABLE_COLLECTION_PKGPROTECT">Bug type MS_MUTABLE_COLLECTION_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSImageFormat<br/>Field org.apache.hadoop.hdfs.server.namenode.FSImageFormat.renameReservedMap<br/>At FSImageFormat.java:[line 913]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N124733');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.FSImageUtil.MAGIC_HEADER should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N124733" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSImageUtil<br/>Field org.apache.hadoop.hdfs.server.namenode.FSImageUtil.MAGIC_HEADER<br/>At FSImageUtil.java:[line 35]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N125803');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.NameNode.NAMENODE_SPECIFIC_KEYS is a mutable array</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N125803" style="display: none;">
<a href="#MS_MUTABLE_ARRAY">Bug type MS_MUTABLE_ARRAY (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.NameNode<br/>Field org.apache.hadoop.hdfs.server.namenode.NameNode.NAMENODE_SPECIFIC_KEYS<br/>At NameNode.java:[line 165]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N125855');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.NameNode.NAMESERVICE_SPECIFIC_KEYS should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N125855" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.NameNode<br/>Field org.apache.hadoop.hdfs.server.namenode.NameNode.NAMESERVICE_SPECIFIC_KEYS<br/>At NameNode.java:[line 196]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N125907');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.NameNodeLayoutVersion.FEATURES is a mutable collection</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N125907" style="display: none;">
<a href="#MS_MUTABLE_COLLECTION">Bug type MS_MUTABLE_COLLECTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.NameNodeLayoutVersion<br/>Field org.apache.hadoop.hdfs.server.namenode.NameNodeLayoutVersion.FEATURES<br/>At NameNodeLayoutVersion.java:[line 33]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N138191');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot.cluster should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N138191" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot.cluster<br/>In TestDisallowModifyROSnapshot.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N138239');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot.conf should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N138239" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot.conf<br/>In TestDisallowModifyROSnapshot.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N138287');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot.fs should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N138287" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestDisallowModifyROSnapshot.fs<br/>In TestDisallowModifyROSnapshot.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N139005');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.snapshotList is a mutable collection which should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N139005" style="display: none;">
<a href="#MS_MUTABLE_COLLECTION_PKGPROTECT">Bug type MS_MUTABLE_COLLECTION_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.snapshotList<br/>At TestSnapshot.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N139057');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.cluster should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N139057" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.cluster<br/>In TestSnapshot.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N139105');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.fsdir should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N139105" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.fsdir<br/>In TestSnapshot.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N139153');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.fsn should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N139153" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.fsn<br/>In TestSnapshot.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N152752');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.io.compress.bzip2.BZip2Constants.rNums should be moved out of an interface and made package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N152752" style="display: none;">
<a href="#MS_OOI_PKGPROTECT">Bug type MS_OOI_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.bzip2.BZip2Constants<br/>Field org.apache.hadoop.io.compress.bzip2.BZip2Constants.rNums<br/>At BZip2Constants.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N150115');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.io.TestMD5Hash.D00 should be both final and package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N150115" style="display: none;">
<a href="#MS_FINAL_PKGPROTECT">Bug type MS_FINAL_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.io.TestMD5Hash<br/>Field org.apache.hadoop.io.TestMD5Hash.D00<br/>At TestMD5Hash.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N150167');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.io.TestMD5Hash.DFF should be both final and package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N150167" style="display: none;">
<a href="#MS_FINAL_PKGPROTECT">Bug type MS_FINAL_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.io.TestMD5Hash<br/>Field org.apache.hadoop.io.TestMD5Hash.DFF<br/>At TestMD5Hash.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N166432');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapred.BigMapOutput.MAX_KEY isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N166432" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapred.BigMapOutput<br/>Field org.apache.hadoop.mapred.BigMapOutput.MAX_KEY<br/>At BigMapOutput.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N166484');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapred.BigMapOutput.MAX_VALUE isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N166484" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapred.BigMapOutput<br/>Field org.apache.hadoop.mapred.BigMapOutput.MAX_VALUE<br/>At BigMapOutput.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N166536');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapred.BigMapOutput.MIN_KEY isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N166536" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapred.BigMapOutput<br/>Field org.apache.hadoop.mapred.BigMapOutput.MIN_KEY<br/>At BigMapOutput.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N166588');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapred.BigMapOutput.MIN_VALUE isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N166588" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapred.BigMapOutput<br/>Field org.apache.hadoop.mapred.BigMapOutput.MIN_VALUE<br/>At BigMapOutput.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N178940');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapred.gridmix.CommonJobTest.policy should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N178940" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.CommonJobTest<br/>Field org.apache.hadoop.mapred.gridmix.CommonJobTest.policy<br/>At CommonJobTest.java:[line 64]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N169452');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapred.Task.MERGED_OUTPUT_PREFIX isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N169452" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapred.Task<br/>Field org.apache.hadoop.mapred.Task.MERGED_OUTPUT_PREFIX<br/>At Task.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N175967');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.mySuite should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N175967" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestReduceFetchFromPartialMem<br/>Field org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.mySuite<br/>In TestReduceFetchFromPartialMem.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N176015');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.dfsCluster isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N176015" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestReduceFetchFromPartialMem<br/>Field org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.dfsCluster<br/>At TestReduceFetchFromPartialMem.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N176067');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.mrCluster isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N176067" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestReduceFetchFromPartialMem<br/>Field org.apache.hadoop.mapred.TestReduceFetchFromPartialMem.mrCluster<br/>At TestReduceFetchFromPartialMem.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N185709');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.FailJob.FAIL_MAP isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N185709" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.FailJob<br/>Field org.apache.hadoop.mapreduce.FailJob.FAIL_MAP<br/>At FailJob.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N185761');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.FailJob.FAIL_REDUCE isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N185761" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.FailJob<br/>Field org.apache.hadoop.mapreduce.FailJob.FAIL_REDUCE<br/>At FailJob.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N190720');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase.aggregatorDescriptorList should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N190720" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase<br/>Field org.apache.hadoop.mapreduce.lib.aggregate.ValueAggregatorJobBase.aggregatorDescriptorList<br/>At ValueAggregatorJobBase.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N191264');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.emptyText isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N191264" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper<br/>Field org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.emptyText<br/>At FieldSelectionHelper.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N193093');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.MAP_CLASS isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N193093" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper<br/>Field org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.MAP_CLASS<br/>At MultithreadedMapper.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N193145');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.NUM_THREADS isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N193145" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper<br/>Field org.apache.hadoop.mapreduce.lib.map.MultithreadedMapper.NUM_THREADS<br/>At MultithreadedMapper.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N193197');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.map.RegexMapper.GROUP isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N193197" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.map.RegexMapper<br/>Field org.apache.hadoop.mapreduce.lib.map.RegexMapper.GROUP<br/>At RegexMapper.java:[line 39]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N193249');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.map.RegexMapper.PATTERN isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N193249" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.map.RegexMapper<br/>Field org.apache.hadoop.mapreduce.lib.map.RegexMapper.PATTERN<br/>At RegexMapper.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N193301');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat.OUTPUT_FORMAT isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N193301" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat<br/>Field org.apache.hadoop.mapreduce.lib.output.LazyOutputFormat.OUTPUT_FORMAT<br/>At LazyOutputFormat.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N193353');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.KEY_CLASS isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N193353" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat<br/>Field org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.KEY_CLASS<br/>At SequenceFileAsBinaryOutputFormat.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N193405');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.VALUE_CLASS isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N193405" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat<br/>Field org.apache.hadoop.mapreduce.lib.output.SequenceFileAsBinaryOutputFormat.VALUE_CLASS<br/>At SequenceFileAsBinaryOutputFormat.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N193885');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.SEPERATOR isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N193885" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.TextOutputFormat<br/>Field org.apache.hadoop.mapreduce.lib.output.TextOutputFormat.SEPERATOR<br/>At TextOutputFormat.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N193937');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator.COMPARATOR_OPTIONS isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N193937" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator<br/>Field org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedComparator.COMPARATOR_OPTIONS<br/>At KeyFieldBasedComparator.java:[line 56]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N193989');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner.PARTITIONER_OPTIONS isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N193989" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner<br/>Field org.apache.hadoop.mapreduce.lib.partition.KeyFieldBasedPartitioner.PARTITIONER_OPTIONS<br/>At KeyFieldBasedPartitioner.java:[line 56]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N186606');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.SleepJob.MAP_SLEEP_COUNT isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N186606" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.SleepJob<br/>Field org.apache.hadoop.mapreduce.SleepJob.MAP_SLEEP_COUNT<br/>At SleepJob.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N186658');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.SleepJob.MAP_SLEEP_TIME isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N186658" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.SleepJob<br/>Field org.apache.hadoop.mapreduce.SleepJob.MAP_SLEEP_TIME<br/>At SleepJob.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N186710');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.SleepJob.REDUCE_SLEEP_COUNT isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N186710" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.SleepJob<br/>Field org.apache.hadoop.mapreduce.SleepJob.REDUCE_SLEEP_COUNT<br/>At SleepJob.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N186762');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.SleepJob.REDUCE_SLEEP_TIME isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N186762" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.SleepJob<br/>Field org.apache.hadoop.mapreduce.SleepJob.REDUCE_SLEEP_TIME<br/>At SleepJob.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N196705');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.tools.CLI.dataPattern isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N196705" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.tools.CLI<br/>Field org.apache.hadoop.mapreduce.tools.CLI.dataPattern<br/>At CLI.java:[line 598]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N196757');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.tools.CLI.headerPattern isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N196757" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.tools.CLI<br/>Field org.apache.hadoop.mapreduce.tools.CLI.headerPattern<br/>At CLI.java:[line 596]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N199593');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.MRApp.NM_HOST isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N199593" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MRApp<br/>Field org.apache.hadoop.mapreduce.v2.app.MRApp.NM_HOST<br/>At MRApp.java:[line 123]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N199645');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.MRApp.NM_HTTP_PORT isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N199645" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MRApp<br/>Field org.apache.hadoop.mapreduce.v2.app.MRApp.NM_HTTP_PORT<br/>At MRApp.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N199697');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.MRApp.NM_PORT isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N199697" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MRApp<br/>Field org.apache.hadoop.mapreduce.v2.app.MRApp.NM_PORT<br/>At MRApp.java:[line 124]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N209121');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.jobhistory.JHAdminConfig.DEFAULT_MR_HS_HTTP_POLICY isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N209121" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.JHAdminConfig<br/>Field org.apache.hadoop.mapreduce.v2.jobhistory.JHAdminConfig.DEFAULT_MR_HS_HTTP_POLICY<br/>At JHAdminConfig.java:[line 138]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N197742');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities.mrCluster should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N197742" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities<br/>Field org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities.mrCluster<br/>At TestMRAMWithNonNormalizedCapabilities.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N197863');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner.mrCluster should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N197863" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner<br/>Field org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner.mrCluster<br/>In TestMRAppWithCombiner.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N198187');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.TestMRJobs.dfsCluster should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N198187" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobs<br/>Field org.apache.hadoop.mapreduce.v2.TestMRJobs.dfsCluster<br/>In TestMRJobs.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N198235');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.TestMRJobs.mrCluster should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N198235" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobs<br/>Field org.apache.hadoop.mapreduce.v2.TestMRJobs.mrCluster<br/>In TestMRJobs.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N198721');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.TestMROldApiJobs.mrCluster should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N198721" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMROldApiJobs<br/>Field org.apache.hadoop.mapreduce.v2.TestMROldApiJobs.mrCluster<br/>In TestMROldApiJobs.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N199049');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.TestRMNMInfo.mrCluster should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N199049" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestRMNMInfo<br/>Field org.apache.hadoop.mapreduce.v2.TestRMNMInfo.mrCluster<br/>In TestRMNMInfo.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N199422');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution.mrCluster should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N199422" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution<br/>Field org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution.mrCluster<br/>In TestSpeculativeExecution.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N211957');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.metrics2.lib.MutableQuantiles.quantiles is a mutable array</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N211957" style="display: none;">
<a href="#MS_MUTABLE_ARRAY">Bug type MS_MUTABLE_ARRAY (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.lib.MutableQuantiles<br/>Field org.apache.hadoop.metrics2.lib.MutableQuantiles.quantiles<br/>At MutableQuantiles.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N214234');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.nfs.nfs3.Nfs3Status.NFS3ERR_NOTDIR isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N214234" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.nfs.nfs3.Nfs3Status<br/>Field org.apache.hadoop.nfs.nfs3.Nfs3Status.NFS3ERR_NOTDIR<br/>At Nfs3Status.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N215756');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.record.compiler.generated.RccConstants.tokenImage should be moved out of an interface and made package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N215756" style="display: none;">
<a href="#MS_OOI_PKGPROTECT">Bug type MS_OOI_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.RccConstants<br/>Field org.apache.hadoop.record.compiler.generated.RccConstants.tokenImage<br/>At RccConstants.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N215808');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.record.compiler.generated.RccTokenManager.jjnewLexState should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N215808" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.RccTokenManager<br/>Field org.apache.hadoop.record.compiler.generated.RccTokenManager.jjnewLexState<br/>At RccTokenManager.java:[line 622]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N215860');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.record.compiler.generated.RccTokenManager.jjstrLiteralImages should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N215860" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.RccTokenManager<br/>Field org.apache.hadoop.record.compiler.generated.RccTokenManager.jjstrLiteralImages<br/>At RccTokenManager.java:[line 611]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N216889');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.security.LdapGroupsMapping.RECONNECT_RETRY_COUNT isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N216889" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.security.LdapGroupsMapping<br/>Field org.apache.hadoop.security.LdapGroupsMapping.RECONNECT_RETRY_COUNT<br/>At LdapGroupsMapping.java:[line 178]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N223246');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.streaming.TestStreamingStatus.TEST_ROOT_DIR isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N223246" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestStreamingStatus<br/>Field org.apache.hadoop.streaming.TestStreamingStatus.TEST_ROOT_DIR<br/>At TestStreamingStatus.java:[line 56]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N224590');">
<td>
<span class="priority-2">MS</span>
</td>
<td>Public static org.apache.hadoop.test.HadoopUsersConfTestHelper.getHadoopUserGroups(String) may expose internal representation by returning HadoopUsersConfTestHelper.DEFAULT_USERS_GROUP</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N224590" style="display: none;">
<a href="#MS_EXPOSE_REP">Bug type MS_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.test.HadoopUsersConfTestHelper<br/>In method org.apache.hadoop.test.HadoopUsersConfTestHelper.getHadoopUserGroups(String)<br/>Field org.apache.hadoop.test.HadoopUsersConfTestHelper.DEFAULT_USERS_GROUP<br/>At HadoopUsersConfTestHelper.java:[line 150]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N224658');">
<td>
<span class="priority-2">MS</span>
</td>
<td>Public static org.apache.hadoop.test.HadoopUsersConfTestHelper.getHadoopUsers() may expose internal representation by returning HadoopUsersConfTestHelper.DEFAULT_USERS</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N224658" style="display: none;">
<a href="#MS_EXPOSE_REP">Bug type MS_EXPOSE_REP (click for details)</a>
<br/>In class org.apache.hadoop.test.HadoopUsersConfTestHelper<br/>In method org.apache.hadoop.test.HadoopUsersConfTestHelper.getHadoopUsers()<br/>Field org.apache.hadoop.test.HadoopUsersConfTestHelper.DEFAULT_USERS<br/>At HadoopUsersConfTestHelper.java:[line 128]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N228012');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.tools.TestGlobbedCopyListing.expectedValues isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N228012" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestGlobbedCopyListing<br/>Field org.apache.hadoop.tools.TestGlobbedCopyListing.expectedValues<br/>At TestGlobbedCopyListing.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N238068');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.yarn.applications.unmanagedamlauncher.TestUnmanagedAMLauncher.yarnCluster should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N238068" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.unmanagedamlauncher.TestUnmanagedAMLauncher<br/>Field org.apache.hadoop.yarn.applications.unmanagedamlauncher.TestUnmanagedAMLauncher.yarnCluster<br/>At TestUnmanagedAMLauncher.java:[line 56]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N238120');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.yarn.applications.unmanagedamlauncher.TestUnmanagedAMLauncher.conf isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N238120" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.unmanagedamlauncher.TestUnmanagedAMLauncher<br/>Field org.apache.hadoop.yarn.applications.unmanagedamlauncher.TestUnmanagedAMLauncher.conf<br/>At TestUnmanagedAMLauncher.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N243235');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.yarn.conf.YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH is a mutable array</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N243235" style="display: none;">
<a href="#MS_MUTABLE_ARRAY">Bug type MS_MUTABLE_ARRAY (click for details)</a>
<br/>In class org.apache.hadoop.yarn.conf.YarnConfiguration<br/>Field org.apache.hadoop.yarn.conf.YarnConfiguration.DEFAULT_YARN_APPLICATION_CLASSPATH<br/>At YarnConfiguration.java:[line 997]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N243287');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.yarn.conf.YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH is a mutable array</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N243287" style="display: none;">
<a href="#MS_MUTABLE_ARRAY">Bug type MS_MUTABLE_ARRAY (click for details)</a>
<br/>In class org.apache.hadoop.yarn.conf.YarnConfiguration<br/>Field org.apache.hadoop.yarn.conf.YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH<br/>At YarnConfiguration.java:[line 971]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N243874');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.yarn.lib.TestZKClient.CONNECTION_TIMEOUT isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N243874" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.yarn.lib.TestZKClient<br/>Field org.apache.hadoop.yarn.lib.TestZKClient.CONNECTION_TIMEOUT<br/>At TestZKClient.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N248573');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.localDir isn't final and can't be protected from malicious code </td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N248573" style="display: none;">
<a href="#MS_CANNOT_BE_FINAL">Bug type MS_CANNOT_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.localDir<br/>At TestContainerManagerWithLCE.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N248625');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.localFS isn't final and can't be protected from malicious code </td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N248625" style="display: none;">
<a href="#MS_CANNOT_BE_FINAL">Bug type MS_CANNOT_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.localFS<br/>In BaseContainerManagerTest.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N248673');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.localLogDir isn't final and can't be protected from malicious code </td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N248673" style="display: none;">
<a href="#MS_CANNOT_BE_FINAL">Bug type MS_CANNOT_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.localLogDir<br/>In BaseContainerManagerTest.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N248721');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.tmpDir isn't final and can't be protected from malicious code </td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N248721" style="display: none;">
<a href="#MS_CANNOT_BE_FINAL">Bug type MS_CANNOT_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.tmpDir<br/>At TestContainerManagerWithLCE.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N248773');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.remoteLogDir should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N248773" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.remoteLogDir<br/>In BaseContainerManagerTest.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N248821');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.LOG isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N248821" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.LOG<br/>At BaseContainerManagerTest.java:[line 100]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N248873');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.recordFactory isn't final but should be</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N248873" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.recordFactory<br/>At BaseContainerManagerTest.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N247409');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService.testRootDir isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N247409" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService<br/>Field org.apache.hadoop.yarn.server.nodemanager.TestNodeHealthService.testRootDir<br/>At TestNodeHealthService.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N261534');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.EMPTY_CONTAINER_LIST is a mutable collection which should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N261534" style="display: none;">
<a href="#MS_MUTABLE_COLLECTION_PKGPROTECT">Bug type MS_MUTABLE_COLLECTION_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.AbstractYarnScheduler.EMPTY_CONTAINER_LIST<br/>At AbstractYarnScheduler.java:[line 40]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N261586');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics.queueMetrics is a mutable collection</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N261586" style="display: none;">
<a href="#MS_MUTABLE_COLLECTION">Bug type MS_MUTABLE_COLLECTION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.QueueMetrics.queueMetrics<br/>At QueueMetrics.java:[line 140]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N271937');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.yarn.sls.SLSRunner.simulateInfoMap is a mutable collection</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N271937" style="display: none;">
<a href="#MS_MUTABLE_COLLECTION">Bug type MS_MUTABLE_COLLECTION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.SLSRunner<br/>Field org.apache.hadoop.yarn.sls.SLSRunner.simulateInfoMap<br/>At SLSRunner.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N275636');">
<td>
<span class="priority-1">MS</span>
</td>
<td>org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.TEST_ROOT_DIR isn't final but should be</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N275636" style="display: none;">
<a href="#MS_SHOULD_BE_FINAL">Bug type MS_SHOULD_BE_FINAL (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree<br/>Field org.apache.hadoop.yarn.util.TestProcfsBasedProcessTree.TEST_ROOT_DIR<br/>At TestProcfsBasedProcessTree.java:[line 63]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N276602');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.yarn.webapp.view.TestInfoBlock.pw should be package protected</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N276602" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.webapp.view.TestInfoBlock<br/>Field org.apache.hadoop.yarn.webapp.view.TestInfoBlock.pw<br/>In TestInfoBlock.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N276650');">
<td>
<span class="priority-2">MS</span>
</td>
<td>org.apache.hadoop.yarn.webapp.view.TestInfoBlock.sw should be package protected</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N276650" style="display: none;">
<a href="#MS_PKGPROTECT">Bug type MS_PKGPROTECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.webapp.view.TestInfoBlock<br/>Field org.apache.hadoop.yarn.webapp.view.TestInfoBlock.sw<br/>In TestInfoBlock.java</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_MT_CORRECTNESS">Multithreaded correctness Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N212862');">
<td>
<span class="priority-2">AT</span>
</td>
<td>Sequence of calls to java.util.concurrent.ConcurrentHashMap may not be atomic in org.apache.hadoop.net.NetUtils.canonicalizeHost(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N212862" style="display: none;">
<a href="#AT_OPERATION_SEQUENCE_ON_CONCURRENT_ABSTRACTION">Bug type AT_OPERATION_SEQUENCE_ON_CONCURRENT_ABSTRACTION (click for details)</a>
<br/>In class org.apache.hadoop.net.NetUtils<br/>In method org.apache.hadoop.net.NetUtils.canonicalizeHost(String)<br/>Type java.util.concurrent.ConcurrentHashMap<br/>Called method java.util.concurrent.ConcurrentHashMap.put(Object, Object)<br/>At NetUtils.java:[line 290]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N266595');">
<td>
<span class="priority-2">AT</span>
</td>
<td>Sequence of calls to java.util.concurrent.ConcurrentHashMap may not be atomic in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.SchedulingPolicy.getInstance(Class)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N266595" style="display: none;">
<a href="#AT_OPERATION_SEQUENCE_ON_CONCURRENT_ABSTRACTION">Bug type AT_OPERATION_SEQUENCE_ON_CONCURRENT_ABSTRACTION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.SchedulingPolicy<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.SchedulingPolicy.getInstance(Class)<br/>Type java.util.concurrent.ConcurrentHashMap<br/>Called method java.util.concurrent.ConcurrentHashMap.put(Object, Object)<br/>At SchedulingPolicy.java:[line 54]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N270547');">
<td>
<span class="priority-2">DC</span>
</td>
<td>Possible doublecheck on org.apache.hadoop.yarn.server.resourcemanager.security.authorize.RMPolicyProvider.rmPolicyProvider in org.apache.hadoop.yarn.server.resourcemanager.security.authorize.RMPolicyProvider.getInstance()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N270547" style="display: none;">
<a href="#DC_DOUBLECHECK">Bug type DC_DOUBLECHECK (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.security.authorize.RMPolicyProvider<br/>In method org.apache.hadoop.yarn.server.resourcemanager.security.authorize.RMPolicyProvider.getInstance()<br/>On field org.apache.hadoop.yarn.server.resourcemanager.security.authorize.RMPolicyProvider.rmPolicyProvider<br/>At RMPolicyProvider.java:[lines 49-51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N92325');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.ha.ClientBaseWithFixes.allClients; locked 83% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N92325" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.ha.ClientBaseWithFixes<br/>Field org.apache.hadoop.ha.ClientBaseWithFixes.allClients<br/>Synchronized 83% of the time<br/>Unsynchronized access at ClientBaseWithFixes.java:[line 388]<br/>Synchronized access at ClientBaseWithFixes.java:[line 187]<br/>Synchronized access at ClientBaseWithFixes.java:[line 188]<br/>Synchronized access at ClientBaseWithFixes.java:[line 456]<br/>Synchronized access at ClientBaseWithFixes.java:[line 464]<br/>Synchronized access at ClientBaseWithFixes.java:[line 456]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92438');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.ha.ClientBaseWithFixes.allClientsSetup; locked 50% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92438" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.ha.ClientBaseWithFixes<br/>Field org.apache.hadoop.ha.ClientBaseWithFixes.allClientsSetup<br/>Synchronized 50% of the time<br/>Unsynchronized access at ClientBaseWithFixes.java:[line 389]<br/>Synchronized access at ClientBaseWithFixes.java:[line 183]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N94977');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.hdfs.DFSOutputStream.src; locked 77% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N94977" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.DFSOutputStream<br/>Field org.apache.hadoop.hdfs.DFSOutputStream.src<br/>Synchronized 77% of the time<br/>Unsynchronized access at DFSOutputStream.java:[line 1926]<br/>Unsynchronized access at DFSOutputStream.java:[line 1928]<br/>Synchronized access at DFSOutputStream.java:[line 2047]<br/>Synchronized access at DFSOutputStream.java:[line 2116]<br/>Synchronized access at DFSOutputStream.java:[line 2138]<br/>Synchronized access at DFSOutputStream.java:[line 2159]<br/>Synchronized access at DFSOutputStream.java:[line 1731]<br/>Synchronized access at DFSOutputStream.java:[line 1750]<br/>Synchronized access at DFSOutputStream.java:[line 1661]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N96012');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.hdfs.MiniDFSCluster.numDataNodes; locked 64% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N96012" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.MiniDFSCluster<br/>Field org.apache.hadoop.hdfs.MiniDFSCluster.numDataNodes<br/>Synchronized 64% of the time<br/>Unsynchronized access at MiniDFSCluster.java:[line 2454]<br/>Unsynchronized access at MiniDFSCluster.java:[line 1078]<br/>Unsynchronized access at MiniDFSCluster.java:[line 867]<br/>Unsynchronized access at MiniDFSCluster.java:[line 1581]<br/>Unsynchronized access at MiniDFSCluster.java:[line 1581]<br/>Synchronized access at MiniDFSCluster.java:[line 1745]<br/>Synchronized access at MiniDFSCluster.java:[line 1745]<br/>Synchronized access at MiniDFSCluster.java:[line 1338]<br/>Synchronized access at MiniDFSCluster.java:[line 1338]<br/>Synchronized access at MiniDFSCluster.java:[line 2061]<br/>Synchronized access at MiniDFSCluster.java:[line 1798]<br/>Synchronized access at MiniDFSCluster.java:[line 1798]<br/>Synchronized access at MiniDFSClusterWithNodeGroup.java:[line 184]<br/>Synchronized access at MiniDFSClusterWithNodeGroup.java:[line 184]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N115411');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.hdfs.server.datanode.BPOfferService.bpNSInfo; locked 85% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N115411" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.BPOfferService<br/>Field org.apache.hadoop.hdfs.server.datanode.BPOfferService.bpNSInfo<br/>Synchronized 85% of the time<br/>Unsynchronized access at TestDataNodeMultipleRegistrations.java:[line 124]<br/>Unsynchronized access at TestDataNodeMultipleRegistrations.java:[line 126]<br/>Synchronized access at BPOfferService.java:[line 159]<br/>Synchronized access at BPOfferService.java:[line 337]<br/>Synchronized access at BPOfferService.java:[line 339]<br/>Synchronized access at BPOfferService.java:[line 154]<br/>Synchronized access at BPOfferService.java:[line 270]<br/>Synchronized access at BPOfferService.java:[line 289]<br/>Synchronized access at BPOfferService.java:[line 271]<br/>Synchronized access at BPOfferService.java:[line 285]<br/>Synchronized access at BPOfferService.java:[line 285]<br/>Synchronized access at BPOfferService.java:[line 291]<br/>Synchronized access at BPOfferService.java:[line 293]<br/>Synchronized access at BPOfferService.java:[line 140]<br/>Synchronized access at BPOfferService.java:[line 141]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N123047');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.hdfs.server.namenode.FSEditLog.metrics; locked 50% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N123047" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSEditLog<br/>Field org.apache.hadoop.hdfs.server.namenode.FSEditLog.metrics<br/>Synchronized 50% of the time<br/>Unsynchronized access at FSEditLog.java:[line 1079]<br/>Unsynchronized access at FSEditLog.java:[line 637]<br/>Unsynchronized access at FSEditLog.java:[line 638]<br/>Synchronized access at FSEditLog.java:[line 478]<br/>Synchronized access at FSEditLog.java:[line 479]<br/>Synchronized access at FSEditLog.java:[line 583]<br/>Synchronized access at FSEditLog.java:[line 585]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N153321');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.io.compress.snappy.SnappyDecompressor.compressedDirectBufLen; locked 70% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N153321" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.snappy.SnappyDecompressor<br/>Field org.apache.hadoop.io.compress.snappy.SnappyDecompressor.compressedDirectBufLen<br/>Synchronized 70% of the time<br/>Unsynchronized access at SnappyDecompressor.java:[line 300]<br/>Unsynchronized access at SnappyDecompressor.java:[line 313]<br/>Unsynchronized access at SnappyDecompressor.java:[line 313]<br/>Synchronized access at SnappyDecompressor.java:[line 268]<br/>Synchronized access at SnappyDecompressor.java:[line 233]<br/>Synchronized access at SnappyDecompressor.java:[line 131]<br/>Synchronized access at SnappyDecompressor.java:[line 135]<br/>Synchronized access at SnappyDecompressor.java:[line 139]<br/>Synchronized access at SnappyDecompressor.java:[line 140]<br/>Synchronized access at SnappyDecompressor.java:[line 168]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N153478');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.io.compress.snappy.SnappyDecompressor.finished; locked 75% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N153478" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.snappy.SnappyDecompressor<br/>Field org.apache.hadoop.io.compress.snappy.SnappyDecompressor.finished<br/>Synchronized 75% of the time<br/>Unsynchronized access at SnappyDecompressor.java:[line 309]<br/>Synchronized access at SnappyDecompressor.java:[line 267]<br/>Synchronized access at SnappyDecompressor.java:[line 243]<br/>Synchronized access at SnappyDecompressor.java:[line 199]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N153569');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.io.compress.snappy.SnappyDecompressor.uncompressedDirectBuf; locked 75% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N153569" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.snappy.SnappyDecompressor<br/>Field org.apache.hadoop.io.compress.snappy.SnappyDecompressor.uncompressedDirectBuf<br/>Synchronized 75% of the time<br/>Unsynchronized access at SnappyDecompressor.java:[line 297]<br/>Unsynchronized access at SnappyDecompressor.java:[line 301]<br/>Unsynchronized access at SnappyDecompressor.java:[line 312]<br/>Unsynchronized access at SnappyDecompressor.java:[line 312]<br/>Synchronized access at SnappyDecompressor.java:[line 121]<br/>Synchronized access at SnappyDecompressor.java:[line 122]<br/>Synchronized access at SnappyDecompressor.java:[line 269]<br/>Synchronized access at SnappyDecompressor.java:[line 270]<br/>Synchronized access at SnappyDecompressor.java:[line 227]<br/>Synchronized access at SnappyDecompressor.java:[line 235]<br/>Synchronized access at SnappyDecompressor.java:[line 230]<br/>Synchronized access at SnappyDecompressor.java:[line 236]<br/>Synchronized access at SnappyDecompressor.java:[line 240]<br/>Synchronized access at SnappyDecompressor.java:[line 248]<br/>Synchronized access at SnappyDecompressor.java:[line 199]<br/>Synchronized access at SnappyDecompressor.java:[line 163]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N154218');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.io.compress.zlib.ZlibDecompressor.compressedDirectBufLen; locked 66% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N154218" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.zlib.ZlibDecompressor<br/>Field org.apache.hadoop.io.compress.zlib.ZlibDecompressor.compressedDirectBufLen<br/>Synchronized 66% of the time<br/>Unsynchronized access at ZlibDecompressor.java:[line 329]<br/>Unsynchronized access at ZlibDecompressor.java:[line 345]<br/>Unsynchronized access at ZlibDecompressor.java:[line 336]<br/>Unsynchronized access at ZlibDecompressor.java:[line 345]<br/>Synchronized access at ZlibDecompressor.java:[line 280]<br/>Synchronized access at ZlibDecompressor.java:[line 144]<br/>Synchronized access at ZlibDecompressor.java:[line 145]<br/>Synchronized access at ZlibDecompressor.java:[line 146]<br/>Synchronized access at ZlibDecompressor.java:[line 151]<br/>Synchronized access at ZlibDecompressor.java:[line 155]<br/>Synchronized access at ZlibDecompressor.java:[line 156]<br/>Synchronized access at ZlibDecompressor.java:[line 179]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N154397');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.io.compress.zlib.ZlibDecompressor.uncompressedDirectBuf; locked 75% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N154397" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.zlib.ZlibDecompressor<br/>Field org.apache.hadoop.io.compress.zlib.ZlibDecompressor.uncompressedDirectBuf<br/>Synchronized 75% of the time<br/>Unsynchronized access at ZlibDecompressor.java:[line 325]<br/>Unsynchronized access at ZlibDecompressor.java:[line 330]<br/>Unsynchronized access at ZlibDecompressor.java:[line 343]<br/>Unsynchronized access at ZlibDecompressor.java:[line 343]<br/>Synchronized access at ZlibDecompressor.java:[line 138]<br/>Synchronized access at ZlibDecompressor.java:[line 139]<br/>Synchronized access at ZlibDecompressor.java:[line 200]<br/>Synchronized access at ZlibDecompressor.java:[line 281]<br/>Synchronized access at ZlibDecompressor.java:[line 282]<br/>Synchronized access at ZlibDecompressor.java:[line 216]<br/>Synchronized access at ZlibDecompressor.java:[line 224]<br/>Synchronized access at ZlibDecompressor.java:[line 225]<br/>Synchronized access at ZlibDecompressor.java:[line 219]<br/>Synchronized access at ZlibDecompressor.java:[line 229]<br/>Synchronized access at ZlibDecompressor.java:[line 233]<br/>Synchronized access at ZlibDecompressor.java:[line 174]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N165415');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.lib.servlet.ServerWebApp.authority; locked 50% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N165415" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.lib.servlet.ServerWebApp<br/>Field org.apache.hadoop.lib.servlet.ServerWebApp.authority<br/>Synchronized 50% of the time<br/>Unsynchronized access at ServerWebApp.java:[line 227]<br/>Unsynchronized access at ServerWebApp.java:[line 215]<br/>Synchronized access at ServerWebApp.java:[line 211]<br/>Synchronized access at ServerWebApp.java:[line 212]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N166704');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapred.ClusterMapReduceTestCase.dfsCluster; locked 42% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N166704" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapred.ClusterMapReduceTestCase<br/>Field org.apache.hadoop.mapred.ClusterMapReduceTestCase.dfsCluster<br/>Synchronized 42% of the time<br/>Unsynchronized access at ClusterMapReduceTestCase.java:[line 131]<br/>Unsynchronized access at ClusterMapReduceTestCase.java:[line 132]<br/>Unsynchronized access at ClusterMapReduceTestCase.java:[line 133]<br/>Synchronized access at ClusterMapReduceTestCase.java:[line 157]<br/>Synchronized access at ClusterMapReduceTestCase.java:[line 74]<br/>Synchronized access at ClusterMapReduceTestCase.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N200777');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler.commitThreadCancelTimeoutMs; locked 50% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N200777" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler<br/>Field org.apache.hadoop.mapreduce.v2.app.commit.CommitterEventHandler.commitThreadCancelTimeoutMs<br/>Synchronized 50% of the time<br/>Unsynchronized access at CommitterEventHandler.java:[line 92]<br/>Synchronized access at CommitterEventHandler.java:[line 189]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N201273');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.local.LocalContainerAllocator.retryInterval; locked 75% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N201273" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.local.LocalContainerAllocator<br/>Field org.apache.hadoop.mapreduce.v2.app.local.LocalContainerAllocator.retryInterval<br/>Synchronized 75% of the time<br/>Unsynchronized access at LocalContainerAllocator.java:[line 85]<br/>Synchronized access at LocalContainerAllocator.java:[line 108]<br/>Synchronized access at LocalContainerAllocator.java:[line 109]<br/>Synchronized access at LocalContainerAllocator.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N201364');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.local.LocalContainerAllocator.retrystartTime; locked 66% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N201364" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.local.LocalContainerAllocator<br/>Field org.apache.hadoop.mapreduce.v2.app.local.LocalContainerAllocator.retrystartTime<br/>Synchronized 66% of the time<br/>Unsynchronized access at LocalContainerAllocator.java:[line 90]<br/>Synchronized access at LocalContainerAllocator.java:[line 108]<br/>Synchronized access at LocalContainerAllocator.java:[line 104]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N202154');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.mapResourceReqt; locked 91% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N202154" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.mapResourceReqt<br/>Synchronized 91% of the time<br/>Unsynchronized access at RMContainerAllocator.java:[line 694]<br/>Synchronized access at RMContainerAllocator.java:[line 394]<br/>Synchronized access at RMContainerAllocator.java:[line 405]<br/>Synchronized access at RMContainerAllocator.java:[line 408]<br/>Synchronized access at RMContainerAllocator.java:[line 235]<br/>Synchronized access at RMContainerAllocator.java:[line 296]<br/>Synchronized access at RMContainerAllocator.java:[line 313]<br/>Synchronized access at RMContainerAllocator.java:[line 297]<br/>Synchronized access at RMContainerAllocator.java:[line 298]<br/>Synchronized access at RMContainerAllocator.java:[line 301]<br/>Synchronized access at RMContainerAllocator.java:[line 302]<br/>Synchronized access at RMContainerAllocator.java:[line 303]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N202333');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.maxReduceRampupLimit; locked 50% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N202333" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.maxReduceRampupLimit<br/>Synchronized 50% of the time<br/>Unsynchronized access at RMContainerAllocator.java:[line 167]<br/>Synchronized access at RMContainerAllocator.java:[line 235]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N202402');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.reduceResourceReqt; locked 91% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N202402" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.reduceResourceReqt<br/>Synchronized 91% of the time<br/>Unsynchronized access at RMContainerAllocator.java:[line 694]<br/>Synchronized access at RMContainerAllocator.java:[line 384]<br/>Synchronized access at RMContainerAllocator.java:[line 391]<br/>Synchronized access at RMContainerAllocator.java:[line 411]<br/>Synchronized access at RMContainerAllocator.java:[line 235]<br/>Synchronized access at RMContainerAllocator.java:[line 316]<br/>Synchronized access at RMContainerAllocator.java:[line 335]<br/>Synchronized access at RMContainerAllocator.java:[line 317]<br/>Synchronized access at RMContainerAllocator.java:[line 318]<br/>Synchronized access at RMContainerAllocator.java:[line 322]<br/>Synchronized access at RMContainerAllocator.java:[line 323]<br/>Synchronized access at RMContainerAllocator.java:[line 324]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N202581');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.reduceSlowStart; locked 50% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N202581" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator<br/>Field org.apache.hadoop.mapreduce.v2.app.rm.RMContainerAllocator.reduceSlowStart<br/>Synchronized 50% of the time<br/>Unsynchronized access at RMContainerAllocator.java:[line 164]<br/>Synchronized access at RMContainerAllocator.java:[line 235]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N220250');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.delegationTokenSequenceNumber; locked 62% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N220250" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager<br/>Field org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.delegationTokenSequenceNumber<br/>Synchronized 62% of the time<br/>Unsynchronized access at RMDelegationTokenSecretManager.java:[line 189]<br/>Unsynchronized access at RMDelegationTokenSecretManager.java:[line 173]<br/>Unsynchronized access at RMDelegationTokenSecretManager.java:[line 140]<br/>Synchronized access at AbstractDelegationTokenSecretManager.java:[line 205]<br/>Synchronized access at AbstractDelegationTokenSecretManager.java:[line 206]<br/>Synchronized access at AbstractDelegationTokenSecretManager.java:[line 130]<br/>Synchronized access at AbstractDelegationTokenSecretManager.java:[line 279]<br/>Synchronized access at AbstractDelegationTokenSecretManager.java:[line 279]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N259880');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.fs; locked 95% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N259880" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore<br/>Field org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore.fs<br/>Synchronized 95% of the time<br/>Unsynchronized access at TestFSRMStateStore.java:[line 152]<br/>Synchronized access at FileSystemRMStateStore.java:[line 162]<br/>Synchronized access at FileSystemRMStateStore.java:[line 164]<br/>Synchronized access at FileSystemRMStateStore.java:[line 550]<br/>Synchronized access at FileSystemRMStateStore.java:[line 114]<br/>Synchronized access at FileSystemRMStateStore.java:[line 501]<br/>Synchronized access at FileSystemRMStateStore.java:[line 251]<br/>Synchronized access at FileSystemRMStateStore.java:[line 280]<br/>Synchronized access at FileSystemRMStateStore.java:[line 495]<br/>Synchronized access at FileSystemRMStateStore.java:[line 261]<br/>Synchronized access at FileSystemRMStateStore.java:[line 107]<br/>Synchronized access at FileSystemRMStateStore.java:[line 108]<br/>Synchronized access at FileSystemRMStateStore.java:[line 109]<br/>Synchronized access at FileSystemRMStateStore.java:[line 125]<br/>Synchronized access at FileSystemRMStateStore.java:[line 126]<br/>Synchronized access at FileSystemRMStateStore.java:[line 140]<br/>Synchronized access at FileSystemRMStateStore.java:[line 554]<br/>Synchronized access at FileSystemRMStateStore.java:[line 320]<br/>Synchronized access at FileSystemRMStateStore.java:[line 539]<br/>Synchronized access at FileSystemRMStateStore.java:[line 544]<br/>Synchronized access at FileSystemRMStateStore.java:[line 520]<br/>Synchronized access at FileSystemRMStateStore.java:[line 523]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N260748');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.zkClient; locked 91% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N260748" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<br/>Field org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.zkClient<br/>Synchronized 91% of the time<br/>Unsynchronized access at TestZKRMStateStoreZKClientConnections.java:[line 249]<br/>Synchronized access at ZKRMStateStore.java:[line 328]<br/>Synchronized access at ZKRMStateStore.java:[line 330]<br/>Synchronized access at ZKRMStateStore.java:[line 334]<br/>Synchronized access at ZKRMStateStore.java:[line 1028]<br/>Synchronized access at ZKRMStateStore.java:[line 1010]<br/>Synchronized access at ZKRMStateStore.java:[line 1013]<br/>Synchronized access at ZKRMStateStore.java:[line 1018]<br/>Synchronized access at ZKRMStateStore.java:[line 1015]<br/>Synchronized access at ZKRMStateStore.java:[line 813]<br/>Synchronized access at ZKRMStateStore.java:[line 814]<br/>Synchronized access at ZKRMStateStore.java:[line 805]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N260927');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.znodeWorkingPath; locked 75% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N260927" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<br/>Field org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore.znodeWorkingPath<br/>Synchronized 75% of the time<br/>Unsynchronized access at TestZKRMStateStoreZKClientConnections.java:[line 249]<br/>Synchronized access at ZKRMStateStore.java:[line 251]<br/>Synchronized access at ZKRMStateStore.java:[line 196]<br/>Synchronized access at ZKRMStateStore.java:[line 209]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N262516');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.scheduleAsynchronously; locked 83% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N262516" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.scheduleAsynchronously<br/>Synchronized 83% of the time<br/>Unsynchronized access at CapacityScheduler.java:[line 877]<br/>Synchronized access at CapacityScheduler.java:[line 953]<br/>Synchronized access at CapacityScheduler.java:[line 939]<br/>Synchronized access at CapacityScheduler.java:[line 290]<br/>Synchronized access at CapacityScheduler.java:[line 294]<br/>Synchronized access at CapacityScheduler.java:[line 300]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N262629');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.absoluteCapacity; locked 83% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N262629" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.absoluteCapacity<br/>Synchronized 83% of the time<br/>Unsynchronized access at LeafQueue.java:[line 601]<br/>Synchronized access at LeafQueue.java:[line 1501]<br/>Synchronized access at LeafQueue.java:[line 458]<br/>Synchronized access at LeafQueue.java:[line 234]<br/>Synchronized access at LeafQueue.java:[line 332]<br/>Synchronized access at LeafQueue.java:[line 557]<br/>Synchronized access at LeafQueue.java:[line 1017]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N262753');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.absoluteMaxCapacity; locked 87% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N262753" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.absoluteMaxCapacity<br/>Synchronized 87% of the time<br/>Unsynchronized access at LeafQueue.java:[line 601]<br/>Synchronized access at LeafQueue.java:[line 948]<br/>Synchronized access at LeafQueue.java:[line 950]<br/>Synchronized access at LeafQueue.java:[line 1496]<br/>Synchronized access at LeafQueue.java:[line 461]<br/>Synchronized access at LeafQueue.java:[line 342]<br/>Synchronized access at LeafQueue.java:[line 237]<br/>Synchronized access at LeafQueue.java:[line 978]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N262888');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.acls; locked 66% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N262888" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.acls<br/>Synchronized 66% of the time<br/>Unsynchronized access at LeafQueue.java:[line 601]<br/>Synchronized access at LeafQueue.java:[line 251]<br/>Synchronized access at LeafQueue.java:[line 624]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N262968');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.capacity; locked 80% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N262968" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.capacity<br/>Synchronized 80% of the time<br/>Unsynchronized access at LeafQueue.java:[line 601]<br/>Synchronized access at LeafQueue.java:[line 327]<br/>Synchronized access at LeafQueue.java:[line 454]<br/>Synchronized access at LeafQueue.java:[line 233]<br/>Synchronized access at LeafQueue.java:[line 253]<br/>Synchronized access at LeafQueue.java:[line 557]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N263081');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.maxAMResourcePerQueuePercent; locked 60% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N263081" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.maxAMResourcePerQueuePercent<br/>Synchronized 60% of the time<br/>Unsynchronized access at LeafQueue.java:[line 601]<br/>Unsynchronized access at LeafQueue.java:[line 399]<br/>Synchronized access at LeafQueue.java:[line 1496]<br/>Synchronized access at LeafQueue.java:[line 1501]<br/>Synchronized access at LeafQueue.java:[line 243]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N263183');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.maximumCapacity; locked 80% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N263183" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.maximumCapacity<br/>Synchronized 80% of the time<br/>Unsynchronized access at LeafQueue.java:[line 601]<br/>Synchronized access at LeafQueue.java:[line 460]<br/>Synchronized access at LeafQueue.java:[line 236]<br/>Synchronized access at LeafQueue.java:[line 254]<br/>Synchronized access at LeafQueue.java:[line 337]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N263285');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.state; locked 75% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N263285" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.state<br/>Synchronized 75% of the time<br/>Unsynchronized access at LeafQueue.java:[line 601]<br/>Synchronized access at LeafQueue.java:[line 514]<br/>Synchronized access at LeafQueue.java:[line 249]<br/>Synchronized access at LeafQueue.java:[line 255]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N263376');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.userLimit; locked 85% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N263376" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.userLimit<br/>Synchronized 85% of the time<br/>Unsynchronized access at LeafQueue.java:[line 601]<br/>Synchronized access at LeafQueue.java:[line 519]<br/>Synchronized access at LeafQueue.java:[line 1506]<br/>Synchronized access at LeafQueue.java:[line 239]<br/>Synchronized access at LeafQueue.java:[line 1039]<br/>Synchronized access at LeafQueue.java:[line 1060]<br/>Synchronized access at LeafQueue.java:[line 469]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N263500');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.userLimitFactor; locked 85% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N263500" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.userLimitFactor<br/>Synchronized 85% of the time<br/>Unsynchronized access at LeafQueue.java:[line 601]<br/>Synchronized access at LeafQueue.java:[line 1506]<br/>Synchronized access at LeafQueue.java:[line 240]<br/>Synchronized access at LeafQueue.java:[line 477]<br/>Synchronized access at LeafQueue.java:[line 1039]<br/>Synchronized access at LeafQueue.java:[line 1060]<br/>Synchronized access at LeafQueue.java:[line 524]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N263758');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.absoluteCapacity; locked 75% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N263758" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.absoluteCapacity<br/>Synchronized 75% of the time<br/>Unsynchronized access at ParentQueue.java:[line 379]<br/>Synchronized access at ParentQueue.java:[line 545]<br/>Synchronized access at ParentQueue.java:[line 252]<br/>Synchronized access at ParentQueue.java:[line 355]<br/>Synchronized access at ParentQueue.java:[line 169]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N263860');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.absoluteMaxCapacity; locked 66% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N263860" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.absoluteMaxCapacity<br/>Synchronized 66% of the time<br/>Unsynchronized access at ParentQueue.java:[line 257]<br/>Unsynchronized access at ParentQueue.java:[line 379]<br/>Synchronized access at ParentQueue.java:[line 624]<br/>Synchronized access at ParentQueue.java:[line 625]<br/>Synchronized access at ParentQueue.java:[line 548]<br/>Synchronized access at ParentQueue.java:[line 172]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N263973');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.acls; locked 66% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N263973" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.acls<br/>Synchronized 66% of the time<br/>Unsynchronized access at ParentQueue.java:[line 379]<br/>Synchronized access at ParentQueue.java:[line 176]<br/>Synchronized access at ParentQueue.java:[line 432]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N264053');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.capacity; locked 57% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N264053" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.capacity<br/>Synchronized 57% of the time<br/>Unsynchronized access at ParentQueue.java:[line 210]<br/>Unsynchronized access at ParentQueue.java:[line 210]<br/>Unsynchronized access at ParentQueue.java:[line 379]<br/>Synchronized access at ParentQueue.java:[line 247]<br/>Synchronized access at ParentQueue.java:[line 543]<br/>Synchronized access at ParentQueue.java:[line 355]<br/>Synchronized access at ParentQueue.java:[line 168]<br/>Synchronized access at ParentQueue.java:[line 178]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N264188');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.maximumCapacity; locked 60% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N264188" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.maximumCapacity<br/>Synchronized 60% of the time<br/>Unsynchronized access at ParentQueue.java:[line 379]<br/>Unsynchronized access at ParentQueue.java:[line 267]<br/>Synchronized access at ParentQueue.java:[line 547]<br/>Synchronized access at ParentQueue.java:[line 171]<br/>Synchronized access at ParentQueue.java:[line 179]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N264290');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.state; locked 80% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N264290" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.state<br/>Synchronized 80% of the time<br/>Unsynchronized access at ParentQueue.java:[line 379]<br/>Synchronized access at ParentQueue.java:[line 301]<br/>Synchronized access at ParentQueue.java:[line 455]<br/>Synchronized access at ParentQueue.java:[line 174]<br/>Synchronized access at ParentQueue.java:[line 180]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N266107');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.allocConf; locked 55% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N266107" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.allocConf<br/>Synchronized 55% of the time<br/>Unsynchronized access at FairScheduler.java:[line 1352]<br/>Unsynchronized access at TestFSLeafQueue.java:[line 54]<br/>Unsynchronized access at TestFSLeafQueue.java:[line 55]<br/>Unsynchronized access at TestFSLeafQueue.java:[line 56]<br/>Synchronized access at FairScheduler.java:[line 494]<br/>Synchronized access at FairScheduler.java:[line 495]<br/>Synchronized access at FairScheduler.java:[line 1426]<br/>Synchronized access at FairScheduler.java:[line 1263]<br/>Synchronized access at FairScheduler.java:[line 690]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N266253');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.assignMultiple; locked 66% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N266253" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.assignMultiple<br/>Synchronized 66% of the time<br/>Unsynchronized access at TestFairScheduler.java:[line 319]<br/>Synchronized access at FairScheduler.java:[line 1081]<br/>Synchronized access at FairScheduler.java:[line 1246]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N266333');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingEnabled; locked 60% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N266333" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingEnabled<br/>Synchronized 60% of the time<br/>Unsynchronized access at FairScheduler.java:[line 572]<br/>Unsynchronized access at TestFairScheduler.java:[line 324]<br/>Synchronized access at FairScheduler.java:[line 990]<br/>Synchronized access at FairScheduler.java:[line 1238]<br/>Synchronized access at FairScheduler.java:[line 1275]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N266435');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingSleepMs; locked 66% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N266435" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.continuousSchedulingSleepMs<br/>Synchronized 66% of the time<br/>Unsynchronized access at TestFairScheduler.java:[line 326]<br/>Synchronized access at FairScheduler.java:[line 576]<br/>Synchronized access at FairScheduler.java:[line 1239]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N266515');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.sizeBasedWeight; locked 66% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N266515" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler.sizeBasedWeight<br/>Synchronized 66% of the time<br/>Unsynchronized access at TestFairScheduler.java:[line 321]<br/>Synchronized access at FairScheduler.java:[line 529]<br/>Synchronized access at FairScheduler.java:[line 1248]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N270106');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.minimumAllocation; locked 60% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N270106" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.minimumAllocation<br/>Synchronized 60% of the time<br/>Unsynchronized access at FifoScheduler.java:[line 222]<br/>Unsynchronized access at FifoScheduler.java:[line 277]<br/>Synchronized access at FifoScheduler.java:[line 717]<br/>Synchronized access at FifoScheduler.java:[line 494]<br/>Synchronized access at FifoScheduler.java:[line 246]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N261638');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.liveContainers; locked 92% of time</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N261638" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.liveContainers<br/>Synchronized 92% of the time<br/>Unsynchronized access at TestSchedulerApplicationAttempt.java:[line 77]<br/>Synchronized access at SchedulerApplicationAttempt.java:[line 487]<br/>Synchronized access at SchedulerApplicationAttempt.java:[line 458]<br/>Synchronized access at SchedulerApplicationAttempt.java:[line 172]<br/>Synchronized access at SchedulerApplicationAttempt.java:[line 471]<br/>Synchronized access at SchedulerApplicationAttempt.java:[line 116]<br/>Synchronized access at SchedulerApplicationAttempt.java:[line 451]<br/>Synchronized access at FSSchedulerApp.java:[line 279]<br/>Synchronized access at FSSchedulerApp.java:[line 94]<br/>Synchronized access at FiCaSchedulerApp.java:[line 129]<br/>Synchronized access at FiCaSchedulerApp.java:[line 77]<br/>Synchronized access at FiCaSchedulerApp.java:[line 232]<br/>Synchronized access at FiCaSchedulerApp.java:[line 209]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N271155');">
<td>
<span class="priority-2">IS</span>
</td>
<td>Inconsistent synchronization of org.apache.hadoop.yarn.server.security.BaseNMTokenSecretManager.currentMasterKey; locked 52% of time</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N271155" style="display: none;">
<a href="#IS2_INCONSISTENT_SYNC">Bug type IS2_INCONSISTENT_SYNC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.security.BaseNMTokenSecretManager<br/>Field org.apache.hadoop.yarn.server.security.BaseNMTokenSecretManager.currentMasterKey<br/>Synchronized 52% of the time<br/>Unsynchronized access at NMTokenSecretManagerInRM.java:[line 133]<br/>Unsynchronized access at NMTokenSecretManagerInRM.java:[line 96]<br/>Unsynchronized access at NMTokenSecretManagerInRM.java:[line 97]<br/>Unsynchronized access at BaseNMTokenSecretManager.java:[line 94]<br/>Unsynchronized access at BaseNMTokenSecretManager.java:[line 128]<br/>Unsynchronized access at BaseNMTokenSecretManager.java:[line 66]<br/>Unsynchronized access at BaseNMTokenSecretManager.java:[line 82]<br/>Synchronized access at NMTokenSecretManagerInNM.java:[line 165]<br/>Synchronized access at NMTokenSecretManagerInNM.java:[line 167]<br/>Synchronized access at NMTokenSecretManagerInNM.java:[line 104]<br/>Synchronized access at NMTokenSecretManagerInNM.java:[line 105]<br/>Synchronized access at NMTokenSecretManagerInNM.java:[line 67]<br/>Synchronized access at NMTokenSecretManagerInNM.java:[line 72]<br/>Synchronized access at NMTokenSecretManagerInNM.java:[line 74]<br/>Synchronized access at NMTokenSecretManagerInNM.java:[line 68]<br/>Synchronized access at NMTokenSecretManagerInNM.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N220528');">
<td>
<span class="priority-2">JLM</span>
</td>
<td>Synchronization performed on java.util.concurrent.atomic.AtomicBoolean in org.apache.hadoop.service.AbstractService.stop()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N220528" style="display: none;">
<a href="#JLM_JSR166_UTILCONCURRENT_MONITORENTER">Bug type JLM_JSR166_UTILCONCURRENT_MONITORENTER (click for details)</a>
<br/>In class org.apache.hadoop.service.AbstractService<br/>In method org.apache.hadoop.service.AbstractService.stop()<br/>Type java.util.concurrent.atomic.AtomicBoolean<br/>Value loaded from field org.apache.hadoop.service.AbstractService.terminationNotification<br/>At AbstractService.java:[line 229]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N220608');">
<td>
<span class="priority-2">JLM</span>
</td>
<td>Synchronization performed on java.util.concurrent.atomic.AtomicBoolean in org.apache.hadoop.service.AbstractService.stop()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N220608" style="display: none;">
<a href="#JLM_JSR166_UTILCONCURRENT_MONITORENTER">Bug type JLM_JSR166_UTILCONCURRENT_MONITORENTER (click for details)</a>
<br/>In class org.apache.hadoop.service.AbstractService<br/>In method org.apache.hadoop.service.AbstractService.stop()<br/>Type java.util.concurrent.atomic.AtomicBoolean<br/>Value loaded from e<br/>At AbstractService.java:[line 229]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N220680');">
<td>
<span class="priority-2">JLM</span>
</td>
<td>Synchronization performed on java.util.concurrent.atomic.AtomicBoolean in org.apache.hadoop.service.AbstractService.waitForServiceToStop(long)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N220680" style="display: none;">
<a href="#JLM_JSR166_UTILCONCURRENT_MONITORENTER">Bug type JLM_JSR166_UTILCONCURRENT_MONITORENTER (click for details)</a>
<br/>In class org.apache.hadoop.service.AbstractService<br/>In method org.apache.hadoop.service.AbstractService.waitForServiceToStop(long)<br/>Type java.util.concurrent.atomic.AtomicBoolean<br/>Value loaded from e<br/>At AbstractService.java:[line 285]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N238878');">
<td>
<span class="priority-2">JLM</span>
</td>
<td>Synchronization performed on java.util.concurrent.atomic.AtomicBoolean in org.apache.hadoop.yarn.client.api.async.impl.TestAMRMClientAsync.testAMRMClientAsync()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N238878" style="display: none;">
<a href="#JLM_JSR166_UTILCONCURRENT_MONITORENTER">Bug type JLM_JSR166_UTILCONCURRENT_MONITORENTER (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.api.async.impl.TestAMRMClientAsync<br/>In method org.apache.hadoop.yarn.client.api.async.impl.TestAMRMClientAsync.testAMRMClientAsync()<br/>Type java.util.concurrent.atomic.AtomicBoolean<br/>Value loaded from heartbeatBlock<br/>At TestAMRMClientAsync.java:[line 135]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N247907');">
<td>
<span class="priority-2">JLM</span>
</td>
<td>Synchronization performed on java.util.concurrent.atomic.AtomicBoolean in org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerResync.testNMshutdownWhenResyncThrowException()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N247907" style="display: none;">
<a href="#JLM_JSR166_UTILCONCURRENT_MONITORENTER">Bug type JLM_JSR166_UTILCONCURRENT_MONITORENTER (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerResync<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerResync.testNMshutdownWhenResyncThrowException()<br/>Type java.util.concurrent.atomic.AtomicBoolean<br/>Value loaded from field org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerResync.isNMShutdownCalled<br/>At TestNodeManagerResync.java:[line 165]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N71342');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.fi.FiConfig.conf in org.apache.hadoop.fi.FiConfig.init()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N71342" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.fi.FiConfig<br/>In method org.apache.hadoop.fi.FiConfig.init()<br/>On field org.apache.hadoop.fi.FiConfig.conf<br/>At FiConfig.java:[lines 40-41]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N174739');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapred.TestMiniMRChildTask.mr in org.apache.hadoop.mapred.TestMiniMRChildTask.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N174739" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMiniMRChildTask<br/>In method org.apache.hadoop.mapred.TestMiniMRChildTask.setup()<br/>On field org.apache.hadoop.mapred.TestMiniMRChildTask.mr<br/>At TestMiniMRChildTask.java:[lines 336-337]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N197673');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities.mrCluster in org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N197673" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities<br/>In method org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestMRAMWithNonNormalizedCapabilities.mrCluster<br/>At TestMRAMWithNonNormalizedCapabilities.java:[lines 69-70]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N197794');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner.mrCluster in org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N197794" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner<br/>In method org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestMRAppWithCombiner.mrCluster<br/>At TestMRAppWithCombiner.java:[lines 76-77]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N197980');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization of static field org.apache.hadoop.mapreduce.v2.TestMRJobs.dfsCluster in org.apache.hadoop.mapreduce.v2.TestMRJobs.tearDown()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N197980" style="display: none;">
<a href="#LI_LAZY_INIT_STATIC">Bug type LI_LAZY_INIT_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobs<br/>In method org.apache.hadoop.mapreduce.v2.TestMRJobs.tearDown()<br/>On field org.apache.hadoop.mapreduce.v2.TestMRJobs.dfsCluster<br/>At TestMRJobs.java:[lines 162-164]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N198049');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization of static field org.apache.hadoop.mapreduce.v2.TestMRJobs.mrCluster in org.apache.hadoop.mapreduce.v2.TestMRJobs.tearDown()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N198049" style="display: none;">
<a href="#LI_LAZY_INIT_STATIC">Bug type LI_LAZY_INIT_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobs<br/>In method org.apache.hadoop.mapreduce.v2.TestMRJobs.tearDown()<br/>On field org.apache.hadoop.mapreduce.v2.TestMRJobs.mrCluster<br/>At TestMRJobs.java:[lines 158-160]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N198118');">
<td>
<span class="priority-1">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestMRJobs.mrCluster in org.apache.hadoop.mapreduce.v2.TestMRJobs.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N198118" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobs<br/>In method org.apache.hadoop.mapreduce.v2.TestMRJobs.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestMRJobs.mrCluster<br/>At TestMRJobs.java:[lines 140-141]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N198423');">
<td>
<span class="priority-1">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService.mrCluster in org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N198423" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService<br/>In method org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestMRJobsWithHistoryService.mrCluster<br/>At TestMRJobsWithHistoryService.java:[lines 89-90]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N198583');">
<td>
<span class="priority-1">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.mrCluster in org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N198583" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler<br/>In method org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestMRJobsWithProfiler.mrCluster<br/>At TestMRJobsWithProfiler.java:[lines 81-82]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N198652');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestMROldApiJobs.mrCluster in org.apache.hadoop.mapreduce.v2.TestMROldApiJobs.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N198652" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestMROldApiJobs<br/>In method org.apache.hadoop.mapreduce.v2.TestMROldApiJobs.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestMROldApiJobs.mrCluster<br/>At TestMROldApiJobs.java:[lines 74-75]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N198911');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization of static field org.apache.hadoop.mapreduce.v2.TestRMNMInfo.mrCluster in org.apache.hadoop.mapreduce.v2.TestRMNMInfo.tearDown()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N198911" style="display: none;">
<a href="#LI_LAZY_INIT_STATIC">Bug type LI_LAZY_INIT_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestRMNMInfo<br/>In method org.apache.hadoop.mapreduce.v2.TestRMNMInfo.tearDown()<br/>On field org.apache.hadoop.mapreduce.v2.TestRMNMInfo.mrCluster<br/>At TestRMNMInfo.java:[lines 90-92]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N198980');">
<td>
<span class="priority-1">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestRMNMInfo.mrCluster in org.apache.hadoop.mapreduce.v2.TestRMNMInfo.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N198980" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestRMNMInfo<br/>In method org.apache.hadoop.mapreduce.v2.TestRMNMInfo.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestRMNMInfo.mrCluster<br/>At TestRMNMInfo.java:[lines 75-76]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N199353');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution.mrCluster in org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N199353" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution<br/>In method org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution.setup()<br/>On field org.apache.hadoop.mapreduce.v2.TestSpeculativeExecution.mrCluster<br/>At TestSpeculativeExecution.java:[lines 114-115]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N237999');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.yarn.applications.unmanagedamlauncher.TestUnmanagedAMLauncher.yarnCluster in org.apache.hadoop.yarn.applications.unmanagedamlauncher.TestUnmanagedAMLauncher.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N237999" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.unmanagedamlauncher.TestUnmanagedAMLauncher<br/>In method org.apache.hadoop.yarn.applications.unmanagedamlauncher.TestUnmanagedAMLauncher.setup()<br/>On field org.apache.hadoop.yarn.applications.unmanagedamlauncher.TestUnmanagedAMLauncher.yarnCluster<br/>At TestUnmanagedAMLauncher.java:[lines 63-64]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N245440');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization of static field org.apache.hadoop.yarn.server.TestContainerManagerSecurity.yarnCluster in org.apache.hadoop.yarn.server.TestContainerManagerSecurity.testContainerManager()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N245440" style="display: none;">
<a href="#LI_LAZY_INIT_STATIC">Bug type LI_LAZY_INIT_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.TestContainerManagerSecurity<br/>In method org.apache.hadoop.yarn.server.TestContainerManagerSecurity.testContainerManager()<br/>On field org.apache.hadoop.yarn.server.TestContainerManagerSecurity.yarnCluster<br/>At TestContainerManagerSecurity.java:[lines 153-155]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N245770');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization of static field org.apache.hadoop.yarn.server.TestDiskFailures.yarnCluster in org.apache.hadoop.yarn.server.TestDiskFailures.teardown()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N245770" style="display: none;">
<a href="#LI_LAZY_INIT_STATIC">Bug type LI_LAZY_INIT_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.TestDiskFailures<br/>In method org.apache.hadoop.yarn.server.TestDiskFailures.teardown()<br/>On field org.apache.hadoop.yarn.server.TestDiskFailures.yarnCluster<br/>At TestDiskFailures.java:[lines 83-85]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N245839');">
<td>
<span class="priority-2">LI</span>
</td>
<td>Incorrect lazy initialization and update of static field org.apache.hadoop.yarn.server.TestDiskFailures.yarnCluster in org.apache.hadoop.yarn.server.TestDiskFailures.testDirsFailures(boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N245839" style="display: none;">
<a href="#LI_LAZY_INIT_UPDATE_STATIC">Bug type LI_LAZY_INIT_UPDATE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.TestDiskFailures<br/>In method org.apache.hadoop.yarn.server.TestDiskFailures.testDirsFailures(boolean)<br/>On field org.apache.hadoop.yarn.server.TestDiskFailures.yarnCluster<br/>At TestDiskFailures.java:[lines 157-163]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N238950');">
<td>
<span class="priority-2">MWN</span>
</td>
<td>Mismatched wait() in org.apache.hadoop.yarn.client.api.async.impl.TestAMRMClientAsync.testAMRMClientAsyncReboot()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N238950" style="display: none;">
<a href="#MWN_MISMATCHED_WAIT">Bug type MWN_MISMATCHED_WAIT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.api.async.impl.TestAMRMClientAsync<br/>In method org.apache.hadoop.yarn.client.api.async.impl.TestAMRMClientAsync.testAMRMClientAsyncReboot()<br/>At TestAMRMClientAsync.java:[line 227]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N239003');">
<td>
<span class="priority-2">MWN</span>
</td>
<td>Mismatched wait() in org.apache.hadoop.yarn.client.api.async.impl.TestAMRMClientAsync.testCallAMRMClientAsyncStopFromCallbackHandler()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N239003" style="display: none;">
<a href="#MWN_MISMATCHED_WAIT">Bug type MWN_MISMATCHED_WAIT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.api.async.impl.TestAMRMClientAsync<br/>In method org.apache.hadoop.yarn.client.api.async.impl.TestAMRMClientAsync.testCallAMRMClientAsyncStopFromCallbackHandler()<br/>At TestAMRMClientAsync.java:[line 290]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N136546');">
<td>
<span class="priority-2">NN</span>
</td>
<td>Naked notify in org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.testDelegationTokenDuringNNFailover()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N136546" style="display: none;">
<a href="#NN_NAKED_NOTIFY">Bug type NN_NAKED_NOTIFY (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.testDelegationTokenDuringNNFailover()<br/>At TestDelegationTokensWithHA.java:[line 242]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N243393');">
<td>
<span class="priority-1">RV</span>
</td>
<td>Return value of putIfAbsent is ignored, but constructor is reused in org.apache.hadoop.yarn.factories.impl.pb.RecordFactoryPBImpl.newRecordInstance(Class)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N243393" style="display: none;">
<a href="#RV_RETURN_VALUE_OF_PUTIFABSENT_IGNORED">Bug type RV_RETURN_VALUE_OF_PUTIFABSENT_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.yarn.factories.impl.pb.RecordFactoryPBImpl<br/>In method org.apache.hadoop.yarn.factories.impl.pb.RecordFactoryPBImpl.newRecordInstance(Class)<br/>Called method java.util.concurrent.ConcurrentMap.putIfAbsent(Object, Object)<br/>Type reflect.Constructor&lt;T&gt;<br/>Value loaded from constructor<br/>At RecordFactoryPBImpl.java:[line 64]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N243479');">
<td>
<span class="priority-1">RV</span>
</td>
<td>Return value of putIfAbsent is ignored, but constructor is reused in org.apache.hadoop.yarn.factories.impl.pb.RpcClientFactoryPBImpl.getClient(Class, long, InetSocketAddress, Configuration)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N243479" style="display: none;">
<a href="#RV_RETURN_VALUE_OF_PUTIFABSENT_IGNORED">Bug type RV_RETURN_VALUE_OF_PUTIFABSENT_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.yarn.factories.impl.pb.RpcClientFactoryPBImpl<br/>In method org.apache.hadoop.yarn.factories.impl.pb.RpcClientFactoryPBImpl.getClient(Class, long, InetSocketAddress, Configuration)<br/>Called method java.util.concurrent.ConcurrentMap.putIfAbsent(Object, Object)<br/>Type reflect.Constructor&lt;T&gt;<br/>Value loaded from constructor<br/>At RpcClientFactoryPBImpl.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N243565');">
<td>
<span class="priority-1">RV</span>
</td>
<td>Return value of putIfAbsent is ignored, but constructor is reused in org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.getServer(Class, Object, InetSocketAddress, Configuration, SecretManager, int, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N243565" style="display: none;">
<a href="#RV_RETURN_VALUE_OF_PUTIFABSENT_IGNORED">Bug type RV_RETURN_VALUE_OF_PUTIFABSENT_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl<br/>In method org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.getServer(Class, Object, InetSocketAddress, Configuration, SecretManager, int, String)<br/>Called method java.util.concurrent.ConcurrentMap.putIfAbsent(Object, Object)<br/>Type reflect.Constructor&lt;T&gt;<br/>Value loaded from constructor<br/>At RpcServerFactoryPBImpl.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N243651');">
<td>
<span class="priority-1">RV</span>
</td>
<td>Return value of putIfAbsent is ignored, but method is reused in org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.getServer(Class, Object, InetSocketAddress, Configuration, SecretManager, int, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N243651" style="display: none;">
<a href="#RV_RETURN_VALUE_OF_PUTIFABSENT_IGNORED">Bug type RV_RETURN_VALUE_OF_PUTIFABSENT_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl<br/>In method org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl.getServer(Class, Object, InetSocketAddress, Configuration, SecretManager, int, String)<br/>Called method java.util.concurrent.ConcurrentMap.putIfAbsent(Object, Object)<br/>Type reflect.Method<br/>Value loaded from method<br/>At RpcServerFactoryPBImpl.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N261203');">
<td>
<span class="priority-1">RV</span>
</td>
<td>Return value of putIfAbsent is ignored, but application is reused in org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestRMAppTransitions.createNewTestApp(ApplicationSubmissionContext)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N261203" style="display: none;">
<a href="#RV_RETURN_VALUE_OF_PUTIFABSENT_IGNORED">Bug type RV_RETURN_VALUE_OF_PUTIFABSENT_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestRMAppTransitions<br/>In method org.apache.hadoop.yarn.server.resourcemanager.rmapp.TestRMAppTransitions.createNewTestApp(ApplicationSubmissionContext)<br/>Called method java.util.concurrent.ConcurrentMap.putIfAbsent(Object, Object)<br/>Type org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl<br/>Value loaded from application<br/>At TestRMAppTransitions.java:[line 244]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N269183');">
<td>
<span class="priority-1">RV</span>
</td>
<td>Return value of putIfAbsent is ignored, but application is reused in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testNotAllowSubmitApplication()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N269183" style="display: none;">
<a href="#RV_RETURN_VALUE_OF_PUTIFABSENT_IGNORED">Bug type RV_RETURN_VALUE_OF_PUTIFABSENT_IGNORED (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testNotAllowSubmitApplication()<br/>Called method java.util.concurrent.ConcurrentMap.putIfAbsent(Object, Object)<br/>Type org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppImpl<br/>Value loaded from application<br/>At TestFairScheduler.java:[line 1788]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N196040');">
<td>
<span class="priority-2">SC</span>
</td>
<td>new org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl(TaskAttemptID, JobConf, FileSystem, LocalDirAllocator, Reporter, CompressionCodec, Class, Task$CombineOutputCollector, Counters$Counter, Counters$Counter, Counters$Counter, ExceptionReporter, Progress, MapOutputFile) invokes org.apache.hadoop.mapreduce.task.reduce.MergeThread.start()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N196040" style="display: none;">
<a href="#SC_START_IN_CTOR">Bug type SC_START_IN_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl<br/>In method new org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl(TaskAttemptID, JobConf, FileSystem, LocalDirAllocator, Reporter, CompressionCodec, Class, Task$CombineOutputCollector, Counters$Counter, Counters$Counter, Counters$Counter, ExceptionReporter, Progress, MapOutputFile)<br/>Called method org.apache.hadoop.mapreduce.task.reduce.MergeThread.start()<br/>At MergeManagerImpl.java:[line 218]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N88545');">
<td>
<span class="priority-2">STCAL</span>
</td>
<td>Call to method of static java.text.DateFormat in org.apache.hadoop.fs.shell.Ls.processPath(PathData)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N88545" style="display: none;">
<a href="#STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE">Bug type STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE (click for details)</a>
<br/>In class org.apache.hadoop.fs.shell.Ls<br/>In method org.apache.hadoop.fs.shell.Ls.processPath(PathData)<br/>Called method java.text.SimpleDateFormat.format(Date)<br/>Field org.apache.hadoop.fs.shell.Ls.dateFormat<br/>At Ls.java:[line 115]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N88625');">
<td>
<span class="priority-2">STCAL</span>
</td>
<td>org.apache.hadoop.fs.shell.Ls.dateFormat is a static field of type java.text.DateFormat, which isn't thread safe</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N88625" style="display: none;">
<a href="#STCAL_STATIC_SIMPLE_DATE_FORMAT_INSTANCE">Bug type STCAL_STATIC_SIMPLE_DATE_FORMAT_INSTANCE (click for details)</a>
<br/>In class org.apache.hadoop.fs.shell.Ls<br/>Field org.apache.hadoop.fs.shell.Ls.dateFormat<br/>In Ls.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N88726');">
<td>
<span class="priority-2">STCAL</span>
</td>
<td>Call to method of static java.text.DateFormat in org.apache.hadoop.fs.shell.Stat.processPath(PathData)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N88726" style="display: none;">
<a href="#STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE">Bug type STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE (click for details)</a>
<br/>In class org.apache.hadoop.fs.shell.Stat<br/>In method org.apache.hadoop.fs.shell.Stat.processPath(PathData)<br/>Called method java.text.SimpleDateFormat.format(Date)<br/>Field org.apache.hadoop.fs.shell.Stat.timeFmt<br/>At Stat.java:[line 113]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N88806');">
<td>
<span class="priority-2">STCAL</span>
</td>
<td>org.apache.hadoop.fs.shell.Stat.timeFmt is a static field of type java.text.DateFormat, which isn't thread safe</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N88806" style="display: none;">
<a href="#STCAL_STATIC_SIMPLE_DATE_FORMAT_INSTANCE">Bug type STCAL_STATIC_SIMPLE_DATE_FORMAT_INSTANCE (click for details)</a>
<br/>In class org.apache.hadoop.fs.shell.Stat<br/>Field org.apache.hadoop.fs.shell.Stat.timeFmt<br/>In Stat.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N97566');">
<td>
<span class="priority-2">STCAL</span>
</td>
<td>Call to method of static java.text.DateFormat in org.apache.hadoop.hdfs.NNBench.analyzeResults()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N97566" style="display: none;">
<a href="#STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE">Bug type STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>In method org.apache.hadoop.hdfs.NNBench.analyzeResults()<br/>Called method java.text.SimpleDateFormat.format(Date)<br/>Field org.apache.hadoop.hdfs.NNBench.sdf<br/>At NNBench.java:[line 412]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97646');">
<td>
<span class="priority-2">STCAL</span>
</td>
<td>Call to method of static java.text.DateFormat in org.apache.hadoop.hdfs.NNBench.parseInputs(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97646" style="display: none;">
<a href="#STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE">Bug type STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.NNBench<br/>In method org.apache.hadoop.hdfs.NNBench.parseInputs(String[])<br/>Called method java.text.SimpleDateFormat.format(Date)<br/>Field org.apache.hadoop.hdfs.NNBench.sdf<br/>At NNBench.java:[line 275]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N109332');">
<td>
<span class="priority-1">STCAL</span>
</td>
<td>Call to method of static java.text.DateFormat in org.apache.hadoop.hdfs.TestSetTimes.testTimes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N109332" style="display: none;">
<a href="#STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE">Bug type STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestSetTimes<br/>In method org.apache.hadoop.hdfs.TestSetTimes.testTimes()<br/>Called method java.text.SimpleDateFormat.format(Date)<br/>Field org.apache.hadoop.hdfs.TestSetTimes.dateForm<br/>At TestSetTimes.java:[line 124]<br/>Another occurrence at TestSetTimes.java:[line 133]<br/>Another occurrence at TestSetTimes.java:[line 134]<br/>Another occurrence at TestSetTimes.java:[line 155]<br/>Another occurrence at TestSetTimes.java:[line 168]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N109456');">
<td>
<span class="priority-1">STCAL</span>
</td>
<td>Call to method of static java.text.DateFormat in org.apache.hadoop.hdfs.TestSetTimes.testTimesAtClose()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N109456" style="display: none;">
<a href="#STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE">Bug type STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestSetTimes<br/>In method org.apache.hadoop.hdfs.TestSetTimes.testTimesAtClose()<br/>Called method java.text.SimpleDateFormat.format(Date)<br/>Field org.apache.hadoop.hdfs.TestSetTimes.dateForm<br/>At TestSetTimes.java:[line 253]<br/>Another occurrence at TestSetTimes.java:[line 264]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N166640');">
<td>
<span class="priority-2">SWL</span>
</td>
<td>org.apache.hadoop.mapred.ClientServiceDelegate.invoke(String, Class, Object) calls Thread.sleep() with a lock held</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N166640" style="display: none;">
<a href="#SWL_SLEEP_WITH_LOCK_HELD">Bug type SWL_SLEEP_WITH_LOCK_HELD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.ClientServiceDelegate<br/>In method org.apache.hadoop.mapred.ClientServiceDelegate.invoke(String, Class, Object)<br/>At ClientServiceDelegate.java:[line 350]<br/>Another occurrence at ClientServiceDelegate.java:[line 336]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N245169');">
<td>
<span class="priority-2">SWL</span>
</td>
<td>org.apache.hadoop.yarn.server.MiniYARNCluster.startResourceManager(int) calls Thread.sleep() with a lock held</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N245169" style="display: none;">
<a href="#SWL_SLEEP_WITH_LOCK_HELD">Bug type SWL_SLEEP_WITH_LOCK_HELD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.MiniYARNCluster<br/>In method org.apache.hadoop.yarn.server.MiniYARNCluster.startResourceManager(int)<br/>At MiniYARNCluster.java:[line 317]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N165351');">
<td>
<span class="priority-1">UL</span>
</td>
<td>org.apache.hadoop.lib.service.instrumentation.InstrumentationService.getToAdd(String, String, Class, Lock, Map) does not release lock on all paths</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N165351" style="display: none;">
<a href="#UL_UNRELEASED_LOCK">Bug type UL_UNRELEASED_LOCK (click for details)</a>
<br/>In class org.apache.hadoop.lib.service.instrumentation.InstrumentationService<br/>In method org.apache.hadoop.lib.service.instrumentation.InstrumentationService.getToAdd(String, String, Class, Lock, Map)<br/>At InstrumentationService.java:[line 126]<br/>Another occurrence at InstrumentationService.java:[line 137]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N87257');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.fs.loadGenerator.LoadGenerator.currentIndex in org.apache.hadoop.fs.loadGenerator.LoadGenerator.run(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N87257" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.fs.loadGenerator.LoadGenerator<br/>In method org.apache.hadoop.fs.loadGenerator.LoadGenerator.run(String[])<br/>Field org.apache.hadoop.fs.loadGenerator.LoadGenerator.currentIndex<br/>At LoadGenerator.java:[line 353]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N121667');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.numFailedVolumes in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.checkDirs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N121667" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList<br/>In method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.checkDirs()<br/>Field org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsVolumeList.numFailedVolumes<br/>At FsVolumeList.java:[line 177]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N211555');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.metrics2.lib.MutableCounterInt.value in org.apache.hadoop.metrics2.lib.MutableCounterInt.incr()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N211555" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.lib.MutableCounterInt<br/>In method org.apache.hadoop.metrics2.lib.MutableCounterInt.incr()<br/>Field org.apache.hadoop.metrics2.lib.MutableCounterInt.value<br/>At MutableCounterInt.java:[line 41]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N211622');">
<td>
<span class="priority-1">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.metrics2.lib.MutableCounterLong.value in org.apache.hadoop.metrics2.lib.MutableCounterLong.incr()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N211622" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.lib.MutableCounterLong<br/>In method org.apache.hadoop.metrics2.lib.MutableCounterLong.incr()<br/>Field org.apache.hadoop.metrics2.lib.MutableCounterLong.value<br/>At MutableCounterLong.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N211689');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.metrics2.lib.MutableGaugeInt.value in org.apache.hadoop.metrics2.lib.MutableGaugeInt.decr()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N211689" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.lib.MutableGaugeInt<br/>In method org.apache.hadoop.metrics2.lib.MutableGaugeInt.decr()<br/>Field org.apache.hadoop.metrics2.lib.MutableGaugeInt.value<br/>At MutableGaugeInt.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N211756');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.metrics2.lib.MutableGaugeInt.value in org.apache.hadoop.metrics2.lib.MutableGaugeInt.incr()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N211756" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.lib.MutableGaugeInt<br/>In method org.apache.hadoop.metrics2.lib.MutableGaugeInt.incr()<br/>Field org.apache.hadoop.metrics2.lib.MutableGaugeInt.value<br/>At MutableGaugeInt.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N211823');">
<td>
<span class="priority-1">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.metrics2.lib.MutableGaugeLong.value in org.apache.hadoop.metrics2.lib.MutableGaugeLong.decr()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N211823" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.lib.MutableGaugeLong<br/>In method org.apache.hadoop.metrics2.lib.MutableGaugeLong.decr()<br/>Field org.apache.hadoop.metrics2.lib.MutableGaugeLong.value<br/>At MutableGaugeLong.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N211890');">
<td>
<span class="priority-1">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.metrics2.lib.MutableGaugeLong.value in org.apache.hadoop.metrics2.lib.MutableGaugeLong.incr()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N211890" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.lib.MutableGaugeLong<br/>In method org.apache.hadoop.metrics2.lib.MutableGaugeLong.incr()<br/>Field org.apache.hadoop.metrics2.lib.MutableGaugeLong.value<br/>At MutableGaugeLong.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N263624');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.numContainers in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.allocateResource(Resource, FiCaSchedulerApp, Resource)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N263624" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.allocateResource(Resource, FiCaSchedulerApp, Resource)<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.numContainers<br/>At LeafQueue.java:[line 1454]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N263691');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.numContainers in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.releaseResource(Resource, FiCaSchedulerApp, Resource)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N263691" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.releaseResource(Resource, FiCaSchedulerApp, Resource)<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.numContainers<br/>At LeafQueue.java:[line 1480]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N264392');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.numApplications in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.addApplication(ApplicationId, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N264392" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.addApplication(ApplicationId, String)<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.numApplications<br/>At ParentQueue.java:[line 493]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N264459');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.numContainers in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.allocateResource(Resource, Resource)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N264459" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.allocateResource(Resource, Resource)<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.numContainers<br/>At ParentQueue.java:[line 742]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N264526');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.numContainers in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.releaseResource(Resource, Resource)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N264526" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.releaseResource(Resource, Resource)<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.numContainers<br/>At ParentQueue.java:[line 750]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N264593');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.numApplications in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.removeApplication(ApplicationId, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N264593" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.removeApplication(ApplicationId, String)<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.ParentQueue.numApplications<br/>At ParentQueue.java:[line 518]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N265839');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode.numContainers in org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode.allocateContainer(ApplicationId, RMContainer)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N265839" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode.allocateContainer(ApplicationId, RMContainer)<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode.numContainers<br/>At FiCaSchedulerNode.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N265906');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode.numContainers in org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode.updateResource(Container)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N265906" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode.updateResource(Container)<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode.numContainers<br/>At FiCaSchedulerNode.java:[line 146]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N265973');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode.numContainers in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode.allocateContainer(ApplicationId, RMContainer)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N265973" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode.allocateContainer(ApplicationId, RMContainer)<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode.numContainers<br/>At FSSchedulerNode.java:[line 115]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N266040');">
<td>
<span class="priority-2">VO</span>
</td>
<td>Increment of volatile field org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode.numContainers in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode.updateResource(Container)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N266040" style="display: none;">
<a href="#VO_VOLATILE_INCREMENT">Bug type VO_VOLATILE_INCREMENT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode.updateResource(Container)<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FSSchedulerNode.numContainers<br/>At FSSchedulerNode.java:[line 145]</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_PERFORMANCE">Performance Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74933');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.fs.MD5MD5CRC32FileChecksum.valueOf(Attributes)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74933" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.fs.MD5MD5CRC32FileChecksum<br/>In method org.apache.hadoop.fs.MD5MD5CRC32FileChecksum.valueOf(Attributes)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At MD5MD5CRC32FileChecksum.java:[line 145]<br/>Another occurrence at MD5MD5CRC32FileChecksum.java:[line 150]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N89462');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>Primitive boxed just to call toString in org.apache.hadoop.fs.slive.ConfigMerger.handleOperations(ArgumentParser$ParsedOutput, Configuration, ConfigExtractor)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N89462" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_TOSTRING">Bug type DM_BOXED_PRIMITIVE_TOSTRING (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.ConfigMerger<br/>In method org.apache.hadoop.fs.slive.ConfigMerger.handleOperations(ArgumentParser$ParsedOutput, Configuration, ConfigExtractor)<br/>Called method Double.toString()<br/>Should call Double.toString(double) instead<br/>At ConfigMerger.java:[line 180]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89700');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>Primitive boxed just to call toString in org.apache.hadoop.fs.slive.PathFinder.getPath(int, int, PathFinder$Type)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89700" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_TOSTRING">Bug type DM_BOXED_PRIMITIVE_TOSTRING (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.PathFinder<br/>In method org.apache.hadoop.fs.slive.PathFinder.getPath(int, int, PathFinder$Type)<br/>Called method Integer.toString()<br/>Should call Integer.toString(int) instead<br/>At PathFinder.java:[line 71]<br/>Another occurrence at PathFinder.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N89788');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.fs.slive.PathFinder.getPath(int, int, PathFinder$Type) invokes inefficient new Integer(int) constructor; use Integer.valueOf(int) instead</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N89788" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.PathFinder<br/>In method org.apache.hadoop.fs.slive.PathFinder.getPath(int, int, PathFinder$Type)<br/>Called method new Integer(int)<br/>Should call Integer.valueOf(int) instead<br/>At PathFinder.java:[line 71]<br/>Another occurrence at PathFinder.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N93964');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.ha.TestSshFenceByTcpPort.&lt;static initializer for TestSshFenceByTcpPort&gt;()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N93964" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestSshFenceByTcpPort<br/>In method org.apache.hadoop.ha.TestSshFenceByTcpPort.&lt;static initializer for TestSshFenceByTcpPort&gt;()<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At TestSshFenceByTcpPort.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N110686');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>Boxed value is unboxed and then immediately reboxed in org.apache.hadoop.hdfs.client.ShortCircuitCache.insertEvictable(Long, ShortCircuitReplica, TreeMap)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N110686" style="display: none;">
<a href="#BX_UNBOXING_IMMEDIATELY_REBOXED">Bug type BX_UNBOXING_IMMEDIATELY_REBOXED (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.client.ShortCircuitCache<br/>In method org.apache.hadoop.hdfs.client.ShortCircuitCache.insertEvictable(Long, ShortCircuitReplica, TreeMap)<br/>Called method Long.valueOf(long)<br/>At ShortCircuitCache.java:[line 621]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N111193');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.hdfs.nfs.nfs3.TestOpenFileCtxCache.testEviction() invokes inefficient new Long(long) constructor; use Long.valueOf(long) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N111193" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.nfs.nfs3.TestOpenFileCtxCache<br/>In method org.apache.hadoop.hdfs.nfs.nfs3.TestOpenFileCtxCache.testEviction()<br/>Called method new Long(long)<br/>Should call Long.valueOf(long) instead<br/>At TestOpenFileCtxCache.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N111278');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testCheckCommit() invokes inefficient new Long(long) constructor; use Long.valueOf(long) instead</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N111278" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.nfs.nfs3.TestWrites<br/>In method org.apache.hadoop.hdfs.nfs.nfs3.TestWrites.testCheckCommit()<br/>Called method new Long(long)<br/>Should call Long.valueOf(long) instead<br/>At TestWrites.java:[line 180]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N113040');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.&lt;static initializer for PipelineAck&gt;()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N113040" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck<br/>In method org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.&lt;static initializer for PipelineAck&gt;()<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At PipelineAck.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N113853');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.qjournal.server.JNStorage.purgeMatching(File, List, long)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N113853" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.qjournal.server.JNStorage<br/>In method org.apache.hadoop.hdfs.qjournal.server.JNStorage.purgeMatching(File, List, long)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At JNStorage.java:[line 168]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N114766');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.parseDNFromHostsEntry(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N114766" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager<br/>In method org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.parseDNFromHostsEntry(String)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At DatanodeManager.java:[line 1161]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N122449');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive new org.apache.hadoop.hdfs.server.namenode.CheckpointSignature(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N122449" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.CheckpointSignature<br/>In method new org.apache.hadoop.hdfs.server.namenode.CheckpointSignature(String)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At CheckpointSignature.java:[line 56]<br/>Another occurrence at CheckpointSignature.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N122537');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive new org.apache.hadoop.hdfs.server.namenode.CheckpointSignature(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N122537" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.CheckpointSignature<br/>In method new org.apache.hadoop.hdfs.server.namenode.CheckpointSignature(String)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At CheckpointSignature.java:[line 58]<br/>Another occurrence at CheckpointSignature.java:[line 59]<br/>Another occurrence at CheckpointSignature.java:[line 60]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N124907');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.server.namenode.FileJournalManager.matchEditLogs(File[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N124907" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FileJournalManager<br/>In method org.apache.hadoop.hdfs.server.namenode.FileJournalManager.matchEditLogs(File[])<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At FileJournalManager.java:[line 250]<br/>Another occurrence at FileJournalManager.java:[line 251]<br/>Another occurrence at FileJournalManager.java:[line 264]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N122866');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.server.namenode.FSDirectory.resolvePath(String, byte[][], FSDirectory)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N122866" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSDirectory<br/>In method org.apache.hadoop.hdfs.server.namenode.FSDirectory.resolvePath(String, byte[][], FSDirectory)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At FSDirectory.java:[line 2965]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N123171');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.blockFromXml(XMLUtils$Stanza)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N123171" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp<br/>In method org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.blockFromXml(XMLUtils$Stanza)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At FSEditLogOp.java:[line 3959]<br/>Another occurrence at FSEditLogOp.java:[line 3960]<br/>Another occurrence at FSEditLogOp.java:[line 3961]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N123270');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.decodeXml(XMLUtils$Stanza)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N123270" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp<br/>In method org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.decodeXml(XMLUtils$Stanza)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At FSEditLogOp.java:[line 3941]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N123347');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.delegationKeyFromXml(XMLUtils$Stanza)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N123347" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp<br/>In method org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.delegationKeyFromXml(XMLUtils$Stanza)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At FSEditLogOp.java:[line 4027]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N123424');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.delegationKeyFromXml(XMLUtils$Stanza)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N123424" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp<br/>In method org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.delegationKeyFromXml(XMLUtils$Stanza)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At FSEditLogOp.java:[line 4028]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N123501');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.delegationTokenFromXml(XMLUtils$Stanza)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N123501" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp<br/>In method org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.delegationTokenFromXml(XMLUtils$Stanza)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At FSEditLogOp.java:[line 3994]<br/>Another occurrence at FSEditLogOp.java:[line 4000]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N123589');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.delegationTokenFromXml(XMLUtils$Stanza)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N123589" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp<br/>In method org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.delegationTokenFromXml(XMLUtils$Stanza)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At FSEditLogOp.java:[line 3998]<br/>Another occurrence at FSEditLogOp.java:[line 3999]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N123677');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.readRpcIdsFromXml(XMLUtils$Stanza)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N123677" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp<br/>In method org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.readRpcIdsFromXml(XMLUtils$Stanza)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At FSEditLogOp.java:[line 290]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N123754');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Primitive boxed just to call toString in org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.appendRpcIdsToXml(ContentHandler, byte[], int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N123754" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_TOSTRING">Bug type DM_BOXED_PRIMITIVE_TOSTRING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp<br/>In method org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.appendRpcIdsToXml(ContentHandler, byte[], int)<br/>Called method Integer.toString()<br/>Should call Integer.toString(int) instead<br/>At FSEditLogOp.java:[line 307]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N123831');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Primitive boxed just to call toString in org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.delegationKeyToXml(ContentHandler, DelegationKey)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N123831" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_TOSTRING">Bug type DM_BOXED_PRIMITIVE_TOSTRING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp<br/>In method org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.delegationKeyToXml(ContentHandler, DelegationKey)<br/>Called method Integer.toString()<br/>Should call Integer.toString(int) instead<br/>At FSEditLogOp.java:[line 4014]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N123908');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Primitive boxed just to call toString in org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.delegationTokenToXml(ContentHandler, DelegationTokenIdentifier)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N123908" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_TOSTRING">Bug type DM_BOXED_PRIMITIVE_TOSTRING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSEditLogOp<br/>In method org.apache.hadoop.hdfs.server.namenode.FSEditLogOp.delegationTokenToXml(ContentHandler, DelegationTokenIdentifier)<br/>Called method Integer.toString()<br/>Should call Integer.toString(int) instead<br/>At FSEditLogOp.java:[line 3969]<br/>Another occurrence at FSEditLogOp.java:[line 3981]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N124587');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector.inspectDirectory(Storage$StorageDirectory)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N124587" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector<br/>In method org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector.inspectDirectory(Storage$StorageDirectory)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At FSImageTransactionalStorageInspector.java:[line 118]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N128763');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.server.namenode.TestEditLog.mockStorageWithEdits(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N128763" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestEditLog<br/>In method org.apache.hadoop.hdfs.server.namenode.TestEditLog.mockStorageWithEdits(String[])<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At TestEditLog.java:[line 1061]<br/>Another occurrence at TestEditLog.java:[line 1064]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N133635');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.server.namenode.TestNameNodeJspHelper.assertCounts(TestNameNodeJspHelper$DataNodeStatus, String, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N133635" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNameNodeJspHelper<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNameNodeJspHelper.assertCounts(TestNameNodeJspHelper$DataNodeStatus, String, int)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At TestNameNodeJspHelper.java:[line 318]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N101908');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.hdfs.TestDFSShell.testSetrep() invokes inefficient new Short(short) constructor; use Short.valueOf(short) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N101908" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testSetrep()<br/>Called method new Short(short)<br/>Should call Short.valueOf(short) instead<br/>At TestDFSShell.java:[line 1686]<br/>Another occurrence at TestDFSShell.java:[line 1687]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N103316');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.hdfs.TestDFSUtil.testAssertAllResultsEqual() invokes inefficient new Long(long) constructor; use Long.valueOf(long) instead</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N103316" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSUtil<br/>In method org.apache.hadoop.hdfs.TestDFSUtil.testAssertAllResultsEqual()<br/>Called method new Long(long)<br/>Should call Long.valueOf(long) instead<br/>At TestDFSUtil.java:[line 789]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N105239');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.TestFetchImage.getHighestFsImageOnCluster(MiniDFSCluster)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N105239" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFetchImage<br/>In method org.apache.hadoop.hdfs.TestFetchImage.getHighestFsImageOnCluster(MiniDFSCluster)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At TestFetchImage.java:[line 110]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N109850');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.hdfs.TestShortCircuitCache.testEviction() invokes inefficient new Integer(int) constructor; use Integer.valueOf(int) instead</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N109850" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestShortCircuitCache<br/>In method org.apache.hadoop.hdfs.TestShortCircuitCache.testEviction()<br/>Called method new Integer(int)<br/>Should call Integer.valueOf(int) instead<br/>At TestShortCircuitCache.java:[line 257]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N109935');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.hdfs.TestShortCircuitCache.testTimeBasedStaleness() invokes inefficient new Integer(int) constructor; use Integer.valueOf(int) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N109935" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestShortCircuitCache<br/>In method org.apache.hadoop.hdfs.TestShortCircuitCache.testTimeBasedStaleness()<br/>Called method new Integer(int)<br/>Should call Integer.valueOf(int) instead<br/>At TestShortCircuitCache.java:[line 310]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N110093');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.TestShortCircuitLocalRead.main(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N110093" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestShortCircuitLocalRead<br/>In method org.apache.hadoop.hdfs.TestShortCircuitLocalRead.main(String[])<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At TestShortCircuitLocalRead.java:[line 522]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N143089');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.tools.offlineImageViewer.DelimitedImageVisitor.visit(ImageVisitor$ImageElement, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N143089" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.DelimitedImageVisitor<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.DelimitedImageVisitor.visit(ImageVisitor$ImageElement, String)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At DelimitedImageVisitor.java:[line 147]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N143287');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.tools.offlineImageViewer.FileDistributionVisitor.visit(ImageVisitor$ImageElement, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N143287" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.FileDistributionVisitor<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.FileDistributionVisitor.visit(ImageVisitor$ImageElement, String)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At FileDistributionVisitor.java:[line 162]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N143364');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.tools.offlineImageViewer.FileDistributionVisitor.visit(ImageVisitor$ImageElement, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N143364" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.FileDistributionVisitor<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.FileDistributionVisitor.visit(ImageVisitor$ImageElement, String)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At FileDistributionVisitor.java:[line 165]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N143509');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.tools.offlineImageViewer.LsImageVisitor.visit(ImageVisitor$ImageElement, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N143509" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.LsImageVisitor<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.LsImageVisitor.visit(ImageVisitor$ImageElement, String)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At LsImageVisitor.java:[line 138]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N143586');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.tools.offlineImageViewer.LsImageVisitor.visit(ImageVisitor$ImageElement, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N143586" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.LsImageVisitor<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.LsImageVisitor.visit(ImageVisitor$ImageElement, String)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At LsImageVisitor.java:[line 147]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N143663');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.tools.offlineImageViewer.LsImageVisitor.visitEnclosingElement(ImageVisitor$ImageElement, ImageVisitor$ImageElement, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N143663" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.LsImageVisitor<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.LsImageVisitor.visitEnclosingElement(ImageVisitor$ImageElement, ImageVisitor$ImageElement, String)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At LsImageVisitor.java:[line 176]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N144100');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.tools.offlineImageViewer.SpotCheckImageVisitor.visit(ImageVisitor$ImageElement, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N144100" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.SpotCheckImageVisitor<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.SpotCheckImageVisitor.visit(ImageVisitor$ImageElement, String)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At SpotCheckImageVisitor.java:[line 46]<br/>Another occurrence at SpotCheckImageVisitor.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N144188');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.tools.offlineImageViewer.SpotCheckImageVisitor.visitEnclosingElement(ImageVisitor$ImageElement, ImageVisitor$ImageElement, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N144188" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.SpotCheckImageVisitor<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.SpotCheckImageVisitor.visitEnclosingElement(ImageVisitor$ImageElement, ImageVisitor$ImageElement, String)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At SpotCheckImageVisitor.java:[line 64]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N144527');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.hdfs.util.PersistentLongFile.readFile(File, long)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N144527" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.PersistentLongFile<br/>In method org.apache.hadoop.hdfs.util.PersistentLongFile.readFile(File, long)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At PersistentLongFile.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N148154');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.io.FileBench.run(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N148154" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.io.FileBench<br/>In method org.apache.hadoop.io.FileBench.run(String[])<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At FileBench.java:[line 175]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N178992');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.mapred.gridmix.DistributedCacheEmulator.configureDistCacheFiles(Configuration, JobConf)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N178992" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.DistributedCacheEmulator<br/>In method org.apache.hadoop.mapred.gridmix.DistributedCacheEmulator.configureDistCacheFiles(Configuration, JobConf)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At DistributedCacheEmulator.java:[line 518]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N179069');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.mapred.gridmix.DistributedCacheEmulator.writeDistCacheFilesList()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N179069" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.DistributedCacheEmulator<br/>In method org.apache.hadoop.mapred.gridmix.DistributedCacheEmulator.writeDistCacheFilesList()<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At DistributedCacheEmulator.java:[line 438]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N180547');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.mapred.gridmix.PseudoLocalFs.validateFileNameFormat(Path)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N180547" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.PseudoLocalFs<br/>In method org.apache.hadoop.mapred.gridmix.PseudoLocalFs.validateFileNameFormat(Path)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At PseudoLocalFs.java:[line 127]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N182716');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.mapred.gridmix.TestPseudoLocalFs.validateGetFileStatus(FileSystem, Path, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N182716" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestPseudoLocalFs<br/>In method org.apache.hadoop.mapred.gridmix.TestPseudoLocalFs.validateGetFileStatus(FileSystem, Path, boolean)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At TestPseudoLocalFs.java:[line 98]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N168425');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.mapred.MRBench.runJobInSequence(JobConf, int) invokes inefficient new Long(long) constructor; use Long.valueOf(long) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N168425" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRBench<br/>In method org.apache.hadoop.mapred.MRBench.runJobInSequence(JobConf, int)<br/>Called method new Long(long)<br/>Should call Long.valueOf(long) instead<br/>At MRBench.java:[line 193]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N168577');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.mapred.MRCaching.validateCacheFileSizes(Configuration, long[], String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N168577" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRCaching<br/>In method org.apache.hadoop.mapred.MRCaching.validateCacheFileSizes(Configuration, long[], String)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At MRCaching.java:[line 313]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N169504');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.mapred.TaskLogAppender.setOptionsFromSystemProperties()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N169504" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TaskLogAppender<br/>In method org.apache.hadoop.mapred.TaskLogAppender.setOptionsFromSystemProperties()<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At TaskLogAppender.java:[line 78]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N175016');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.mapred.TestMultiFileInputFormat.initFiles(FileSystem, int, int) invokes inefficient new Long(long) constructor; use Long.valueOf(long) instead</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N175016" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMultiFileInputFormat<br/>In method org.apache.hadoop.mapred.TestMultiFileInputFormat.initFiles(FileSystem, int, int)<br/>Called method new Long(long)<br/>Should call Long.valueOf(long) instead<br/>At TestMultiFileInputFormat.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N191179');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.extractFields(String[], List) invokes inefficient new Integer(String) constructor; use Integer.valueOf(String) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N191179" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper<br/>In method org.apache.hadoop.mapreduce.lib.fieldsel.FieldSelectionHelper.extractFields(String[], List)<br/>Called method new Integer(String)<br/>Should call Integer.valueOf(String) instead<br/>At FieldSelectionHelper.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N187087');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.mapreduce.TestLocalRunner.verifyNumberJob(int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N187087" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestLocalRunner<br/>In method org.apache.hadoop.mapreduce.TestLocalRunner.verifyNumberJob(int)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At TestLocalRunner.java:[line 497]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N187164');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.mapreduce.TestLocalRunner.verifyOutput(Path)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N187164" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestLocalRunner<br/>In method org.apache.hadoop.mapreduce.TestLocalRunner.verifyOutput(Path)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At TestLocalRunner.java:[line 232]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N211014');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.metrics.spi.CompositeContext.init(String, ContextFactory)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N211014" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.metrics.spi.CompositeContext<br/>In method org.apache.hadoop.metrics.spi.CompositeContext.init(String, ContextFactory)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At CompositeContext.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N220752');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.streaming.DelayEchoApp.main(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N220752" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.streaming.DelayEchoApp<br/>In method org.apache.hadoop.streaming.DelayEchoApp.main(String[])<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At DelayEchoApp.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N221722');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.streaming.TestLoadTypedBytes.testLoading() invokes inefficient new Long(long) constructor; use Long.valueOf(long) instead</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N221722" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestLoadTypedBytes<br/>In method org.apache.hadoop.streaming.TestLoadTypedBytes.testLoading()<br/>Called method new Long(long)<br/>Should call Long.valueOf(long) instead<br/>At TestLoadTypedBytes.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N227124');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.tools.TestDelegationTokenRemoteFetcher.testRenewTokenFromHttp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N227124" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestDelegationTokenRemoteFetcher<br/>In method org.apache.hadoop.tools.TestDelegationTokenRemoteFetcher.testRenewTokenFromHttp()<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At TestDelegationTokenRemoteFetcher.java:[line 188]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N230879');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.util.ServletUtil.parseLongParam(ServletRequest, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N230879" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.util.ServletUtil<br/>In method org.apache.hadoop.util.ServletUtil.parseLongParam(ServletRequest, String)<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At ServletUtil.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N231677');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.util.TestGenericsUtil.testGetClass() invokes inefficient new Integer(int) constructor; use Integer.valueOf(int) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N231677" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.util.TestGenericsUtil<br/>In method org.apache.hadoop.util.TestGenericsUtil.testGetClass()<br/>Called method new Integer(int)<br/>Should call Integer.valueOf(int) instead<br/>At TestGenericsUtil.java:[line 117]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N232939');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.util.TestIdentityHashStore.testDuplicateInserts() invokes inefficient new Integer(int) constructor; use Integer.valueOf(int) instead</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N232939" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.util.TestIdentityHashStore<br/>In method org.apache.hadoop.util.TestIdentityHashStore.testDuplicateInserts()<br/>Called method new Integer(int)<br/>Should call Integer.valueOf(int) instead<br/>At TestIdentityHashStore.java:[line 95]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N233024');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.util.TestIdentityHashStore.testStartingWithZeroCapacity() invokes inefficient new Integer(int) constructor; use Integer.valueOf(int) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N233024" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.util.TestIdentityHashStore<br/>In method org.apache.hadoop.util.TestIdentityHashStore.testStartingWithZeroCapacity()<br/>Called method new Integer(int)<br/>Should call Integer.valueOf(int) instead<br/>At TestIdentityHashStore.java:[line 69]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N233977');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>Boxed value is unboxed and then immediately reboxed in org.apache.hadoop.util.TestOptions.testFind()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N233977" style="display: none;">
<a href="#BX_UNBOXING_IMMEDIATELY_REBOXED">Bug type BX_UNBOXING_IMMEDIATELY_REBOXED (click for details)</a>
<br/>In class org.apache.hadoop.util.TestOptions<br/>In method org.apache.hadoop.util.TestOptions.testFind()<br/>Called method Boolean.valueOf(boolean)<br/>At TestOptions.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N236874');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Primitive boxed just to call toString in org.apache.hadoop.yarn.api.records.impl.pb.PriorityPBImpl.toString()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N236874" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_TOSTRING">Bug type DM_BOXED_PRIMITIVE_TOSTRING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.api.records.impl.pb.PriorityPBImpl<br/>In method org.apache.hadoop.yarn.api.records.impl.pb.PriorityPBImpl.toString()<br/>Called method Integer.toString()<br/>Should call Integer.toString(int) instead<br/>At PriorityPBImpl.java:[line 71]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N236951');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster.init(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N236951" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster<br/>In method org.apache.hadoop.yarn.applications.distributedshell.ApplicationMaster.init(String[])<br/>Called method Long.longValue()<br/>Should call Long.parseLong(String) instead<br/>At ApplicationMaster.java:[line 460]<br/>Another occurrence at ApplicationMaster.java:[line 464]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N243158');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.yarn.conf.TestYarnConfiguration.testRMWebUrlSpecified()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N243158" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.conf.TestYarnConfiguration<br/>In method org.apache.hadoop.yarn.conf.TestYarnConfiguration.testRMWebUrlSpecified()<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At TestYarnConfiguration.java:[line 54]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N246567');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>Primitive value is boxed then unboxed to perform primitive coercion in org.apache.hadoop.yarn.server.nodemanager.LocalRMInterface.registerNodeManager(RegisterNodeManagerRequest)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N246567" style="display: none;">
<a href="#BX_BOXING_IMMEDIATELY_UNBOXED_TO_PERFORM_COERCION">Bug type BX_BOXING_IMMEDIATELY_UNBOXED_TO_PERFORM_COERCION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.LocalRMInterface<br/>In method org.apache.hadoop.yarn.server.nodemanager.LocalRMInterface.registerNodeManager(RegisterNodeManagerRequest)<br/>At LocalRMInterface.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N246621');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.LocalRMInterface.registerNodeManager(RegisterNodeManagerRequest) invokes inefficient new Integer(int) constructor; use Integer.valueOf(int) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N246621" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.LocalRMInterface<br/>In method org.apache.hadoop.yarn.server.nodemanager.LocalRMInterface.registerNodeManager(RegisterNodeManagerRequest)<br/>Called method new Integer(int)<br/>Should call Integer.valueOf(int) instead<br/>At LocalRMInterface.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N248331');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>Primitive value is boxed then unboxed to perform primitive coercion in org.apache.hadoop.yarn.server.nodemanager.TestNodeStatusUpdater.createMasterKey()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N248331" style="display: none;">
<a href="#BX_BOXING_IMMEDIATELY_UNBOXED_TO_PERFORM_COERCION">Bug type BX_BOXING_IMMEDIATELY_UNBOXED_TO_PERFORM_COERCION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeStatusUpdater<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestNodeStatusUpdater.createMasterKey()<br/>At TestNodeStatusUpdater.java:[line 142]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N248385');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.TestNodeStatusUpdater.createMasterKey() invokes inefficient new Integer(int) constructor; use Integer.valueOf(int) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N248385" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeStatusUpdater<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestNodeStatusUpdater.createMasterKey()<br/>Called method new Integer(int)<br/>Should call Integer.valueOf(int) instead<br/>At TestNodeStatusUpdater.java:[line 142]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N260238');">
<td>
<span class="priority-2">Bx</span>
</td>
<td>org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreTestBase.testRMDTSecretManagerStateStore(RMStateStoreTestBase$RMStateStoreHelper) invokes inefficient new Long(long) constructor; use Long.valueOf(long) instead</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N260238" style="display: none;">
<a href="#DM_NUMBER_CTOR">Bug type DM_NUMBER_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreTestBase<br/>In method org.apache.hadoop.yarn.server.resourcemanager.recovery.RMStateStoreTestBase.testRMDTSecretManagerStateStore(RMStateStoreTestBase$RMStateStoreHelper)<br/>Called method new Long(long)<br/>Should call Long.valueOf(long) instead<br/>At RMStateStoreTestBase.java:[line 392]<br/>Another occurrence at RMStateStoreTestBase.java:[line 415]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N271378');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.yarn.server.utils.BuilderUtils.convert(long, CharSequence)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N271378" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.utils.BuilderUtils<br/>In method org.apache.hadoop.yarn.server.utils.BuilderUtils.convert(long, CharSequence)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At BuilderUtils.java:[line 136]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N271455');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.yarn.server.utils.BuilderUtils.newApplicationId(RecordFactory, long, CharSequence)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N271455" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.utils.BuilderUtils<br/>In method org.apache.hadoop.yarn.server.utils.BuilderUtils.newApplicationId(RecordFactory, long, CharSequence)<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At BuilderUtils.java:[line 117]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N273930');">
<td>
<span class="priority-1">Bx</span>
</td>
<td>Boxing/unboxing to parse a primitive org.apache.hadoop.yarn.util.TestFSDownload.testDownload()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N273930" style="display: none;">
<a href="#DM_BOXED_PRIMITIVE_FOR_PARSING">Bug type DM_BOXED_PRIMITIVE_FOR_PARSING (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestFSDownload<br/>In method org.apache.hadoop.yarn.util.TestFSDownload.testDownload()<br/>Called method Integer.intValue()<br/>Should call Integer.parseInt(String) instead<br/>At TestFSDownload.java:[line 427]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N72564');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.fs.DFSCIOTest.&lt;static initializer for DFSCIOTest&gt;() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N72564" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.DFSCIOTest<br/>In method org.apache.hadoop.fs.DFSCIOTest.&lt;static initializer for DFSCIOTest&gt;()<br/>At DFSCIOTest.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N77934');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.fs.TestDFVariations.testDFInvalidPath() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N77934" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestDFVariations<br/>In method org.apache.hadoop.fs.TestDFVariations.testDFInvalidPath()<br/>At TestDFVariations.java:[line 72]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95554');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.hdfs.DFSTestUtil.runOperations(MiniDFSCluster, DistributedFileSystem, Configuration, long, int) invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95554" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.DFSTestUtil<br/>In method org.apache.hadoop.hdfs.DFSTestUtil.runOperations(MiniDFSCluster, DistributedFileSystem, Configuration, long, int)<br/>At DFSTestUtil.java:[line 1078]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N116644');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.hdfs.server.datanode.ReplicaInfo.setDirInternal(File) invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N116644" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.ReplicaInfo<br/>In method org.apache.hadoop.hdfs.server.datanode.ReplicaInfo.setDirInternal(File)<br/>At ReplicaInfo.java:[line 190]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N126247');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestAuditLogs.data() invokes inefficient Boolean constructor; use Boolean.valueOf(...) instead</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N126247" style="display: none;">
<a href="#DM_BOOLEAN_CTOR">Bug type DM_BOOLEAN_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestAuditLogs<br/>In method org.apache.hadoop.hdfs.server.namenode.TestAuditLogs.data()<br/>At TestAuditLogs.java:[line 76]<br/>Another occurrence at TestAuditLogs.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N130223');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.&lt;static initializer for TestFavoredNodesEndToEnd&gt;() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N130223" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.&lt;static initializer for TestFavoredNodesEndToEnd&gt;()<br/>At TestFavoredNodesEndToEnd.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N131631');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckMisPlacedReplicas() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N131631" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckMisPlacedReplicas()<br/>At TestFsck.java:[line 930]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N131684');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckMissingReplicas() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N131684" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckMissingReplicas()<br/>At TestFsck.java:[line 858]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N132153');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestHDFSConcat.testConcat() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N132153" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestHDFSConcat<br/>In method org.apache.hadoop.hdfs.server.namenode.TestHDFSConcat.testConcat()<br/>At TestHDFSConcat.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N132424');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestINodeFile.testFilesInGetListingOps() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N132424" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestINodeFile<br/>In method org.apache.hadoop.hdfs.server.namenode.TestINodeFile.testFilesInGetListingOps()<br/>At TestINodeFile.java:[line 1009]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N135654');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.setUpNameDirs() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N135654" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestStorageRestore<br/>In method org.apache.hadoop.hdfs.server.namenode.TestStorageRestore.setUpNameDirs()<br/>At TestStorageRestore.java:[line 90]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N171707');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.TestFixedLengthInputFormat.testNegativeRecordLength() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N171707" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFixedLengthInputFormat<br/>In method org.apache.hadoop.mapred.TestFixedLengthInputFormat.testNegativeRecordLength()<br/>At TestFixedLengthInputFormat.java:[line 154]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N171760');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.TestFixedLengthInputFormat.testNoRecordLength() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N171760" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFixedLengthInputFormat<br/>In method org.apache.hadoop.mapred.TestFixedLengthInputFormat.testNoRecordLength()<br/>At TestFixedLengthInputFormat.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N171813');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapred.TestFixedLengthInputFormat.testZeroRecordLength() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N171813" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFixedLengthInputFormat<br/>In method org.apache.hadoop.mapred.TestFixedLengthInputFormat.testZeroRecordLength()<br/>At TestFixedLengthInputFormat.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N199939');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.MockJobs.newJobReport(JobId) uses the nextDouble method of Random to generate a random integer; using nextInt is more efficient</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N199939" style="display: none;">
<a href="#DM_NEXTINT_VIA_NEXTDOUBLE">Bug type DM_NEXTINT_VIA_NEXTDOUBLE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MockJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.MockJobs.newJobReport(JobId)<br/>At MockJobs.java:[line 159]<br/>Another occurrence at MockJobs.java:[line 161]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N200003');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.MockJobs.newTaskAttemptReport(TaskAttemptId) uses the nextDouble method of Random to generate a random integer; using nextInt is more efficient</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N200003" style="display: none;">
<a href="#DM_NEXTINT_VIA_NEXTDOUBLE">Bug type DM_NEXTINT_VIA_NEXTDOUBLE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MockJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.MockJobs.newTaskAttemptReport(TaskAttemptId)<br/>At MockJobs.java:[line 189]<br/>Another occurrence at MockJobs.java:[line 191]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N200067');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.MockJobs.newTaskReport(TaskId) uses the nextDouble method of Random to generate a random integer; using nextInt is more efficient</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N200067" style="display: none;">
<a href="#DM_NEXTINT_VIA_NEXTDOUBLE">Bug type DM_NEXTINT_VIA_NEXTDOUBLE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MockJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.MockJobs.newTaskReport(TaskId)<br/>At MockJobs.java:[line 172]<br/>Another occurrence at MockJobs.java:[line 174]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N200713');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup.testDeletionofStagingOnUnregistrationFailure(int, boolean) invokes inefficient Boolean constructor; use Boolean.valueOf(...) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N200713" style="display: none;">
<a href="#DM_BOOLEAN_CTOR">Bug type DM_BOOLEAN_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup<br/>In method org.apache.hadoop.mapreduce.v2.app.TestStagingCleanup.testDeletionofStagingOnUnregistrationFailure(int, boolean)<br/>At TestStagingCleanup.java:[line 109]<br/>Another occurrence at TestStagingCleanup.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N234325');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.util.TestStringInterner.testNoIntern() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N234325" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.util.TestStringInterner<br/>In method org.apache.hadoop.util.TestStringInterner.testNoIntern()<br/>At TestStringInterner.java:[line 40]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N234378');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.util.TestStringInterner.testStrongIntern() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N234378" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.util.TestStringInterner<br/>In method org.apache.hadoop.util.TestStringInterner.testStrongIntern()<br/>At TestStringInterner.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N234431');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.util.TestStringInterner.testWeakIntern() invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N234431" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.util.TestStringInterner<br/>In method org.apache.hadoop.util.TestStringInterner.testWeakIntern()<br/>At TestStringInterner.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N253361');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.verifyContainerLogs(LogAggregationService, ApplicationId, ContainerId[]) invokes inefficient new String(String) constructor</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N253361" style="display: none;">
<a href="#DM_STRING_CTOR">Bug type DM_STRING_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.verifyContainerLogs(LogAggregationService, ApplicationId, ContainerId[])<br/>At TestLogAggregationService.java:[line 755]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N261088');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>new org.apache.hadoop.yarn.server.resourcemanager.rmapp.MockRMApp(int, long, RMAppState) uses the nextDouble method of Random to generate a random integer; using nextInt is more efficient</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N261088" style="display: none;">
<a href="#DM_NEXTINT_VIA_NEXTDOUBLE">Bug type DM_NEXTINT_VIA_NEXTDOUBLE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.rmapp.MockRMApp<br/>In method new org.apache.hadoop.yarn.server.resourcemanager.rmapp.MockRMApp(int, long, RMAppState)<br/>At MockRMApp.java:[line 44]<br/>Another occurrence at MockRMApp.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N258491');">
<td>
<span class="priority-2">Dm</span>
</td>
<td>org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions.getMockRMNodeStatusEvent() invokes inefficient Boolean constructor; use Boolean.valueOf(...) instead</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N258491" style="display: none;">
<a href="#DM_BOOLEAN_CTOR">Bug type DM_BOOLEAN_CTOR (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions.getMockRMNodeStatusEvent()<br/>At TestRMNodeTransitions.java:[line 150]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70491');">
<td>
<span class="priority-2">SBSC</span>
</td>
<td>org.apache.hadoop.contrib.utils.join.SampleDataJoinReducer.combine(Object[], Object[]) concatenates strings using + in a loop</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70491" style="display: none;">
<a href="#SBSC_USE_STRINGBUFFER_CONCATENATION">Bug type SBSC_USE_STRINGBUFFER_CONCATENATION (click for details)</a>
<br/>In class org.apache.hadoop.contrib.utils.join.SampleDataJoinReducer<br/>In method org.apache.hadoop.contrib.utils.join.SampleDataJoinReducer.combine(Object[], Object[])<br/>At SampleDataJoinReducer.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N117703');">
<td>
<span class="priority-2">SBSC</span>
</td>
<td>org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement.checkBlocks(DatanodeInfo[], String, long, short, DFSClient) concatenates strings using + in a loop</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N117703" style="display: none;">
<a href="#SBSC_USE_STRINGBUFFER_CONCATENATION">Bug type SBSC_USE_STRINGBUFFER_CONCATENATION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBlockReplacement.checkBlocks(DatanodeInfo[], String, long, short, DFSClient)<br/>At TestBlockReplacement.java:[line 240]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N125006');">
<td>
<span class="priority-2">SBSC</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.FileNameGenerator.getNextDirName(String) concatenates strings using + in a loop</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N125006" style="display: none;">
<a href="#SBSC_USE_STRINGBUFFER_CONCATENATION">Bug type SBSC_USE_STRINGBUFFER_CONCATENATION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FileNameGenerator<br/>In method org.apache.hadoop.hdfs.server.namenode.FileNameGenerator.getNextDirName(String)<br/>At FileNameGenerator.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N132555');">
<td>
<span class="priority-2">SBSC</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.TestLargeDirectoryDelete.createFiles() concatenates strings using + in a loop</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N132555" style="display: none;">
<a href="#SBSC_USE_STRINGBUFFER_CONCATENATION">Bug type SBSC_USE_STRINGBUFFER_CONCATENATION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestLargeDirectoryDelete<br/>In method org.apache.hadoop.hdfs.server.namenode.TestLargeDirectoryDelete.createFiles()<br/>At TestLargeDirectoryDelete.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N160990');">
<td>
<span class="priority-2">SBSC</span>
</td>
<td>org.apache.hadoop.io.nativeio.TestNativeIO.testAccess() concatenates strings using + in a loop</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N160990" style="display: none;">
<a href="#SBSC_USE_STRINGBUFFER_CONCATENATION">Bug type SBSC_USE_STRINGBUFFER_CONCATENATION (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestNativeIO<br/>In method org.apache.hadoop.io.nativeio.TestNativeIO.testAccess()<br/>At TestNativeIO.java:[line 294]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N178023');">
<td>
<span class="priority-2">SBSC</span>
</td>
<td>org.apache.hadoop.mapred.TestTextOutputFormat.testCompress() concatenates strings using + in a loop</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N178023" style="display: none;">
<a href="#SBSC_USE_STRINGBUFFER_CONCATENATION">Bug type SBSC_USE_STRINGBUFFER_CONCATENATION (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestTextOutputFormat<br/>In method org.apache.hadoop.mapred.TestTextOutputFormat.testCompress()<br/>At TestTextOutputFormat.java:[line 224]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N203333');">
<td>
<span class="priority-2">SBSC</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TasksBlockForTest.url(String[]) concatenates strings using + in a loop</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N203333" style="display: none;">
<a href="#SBSC_USE_STRINGBUFFER_CONCATENATION">Bug type SBSC_USE_STRINGBUFFER_CONCATENATION (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TasksBlockForTest<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TasksBlockForTest.url(String[])<br/>At TasksBlockForTest.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N215170');">
<td>
<span class="priority-2">SBSC</span>
</td>
<td>org.apache.hadoop.record.compiler.generated.ParseException.getMessage() concatenates strings using + in a loop</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N215170" style="display: none;">
<a href="#SBSC_USE_STRINGBUFFER_CONCATENATION">Bug type SBSC_USE_STRINGBUFFER_CONCATENATION (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.ParseException<br/>In method org.apache.hadoop.record.compiler.generated.ParseException.getMessage()<br/>At ParseException.java:[line 150]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N215480');">
<td>
<span class="priority-2">SBSC</span>
</td>
<td>org.apache.hadoop.record.compiler.generated.Rcc.ModuleName() concatenates strings using + in a loop</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N215480" style="display: none;">
<a href="#SBSC_USE_STRINGBUFFER_CONCATENATION">Bug type SBSC_USE_STRINGBUFFER_CONCATENATION (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.Rcc<br/>In method org.apache.hadoop.record.compiler.generated.Rcc.ModuleName()<br/>At Rcc.java:[line 217]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N226632');">
<td>
<span class="priority-2">SBSC</span>
</td>
<td>org.apache.hadoop.tools.GetGroupsTestBase.getExpectedOutput(UserGroupInformation) concatenates strings using + in a loop</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N226632" style="display: none;">
<a href="#SBSC_USE_STRINGBUFFER_CONCATENATION">Bug type SBSC_USE_STRINGBUFFER_CONCATENATION (click for details)</a>
<br/>In class org.apache.hadoop.tools.GetGroupsTestBase<br/>In method org.apache.hadoop.tools.GetGroupsTestBase.getExpectedOutput(UserGroupInformation)<br/>At GetGroupsTestBase.java:[line 109]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N272599');">
<td>
<span class="priority-2">SBSC</span>
</td>
<td>org.apache.hadoop.yarn.sls.web.TestSLSWebApp.testSimulatePageHtmlTemplate() concatenates strings using + in a loop</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N272599" style="display: none;">
<a href="#SBSC_USE_STRINGBUFFER_CONCATENATION">Bug type SBSC_USE_STRINGBUFFER_CONCATENATION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.web.TestSLSWebApp<br/>In method org.apache.hadoop.yarn.sls.web.TestSLSWebApp.testSimulatePageHtmlTemplate()<br/>At TestSLSWebApp.java:[line 86]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N272652');">
<td>
<span class="priority-2">SBSC</span>
</td>
<td>org.apache.hadoop.yarn.sls.web.TestSLSWebApp.testTrackPageHtmlTemplate() concatenates strings using + in a loop</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N272652" style="display: none;">
<a href="#SBSC_USE_STRINGBUFFER_CONCATENATION">Bug type SBSC_USE_STRINGBUFFER_CONCATENATION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.sls.web.TestSLSWebApp<br/>In method org.apache.hadoop.yarn.sls.web.TestSLSWebApp.testTrackPageHtmlTemplate()<br/>At TestSLSWebApp.java:[line 106]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N275074');">
<td>
<span class="priority-2">SBSC</span>
</td>
<td>org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.parsingProcStatAndCpuFile() concatenates strings using + in a loop</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N275074" style="display: none;">
<a href="#SBSC_USE_STRINGBUFFER_CONCATENATION">Bug type SBSC_USE_STRINGBUFFER_CONCATENATION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin<br/>In method org.apache.hadoop.yarn.util.TestLinuxResourceCalculatorPlugin.parsingProcStatAndCpuFile()<br/>At TestLinuxResourceCalculatorPlugin.java:[line 154]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N114913');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.blockmanagement.TestNodeCount.REPLICATION_FACTOR; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N114913" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.blockmanagement.TestNodeCount<br/>Field org.apache.hadoop.hdfs.server.blockmanagement.TestNodeCount.REPLICATION_FACTOR<br/>At TestNodeCount.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N114964');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.blockmanagement.TestNodeCount.TIMEOUT; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N114964" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.blockmanagement.TestNodeCount<br/>Field org.apache.hadoop.hdfs.server.blockmanagement.TestNodeCount.TIMEOUT<br/>At TestNodeCount.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N118356');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.block_size; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N118356" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure<br/>Field org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.block_size<br/>At TestDataNodeVolumeFailure.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N118407');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.blocks_num; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N118407" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure<br/>Field org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.blocks_num<br/>At TestDataNodeVolumeFailure.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N118458');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.dn_num; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N118458" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure<br/>Field org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.dn_num<br/>At TestDataNodeVolumeFailure.java:[line 73]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N118509');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.repl; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N118509" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure<br/>Field org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.repl<br/>At TestDataNodeVolumeFailure.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N118767');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.WAIT_FOR_DEATH; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N118767" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration<br/>Field org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.WAIT_FOR_DEATH<br/>At TestDataNodeVolumeFailureToleration.java:[line 56]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N118818');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.WAIT_FOR_HEARTBEATS; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N118818" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration<br/>Field org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration.WAIT_FOR_HEARTBEATS<br/>At TestDataNodeVolumeFailureToleration.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N120783');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes.nnPort1; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N120783" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes<br/>Field org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes.nnPort1<br/>At TestRefreshNamenodes.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N120834');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes.nnPort2; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N120834" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes<br/>Field org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes.nnPort2<br/>At TestRefreshNamenodes.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N120885');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes.nnPort3; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N120885" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes<br/>Field org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes.nnPort3<br/>At TestRefreshNamenodes.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N120936');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes.nnPort4; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N120936" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes<br/>Field org.apache.hadoop.hdfs.server.datanode.TestRefreshNamenodes.nnPort4<br/>At TestRefreshNamenodes.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N139682');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength.file1Name; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N139682" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength.file1Name<br/>At TestSnapshotFileLength.java:[line 53]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N139733');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength.snapshot1; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N139733" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength.snapshot1<br/>At TestSnapshotFileLength.java:[line 54]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N140223');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.file1Name; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N140223" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.file1Name<br/>At TestSnapshotNameWithInvalidCharacters.java:[line 41]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N140274');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.snapshot1; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N140274" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.snapshot1<br/>At TestSnapshotNameWithInvalidCharacters.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N140325');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.snapshot2; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N140325" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.snapshot2<br/>At TestSnapshotNameWithInvalidCharacters.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N134014');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.namenode.TestNameNodeRetryCacheMetrics.namenodeId; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N134014" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNameNodeRetryCacheMetrics<br/>Field org.apache.hadoop.hdfs.server.namenode.TestNameNodeRetryCacheMetrics.namenodeId<br/>At TestNameNodeRetryCacheMetrics.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N135058');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId.BLOCK_SIZE; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N135058" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId<br/>Field org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId.BLOCK_SIZE<br/>At TestSequentialBlockId.java:[line 54]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N135109');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId.IO_SIZE; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N135109" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId<br/>Field org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId.IO_SIZE<br/>At TestSequentialBlockId.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N135160');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId.REPLICATION; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N135160" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId<br/>Field org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId.REPLICATION<br/>At TestSequentialBlockId.java:[line 56]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N135211');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId.SEED; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N135211" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId<br/>Field org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId.SEED<br/>At TestSequentialBlockId.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N103668');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestDatanodeDeath.numThreads; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N103668" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeDeath<br/>Field org.apache.hadoop.hdfs.TestDatanodeDeath.numThreads<br/>At TestDatanodeDeath.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N103719');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestDatanodeDeath.numberOfFiles; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N103719" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeDeath<br/>Field org.apache.hadoop.hdfs.TestDatanodeDeath.numberOfFiles<br/>At TestDatanodeDeath.java:[line 64]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N105459');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestFileAppend.simulatedStorage; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N105459" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileAppend<br/>Field org.apache.hadoop.hdfs.TestFileAppend.simulatedStorage<br/>At TestFileAppend.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N105711');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestFileAppend2.numAppendsPerThread; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N105711" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileAppend2<br/>Field org.apache.hadoop.hdfs.TestFileAppend2.numAppendsPerThread<br/>At TestFileAppend2.java:[line 69]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N105762');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestFileAppend2.numDatanodes; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N105762" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileAppend2<br/>Field org.apache.hadoop.hdfs.TestFileAppend2.numDatanodes<br/>At TestFileAppend2.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N105813');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestFileAppend2.numThreads; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N105813" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileAppend2<br/>Field org.apache.hadoop.hdfs.TestFileAppend2.numThreads<br/>At TestFileAppend2.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N105864');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestFileAppend2.numberOfFiles; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N105864" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileAppend2<br/>Field org.apache.hadoop.hdfs.TestFileAppend2.numberOfFiles<br/>At TestFileAppend2.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N105915');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestFileAppend2.simulatedStorage; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N105915" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileAppend2<br/>Field org.apache.hadoop.hdfs.TestFileAppend2.simulatedStorage<br/>At TestFileAppend2.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N106561');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestHFlush.fName; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N106561" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestHFlush<br/>Field org.apache.hadoop.hdfs.TestHFlush.fName<br/>At TestHFlush.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N106612');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage.blockSize; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N106612" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage<br/>Field org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage.blockSize<br/>At TestInjectionForSimulatedStorage.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N106663');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage.checksumSize; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N106663" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage<br/>Field org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage.checksumSize<br/>At TestInjectionForSimulatedStorage.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N106714');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage.filesize; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N106714" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage<br/>Field org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage.filesize<br/>At TestInjectionForSimulatedStorage.java:[line 54]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N106765');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage.numBlocks; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N106765" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage<br/>Field org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage.numBlocks<br/>At TestInjectionForSimulatedStorage.java:[line 53]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N106816');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage.numDataNodes; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N106816" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage<br/>Field org.apache.hadoop.hdfs.TestInjectionForSimulatedStorage.numDataNodes<br/>At TestInjectionForSimulatedStorage.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N107533');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestLeaseRenewer.FAKE_AUTHORITY; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N107533" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestLeaseRenewer<br/>Field org.apache.hadoop.hdfs.TestLeaseRenewer.FAKE_AUTHORITY<br/>At TestLeaseRenewer.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N108445');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestRead.BLOCK_SIZE; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N108445" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestRead<br/>Field org.apache.hadoop.hdfs.TestRead.BLOCK_SIZE<br/>At TestRead.java:[line 33]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N110170');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestShortCircuitLocalRead.simulatedStorage; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N110170" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestShortCircuitLocalRead<br/>Field org.apache.hadoop.hdfs.TestShortCircuitLocalRead.simulatedStorage<br/>At TestShortCircuitLocalRead.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N145583');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.util.TestLightWeightHashSet.NUM; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N145583" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestLightWeightHashSet<br/>Field org.apache.hadoop.hdfs.util.TestLightWeightHashSet.NUM<br/>At TestLightWeightHashSet.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N145634');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.util.TestLightWeightLinkedSet.NUM; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N145634" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.util.TestLightWeightLinkedSet<br/>Field org.apache.hadoop.hdfs.util.TestLightWeightLinkedSet.NUM<br/>At TestLightWeightLinkedSet.java:[line 41]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N152701');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.io.compress.TestCodecPool.LEASE_COUNT_ERR; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N152701" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.TestCodecPool<br/>Field org.apache.hadoop.io.compress.TestCodecPool.LEASE_COUNT_ERR<br/>At TestCodecPool.java:[line 27]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N188882');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.mapreduce.TestMapperReducerCleanup.INPUT_DIR; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N188882" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMapperReducerCleanup<br/>Field org.apache.hadoop.mapreduce.TestMapperReducerCleanup.INPUT_DIR<br/>At TestMapperReducerCleanup.java:[line 199]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N188933');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.mapreduce.TestMapperReducerCleanup.OUTPUT_DIR; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N188933" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestMapperReducerCleanup<br/>Field org.apache.hadoop.mapreduce.TestMapperReducerCleanup.OUTPUT_DIR<br/>At TestMapperReducerCleanup.java:[line 200]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N206508');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEntities.confFileName; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N206508" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEntities<br/>Field org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEntities.confFileName<br/>At TestJobHistoryEntities.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N206559');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEntities.historyFileName; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N206559" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEntities<br/>Field org.apache.hadoop.mapreduce.v2.hs.TestJobHistoryEntities.historyFileName<br/>At TestJobHistoryEntities.java:[line 56]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N212056');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.metrics2.lib.TestMutableMetrics.EPSILON; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N212056" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.lib.TestMutableMetrics<br/>Field org.apache.hadoop.metrics2.lib.TestMutableMetrics.EPSILON<br/>At TestMutableMetrics.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N213818');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.nfs.TestNfsExports.address1; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N213818" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.nfs.TestNfsExports<br/>Field org.apache.hadoop.nfs.TestNfsExports.address1<br/>At TestNfsExports.java:[line 29]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N213869');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.nfs.TestNfsExports.address2; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N213869" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.nfs.TestNfsExports<br/>Field org.apache.hadoop.nfs.TestNfsExports.address2<br/>At TestNfsExports.java:[line 30]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N213920');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.nfs.TestNfsExports.hostname1; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N213920" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.nfs.TestNfsExports<br/>Field org.apache.hadoop.nfs.TestNfsExports.hostname1<br/>At TestNfsExports.java:[line 31]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N213971');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.nfs.TestNfsExports.hostname2; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N213971" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.nfs.TestNfsExports<br/>Field org.apache.hadoop.nfs.TestNfsExports.hostname2<br/>At TestNfsExports.java:[line 32]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N223862');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.streaming.TestUnconsumedInput.EXPECTED_OUTPUT_SIZE; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N223862" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestUnconsumedInput<br/>Field org.apache.hadoop.streaming.TestUnconsumedInput.EXPECTED_OUTPUT_SIZE<br/>At TestUnconsumedInput.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N225766');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.test.UnitTestcaseTimeLimit.timeOutSecs; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N225766" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.test.UnitTestcaseTimeLimit<br/>Field org.apache.hadoop.test.UnitTestcaseTimeLimit.timeOutSecs<br/>At UnitTestcaseTimeLimit.java:[line 31]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N250542');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.yarn.server.nodemanager.containermanager.container.TestContainer.FAKE_LOCALIZATION_ERROR; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N250542" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.TestContainer<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.container.TestContainer.FAKE_LOCALIZATION_ERROR<br/>At TestContainer.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N257139');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.yarn.server.resourcemanager.MockNM.httpPort; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N257139" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.MockNM<br/>Field org.apache.hadoop.yarn.server.resourcemanager.MockNM.httpPort<br/>At MockNM.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N265508');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerAllocation.GB; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N265508" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerAllocation<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestContainerAllocation.GB<br/>At TestContainerAllocation.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N257767');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.yarn.server.resourcemanager.TestApplicationMasterService.GB; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N257767" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestApplicationMasterService<br/>Field org.apache.hadoop.yarn.server.resourcemanager.TestApplicationMasterService.GB<br/>At TestApplicationMasterService.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N270798');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.yarn.server.resourcemanager.webapp.TestNodesPage.numberOfActualTableHeaders; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N270798" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.webapp.TestNodesPage<br/>Field org.apache.hadoop.yarn.server.resourcemanager.webapp.TestNodesPage.numberOfActualTableHeaders<br/>At TestNodesPage.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N270849');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.yarn.server.resourcemanager.webapp.TestNodesPage.numberOfNodesPerRack; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N270849" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.webapp.TestNodesPage<br/>Field org.apache.hadoop.yarn.server.resourcemanager.webapp.TestNodesPage.numberOfNodesPerRack<br/>At TestNodesPage.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N270900');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.yarn.server.resourcemanager.webapp.TestNodesPage.numberOfRacks; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N270900" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.webapp.TestNodesPage<br/>Field org.apache.hadoop.yarn.server.resourcemanager.webapp.TestNodesPage.numberOfRacks<br/>At TestNodesPage.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N270951');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.yarn.server.resourcemanager.webapp.TestNodesPage.numberOfThInMetricsTable; should this field be static?</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N270951" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.webapp.TestNodesPage<br/>Field org.apache.hadoop.yarn.server.resourcemanager.webapp.TestNodesPage.numberOfThInMetricsTable<br/>At TestNodesPage.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N271532');">
<td>
<span class="priority-2">SS</span>
</td>
<td>Unread field: org.apache.hadoop.yarn.server.webproxy.TestWebAppProxyServer.proxyAddress; should this field be static?</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N271532" style="display: none;">
<a href="#SS_SHOULD_BE_STATIC">Bug type SS_SHOULD_BE_STATIC (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.webproxy.TestWebAppProxyServer<br/>Field org.apache.hadoop.yarn.server.webproxy.TestWebAppProxyServer.proxyAddress<br/>At TestWebAppProxyServer.java:[line 33]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N139918');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotListing.fsn</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N139918" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotListing<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotListing.fsn<br/>At TestSnapshotListing.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N140765');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshottableDirListing.fsn</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N140765" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshottableDirListing<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshottableDirListing.fsn<br/>At TestSnapshottableDirListing.java:[line 60]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N127030');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens.replication</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N127030" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens<br/>Field org.apache.hadoop.hdfs.server.namenode.TestCheckPointForSecurityTokens.replication<br/>At TestCheckPointForSecurityTokens.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N107876');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestModTime.myrand</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N107876" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestModTime<br/>Field org.apache.hadoop.hdfs.TestModTime.myrand<br/>At TestModTime.java:[line 50]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N109547');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.hdfs.TestSetTimes.myrand</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N109547" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestSetTimes<br/>Field org.apache.hadoop.hdfs.TestSetTimes.myrand<br/>At TestSetTimes.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N158330');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.io.file.tfile.TestTFileComparators.records1stBlock</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N158330" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileComparators<br/>Field org.apache.hadoop.io.file.tfile.TestTFileComparators.records1stBlock<br/>At TestTFileComparators.java:[line 56]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N158381');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.io.file.tfile.TestTFileComparators.records2ndBlock</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N158381" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileComparators<br/>Field org.apache.hadoop.io.file.tfile.TestTFileComparators.records2ndBlock<br/>At TestTFileComparators.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N159940');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.records1stBlock</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N159940" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays<br/>Field org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.records1stBlock<br/>At TestTFileUnsortedByteArrays.java:[line 53]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N159991');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.records2ndBlock</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N159991" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays<br/>Field org.apache.hadoop.io.file.tfile.TestTFileUnsortedByteArrays.records2ndBlock<br/>At TestTFileUnsortedByteArrays.java:[line 54]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N216177');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.record.compiler.generated.RccTokenManager.image</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N216177" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.RccTokenManager<br/>Field org.apache.hadoop.record.compiler.generated.RccTokenManager.image<br/>At RccTokenManager.java:[line 722]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N221942');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.streaming.TestMultipleCachefiles.input</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N221942" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestMultipleCachefiles<br/>Field org.apache.hadoop.streaming.TestMultipleCachefiles.input<br/>At TestMultipleCachefiles.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N223601');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.streaming.TestSymLink.input</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N223601" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.streaming.TestSymLink<br/>Field org.apache.hadoop.streaming.TestSymLink.input<br/>At TestSymLink.java:[line 49]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N228946');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.tools.rumen.Job20LineHistoryEventEmitter.originalSubmitTime</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N228946" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.tools.rumen.Job20LineHistoryEventEmitter<br/>Field org.apache.hadoop.tools.rumen.Job20LineHistoryEventEmitter.originalSubmitTime<br/>At Job20LineHistoryEventEmitter.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N229297');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.tools.rumen.Task20LineHistoryEventEmitter.originalStartTime</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N229297" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.tools.rumen.Task20LineHistoryEventEmitter<br/>Field org.apache.hadoop.tools.rumen.Task20LineHistoryEventEmitter.originalStartTime<br/>At Task20LineHistoryEventEmitter.java:[line 41]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N229348');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.tools.rumen.Task20LineHistoryEventEmitter.originalTaskType</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N229348" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.tools.rumen.Task20LineHistoryEventEmitter<br/>Field org.apache.hadoop.tools.rumen.Task20LineHistoryEventEmitter.originalTaskType<br/>At Task20LineHistoryEventEmitter.java:[line 42]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N229399');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.tools.rumen.TaskAttempt20LineEventEmitter.originalStartTime</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N229399" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.tools.rumen.TaskAttempt20LineEventEmitter<br/>Field org.apache.hadoop.tools.rumen.TaskAttempt20LineEventEmitter.originalStartTime<br/>At TaskAttempt20LineEventEmitter.java:[line 40]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N229450');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.tools.rumen.TaskAttempt20LineEventEmitter.originalTaskType</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N229450" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.tools.rumen.TaskAttempt20LineEventEmitter<br/>Field org.apache.hadoop.tools.rumen.TaskAttempt20LineEventEmitter.originalTaskType<br/>At TaskAttempt20LineEventEmitter.java:[line 41]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N259711');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCNodeUpdates.amService</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N259711" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCNodeUpdates<br/>Field org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCNodeUpdates.amService<br/>At TestAMRMRPCNodeUpdates.java:[line 50]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N259762');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCResponseId.amService</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N259762" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCResponseId<br/>Field org.apache.hadoop.yarn.server.resourcemanager.applicationsmanager.TestAMRMRPCResponseId.amService<br/>At TestAMRMRPCResponseId.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N257260');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.yarn.server.resourcemanager.QueueACLsTestBase.rmAddress</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N257260" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.QueueACLsTestBase<br/>Field org.apache.hadoop.yarn.server.resourcemanager.QueueACLsTestBase.rmAddress<br/>At QueueACLsTestBase.java:[line 78]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N257311');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.yarn.server.resourcemanager.QueueACLsTestBase.rpc</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N257311" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.QueueACLsTestBase<br/>Field org.apache.hadoop.yarn.server.resourcemanager.QueueACLsTestBase.rpc<br/>At QueueACLsTestBase.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N261152');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread field: org.apache.hadoop.yarn.server.resourcemanager.rmapp.MockRMApp.failCount</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N261152" style="display: none;">
<a href="#URF_UNREAD_FIELD">Bug type URF_UNREAD_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.rmapp.MockRMApp<br/>Field org.apache.hadoop.yarn.server.resourcemanager.rmapp.MockRMApp.failCount<br/>At MockRMApp.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N91199');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.fclocal</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N91199" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs<br/>Field org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.fclocal<br/>In TestFcMainOperationsLocalFs.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91246');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.targetOfTests</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91246" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs<br/>Field org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.targetOfTests<br/>In TestFcMainOperationsLocalFs.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N92046');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.fs.viewfs.ViewFsBaseTest.schemeWithAuthority</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N92046" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.ViewFsBaseTest<br/>Field org.apache.hadoop.fs.viewfs.ViewFsBaseTest.schemeWithAuthority<br/>In ViewFsBaseTest.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N92093');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.fs.viewfs.ViewFsBaseTest.xfcViewWithAuthority</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N92093" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.ViewFsBaseTest<br/>Field org.apache.hadoop.fs.viewfs.ViewFsBaseTest.xfcViewWithAuthority<br/>In ViewFsBaseTest.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N130690');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.hdfs.server.namenode.TestFsLimits.inodes</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N130690" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsLimits<br/>Field org.apache.hadoop.hdfs.server.namenode.TestFsLimits.inodes<br/>In TestFsLimits.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N134065');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.hdfs.server.namenode.TestNameNodeRetryCacheMetrics.client</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N134065" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNameNodeRetryCacheMetrics<br/>Field org.apache.hadoop.hdfs.server.namenode.TestNameNodeRetryCacheMetrics.client<br/>In TestNameNodeRetryCacheMetrics.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N135262');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId.datanode</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N135262" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId<br/>Field org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId.datanode<br/>In TestSequentialBlockId.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N135309');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId.dnAddr</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N135309" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId<br/>Field org.apache.hadoop.hdfs.server.namenode.TestSequentialBlockId.dnAddr<br/>In TestSequentialBlockId.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N107927');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.hdfs.TestModTime.excludeFile</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N107927" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestModTime<br/>Field org.apache.hadoop.hdfs.TestModTime.excludeFile<br/>In TestModTime.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N107974');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.hdfs.TestModTime.hostsFile</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N107974" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestModTime<br/>Field org.apache.hadoop.hdfs.TestModTime.hostsFile<br/>In TestModTime.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N109598');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.hdfs.TestSetTimes.excludeFile</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N109598" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestSetTimes<br/>Field org.apache.hadoop.hdfs.TestSetTimes.excludeFile<br/>In TestSetTimes.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N109645');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.hdfs.TestSetTimes.hostsFile</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N109645" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestSetTimes<br/>Field org.apache.hadoop.hdfs.TestSetTimes.hostsFile<br/>In TestSetTimes.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N199819');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.mapreduce.v2.app.MockAppContext.queue</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N199819" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MockAppContext<br/>Field org.apache.hadoop.mapreduce.v2.app.MockAppContext.queue<br/>In MockAppContext.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N216279');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.record.compiler.generated.RccTokenManager.lengthOfMatch</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N216279" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.RccTokenManager<br/>Field org.apache.hadoop.record.compiler.generated.RccTokenManager.lengthOfMatch<br/>In RccTokenManager.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N238252');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.yarn.client.TestApplicationMasterServiceOnHA.appAttempt</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N238252" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.TestApplicationMasterServiceOnHA<br/>Field org.apache.hadoop.yarn.client.TestApplicationMasterServiceOnHA.appAttempt<br/>In TestApplicationMasterServiceOnHA.java</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N255686');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused field: org.apache.hadoop.yarn.server.nodemanager.webapp.MockApp.app</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N255686" style="display: none;">
<a href="#UUF_UNUSED_FIELD">Bug type UUF_UNUSED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.MockApp<br/>Field org.apache.hadoop.yarn.server.nodemanager.webapp.MockApp.app<br/>In MockApp.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89409');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.fs.slive.ConfigExtractor.dumpOptions(ConfigExtractor) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89409" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.ConfigExtractor<br/>In method org.apache.hadoop.fs.slive.ConfigExtractor.dumpOptions(ConfigExtractor)<br/>At ConfigExtractor.java:[line 723]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N89539');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.fs.slive.ConfigMerger.handleOperations(ArgumentParser$ParsedOutput, Configuration, ConfigExtractor) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N89539" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.ConfigMerger<br/>In method org.apache.hadoop.fs.slive.ConfigMerger.handleOperations(ArgumentParser$ParsedOutput, Configuration, ConfigExtractor)<br/>At ConfigMerger.java:[line 110]<br/>Another occurrence at ConfigMerger.java:[line 124]<br/>Another occurrence at ConfigMerger.java:[line 138]<br/>Another occurrence at ConfigMerger.java:[line 153]<br/>Another occurrence at ConfigMerger.java:[line 166]<br/>Another occurrence at ConfigMerger.java:[line 178]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89937');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.fs.slive.ReportWriter.opReport(String, List, PrintWriter) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89937" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.ReportWriter<br/>In method org.apache.hadoop.fs.slive.ReportWriter.opReport(String, List, PrintWriter)<br/>At ReportWriter.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90128');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.fs.slive.SliveTest.writeReport(ConfigExtractor) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90128" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.SliveTest<br/>In method org.apache.hadoop.fs.slive.SliveTest.writeReport(ConfigExtractor)<br/>At SliveTest.java:[line 273]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N90412');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.fs.slive.WeightSelector.configureOperations(ConfigExtractor) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N90412" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.WeightSelector<br/>In method org.apache.hadoop.fs.slive.WeightSelector.configureOperations(ConfigExtractor)<br/>At WeightSelector.java:[line 124]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90465');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.fs.slive.WeightSelector.select(int, int) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90465" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.WeightSelector<br/>In method org.apache.hadoop.fs.slive.WeightSelector.select(int, int)<br/>Field org.apache.hadoop.fs.slive.WeightSelector.operations<br/>At WeightSelector.java:[line 176]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N116502');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.restartNotifyPeers() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N116502" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.DataXceiverServer<br/>In method org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.restartNotifyPeers()<br/>Field org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.peers<br/>At DataXceiverServer.java:[line 234]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N118560');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.verify(String, int) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N118560" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.verify(String, int)<br/>Field org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.block_map<br/>At TestDataNodeVolumeFailure.java:[line 212]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N140659');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotReplication.checkSnapshotFileReplication(Path, Map, short) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N140659" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotReplication<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotReplication.checkSnapshotFileReplication(Path, Map, short)<br/>At TestSnapshotReplication.java:[line 152]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N140712');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotReplication.testReplicationAfterDeletion() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N140712" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotReplication<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotReplication.testReplicationAfterDeletion()<br/>At TestSnapshotReplication.java:[line 225]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N103263');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.hdfs.TestDFSUpgradeFromImage.verifyDir(DistributedFileSystem, Path, CRC32) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N103263" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSUpgradeFromImage<br/>In method org.apache.hadoop.hdfs.TestDFSUpgradeFromImage.verifyDir(DistributedFileSystem, Path, CRC32)<br/>At TestDFSUpgradeFromImage.java:[line 193]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N182867');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapred.gridmix.TestRandomAlgorithm.verifyResults(Map, int, int) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N182867" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestRandomAlgorithm<br/>In method org.apache.hadoop.mapred.gridmix.TestRandomAlgorithm.verifyResults(Map, int, int)<br/>At TestRandomAlgorithm.java:[line 116]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N169061');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapred.QueueManager.getJobQueueInfoMapping() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N169061" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapred.QueueManager<br/>In method org.apache.hadoop.mapred.QueueManager.getJobQueueInfoMapping()<br/>Field org.apache.hadoop.mapred.QueueManager.allQueues<br/>At QueueManager.java:[line 445]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N189612');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N189612" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler<br/>In method org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.serviceStop()<br/>Field org.apache.hadoop.mapreduce.jobhistory.JobHistoryEventHandler.fileMap<br/>At JobHistoryEventHandler.java:[line 345]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N196652');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.task.reduce.TestMerger.writeMapOutput(Configuration, Map) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N196652" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.TestMerger<br/>In method org.apache.hadoop.mapreduce.task.reduce.TestMerger.writeMapOutput(Configuration, Map)<br/>At TestMerger.java:[line 149]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N200660');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.TestRecovery.recoveryChecker(MapTaskImpl, TaskState, Map, ArgumentCaptor, List, long, long) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N200660" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestRecovery<br/>In method org.apache.hadoop.mapreduce.v2.app.TestRecovery.recoveryChecker(MapTaskImpl, TaskState, Map, ArgumentCaptor, List, long, long)<br/>At TestRecovery.java:[line 1462]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N203522');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptId() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N203522" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptId()<br/>At TestAMWebServicesAttempts.java:[line 215]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N203575');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdCounters() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N203575" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdCounters()<br/>At TestAMWebServicesAttempts.java:[line 551]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N203628');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N203628" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdDefault()<br/>At TestAMWebServicesAttempts.java:[line 273]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N203681');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdErrorGeneric(String, String) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N203681" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdErrorGeneric(String, String)<br/>At TestAMWebServicesAttempts.java:[line 372]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N203734');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N203734" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdSlash()<br/>At TestAMWebServicesAttempts.java:[line 244]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N203787');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N203787" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdXML()<br/>At TestAMWebServicesAttempts.java:[line 299]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N203840');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdXMLCounters() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N203840" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptIdXMLCounters()<br/>At TestAMWebServicesAttempts.java:[line 578]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N203893');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttempts() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N203893" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttempts()<br/>At TestAMWebServicesAttempts.java:[line 127]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N203946');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptsDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N203946" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptsDefault()<br/>At TestAMWebServicesAttempts.java:[line 165]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N203999');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptsSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N203999" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptsSlash()<br/>At TestAMWebServicesAttempts.java:[line 146]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N204052');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptsXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N204052" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesAttempts.testTaskAttemptsXML()<br/>At TestAMWebServicesAttempts.java:[line 184]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N204175');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConf() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N204175" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConf()<br/>At TestAMWebServicesJobConf.java:[line 172]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N204228');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConfDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N204228" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConfDefault()<br/>At TestAMWebServicesJobConf.java:[line 207]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N204281');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConfSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N204281" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConfSlash()<br/>At TestAMWebServicesJobConf.java:[line 190]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N204334');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConfXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N204334" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobConf.testJobConfXML()<br/>At TestAMWebServicesJobConf.java:[line 229]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N204461');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttempts() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N204461" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttempts()<br/>At TestAMWebServicesJobs.java:[line 791]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N204514');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttemptsDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N204514" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttemptsDefault()<br/>At TestAMWebServicesJobs.java:[line 827]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N204567');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttemptsSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N204567" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttemptsSlash()<br/>At TestAMWebServicesJobs.java:[line 809]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N204620');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttemptsXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N204620" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobAttemptsXML()<br/>At TestAMWebServicesJobs.java:[line 851]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N204673');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCounters() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N204673" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCounters()<br/>At TestAMWebServicesJobs.java:[line 639]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N204726');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCountersDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N204726" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCountersDefault()<br/>At TestAMWebServicesJobs.java:[line 674]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N204779');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCountersSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N204779" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCountersSlash()<br/>At TestAMWebServicesJobs.java:[line 657]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N204832');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCountersXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N204832" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobCountersXML()<br/>At TestAMWebServicesJobs.java:[line 696]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N204885');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobId() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N204885" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobId()<br/>At TestAMWebServicesJobs.java:[line 208]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N204938');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobIdDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N204938" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobIdDefault()<br/>At TestAMWebServicesJobs.java:[line 244]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N204991');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobIdSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N204991" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.testJobIdSlash()<br/>At TestAMWebServicesJobs.java:[line 227]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N205044');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testJobTaskCountersXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N205044" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testJobTaskCountersXML()<br/>At TestAMWebServicesTasks.java:[line 680]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N205097');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskId() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N205097" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskId()<br/>At TestAMWebServicesTasks.java:[line 280]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N205150');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdCounters() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N205150" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdCounters()<br/>At TestAMWebServicesTasks.java:[line 617]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N205203');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdCountersDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N205203" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdCountersDefault()<br/>At TestAMWebServicesTasks.java:[line 659]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N205256');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdCountersSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N205256" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdCountersSlash()<br/>At TestAMWebServicesTasks.java:[line 638]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N205309');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N205309" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdDefault()<br/>At TestAMWebServicesTasks.java:[line 322]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N205362');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N205362" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdSlash()<br/>At TestAMWebServicesTasks.java:[line 301]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N205415');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N205415" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTaskIdXML()<br/>At TestAMWebServicesTasks.java:[line 503]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N205468');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasks() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N205468" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasks()<br/>At TestAMWebServicesTasks.java:[line 133]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N205521');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N205521" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksDefault()<br/>At TestAMWebServicesTasks.java:[line 152]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N205574');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksQueryMap() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N205574" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksQueryMap()<br/>At TestAMWebServicesTasks.java:[line 216]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N205627');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksQueryReduce() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N205627" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksQueryReduce()<br/>At TestAMWebServicesTasks.java:[line 236]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N205680');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N205680" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksSlash()<br/>At TestAMWebServicesTasks.java:[line 172]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N205733');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N205733" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesTasks.testTasksXML()<br/>At TestAMWebServicesTasks.java:[line 196]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N205982');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.CompletedJob.constructTaskAttemptCompletionEvents() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N205982" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.CompletedJob<br/>In method org.apache.hadoop.mapreduce.v2.hs.CompletedJob.constructTaskAttemptCompletionEvents()<br/>Field org.apache.hadoop.mapreduce.v2.hs.CompletedJob.tasks<br/>At CompletedJob.java:[line 218]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N207394');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAcls.buildHistoryContext(Configuration) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N207394" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAcls<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAcls.buildHistoryContext(Configuration)<br/>At TestHsWebServicesAcls.java:[line 259]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N207447');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptId() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N207447" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptId()<br/>At TestHsWebServicesAttempts.java:[line 228]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N207500');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdCounters() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N207500" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdCounters()<br/>At TestHsWebServicesAttempts.java:[line 569]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N207553');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N207553" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdDefault()<br/>At TestHsWebServicesAttempts.java:[line 286]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N207606');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdErrorGeneric(String, String) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N207606" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdErrorGeneric(String, String)<br/>At TestHsWebServicesAttempts.java:[line 389]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N207659');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N207659" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdSlash()<br/>At TestHsWebServicesAttempts.java:[line 257]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N207712');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N207712" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdXML()<br/>At TestHsWebServicesAttempts.java:[line 312]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N207765');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdXMLCounters() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N207765" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptIdXMLCounters()<br/>At TestHsWebServicesAttempts.java:[line 596]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N207818');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttempts() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N207818" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttempts()<br/>At TestHsWebServicesAttempts.java:[line 137]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N207871');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptsDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N207871" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptsDefault()<br/>At TestHsWebServicesAttempts.java:[line 177]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N207924');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptsSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N207924" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptsSlash()<br/>At TestHsWebServicesAttempts.java:[line 157]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N207977');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptsXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N207977" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesAttempts.testTaskAttemptsXML()<br/>At TestHsWebServicesAttempts.java:[line 196]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N208100');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConf() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N208100" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConf()<br/>At TestHsWebServicesJobConf.java:[line 176]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N208153');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConfDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N208153" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConfDefault()<br/>At TestHsWebServicesJobConf.java:[line 211]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N208206');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConfSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N208206" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConfSlash()<br/>At TestHsWebServicesJobConf.java:[line 194]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N208259');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConfXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N208259" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobConf.testJobConfXML()<br/>At TestHsWebServicesJobConf.java:[line 233]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N208379');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testJobTaskCountersXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N208379" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testJobTaskCountersXML()<br/>At TestHsWebServicesTasks.java:[line 692]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N208432');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskId() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N208432" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskId()<br/>At TestHsWebServicesTasks.java:[line 292]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N208485');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdCounters() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N208485" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdCounters()<br/>At TestHsWebServicesTasks.java:[line 627]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N208538');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdCountersDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N208538" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdCountersDefault()<br/>At TestHsWebServicesTasks.java:[line 671]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N208591');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdCountersSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N208591" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdCountersSlash()<br/>At TestHsWebServicesTasks.java:[line 649]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N208644');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N208644" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdDefault()<br/>At TestHsWebServicesTasks.java:[line 335]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N208697');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N208697" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdSlash()<br/>At TestHsWebServicesTasks.java:[line 313]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N208750');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N208750" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTaskIdXML()<br/>At TestHsWebServicesTasks.java:[line 516]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N208803');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasks() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N208803" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasks()<br/>At TestHsWebServicesTasks.java:[line 142]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N208856');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksDefault() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N208856" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksDefault()<br/>At TestHsWebServicesTasks.java:[line 162]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N208909');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksQueryMap() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N208909" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksQueryMap()<br/>At TestHsWebServicesTasks.java:[line 227]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N208962');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksQueryReduce() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N208962" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksQueryReduce()<br/>At TestHsWebServicesTasks.java:[line 248]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N209015');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksSlash() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N209015" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksSlash()<br/>At TestHsWebServicesTasks.java:[line 182]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N209068');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksXML() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N209068" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesTasks.testTasksXML()<br/>At TestHsWebServicesTasks.java:[line 206]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N210880');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.metrics.spi.AbstractMetricsContext.emitRecords() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N210880" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.metrics.spi.AbstractMetricsContext<br/>In method org.apache.hadoop.metrics.spi.AbstractMetricsContext.emitRecords()<br/>Field org.apache.hadoop.metrics.spi.AbstractMetricsContext.bufferedData<br/>At AbstractMetricsContext.java:[line 314]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N210947');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.metrics.spi.AbstractMetricsContext.getAllRecords() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N210947" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.metrics.spi.AbstractMetricsContext<br/>In method org.apache.hadoop.metrics.spi.AbstractMetricsContext.getAllRecords()<br/>Field org.apache.hadoop.metrics.spi.AbstractMetricsContext.bufferedData<br/>At AbstractMetricsContext.java:[line 334]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N216941');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.security.NetgroupCache.getNetgroups(String, List) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N216941" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.security.NetgroupCache<br/>In method org.apache.hadoop.security.NetgroupCache.getNetgroups(String, List)<br/>Field org.apache.hadoop.security.NetgroupCache.netgroupToUsersMap<br/>At NetgroupCache.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N217652');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.security.TestCredentials.testReadWriteStorage() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N217652" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.security.TestCredentials<br/>In method org.apache.hadoop.security.TestCredentials.testReadWriteStorage()<br/>At TestCredentials.java:[line 130]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N239253');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(String, ContainerId) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N239253" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy<br/>In method org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.getProxy(String, ContainerId)<br/>Field org.apache.hadoop.yarn.client.api.impl.ContainerManagementProtocolProxy.cmProxy<br/>At ContainerManagementProtocolProxy.java:[line 123]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N240169');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.yarn.client.cli.RMAdminCLI.appendHAUsage(StringBuilder) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N240169" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.RMAdminCLI<br/>In method org.apache.hadoop.yarn.client.cli.RMAdminCLI.appendHAUsage(StringBuilder)<br/>Field org.apache.hadoop.yarn.client.cli.RMAdminCLI.USAGE<br/>At RMAdminCLI.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N240236');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.yarn.client.cli.RMAdminCLI.buildUsageMsg(StringBuilder, boolean) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N240236" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.RMAdminCLI<br/>In method org.apache.hadoop.yarn.client.cli.RMAdminCLI.buildUsageMsg(StringBuilder, boolean)<br/>Field org.apache.hadoop.yarn.client.cli.RMAdminCLI.ADMIN_USAGE<br/>At RMAdminCLI.java:[line 138]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N240303');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.yarn.client.cli.RMAdminCLI.buildUsageMsg(StringBuilder, boolean) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N240303" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.RMAdminCLI<br/>In method org.apache.hadoop.yarn.client.cli.RMAdminCLI.buildUsageMsg(StringBuilder, boolean)<br/>Field org.apache.hadoop.yarn.client.cli.RMAdminCLI.USAGE<br/>At RMAdminCLI.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N251882');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.createStatus() makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N251882" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.createStatus()<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ContainerLocalizer.pendingResources<br/>At ContainerLocalizer.java:[line 286]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N254393');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.verifyAcls(Map) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N254393" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.verifyAcls(Map)<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.acls<br/>At TestLogAggregationService.java:[line 836]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N259813');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.containerBasedPreemptOrKill(CSQueue, Resource) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N259813" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy<br/>In method org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.containerBasedPreemptOrKill(CSQueue, Resource)<br/>Field org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy.preempted<br/>At ProportionalCapacityPreemptionPolicy.java:[line 239]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N273084');">
<td>
<span class="priority-2">WMI</span>
</td>
<td>org.apache.hadoop.yarn.state.StateMachineFactory.generateStateGraph(String) makes inefficient use of keySet iterator instead of entrySet iterator</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N273084" style="display: none;">
<a href="#WMI_WRONG_MAP_ITERATOR">Bug type WMI_WRONG_MAP_ITERATOR (click for details)</a>
<br/>In class org.apache.hadoop.yarn.state.StateMachineFactory<br/>In method org.apache.hadoop.yarn.state.StateMachineFactory.generateStateGraph(String)<br/>Field org.apache.hadoop.yarn.state.StateMachineFactory.stateMachineTable<br/>At StateMachineFactory.java:[line 464]</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_SECURITY">Security Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N164847');">
<td>
<span class="priority-2">XSS</span>
</td>
<td>HTTP parameter written to Servlet output in org.apache.hadoop.jmx.JMXJsonServlet.doGet(HttpServletRequest, HttpServletResponse)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N164847" style="display: none;">
<a href="#XSS_REQUEST_PARAMETER_TO_SERVLET_WRITER">Bug type XSS_REQUEST_PARAMETER_TO_SERVLET_WRITER (click for details)</a>
<br/>In class org.apache.hadoop.jmx.JMXJsonServlet<br/>In method org.apache.hadoop.jmx.JMXJsonServlet.doGet(HttpServletRequest, HttpServletResponse)<br/>Parameter "callback"<br/>Value generated at JMXJsonServlet.java:[line 166]<br/>At JMXJsonServlet.java:[line 169]</p>
</td>
</tr>
</table>
<h2>
<a name="Warnings_STYLE">Dodgy code Warnings</a>
</h2>
<table class="warningtable" width="100%" cellspacing="0">
<tr class="tableheader">
<th align="left">Code</th>
<th align="left">Warning</th>
</tr>
<tr class="tablerow1" onclick="toggleRow('N65602');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.cli.TestHDFSCLI.setUp(), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N65602" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.cli.TestHDFSCLI<br/>In method org.apache.hadoop.cli.TestHDFSCLI.setUp()<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestHDFSCLI.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N87916');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.fs.permission.TestStickyBit.initCluster(boolean), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N87916" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.fs.permission.TestStickyBit<br/>In method org.apache.hadoop.fs.permission.TestStickyBit.initCluster(boolean)<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestStickyBit.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75176');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.fs.SymlinkBaseTest.testRenameDirToDanglingSymlink(), since all java.io.IOException are instances of java.io.IOException</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75176" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.fs.SymlinkBaseTest<br/>In method org.apache.hadoop.fs.SymlinkBaseTest.testRenameDirToDanglingSymlink()<br/>Actual type java.io.IOException<br/>Expected java.io.IOException<br/>At SymlinkBaseTest.java:[line 951]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N75256');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.fs.SymlinkBaseTest.testRenameDirToSymlinkToDir(), since all java.io.IOException are instances of java.io.IOException</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N75256" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.fs.SymlinkBaseTest<br/>In method org.apache.hadoop.fs.SymlinkBaseTest.testRenameDirToSymlinkToDir()<br/>Actual type java.io.IOException<br/>Expected java.io.IOException<br/>At SymlinkBaseTest.java:[line 915]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75336');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.fs.SymlinkBaseTest.testRenameDirToSymlinkToFile(), since all java.io.IOException are instances of java.io.IOException</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75336" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.fs.SymlinkBaseTest<br/>In method org.apache.hadoop.fs.SymlinkBaseTest.testRenameDirToSymlinkToFile()<br/>Actual type java.io.IOException<br/>Expected java.io.IOException<br/>At SymlinkBaseTest.java:[line 934]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N75416');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.fs.SymlinkBaseTest.testRenameFileToDestViaSymlink(), since all java.io.IOException are instances of java.io.IOException</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N75416" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.fs.SymlinkBaseTest<br/>In method org.apache.hadoop.fs.SymlinkBaseTest.testRenameFileToDestViaSymlink()<br/>Actual type java.io.IOException<br/>Expected java.io.IOException<br/>At SymlinkBaseTest.java:[line 859]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N75496');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.fs.SymlinkBaseTest.testRenameSymlinkToExistingDir(), since all java.io.IOException are instances of java.io.IOException</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N75496" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.fs.SymlinkBaseTest<br/>In method org.apache.hadoop.fs.SymlinkBaseTest.testRenameSymlinkToExistingDir()<br/>Actual type java.io.IOException<br/>Expected java.io.IOException<br/>At SymlinkBaseTest.java:[line 1081]<br/>Another occurrence at SymlinkBaseTest.java:[line 1088]<br/>Another occurrence at SymlinkBaseTest.java:[line 1097]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95123');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.fs.FSDataInputStream to org.apache.hadoop.hdfs.client.HdfsDataInputStream in org.apache.hadoop.hdfs.DFSTestUtil.getAllBlocks(FSDataInputStream)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95123" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.DFSTestUtil<br/>In method org.apache.hadoop.hdfs.DFSTestUtil.getAllBlocks(FSDataInputStream)<br/>Actual type org.apache.hadoop.fs.FSDataInputStream<br/>Expected org.apache.hadoop.hdfs.client.HdfsDataInputStream<br/>Value loaded from in<br/>At DFSTestUtil.java:[line 659]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N100108');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.hdfs.TestDFSShell.testAppendToFile(), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N100108" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testAppendToFile()<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestDFSShell.java:[line 1801]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100188');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.hdfs.TestDFSShell.testAppendToFileBadArgs(), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100188" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testAppendToFileBadArgs()<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestDFSShell.java:[line 1840]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N100268');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.hdfs.TestDFSShell.testCopyToLocal(), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N100268" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testCopyToLocal()<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestDFSShell.java:[line 691]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100348');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.hdfs.TestDFSShell.testDFSShell(), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100348" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testDFSShell()<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestDFSShell.java:[line 1031]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N100428');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.hdfs.TestDFSShell.testPut(), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N100428" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testPut()<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestDFSShell.java:[line 235]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N100508');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.hdfs.TestDFSShell.testRecrusiveRm(), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N100508" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testRecrusiveRm()<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestDFSShell.java:[line 162]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N100588');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.hdfs.TestDFSShell.testZeroSizeFile(), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N100588" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSShell<br/>In method org.apache.hadoop.hdfs.TestDFSShell.testZeroSizeFile()<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestDFSShell.java:[line 119]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N107729');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.hdfs.TestModTime.testModTime(), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N107729" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestModTime<br/>In method org.apache.hadoop.hdfs.TestModTime.testModTime()<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestModTime.java:[line 98]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N108088');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.hdfs.TestQuota.testQuotaCommands(), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N108088" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestQuota<br/>In method org.apache.hadoop.hdfs.TestQuota.testQuotaCommands()<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestQuota.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N108168');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.hdfs.TestQuota.testSpaceCommands(), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N108168" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestQuota<br/>In method org.apache.hadoop.hdfs.TestQuota.testSpaceCommands()<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestQuota.java:[line 543]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N109692');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.hdfs.TestSetrepIncreasing.setrep(int, int, boolean), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N109692" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestSetrepIncreasing<br/>In method org.apache.hadoop.hdfs.TestSetrepIncreasing.setrep(int, int, boolean)<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestSetrepIncreasing.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N109102');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.hdfs.TestSetTimes.testTimes(), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N109102" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestSetTimes<br/>In method org.apache.hadoop.hdfs.TestSetTimes.testTimes()<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestSetTimes.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N109182');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.hdfs.TestSetTimes.testTimesAtClose(), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N109182" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestSetTimes<br/>In method org.apache.hadoop.hdfs.TestSetTimes.testTimesAtClose()<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestSetTimes.java:[line 244]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N162290');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.ipc.TestMRCJCSocketFactory.testSocketFactory(), since all org.apache.hadoop.hdfs.DistributedFileSystem are instances of org.apache.hadoop.hdfs.DistributedFileSystem</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N162290" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestMRCJCSocketFactory<br/>In method org.apache.hadoop.ipc.TestMRCJCSocketFactory.testSocketFactory()<br/>Actual type org.apache.hadoop.hdfs.DistributedFileSystem<br/>Expected org.apache.hadoop.hdfs.DistributedFileSystem<br/>At TestMRCJCSocketFactory.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N193457');">
<td>
<span class="priority-2">BC</span>
</td>
<td>instanceof will always return true for all non-null values in org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbort(), since all java.io.IOException are instances of java.io.IOException</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N193457" style="display: none;">
<a href="#BC_VACUOUS_INSTANCEOF">Bug type BC_VACUOUS_INSTANCEOF (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter<br/>In method org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.testFailAbort()<br/>Actual type java.io.IOException<br/>Expected java.io.IOException<br/>At TestFileOutputCommitter.java:[line 334]<br/>Another occurrence at TestFileOutputCommitter.java:[line 350]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N249363');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEvent to org.apache.hadoop.yarn.server.nodemanager.CMgrCompletedAppsEvent in org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.handle(ContainerManagerEvent)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N249363" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.handle(ContainerManagerEvent)<br/>Actual type org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEvent<br/>Expected org.apache.hadoop.yarn.server.nodemanager.CMgrCompletedAppsEvent<br/>Value loaded from event<br/>At ContainerManagerImpl.java:[line 858]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N249449');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEvent to org.apache.hadoop.yarn.server.nodemanager.CMgrCompletedContainersEvent in org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.handle(ContainerManagerEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N249449" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl.handle(ContainerManagerEvent)<br/>Actual type org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEvent<br/>Expected org.apache.hadoop.yarn.server.nodemanager.CMgrCompletedContainersEvent<br/>Value loaded from event<br/>At ContainerManagerImpl.java:[line 873]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N251949');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.ResourceEvent to org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.ResourceReleaseEvent in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalResourcesTrackerImpl.handle(ResourceEvent)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N251949" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalResourcesTrackerImpl<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalResourcesTrackerImpl.handle(ResourceEvent)<br/>Actual type org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.ResourceEvent<br/>Expected org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.ResourceReleaseEvent<br/>Value loaded from event<br/>At LocalResourcesTrackerImpl.java:[line 136]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N252219');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEvent to org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.ApplicationLocalizationEvent in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handle(LocalizationEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N252219" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handle(LocalizationEvent)<br/>Actual type org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEvent<br/>Expected org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.ApplicationLocalizationEvent<br/>Value loaded from event<br/>At ResourceLocalizationService.java:[line 310]<br/>Another occurrence at ResourceLocalizationService.java:[line 323]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N252316');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEvent to org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.ContainerLocalizationCleanupEvent in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handle(LocalizationEvent)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N252316" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handle(LocalizationEvent)<br/>Actual type org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEvent<br/>Expected org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.ContainerLocalizationCleanupEvent<br/>Value loaded from event<br/>At ResourceLocalizationService.java:[line 320]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N252402');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEvent to org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.ContainerLocalizationRequestEvent in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handle(LocalizationEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N252402" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService.handle(LocalizationEvent)<br/>Actual type org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEvent<br/>Expected org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.ContainerLocalizationRequestEvent<br/>Value loaded from event<br/>At ResourceLocalizationService.java:[line 314]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N252749');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEvent to org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerAppFinishedEvent in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogHandlerEvent)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N252749" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogHandlerEvent)<br/>Actual type org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEvent<br/>Expected org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerAppFinishedEvent<br/>Value loaded from event<br/>At LogAggregationService.java:[line 425]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N252835');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEvent to org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerAppStartedEvent in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogHandlerEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N252835" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogHandlerEvent)<br/>Actual type org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEvent<br/>Expected org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerAppStartedEvent<br/>Value loaded from event<br/>At LogAggregationService.java:[line 411]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N252921');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEvent to org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerContainerFinishedEvent in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogHandlerEvent)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N252921" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.LogAggregationService.handle(LogHandlerEvent)<br/>Actual type org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEvent<br/>Expected org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerContainerFinishedEvent<br/>Value loaded from event<br/>At LogAggregationService.java:[line 419]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N254460');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEvent to org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerAppFinishedEvent in org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler.handle(LogHandlerEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N254460" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler.handle(LogHandlerEvent)<br/>Actual type org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEvent<br/>Expected org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerAppFinishedEvent<br/>Value loaded from event<br/>At NonAggregatingLogHandler.java:[line 117]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N254546');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEvent to org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerAppStartedEvent in org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler.handle(LogHandlerEvent)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N254546" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler.handle(LogHandlerEvent)<br/>Actual type org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEvent<br/>Expected org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerAppStartedEvent<br/>Value loaded from event<br/>At NonAggregatingLogHandler.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N254693');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEvent to org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainerStartMonitoringEvent in org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.handle(ContainersMonitorEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N254693" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl.handle(ContainersMonitorEvent)<br/>Actual type org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEvent<br/>Expected org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainerStartMonitoringEvent<br/>Value loaded from monitoringEvent<br/>At ContainersMonitorImpl.java:[line 536]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N261828');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAddedSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N261828" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAddedSchedulerEvent<br/>Value loaded from event<br/>At CapacityScheduler.java:[line 884]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N261914');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAttemptAddedSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N261914" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAttemptAddedSchedulerEvent<br/>Value loaded from event<br/>At CapacityScheduler.java:[line 898]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N262000');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAttemptRemovedSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N262000" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAttemptRemovedSchedulerEvent<br/>Value loaded from event<br/>At CapacityScheduler.java:[line 906]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N262086');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppRemovedSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N262086" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppRemovedSchedulerEvent<br/>Value loaded from event<br/>At CapacityScheduler.java:[line 891]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N262172');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.ContainerExpiredSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N262172" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.ContainerExpiredSchedulerEvent<br/>Value loaded from event<br/>At CapacityScheduler.java:[line 915]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N262258');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeAddedSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N262258" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeAddedSchedulerEvent<br/>Value loaded from event<br/>At CapacityScheduler.java:[line 862]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N262344');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeRemovedSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N262344" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeRemovedSchedulerEvent<br/>Value loaded from event<br/>At CapacityScheduler.java:[line 868]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N262430');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeUpdateSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N262430" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeUpdateSchedulerEvent<br/>Value loaded from event<br/>At CapacityScheduler.java:[line 874]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N269418');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAddedSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N269418" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAddedSchedulerEvent<br/>Value loaded from event<br/>At FifoScheduler.java:[line 756]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N269504');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAttemptAddedSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N269504" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAttemptAddedSchedulerEvent<br/>Value loaded from event<br/>At FifoScheduler.java:[line 770]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N269590');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAttemptRemovedSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N269590" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppAttemptRemovedSchedulerEvent<br/>Value loaded from event<br/>At FifoScheduler.java:[line 778]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N269676');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppRemovedSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N269676" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.AppRemovedSchedulerEvent<br/>Value loaded from event<br/>At FifoScheduler.java:[line 763]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N269762');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.ContainerExpiredSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N269762" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.ContainerExpiredSchedulerEvent<br/>Value loaded from event<br/>At FifoScheduler.java:[line 793]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N269848');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeAddedSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N269848" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeAddedSchedulerEvent<br/>Value loaded from event<br/>At FifoScheduler.java:[line 737]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N269934');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeRemovedSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N269934" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeRemovedSchedulerEvent<br/>Value loaded from event<br/>At FifoScheduler.java:[line 743]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N270020');">
<td>
<span class="priority-2">BC</span>
</td>
<td>Unchecked/unconfirmed cast from org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent to org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeUpdateSchedulerEvent in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N270020" style="display: none;">
<a href="#BC_UNCONFIRMED_CAST">Bug type BC_UNCONFIRMED_CAST (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fifo.FifoScheduler.handle(SchedulerEvent)<br/>Actual type org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.SchedulerEvent<br/>Expected org.apache.hadoop.yarn.server.resourcemanager.scheduler.event.NodeUpdateSchedulerEvent<br/>Value loaded from event<br/>At FifoScheduler.java:[line 749]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71289');">
<td>
<span class="priority-2">BSHIFT</span>
</td>
<td>Unsigned right shift cast to short/byte in org.apache.hadoop.examples.terasort.Unsigned16.getHexDigit(int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71289" style="display: none;">
<a href="#ICAST_QUESTIONABLE_UNSIGNED_RIGHT_SHIFT">Bug type ICAST_QUESTIONABLE_UNSIGNED_RIGHT_SHIFT (click for details)</a>
<br/>In class org.apache.hadoop.examples.terasort.Unsigned16<br/>In method org.apache.hadoop.examples.terasort.Unsigned16.getHexDigit(int)<br/>At Unsigned16.java:[line 181]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N122396');">
<td>
<span class="priority-2">BSHIFT</span>
</td>
<td>Unsigned right shift cast to short/byte in org.apache.hadoop.hdfs.server.namenode.CachedBlock.getReplication()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N122396" style="display: none;">
<a href="#ICAST_QUESTIONABLE_UNSIGNED_RIGHT_SHIFT">Bug type ICAST_QUESTIONABLE_UNSIGNED_RIGHT_SHIFT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.CachedBlock<br/>In method org.apache.hadoop.hdfs.server.namenode.CachedBlock.getReplication()<br/>At CachedBlock.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99849');">
<td>
<span class="priority-2">DB</span>
</td>
<td>org.apache.hadoop.hdfs.TestDFSPermission.createAndCheckPermission(TestDFSPermission$OpType, Path, short, FsPermission, boolean) uses the same code for two branches</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99849" style="display: none;">
<a href="#DB_DUPLICATE_BRANCHES">Bug type DB_DUPLICATE_BRANCHES (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSPermission<br/>In method org.apache.hadoop.hdfs.TestDFSPermission.createAndCheckPermission(TestDFSPermission$OpType, Path, short, FsPermission, boolean)<br/>At TestDFSPermission.java:[line 235]<br/>At TestDFSPermission.java:[line 235]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N66295');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to y in org.apache.hadoop.conf.TestConfiguration.testEnum()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N66295" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfiguration<br/>In method org.apache.hadoop.conf.TestConfiguration.testEnum()<br/>Local variable named y<br/>At TestConfiguration.java:[line 735]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N68703');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to properties in org.apache.hadoop.conf.TestConfigurationSubclass.testReload()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N68703" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.conf.TestConfigurationSubclass<br/>In method org.apache.hadoop.conf.TestConfigurationSubclass.testReload()<br/>Local variable named properties<br/>At TestConfigurationSubclass.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69349');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to nn1 in org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir.testFailoverWithBK()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69349" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir<br/>In method org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir.testFailoverWithBK()<br/>Local variable named nn1<br/>At TestBookKeeperAsHASharedDir.java:[line 106]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69419');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to nn2 in org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir.testFailoverWithBK()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69419" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir<br/>In method org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir.testFailoverWithBK()<br/>Local variable named nn2<br/>At TestBookKeeperAsHASharedDir.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69489');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to nn1 in org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir.testFailoverWithFailingBKCluster()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69489" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir<br/>In method org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir.testFailoverWithFailingBKCluster()<br/>Local variable named nn1<br/>At TestBookKeeperAsHASharedDir.java:[line 163]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69559');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to nn2 in org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir.testFailoverWithFailingBKCluster()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69559" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir<br/>In method org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir.testFailoverWithFailingBKCluster()<br/>Local variable named nn2<br/>At TestBookKeeperAsHASharedDir.java:[line 164]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69629');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to nn2 in org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir.testMultiplePrimariesStarted()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69629" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir<br/>In method org.apache.hadoop.contrib.bkjournal.TestBookKeeperAsHASharedDir.testMultiplePrimariesStarted()<br/>Local variable named nn2<br/>At TestBookKeeperAsHASharedDir.java:[line 237]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71077');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to max in org.apache.hadoop.examples.pi.math.TestLongLong.testMultiplication()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71077" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.examples.pi.math.TestLongLong<br/>In method org.apache.hadoop.examples.pi.math.TestLongLong.testMultiplication()<br/>Local variable named max<br/>At TestLongLong.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89108');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to item in org.apache.hadoop.fs.shell.TestPathData.testInvalidWindowsPath()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89108" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.fs.shell.TestPathData<br/>In method org.apache.hadoop.fs.shell.TestPathData.testInvalidWindowsPath()<br/>Local variable named item<br/>At TestPathData.java:[line 164]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N75598');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to stats in org.apache.hadoop.fs.SymlinkBaseTest.testCreateLinkUsingRelPaths()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N75598" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.fs.SymlinkBaseTest<br/>In method org.apache.hadoop.fs.SymlinkBaseTest.testCreateLinkUsingRelPaths()<br/>Local variable named stats<br/>At SymlinkBaseTest.java:[line 456]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78364');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to fs in org.apache.hadoop.fs.TestFileSystem.testFsClose()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78364" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileSystem<br/>In method org.apache.hadoop.fs.TestFileSystem.testFsClose()<br/>Local variable named fs<br/>At TestFileSystem.java:[line 577]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N78574');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to files in org.apache.hadoop.fs.TestFileUtil.testListAPI()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N78574" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testListAPI()<br/>Local variable named files<br/>At TestFileUtil.java:[line 185]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N78641');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to files in org.apache.hadoop.fs.TestFileUtil.testListFiles()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N78641" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestFileUtil<br/>In method org.apache.hadoop.fs.TestFileUtil.testListFiles()<br/>Local variable named files<br/>At TestFileUtil.java:[line 158]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N83940');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to item in org.apache.hadoop.fs.TestPath.testInvalidWindowsPaths()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N83940" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestPath<br/>In method org.apache.hadoop.fs.TestPath.testInvalidWindowsPaths()<br/>Local variable named item<br/>At TestPath.java:[line 267]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N91591');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to status in org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testCreateNonRecursive()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N91591" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest<br/>In method org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testCreateNonRecursive()<br/>Local variable named status<br/>At ViewFileSystemBaseTest.java:[line 683]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N95736');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to curDatanodesNum in org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(Configuration, int, StorageType, boolean, HdfsServerConstants$StartupOption, String[], String[], long[], boolean, boolean, boolean, Configuration[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N95736" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.MiniDFSCluster<br/>In method org.apache.hadoop.hdfs.MiniDFSCluster.startDataNodes(Configuration, int, StorageType, boolean, HdfsServerConstants$StartupOption, String[], String[], long[], boolean, boolean, boolean, Configuration[])<br/>Local variable named curDatanodesNum<br/>At MiniDFSCluster.java:[line 1337]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N96423');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to curDatanodesNum in org.apache.hadoop.hdfs.MiniDFSClusterWithNodeGroup.startDataNodes(Configuration, int, StorageType, boolean, HdfsServerConstants$StartupOption, String[], String[], String[], long[], boolean, boolean, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N96423" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.MiniDFSClusterWithNodeGroup<br/>In method org.apache.hadoop.hdfs.MiniDFSClusterWithNodeGroup.startDataNodes(Configuration, int, StorageType, boolean, HdfsServerConstants$StartupOption, String[], String[], String[], long[], boolean, boolean, boolean)<br/>Local variable named curDatanodesNum<br/>At MiniDFSClusterWithNodeGroup.java:[line 183]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N113568');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to cluster in org.apache.hadoop.hdfs.qjournal.TestNNWithQJM.testMismatchedNNIsRejected()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N113568" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.qjournal.TestNNWithQJM<br/>In method org.apache.hadoop.hdfs.qjournal.TestNNWithQJM.testMismatchedNNIsRejected()<br/>Local variable named cluster<br/>At TestNNWithQJM.java:[line 196]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N115015');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to blocksInvalidateWorkPct in org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy.testGetInvalidateWorkPctPerIteration_GreaterThanOne()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N115015" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy<br/>In method org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy.testGetInvalidateWorkPctPerIteration_GreaterThanOne()<br/>Local variable named blocksInvalidateWorkPct<br/>At TestReplicationPolicy.java:[line 958]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N115088');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to blocksInvalidateWorkPct in org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy.testGetInvalidateWorkPctPerIteration_NegativeValue()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N115088" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy<br/>In method org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy.testGetInvalidateWorkPctPerIteration_NegativeValue()<br/>Local variable named blocksInvalidateWorkPct<br/>At TestReplicationPolicy.java:[line 940]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N115161');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to blocksReplWorkMultiplier in org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy.testGetReplWorkMultiplier()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N115161" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy<br/>In method org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicy.testGetReplWorkMultiplier()<br/>Local variable named blocksReplWorkMultiplier<br/>At TestReplicationPolicy.java:[line 981]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N115692');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to blocks in org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase.blockReport_03()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N115692" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase<br/>In method org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase.blockReport_03()<br/>Local variable named blocks<br/>At BlockReportTestBase.java:[line 330]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N119908');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to current in org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.testUncachingBlocksBeforeCachingFinishes()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N119908" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache<br/>In method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.testUncachingBlocksBeforeCachingFinishes()<br/>Local variable named current<br/>At TestFsDatasetCache.java:[line 417]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N137853');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to aclSpec in org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.testRemoveAclExceedsQuota()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N137853" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.testRemoveAclExceedsQuota()<br/>Local variable named aclSpec<br/>At TestAclWithSnapshot.java:[line 644]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N140816');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to loadingFsImageDelegationKeysTime in org.apache.hadoop.hdfs.server.namenode.startupprogress.TestStartupProgress.testElapsedTime()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N140816" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.startupprogress.TestStartupProgress<br/>In method org.apache.hadoop.hdfs.server.namenode.startupprogress.TestStartupProgress.testElapsedTime()<br/>Local variable named loadingFsImageDelegationKeysTime<br/>At TestStartupProgress.java:[line 132]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N126174');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to val in org.apache.hadoop.hdfs.server.namenode.TestAuditLogs.testAuditHftp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N126174" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestAuditLogs<br/>In method org.apache.hadoop.hdfs.server.namenode.TestAuditLogs.testAuditHftp()<br/>Local variable named val<br/>At TestAuditLogs.java:[line 239]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N128696');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to cluster in org.apache.hadoop.hdfs.server.namenode.TestEditLog.testEditChecksum()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N128696" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestEditLog<br/>In method org.apache.hadoop.hdfs.server.namenode.TestEditLog.testEditChecksum()<br/>Local variable named cluster<br/>At TestEditLog.java:[line 610]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N130084');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to rand in org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.testWhenFavoredNodesNotPresent()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N130084" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFavoredNodesEndToEnd.testWhenFavoredNodesNotPresent()<br/>Local variable named rand<br/>At TestFavoredNodesEndToEnd.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N131205');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to path in org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckFileNotFound()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N131205" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsck.testFsckFileNotFound()<br/>Local variable named path<br/>At TestFsck.java:[line 1004]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N129737');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to cluster in org.apache.hadoop.hdfs.server.namenode.TestFSEditLogLoader.testDisplayRecentEditLogOpCodes()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N129737" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFSEditLogLoader<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFSEditLogLoader.testDisplayRecentEditLogOpCodes()<br/>Local variable named cluster<br/>At TestFSEditLogLoader.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N129804');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to inodeFile in org.apache.hadoop.hdfs.server.namenode.TestFSPermissionChecker.testAclGroupTraverseDeny()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N129804" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFSPermissionChecker<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFSPermissionChecker.testAclGroupTraverseDeny()<br/>Local variable named inodeFile<br/>At TestFSPermissionChecker.java:[line 205]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N129874');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to inodeFile in org.apache.hadoop.hdfs.server.namenode.TestFSPermissionChecker.testAclGroupTraverseDenyOnlyDefaultEntries()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N129874" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFSPermissionChecker<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFSPermissionChecker.testAclGroupTraverseDenyOnlyDefaultEntries()<br/>Local variable named inodeFile<br/>At TestFSPermissionChecker.java:[line 227]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N129944');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to inodeFile in org.apache.hadoop.hdfs.server.namenode.TestFSPermissionChecker.testAclNamedGroupTraverseDeny()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N129944" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFSPermissionChecker<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFSPermissionChecker.testAclNamedGroupTraverseDeny()<br/>Local variable named inodeFile<br/>At TestFSPermissionChecker.java:[line 312]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N130014');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to inodeFile in org.apache.hadoop.hdfs.server.namenode.TestFSPermissionChecker.testAclNamedUserTraverseDeny()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N130014" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFSPermissionChecker<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFSPermissionChecker.testAclNamedUserTraverseDeny()<br/>Local variable named inodeFile<br/>At TestFSPermissionChecker.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N132260');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to nodes in org.apache.hadoop.hdfs.server.namenode.TestHostsFiles.testHostsIncludeForDeadCount()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N132260" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestHostsFiles<br/>In method org.apache.hadoop.hdfs.server.namenode.TestHostsFiles.testHostsIncludeForDeadCount()<br/>Local variable named nodes<br/>At TestHostsFiles.java:[line 170]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N134701');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to rootmtime in org.apache.hadoop.hdfs.server.namenode.TestParallelImageWrite.testRestartDFS()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N134701" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestParallelImageWrite<br/>In method org.apache.hadoop.hdfs.server.namenode.TestParallelImageWrite.testRestartDFS()<br/>Local variable named rootmtime<br/>At TestParallelImageWrite.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98815');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to c in org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery.testPipelineRecoveryForLastBlock()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98815" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery<br/>In method org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery.testPipelineRecoveryForLastBlock()<br/>Local variable named c<br/>At TestClientProtocolForPipelineRecovery.java:[line 150]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99374');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to cacheContext in org.apache.hadoop.hdfs.TestConnCache.testReadFromOneDN()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99374" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestConnCache<br/>In method org.apache.hadoop.hdfs.TestConnCache.testReadFromOneDN()<br/>Local variable named cacheContext<br/>At TestConnCache.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99511');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to props in org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99511" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSClientExcludedNodes<br/>In method org.apache.hadoop.hdfs.TestDFSClientExcludedNodes.testExcludedNodesForgiveness()<br/>Local variable named props<br/>At TestDFSClientExcludedNodes.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N105644');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to offset in org.apache.hadoop.hdfs.TestFileAppend2.testSimpleAppend()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N105644" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileAppend2<br/>In method org.apache.hadoop.hdfs.TestFileAppend2.testSimpleAppend()<br/>Local variable named offset<br/>At TestFileAppend2.java:[line 195]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N106973');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to out1 in org.apache.hadoop.hdfs.TestLease.testFactory()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N106973" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestLease<br/>In method org.apache.hadoop.hdfs.TestLease.testFactory()<br/>Local variable named out1<br/>At TestLease.java:[line 309]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N107043');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to out2 in org.apache.hadoop.hdfs.TestLease.testFactory()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N107043" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestLease<br/>In method org.apache.hadoop.hdfs.TestLease.testFactory()<br/>Local variable named out2<br/>At TestLease.java:[line 311]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N107113');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to out3 in org.apache.hadoop.hdfs.TestLease.testFactory()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N107113" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestLease<br/>In method org.apache.hadoop.hdfs.TestLease.testFactory()<br/>Local variable named out3<br/>At TestLease.java:[line 314]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N107183');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to out4 in org.apache.hadoop.hdfs.TestLease.testFactory()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N107183" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestLease<br/>In method org.apache.hadoop.hdfs.TestLease.testFactory()<br/>Local variable named out4<br/>At TestLease.java:[line 317]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N107253');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to out5 in org.apache.hadoop.hdfs.TestLease.testFactory()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N107253" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestLease<br/>In method org.apache.hadoop.hdfs.TestLease.testFactory()<br/>Local variable named out5<br/>At TestLease.java:[line 320]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N107584');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to listdir in org.apache.hadoop.hdfs.TestListPathServlet.checkStatus(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N107584" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestListPathServlet<br/>In method org.apache.hadoop.hdfs.TestListPathServlet.checkStatus(String)<br/>Local variable named listdir<br/>At TestListPathServlet.java:[line 139]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N107809');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to mdir2 in org.apache.hadoop.hdfs.TestModTime.testModTime()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N107809" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestModTime<br/>In method org.apache.hadoop.hdfs.TestModTime.testModTime()<br/>Local variable named mdir2<br/>At TestModTime.java:[line 178]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N110020');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to nread in org.apache.hadoop.hdfs.TestShortCircuitLocalRead.testSkipWithVerifyChecksum()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N110020" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestShortCircuitLocalRead<br/>In method org.apache.hadoop.hdfs.TestShortCircuitLocalRead.testSkipWithVerifyChecksum()<br/>Local variable named nread<br/>At TestShortCircuitLocalRead.java:[line 415]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N142937');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to filenameLarge in org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer.filesEqualIgnoreTrailingZeros(String, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N142937" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer<br/>In method org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer.filesEqualIgnoreTrailingZeros(String, String)<br/>Local variable named filenameLarge<br/>At TestOfflineEditsViewer.java:[line 247]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N143013');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to filenameSmall in org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer.filesEqualIgnoreTrailingZeros(String, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N143013" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer<br/>In method org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer.filesEqualIgnoreTrailingZeros(String, String)<br/>Local variable named filenameSmall<br/>At TestOfflineEditsViewer.java:[line 246]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N158432');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to duration in org.apache.hadoop.io.file.tfile.TestTFileSeek.seekTFile()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N158432" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.io.file.tfile.TestTFileSeek<br/>In method org.apache.hadoop.io.file.tfile.TestTFileSeek.seekTFile()<br/>Local variable named duration<br/>At TestTFileSeek.java:[line 170]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N160042');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to stat in org.apache.hadoop.io.nativeio.TestNativeIO.testFstatClosedFd()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N160042" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestNativeIO<br/>In method org.apache.hadoop.io.nativeio.TestNativeIO.testFstatClosedFd()<br/>Local variable named stat<br/>At TestNativeIO.java:[line 156]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N160109');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to fd in org.apache.hadoop.io.nativeio.TestNativeIO.testOpenWithCreate()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N160109" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestNativeIO<br/>In method org.apache.hadoop.io.nativeio.TestNativeIO.testOpenWithCreate()<br/>Local variable named fd<br/>At TestNativeIO.java:[line 367]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N150752');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to v in org.apache.hadoop.io.TestSetFile.readTest(FileSystem, RandomDatum[], String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N150752" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.io.TestSetFile<br/>In method org.apache.hadoop.io.TestSetFile.readTest(FileSystem, RandomDatum[], String)<br/>Local variable named v<br/>At TestSetFile.java:[line 119]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N162504');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to echoResponse in org.apache.hadoop.ipc.TestProtoBufRpc.testExtraLongRpc()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N162504" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestProtoBufRpc<br/>In method org.apache.hadoop.ipc.TestProtoBufRpc.testExtraLongRpc()<br/>Local variable named echoResponse<br/>At TestProtoBufRpc.java:[line 254]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N180892');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to client in org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.runDataGenJob(Configuration, Path)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N180892" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils<br/>In method org.apache.hadoop.mapred.gridmix.TestCompressionEmulationUtils.runDataGenJob(Configuration, Path)<br/>Local variable named client<br/>At TestCompressionEmulationUtils.java:[line 155]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N181525');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to key in org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.doValidateSetupGenDC(RecordReader, FileSystem, long[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N181525" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation<br/>In method org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.doValidateSetupGenDC(RecordReader, FileSystem, long[])<br/>Local variable named key<br/>At TestDistCacheEmulation.java:[line 323]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N181598');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to val in org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.doValidateSetupGenDC(RecordReader, FileSystem, long[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N181598" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation<br/>In method org.apache.hadoop.mapred.gridmix.TestDistCacheEmulation.doValidateSetupGenDC(RecordReader, FileSystem, long[])<br/>Local variable named val<br/>At TestDistCacheEmulation.java:[line 324]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N181740');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to q in org.apache.hadoop.mapred.gridmix.TestFileQueue.testEmpty()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N181740" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestFileQueue<br/>In method org.apache.hadoop.mapred.gridmix.TestFileQueue.testEmpty()<br/>Local variable named q<br/>At TestFileQueue.java:[line 139]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N182237');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to fakeProgress in org.apache.hadoop.mapred.gridmix.TestGridmixMemoryEmulation.testTotalHeapUsageEmulatorPlugin()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N182237" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestGridmixMemoryEmulation<br/>In method org.apache.hadoop.mapred.gridmix.TestGridmixMemoryEmulation.testTotalHeapUsageEmulatorPlugin()<br/>Local variable named fakeProgress<br/>At TestGridmixMemoryEmulation.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N182920');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to fakeProgress in org.apache.hadoop.mapred.gridmix.TestResourceUsageEmulators.testCumulativeCpuUsageEmulatorPlugin()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N182920" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestResourceUsageEmulators<br/>In method org.apache.hadoop.mapred.gridmix.TestResourceUsageEmulators.testCumulativeCpuUsageEmulatorPlugin()<br/>Local variable named fakeProgress<br/>At TestResourceUsageEmulators.java:[line 445]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N168089');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to execTimes in org.apache.hadoop.mapred.MRBench.run(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N168089" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRBench<br/>In method org.apache.hadoop.mapred.MRBench.run(String[])<br/>Local variable named execTimes<br/>At MRBench.java:[line 288]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N172058');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to tmpJobACLs in org.apache.hadoop.mapred.TestJobAclsManager.testAclsOff()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N172058" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobAclsManager<br/>In method org.apache.hadoop.mapred.TestJobAclsManager.testAclsOff()<br/>Local variable named tmpJobACLs<br/>At TestJobAclsManager.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N172131');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to tmpJobACLs in org.apache.hadoop.mapred.TestJobAclsManager.testClusterAdmins()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N172131" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobAclsManager<br/>In method org.apache.hadoop.mapred.TestJobAclsManager.testClusterAdmins()<br/>Local variable named tmpJobACLs<br/>At TestJobAclsManager.java:[line 40]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N172204');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to tmpJobACLs in org.apache.hadoop.mapred.TestJobAclsManager.testClusterNoAdmins()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N172204" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobAclsManager<br/>In method org.apache.hadoop.mapred.TestJobAclsManager.testClusterNoAdmins()<br/>Local variable named tmpJobACLs<br/>At TestJobAclsManager.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N172277');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to tmpJobACLs in org.apache.hadoop.mapred.TestJobAclsManager.testGroups()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N172277" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobAclsManager<br/>In method org.apache.hadoop.mapred.TestJobAclsManager.testGroups()<br/>Local variable named tmpJobACLs<br/>At TestJobAclsManager.java:[line 122]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N173302');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to client in org.apache.hadoop.mapred.TestLazyOutput.runTestLazyOutput(JobConf, Path, int, boolean)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N173302" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestLazyOutput<br/>In method org.apache.hadoop.mapred.TestLazyOutput.runTestLazyOutput(JobConf, Path, int, boolean)<br/>Local variable named client<br/>At TestLazyOutput.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N174808');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to parents in org.apache.hadoop.mapred.TestMiniMRClasspath.launchWordCount(URI, JobConf, String, int, int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N174808" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMiniMRClasspath<br/>In method org.apache.hadoop.mapred.TestMiniMRClasspath.launchWordCount(URI, JobConf, String, int, int)<br/>Local variable named parents<br/>At TestMiniMRClasspath.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N173854');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to namenode in org.apache.hadoop.mapred.TestMRCJCFileInputFormat.testMultiLevelInput()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N173854" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMRCJCFileInputFormat<br/>In method org.apache.hadoop.mapred.TestMRCJCFileInputFormat.testMultiLevelInput()<br/>Local variable named namenode<br/>At TestMRCJCFileInputFormat.java:[line 167]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N173927');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to splits in org.apache.hadoop.mapred.TestMRCJCFileInputFormat.testNumInputs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N173927" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMRCJCFileInputFormat<br/>In method org.apache.hadoop.mapred.TestMRCJCFileInputFormat.testNumInputs()<br/>Local variable named splits<br/>At TestMRCJCFileInputFormat.java:[line 131]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N176119');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to buf in org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat.testBinary()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N176119" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat<br/>In method org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat.testBinary()<br/>Local variable named buf<br/>At TestSequenceFileAsBinaryOutputFormat.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N176189');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to fs in org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat.testSequenceOutputClassDefaultsToMapRedOutputClass()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N176189" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat<br/>In method org.apache.hadoop.mapred.TestSequenceFileAsBinaryOutputFormat.testSequenceOutputClassDefaultsToMapRedOutputClass()<br/>Local variable named fs<br/>At TestSequenceFileAsBinaryOutputFormat.java:[line 135]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N178214');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to submissionContext rather than field with same name in org.apache.hadoop.mapred.TestYARNRunner.testWarnCommandOpts()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N178214" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE_SHADOWS_FIELD">Bug type DLS_DEAD_LOCAL_STORE_SHADOWS_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestYARNRunner<br/>In method org.apache.hadoop.mapred.TestYARNRunner.testWarnCommandOpts()<br/>Local variable named submissionContext<br/>Did you mean to refer to the field org.apache.hadoop.mapred.TestYARNRunner.submissionContext?<br/>At TestYARNRunner.java:[line 480]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N178702');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to numBytes in org.apache.hadoop.mapred.UtilsForTests.formatBytes2(long)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N178702" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.UtilsForTests<br/>In method org.apache.hadoop.mapred.UtilsForTests.formatBytes2(long)<br/>Local variable named numBytes<br/>At UtilsForTests.java:[line 131]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N192457');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to bkey in org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsBinaryInputFormat.testBinary()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N192457" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsBinaryInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsBinaryInputFormat.testBinary()<br/>Local variable named bkey<br/>At TestMRSequenceFileAsBinaryInputFormat.java:[line 73]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N192530');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to bval in org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsBinaryInputFormat.testBinary()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N192530" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsBinaryInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestMRSequenceFileAsBinaryInputFormat.testBinary()<br/>Local variable named bval<br/>At TestMRSequenceFileAsBinaryInputFormat.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N193739');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to dwritable in org.apache.hadoop.mapreduce.lib.output.TestMRSequenceFileAsBinaryOutputFormat.testBinary()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N193739" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.TestMRSequenceFileAsBinaryOutputFormat<br/>In method org.apache.hadoop.mapreduce.lib.output.TestMRSequenceFileAsBinaryOutputFormat.testBinary()<br/>Local variable named dwritable<br/>At TestMRSequenceFileAsBinaryOutputFormat.java:[line 85]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N193812');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to iwritable in org.apache.hadoop.mapreduce.lib.output.TestMRSequenceFileAsBinaryOutputFormat.testBinary()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N193812" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.TestMRSequenceFileAsBinaryOutputFormat<br/>In method org.apache.hadoop.mapreduce.lib.output.TestMRSequenceFileAsBinaryOutputFormat.testBinary()<br/>Local variable named iwritable<br/>At TestMRSequenceFileAsBinaryOutputFormat.java:[line 84]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N189470');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to conf in org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N189470" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider<br/>In method org.apache.hadoop.mapreduce.TestYarnClientProtocolProvider.testClusterGetDelegationToken()<br/>Local variable named conf<br/>At TestYarnClientProtocolProvider.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N199866');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to tmpJobACLs in org.apache.hadoop.mapreduce.v2.app.MockJobs.newJob(ApplicationId, int, int, int, Path, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N199866" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.MockJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.MockJobs.newJob(ApplicationId, int, int, int, Path, boolean)<br/>Local variable named tmpJobACLs<br/>At MockJobs.java:[line 495]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N200131');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to mapTask in org.apache.hadoop.mapreduce.v2.app.TestAMInfos.testAMInfosWithoutRecoveryEnabled()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N200131" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.TestAMInfos<br/>In method org.apache.hadoop.mapreduce.v2.app.TestAMInfos.testAMInfosWithoutRecoveryEnabled()<br/>Local variable named mapTask<br/>At TestAMInfos.java:[line 76]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N209173');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId01 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N209173" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId01<br/>At TestJobHistoryUtils.java:[line 54]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N209243');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId03 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N209243" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId03<br/>At TestJobHistoryUtils.java:[line 56]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N209313');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId04 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N209313" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId04<br/>At TestJobHistoryUtils.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N209383');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId05 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N209383" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId05<br/>At TestJobHistoryUtils.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N209453');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId09 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N209453" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId09<br/>At TestJobHistoryUtils.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N209523');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId10 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N209523" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId10<br/>At TestJobHistoryUtils.java:[line 63]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N209593');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId11 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N209593" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId11<br/>At TestJobHistoryUtils.java:[line 64]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N209663');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId12 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N209663" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId12<br/>At TestJobHistoryUtils.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N209733');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId13 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N209733" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId13<br/>At TestJobHistoryUtils.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N209803');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId14 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N209803" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId14<br/>At TestJobHistoryUtils.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N209873');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId15 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N209873" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId15<br/>At TestJobHistoryUtils.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N209943');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId16 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N209943" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId16<br/>At TestJobHistoryUtils.java:[line 69]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N210013');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId17 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N210013" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId17<br/>At TestJobHistoryUtils.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N210083');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId27 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N210083" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId27<br/>At TestJobHistoryUtils.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N210153');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId28 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N210153" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId28<br/>At TestJobHistoryUtils.java:[line 82]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N210223');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to pId29 in org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N210223" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils<br/>In method org.apache.hadoop.mapreduce.v2.jobhistory.TestJobHistoryUtils.testGetHistoryDirsForCleaning()<br/>Local variable named pId29<br/>At TestJobHistoryUtils.java:[line 83]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N198838');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to proxyUser in org.apache.hadoop.mapreduce.v2.TestNonExistentJob.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N198838" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestNonExistentJob<br/>In method org.apache.hadoop.mapreduce.v2.TestNonExistentJob.setUp()<br/>Local variable named proxyUser<br/>At TestNonExistentJob.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N199097');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to client in org.apache.hadoop.mapreduce.v2.TestRPCFactories.testPbClientFactory()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N199097" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestRPCFactories<br/>In method org.apache.hadoop.mapreduce.v2.TestRPCFactories.testPbClientFactory()<br/>Local variable named client<br/>At TestRPCFactories.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N211351');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to registry in org.apache.hadoop.metrics2.impl.TestMetricsVisitor.testCommon()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N211351" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.impl.TestMetricsVisitor<br/>In method org.apache.hadoop.metrics2.impl.TestMetricsVisitor.testCommon()<br/>Local variable named registry<br/>At TestMetricsVisitor.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N213197');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to addr in org.apache.hadoop.net.TestNetUtils.testCreateSocketAddress()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N213197" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.net.TestNetUtils<br/>In method org.apache.hadoop.net.TestNetUtils.testCreateSocketAddress()<br/>Local variable named addr<br/>At TestNetUtils.java:[line 285]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N213538');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to resolved in org.apache.hadoop.net.TestStaticMapping.testCachingCachesNegativeEntries()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N213538" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.net.TestStaticMapping<br/>In method org.apache.hadoop.net.TestStaticMapping.testCachingCachesNegativeEntries()<br/>Local variable named resolved<br/>At TestStaticMapping.java:[line 233]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N217932');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to perm in org.apache.hadoop.security.TestPermission.testBackwardCompatibility()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N217932" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.security.TestPermission<br/>In method org.apache.hadoop.security.TestPermission.testBackwardCompatibility()<br/>Local variable named perm<br/>At TestPermission.java:[line 88]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N226685');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to localFiles in org.apache.hadoop.tools.TestCopyFiles.testDeleteLocal()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N226685" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestCopyFiles<br/>In method org.apache.hadoop.tools.TestCopyFiles.testDeleteLocal()<br/>Local variable named localFiles<br/>At TestCopyFiles.java:[line 1036]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N226755');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to permissions in org.apache.hadoop.tools.TestCopyFiles.testPreserveOption()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N226755" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestCopyFiles<br/>In method org.apache.hadoop.tools.TestCopyFiles.testPreserveOption()<br/>Local variable named permissions<br/>At TestCopyFiles.java:[line 711]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N240726');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to result in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testAppAttemptsHelpCommand()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N240726" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testAppAttemptsHelpCommand()<br/>Local variable named result<br/>At TestYarnCLI.java:[line 722]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N240799');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to result in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testAppsHelpCommand()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N240799" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testAppsHelpCommand()<br/>Local variable named result<br/>At TestYarnCLI.java:[line 693]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N240872');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to result in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testContainersHelpCommand()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N240872" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testContainersHelpCommand()<br/>Local variable named result<br/>At TestYarnCLI.java:[line 752]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N240945');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to result in org.apache.hadoop.yarn.client.cli.TestYarnCLI.testMoveApplicationAcrossQueues()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N240945" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.cli.TestYarnCLI<br/>In method org.apache.hadoop.yarn.client.cli.TestYarnCLI.testMoveApplicationAcrossQueues()<br/>Local variable named result<br/>At TestYarnCLI.java:[line 858]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N245029');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to conf in org.apache.hadoop.yarn.server.MiniYARNCluster.restartResourceManager(int)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N245029" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.MiniYARNCluster<br/>In method org.apache.hadoop.yarn.server.MiniYARNCluster.restartResourceManager(int)<br/>Local variable named conf<br/>At MiniYARNCluster.java:[line 351]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N247767');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to containerManager in org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerReboot.testClearLocalDirWhenNodeReboot()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N247767" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerReboot<br/>In method org.apache.hadoop.yarn.server.nodemanager.TestNodeManagerReboot.testClearLocalDirWhenNodeReboot()<br/>Local variable named containerManager<br/>At TestNodeManagerReboot.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N257190');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to conf in org.apache.hadoop.yarn.server.resourcemanager.MockRM.createResourceTrackerService()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N257190" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.MockRM<br/>In method org.apache.hadoop.yarn.server.resourcemanager.MockRM.createResourceTrackerService()<br/>Local variable named conf<br/>At MockRM.java:[line 406]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N261288');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to user in org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.TestRMAppAttemptTransitions.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N261288" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.TestRMAppAttemptTransitions<br/>In method org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.TestRMAppAttemptTransitions.setUp()<br/>Local variable named user<br/>At TestRMAppAttemptTransitions.java:[line 260]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N264660');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to root in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits.testLimitsComputation()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N264660" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits.testLimitsComputation()<br/>Local variable named root<br/>At TestApplicationLimits.java:[line 286]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N265559');">
<td>
<span class="priority-1">DLS</span>
</td>
<td>Dead store to app_0 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestLeafQueue.testAppAttemptMetrics()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N265559" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestLeafQueue<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestLeafQueue.testAppAttemptMetrics()<br/>Local variable named app_0<br/>At TestLeafQueue.java:[line 353]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N267032');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app10 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChoiceOfPreemptedContainers()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N267032" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChoiceOfPreemptedContainers()<br/>Local variable named app10<br/>At TestFairScheduler.java:[line 1173]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N267102');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app11 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChoiceOfPreemptedContainers()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N267102" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChoiceOfPreemptedContainers()<br/>Local variable named app11<br/>At TestFairScheduler.java:[line 1175]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N267172');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app12 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChoiceOfPreemptedContainers()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N267172" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChoiceOfPreemptedContainers()<br/>Local variable named app12<br/>At TestFairScheduler.java:[line 1177]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N267242');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app7 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChoiceOfPreemptedContainers()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N267242" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChoiceOfPreemptedContainers()<br/>Local variable named app7<br/>At TestFairScheduler.java:[line 1166]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N267309');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app8 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChoiceOfPreemptedContainers()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N267309" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChoiceOfPreemptedContainers()<br/>Local variable named app8<br/>At TestFairScheduler.java:[line 1168]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N267379');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app9 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChoiceOfPreemptedContainers()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N267379" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testChoiceOfPreemptedContainers()<br/>Local variable named app9<br/>At TestFairScheduler.java:[line 1170]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N267449');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app1 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N267449" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()<br/>Local variable named app1<br/>At TestFairScheduler.java:[line 1297]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N267519');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app10 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N267519" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()<br/>Local variable named app10<br/>At TestFairScheduler.java:[line 1333]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N267589');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app11 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N267589" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()<br/>Local variable named app11<br/>At TestFairScheduler.java:[line 1335]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N267659');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app12 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N267659" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()<br/>Local variable named app12<br/>At TestFairScheduler.java:[line 1337]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N267729');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app2 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N267729" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()<br/>Local variable named app2<br/>At TestFairScheduler.java:[line 1299]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N267799');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app3 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N267799" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()<br/>Local variable named app3<br/>At TestFairScheduler.java:[line 1301]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N267869');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app4 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N267869" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()<br/>Local variable named app4<br/>At TestFairScheduler.java:[line 1304]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N267939');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app5 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N267939" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()<br/>Local variable named app5<br/>At TestFairScheduler.java:[line 1306]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N268009');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app6 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N268009" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()<br/>Local variable named app6<br/>At TestFairScheduler.java:[line 1308]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N268079');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app7 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N268079" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()<br/>Local variable named app7<br/>At TestFairScheduler.java:[line 1326]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N268146');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app8 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N268146" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()<br/>Local variable named app8<br/>At TestFairScheduler.java:[line 1328]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N268216');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to app9 in org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N268216" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.TestFairScheduler.testPreemptionDecision()<br/>Local variable named app9<br/>At TestFairScheduler.java:[line 1330]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N257697');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to store in org.apache.hadoop.yarn.server.resourcemanager.TestApplicationACLs.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N257697" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestApplicationACLs<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestApplicationACLs.setup()<br/>Local variable named store<br/>At TestApplicationACLs.java:[line 100]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N257818');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to queueInfo in org.apache.hadoop.yarn.server.resourcemanager.TestClientRMService.testGetQueueInfo()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N257818" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestClientRMService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestClientRMService.testGetQueueInfo()<br/>Local variable named queueInfo<br/>At TestClientRMService.java:[line 452]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N259354');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to nm1 in org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService.testReconnectNode()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N259354" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestResourceTrackerService.testReconnectNode()<br/>Local variable named nm1<br/>At TestResourceTrackerService.java:[line 596]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N236461');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to client in org.apache.hadoop.yarn.TestYSCRPCFactories.testPbClientFactory()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N236461" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.TestYSCRPCFactories<br/>In method org.apache.hadoop.yarn.TestYSCRPCFactories.testPbClientFactory()<br/>Local variable named client<br/>At TestYSCRPCFactories.java:[line 88]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N276392');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to val in org.apache.hadoop.yarn.webapp.test.TestWebAppTests.testInstances()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N276392" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.webapp.test.TestWebAppTests<br/>In method org.apache.hadoop.yarn.webapp.test.TestWebAppTests.testInstances()<br/>Local variable named val<br/>At TestWebAppTests.java:[line 41]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N276465');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to injector in org.apache.hadoop.yarn.webapp.view.TestCommonViews.testErrorPage()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N276465" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.webapp.view.TestCommonViews<br/>In method org.apache.hadoop.yarn.webapp.view.TestCommonViews.testErrorPage()<br/>Local variable named injector<br/>At TestCommonViews.java:[line 36]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N276535');">
<td>
<span class="priority-2">DLS</span>
</td>
<td>Dead store to info in org.apache.hadoop.yarn.webapp.view.TestCommonViews.testInfoBlock()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N276535" style="display: none;">
<a href="#DLS_DEAD_LOCAL_STORE">Bug type DLS_DEAD_LOCAL_STORE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.webapp.view.TestCommonViews<br/>In method org.apache.hadoop.yarn.webapp.view.TestCommonViews.testInfoBlock()<br/>Local variable named info<br/>At TestCommonViews.java:[line 54]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N77815');">
<td>
<span class="priority-2">DMI</span>
</td>
<td>Hard coded reference to an absolute pathname in org.apache.hadoop.fs.TestDFVariations.testDFMalformedOutput()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N77815" style="display: none;">
<a href="#DMI_HARDCODED_ABSOLUTE_FILENAME">Bug type DMI_HARDCODED_ABSOLUTE_FILENAME (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestDFVariations<br/>In method org.apache.hadoop.fs.TestDFVariations.testDFMalformedOutput()<br/>File name /<br/>At TestDFVariations.java:[line 89]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N117756');">
<td>
<span class="priority-2">DMI</span>
</td>
<td>Hard coded reference to an absolute pathname in org.apache.hadoop.hdfs.server.datanode.TestDataDirs.testDataDirParsing()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N117756" style="display: none;">
<a href="#DMI_HARDCODED_ABSOLUTE_FILENAME">Bug type DMI_HARDCODED_ABSOLUTE_FILENAME (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataDirs<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDataDirs.testDataDirParsing()<br/>File name /dir0<br/>At TestDataDirs.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N117815');">
<td>
<span class="priority-2">DMI</span>
</td>
<td>Hard coded reference to an absolute pathname in org.apache.hadoop.hdfs.server.datanode.TestDataDirs.testDataDirParsing()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N117815" style="display: none;">
<a href="#DMI_HARDCODED_ABSOLUTE_FILENAME">Bug type DMI_HARDCODED_ABSOLUTE_FILENAME (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataDirs<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDataDirs.testDataDirParsing()<br/>File name /dir1<br/>At TestDataDirs.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N117874');">
<td>
<span class="priority-2">DMI</span>
</td>
<td>Hard coded reference to an absolute pathname in org.apache.hadoop.hdfs.server.datanode.TestDataDirs.testDataDirParsing()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N117874" style="display: none;">
<a href="#DMI_HARDCODED_ABSOLUTE_FILENAME">Bug type DMI_HARDCODED_ABSOLUTE_FILENAME (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataDirs<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDataDirs.testDataDirParsing()<br/>File name /dir2<br/>At TestDataDirs.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N117933');">
<td>
<span class="priority-2">DMI</span>
</td>
<td>Hard coded reference to an absolute pathname in org.apache.hadoop.hdfs.server.datanode.TestDataDirs.testDataDirParsing()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N117933" style="display: none;">
<a href="#DMI_HARDCODED_ABSOLUTE_FILENAME">Bug type DMI_HARDCODED_ABSOLUTE_FILENAME (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataDirs<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDataDirs.testDataDirParsing()<br/>File name /dir3<br/>At TestDataDirs.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N117992');">
<td>
<span class="priority-2">DMI</span>
</td>
<td>Hard coded reference to an absolute pathname in org.apache.hadoop.hdfs.server.datanode.TestDataDirs.testDataDirValidation()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N117992" style="display: none;">
<a href="#DMI_HARDCODED_ABSOLUTE_FILENAME">Bug type DMI_HARDCODED_ABSOLUTE_FILENAME (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataDirs<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDataDirs.testDataDirValidation()<br/>File name /p3/<br/>At TestDataDirs.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N124191');">
<td>
<span class="priority-2">DMI</span>
</td>
<td>Hard coded reference to an absolute pathname in org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil.mockStorageDirectory(Storage$StorageDirType, boolean, String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N124191" style="display: none;">
<a href="#DMI_HARDCODED_ABSOLUTE_FILENAME">Bug type DMI_HARDCODED_ABSOLUTE_FILENAME (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil<br/>In method org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil.mockStorageDirectory(Storage$StorageDirType, boolean, String[])<br/>File name /dir/current<br/>At FSImageTestUtil.java:[line 159]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N127081');">
<td>
<span class="priority-2">DMI</span>
</td>
<td>Hard coded reference to an absolute pathname in org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testNamespaceVerifiedOnFileTransfer()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N127081" style="display: none;">
<a href="#DMI_HARDCODED_ABSOLUTE_FILENAME">Bug type DMI_HARDCODED_ABSOLUTE_FILENAME (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckpoint<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testNamespaceVerifiedOnFileTransfer()<br/>File name /wont-be-written<br/>At TestCheckpoint.java:[line 1970]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N135987');">
<td>
<span class="priority-2">DMI</span>
</td>
<td>Hard coded reference to an absolute pathname in org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testClientSideException()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N135987" style="display: none;">
<a href="#DMI_HARDCODED_ABSOLUTE_FILENAME">Bug type DMI_HARDCODED_ABSOLUTE_FILENAME (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage<br/>In method org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testClientSideException()<br/>File name /xxxxx-does-not-exist/blah<br/>At TestTransferFsImage.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N136046');">
<td>
<span class="priority-2">DMI</span>
</td>
<td>Hard coded reference to an absolute pathname in org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testClientSideExceptionOnJustOneDir()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N136046" style="display: none;">
<a href="#DMI_HARDCODED_ABSOLUTE_FILENAME">Bug type DMI_HARDCODED_ABSOLUTE_FILENAME (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage<br/>In method org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testClientSideExceptionOnJustOneDir()<br/>File name /xxxxx-does-not-exist/blah<br/>At TestTransferFsImage.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N103609');">
<td>
<span class="priority-2">DMI</span>
</td>
<td>Hard coded reference to an absolute pathname in org.apache.hadoop.hdfs.TestDatanodeBlockScanner.&lt;static initializer for TestDatanodeBlockScanner&gt;()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N103609" style="display: none;">
<a href="#DMI_HARDCODED_ABSOLUTE_FILENAME">Bug type DMI_HARDCODED_ABSOLUTE_FILENAME (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeBlockScanner<br/>In method org.apache.hadoop.hdfs.TestDatanodeBlockScanner.&lt;static initializer for TestDatanodeBlockScanner&gt;()<br/>File name /data/current/finalized<br/>At TestDatanodeBlockScanner.java:[line 443]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N161043');">
<td>
<span class="priority-2">DMI</span>
</td>
<td>Hard coded reference to an absolute pathname in org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory.testDirectoryFallbacks()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N161043" style="display: none;">
<a href="#DMI_HARDCODED_ABSOLUTE_FILENAME">Bug type DMI_HARDCODED_ABSOLUTE_FILENAME (click for details)</a>
<br/>In class org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory<br/>In method org.apache.hadoop.io.nativeio.TestSharedFileDescriptorFactory.testDirectoryFallbacks()<br/>File name /<br/>At TestSharedFileDescriptorFactory.java:[line 95]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N235593');">
<td>
<span class="priority-2">DMI</span>
</td>
<td>Hard coded reference to an absolute pathname in org.apache.hadoop.util.TestZKUtil.&lt;static initializer for TestZKUtil&gt;()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N235593" style="display: none;">
<a href="#DMI_HARDCODED_ABSOLUTE_FILENAME">Bug type DMI_HARDCODED_ABSOLUTE_FILENAME (click for details)</a>
<br/>In class org.apache.hadoop.util.TestZKUtil<br/>In method org.apache.hadoop.util.TestZKUtil.&lt;static initializer for TestZKUtil&gt;()<br/>File name /xxxx-this-does-not-exist<br/>At TestZKUtil.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N134112');">
<td>
<span class="priority-1">FE</span>
</td>
<td>Test for floating point equality in org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testVolumeSize()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N134112" style="display: none;">
<a href="#FE_FLOATING_POINT_EQUALITY">Bug type FE_FLOATING_POINT_EQUALITY (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNamenodeCapacityReport.testVolumeSize()<br/>At TestNamenodeCapacityReport.java:[line 150]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94749');">
<td>
<span class="priority-2">ICAST</span>
</td>
<td>Result of integer multiplication cast to long in org.apache.hadoop.hdfs.BlockReaderTestUtil.getFileBlocks(Path, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94749" style="display: none;">
<a href="#ICAST_INTEGER_MULTIPLY_CAST_TO_LONG">Bug type ICAST_INTEGER_MULTIPLY_CAST_TO_LONG (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.BlockReaderTestUtil<br/>In method org.apache.hadoop.hdfs.BlockReaderTestUtil.getFileBlocks(Path, int)<br/>At BlockReaderTestUtil.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N115231');">
<td>
<span class="priority-2">ICAST</span>
</td>
<td>Result of integer multiplication cast to long in org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicyConsiderLoad.setupCluster()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N115231" style="display: none;">
<a href="#ICAST_INTEGER_MULTIPLY_CAST_TO_LONG">Bug type ICAST_INTEGER_MULTIPLY_CAST_TO_LONG (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicyConsiderLoad<br/>In method org.apache.hadoop.hdfs.server.blockmanagement.TestReplicationPolicyConsiderLoad.setupCluster()<br/>At TestReplicationPolicyConsiderLoad.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N119720');">
<td>
<span class="priority-2">ICAST</span>
</td>
<td>Result of integer multiplication cast to long in org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold.createFile(String, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N119720" style="display: none;">
<a href="#ICAST_INTEGER_MULTIPLY_CAST_TO_LONG">Bug type ICAST_INTEGER_MULTIPLY_CAST_TO_LONG (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold.createFile(String, int)<br/>At TestDnRespectsBlockReportSplitThreshold.java:[line 86]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N108248');">
<td>
<span class="priority-2">ICAST</span>
</td>
<td>Result of integer multiplication cast to long in org.apache.hadoop.hdfs.TestQuota.testSpaceCommands()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N108248" style="display: none;">
<a href="#ICAST_INTEGER_MULTIPLY_CAST_TO_LONG">Bug type ICAST_INTEGER_MULTIPLY_CAST_TO_LONG (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestQuota<br/>In method org.apache.hadoop.hdfs.TestQuota.testSpaceCommands()<br/>At TestQuota.java:[line 557]<br/>Another occurrence at TestQuota.java:[line 559]<br/>Another occurrence at TestQuota.java:[line 563]<br/>Another occurrence at TestQuota.java:[line 565]<br/>Another occurrence at TestQuota.java:[line 653]<br/>Another occurrence at TestQuota.java:[line 668]<br/>Another occurrence at TestQuota.java:[line 671]<br/>Another occurrence at TestQuota.java:[line 689]<br/>Another occurrence at TestQuota.java:[line 714]<br/>Another occurrence at TestQuota.java:[line 715]<br/>Another occurrence at TestQuota.java:[line 745]<br/>Another occurrence at TestQuota.java:[line 748]<br/>Another occurrence at TestQuota.java:[line 766]<br/>Another occurrence at TestQuota.java:[line 770]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N161666');">
<td>
<span class="priority-2">ICAST</span>
</td>
<td>Integral division result cast to double or float in org.apache.hadoop.ipc.RPCCallBenchmark.run(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N161666" style="display: none;">
<a href="#ICAST_IDIV_CAST_TO_DOUBLE">Bug type ICAST_IDIV_CAST_TO_DOUBLE (click for details)</a>
<br/>In class org.apache.hadoop.ipc.RPCCallBenchmark<br/>In method org.apache.hadoop.ipc.RPCCallBenchmark.run(String[])<br/>At RPCCallBenchmark.java:[line 290]<br/>Another occurrence at RPCCallBenchmark.java:[line 298]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N171866');">
<td>
<span class="priority-2">ICAST</span>
</td>
<td>Integral division result cast to double or float in org.apache.hadoop.mapred.TestFixedLengthInputFormat.runRandomTests(CompressionCodec)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N171866" style="display: none;">
<a href="#ICAST_IDIV_CAST_TO_DOUBLE">Bug type ICAST_IDIV_CAST_TO_DOUBLE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestFixedLengthInputFormat<br/>In method org.apache.hadoop.mapred.TestFixedLengthInputFormat.runRandomTests(CompressionCodec)<br/>At TestFixedLengthInputFormat.java:[line 303]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N252557');">
<td>
<span class="priority-2">ICAST</span>
</td>
<td>Result of integer multiplication cast to long in org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestLocalResourcesTrackerImpl.createLocalResourceRequest(String, int, long, LocalResourceVisibility)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N252557" style="display: none;">
<a href="#ICAST_INTEGER_MULTIPLY_CAST_TO_LONG">Bug type ICAST_INTEGER_MULTIPLY_CAST_TO_LONG (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestLocalResourcesTrackerImpl<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestLocalResourcesTrackerImpl.createLocalResourceRequest(String, int, long, LocalResourceVisibility)<br/>At TestLocalResourcesTrackerImpl.java:[line 507]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N193548');">
<td>
<span class="priority-2">IM</span>
</td>
<td>Check for oddness that won't work for negative numbers in org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeMapFileOutput(RecordWriter, TaskAttemptContext)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N193548" style="display: none;">
<a href="#IM_BAD_CHECK_FOR_ODD">Bug type IM_BAD_CHECK_FOR_ODD (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter<br/>In method org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter.writeMapFileOutput(RecordWriter, TaskAttemptContext)<br/>At TestFileOutputCommitter.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N274007');">
<td>
<span class="priority-2">IM</span>
</td>
<td>Check for oddness that won't work for negative numbers in org.apache.hadoop.yarn.util.TestFSDownload.testDirDownload()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N274007" style="display: none;">
<a href="#IM_BAD_CHECK_FOR_ODD">Bug type IM_BAD_CHECK_FOR_ODD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestFSDownload<br/>In method org.apache.hadoop.yarn.util.TestFSDownload.testDirDownload()<br/>At TestFSDownload.java:[line 598]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N274060');">
<td>
<span class="priority-2">IM</span>
</td>
<td>Check for oddness that won't work for negative numbers in org.apache.hadoop.yarn.util.TestFSDownload.testDownload()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N274060" style="display: none;">
<a href="#IM_BAD_CHECK_FOR_ODD">Bug type IM_BAD_CHECK_FOR_ODD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestFSDownload<br/>In method org.apache.hadoop.yarn.util.TestFSDownload.testDownload()<br/>At TestFSDownload.java:[line 402]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N106867');">
<td>
<span class="priority-2">INT</span>
</td>
<td>Vacuous comparison of integer value org.apache.hadoop.hdfs.TestLargeBlock.checkFullFile(FileSystem, Path, long) </td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N106867" style="display: none;">
<a href="#INT_VACUOUS_COMPARISON">Bug type INT_VACUOUS_COMPARISON (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestLargeBlock<br/>In method org.apache.hadoop.hdfs.TestLargeBlock.checkFullFile(FileSystem, Path, long)<br/>At TestLargeBlock.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N106920');">
<td>
<span class="priority-2">INT</span>
</td>
<td>Vacuous comparison of integer value org.apache.hadoop.hdfs.TestLargeBlock.writeFile(FSDataOutputStream, long) </td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N106920" style="display: none;">
<a href="#INT_VACUOUS_COMPARISON">Bug type INT_VACUOUS_COMPARISON (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestLargeBlock<br/>In method org.apache.hadoop.hdfs.TestLargeBlock.writeFile(FSDataOutputStream, long)<br/>At TestLargeBlock.java:[line 78]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N70773');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.examples.pi.Parser.parse(File, Map) due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N70773" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.examples.pi.Parser<br/>In method org.apache.hadoop.examples.pi.Parser.parse(File, Map)<br/>Value loaded from arr$<br/>Dereferenced at Parser.java:[line 70]<br/>Known null at Parser.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70544');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.examples.TestWordStats.deleteDir(File) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70544" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.examples.TestWordStats<br/>In method org.apache.hadoop.examples.TestWordStats.deleteDir(File)<br/>Value loaded from children<br/>Dereferenced at TestWordStats.java:[line 228]<br/>Known null at TestWordStats.java:[line 227]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N86174');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Dereference of the result of readLine() without nullcheck in org.apache.hadoop.fs.http.server.TestHttpFSServer.instrumentation()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N86174" style="display: none;">
<a href="#NP_DEREFERENCE_OF_READLINE_VALUE">Bug type NP_DEREFERENCE_OF_READLINE_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSServer<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSServer.instrumentation()<br/>Value loaded from line<br/>At TestHttpFSServer.java:[line 187]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N75103');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.fs.RawLocalFileSystem.rename(Path, Path) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N75103" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.fs.RawLocalFileSystem<br/>In method org.apache.hadoop.fs.RawLocalFileSystem.rename(Path, Path)<br/>Local variable stored in JVM register ?<br/>Dereferenced at RawLocalFileSystem.java:[line 319]<br/>Known null at RawLocalFileSystem.java:[line 319]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N90181');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.fs.slive.TestSlive.deleteDir(File) due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N90181" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.TestSlive<br/>In method org.apache.hadoop.fs.slive.TestSlive.deleteDir(File)<br/>Value loaded from fns<br/>Dereferenced at TestSlive.java:[line 218]<br/>Known null at TestSlive.java:[line 216]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N82130');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.fs.TestHardLink.testCreateHardLinkMultOversizeAndEmpty() due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N82130" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestHardLink<br/>In method org.apache.hadoop.fs.TestHardLink.testCreateHardLinkMultOversizeAndEmpty()<br/>Value loaded from tgt_multNames<br/>Method invoked at TestHardLink.java:[line 356]<br/>Known null at TestHardLink.java:[line 353]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N82203');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.fs.TestHardLink.testCreateHardLinkMultOversizeAndEmpty() due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N82203" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestHardLink<br/>In method org.apache.hadoop.fs.TestHardLink.testCreateHardLinkMultOversizeAndEmpty()<br/>Value loaded from tgt_multNames<br/>Method invoked at TestHardLink.java:[line 378]<br/>Known null at TestHardLink.java:[line 375]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N92559');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.ha.ClientBaseWithFixes.recursiveDelete(File) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N92559" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.ha.ClientBaseWithFixes<br/>In method org.apache.hadoop.ha.ClientBaseWithFixes.recursiveDelete(File)<br/>Value loaded from children<br/>Dereferenced at ClientBaseWithFixes.java:[line 490]<br/>Known null at ClientBaseWithFixes.java:[line 489]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N95607');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Load of known null value in org.apache.hadoop.hdfs.DFSUtil.assertAllResultsEqual(Collection)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N95607" style="display: none;">
<a href="#NP_LOAD_OF_KNOWN_NULL_VALUE">Bug type NP_LOAD_OF_KNOWN_NULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.DFSUtil<br/>In method org.apache.hadoop.hdfs.DFSUtil.assertAllResultsEqual(Collection)<br/>Value loaded from currElement<br/>At DFSUtil.java:[line 1768]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N114048');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.qjournal.server.JournalNode.getJournalsStatus() due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N114048" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.qjournal.server.JournalNode<br/>In method org.apache.hadoop.hdfs.qjournal.server.JournalNode.getJournalsStatus()<br/>Value loaded from journalDirs<br/>Dereferenced at JournalNode.java:[line 264]<br/>Known null at JournalNode.java:[line 258]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N114560');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.security.token.block.TestBlockToken.countOpenFileDescriptors() due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N114560" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.security.token.block.TestBlockToken<br/>In method org.apache.hadoop.hdfs.security.token.block.TestBlockToken.countOpenFileDescriptors()<br/>Local variable stored in JVM register ?<br/>Dereferenced at TestBlockToken.java:[line 341]<br/>Known null at TestBlockToken.java:[line 341]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N115762');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase.findAllFiles(File, FilenameFilter) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N115762" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase<br/>In method org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase.findAllFiles(File, FilenameFilter)<br/>Value loaded from arr$<br/>Dereferenced at BlockReportTestBase.java:[line 783]<br/>Known null at BlockReportTestBase.java:[line 783]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N116350');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.datanode.DataStorage.linkBlocks(File, File, int, HardLink) due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N116350" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.DataStorage<br/>In method org.apache.hadoop.hdfs.server.datanode.DataStorage.linkBlocks(File, File, int, HardLink)<br/>Value loaded from blockNames<br/>Dereferenced at DataStorage.java:[line 820]<br/>Known null at DataStorage.java:[line 811]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N116426');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.datanode.DataStorage.linkBlocks(File, File, int, HardLink) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N116426" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.DataStorage<br/>In method org.apache.hadoop.hdfs.server.datanode.DataStorage.linkBlocks(File, File, int, HardLink)<br/>Value loaded from otherNames<br/>Dereferenced at DataStorage.java:[line 836]<br/>Known null at DataStorage.java:[line 829]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N121804');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart.testRbwReplicas(MiniDFSCluster, boolean) due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N121804" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart<br/>In method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestDatanodeRestart.testRbwReplicas(MiniDFSCluster, boolean)<br/>Value loaded from arr$<br/>Dereferenced at TestDatanodeRestart.java:[line 108]<br/>Known null at TestDatanodeRestart.java:[line 108]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N118124');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.deteteBlocks(File) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N118124" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.deteteBlocks(File)<br/>Value loaded from fileList<br/>Dereferenced at TestDataNodeVolumeFailure.java:[line 272]<br/>Known null at TestDataNodeVolumeFailure.java:[line 271]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N119521');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.datanode.TestDeleteBlockPool.testDeleteBlockPool() due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N119521" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDeleteBlockPool<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDeleteBlockPool.testDeleteBlockPool()<br/>Local variable stored in JVM register ?<br/>Dereferenced at TestDeleteBlockPool.java:[line 106]<br/>Known null at TestDeleteBlockPool.java:[line 106]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N119647');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.datanode.TestDiskError.testReplicationError() due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N119647" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDiskError<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDiskError.testReplicationError()<br/>Local variable stored in JVM register ?<br/>Dereferenced at TestDiskError.java:[line 168]<br/>Known null at TestDiskError.java:[line 168]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N124250');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil.assertParallelFilesAreIdentical(List, Set) due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N124250" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil<br/>In method org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil.assertParallelFilesAreIdentical(List, Set)<br/>Value loaded from arr$<br/>Dereferenced at FSImageTestUtil.java:[line 303]<br/>Known null at FSImageTestUtil.java:[line 303]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N124323');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil.logStorageContents(Log, NNStorage) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N124323" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil<br/>In method org.apache.hadoop.hdfs.server.namenode.FSImageTestUtil.logStorageContents(Log, NNStorage)<br/>Value loaded from files<br/>Method invoked at FSImageTestUtil.java:[line 541]<br/>Known null at FSImageTestUtil.java:[line 540]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N127785');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testDeleteTemporaryEditsOnStartup() due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N127785" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckpoint<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testDeleteTemporaryEditsOnStartup()<br/>Value loaded from tmpEdits<br/>Dereferenced at TestCheckpoint.java:[line 1661]<br/>Known null at TestCheckpoint.java:[line 1660]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N127858');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testDeleteTemporaryEditsOnStartup() due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N127858" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckpoint<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testDeleteTemporaryEditsOnStartup()<br/>Value loaded from tmpEdits<br/>Dereferenced at TestCheckpoint.java:[line 1672]<br/>Known null at TestCheckpoint.java:[line 1671]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N127931');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testEditFailureBeforeRename() due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N127931" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckpoint<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testEditFailureBeforeRename()<br/>Value loaded from tmpEdits<br/>Dereferenced at TestCheckpoint.java:[line 1546]<br/>Known null at TestCheckpoint.java:[line 1545]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N129037');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.namenode.TestEditLog.testEditLogFailOverFromCorrupt() due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N129037" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestEditLog<br/>In method org.apache.hadoop.hdfs.server.namenode.TestEditLog.testEditLogFailOverFromCorrupt()<br/>Value loaded from files<br/>Dereferenced at TestEditLog.java:[line 1422]<br/>Known null at TestEditLog.java:[line 1413]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N129110');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.namenode.TestEditLog.testEditLogFailOverFromMissing() due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N129110" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestEditLog<br/>In method org.apache.hadoop.hdfs.server.namenode.TestEditLog.testEditLogFailOverFromMissing()<br/>Value loaded from files<br/>Dereferenced at TestEditLog.java:[line 1381]<br/>Known null at TestEditLog.java:[line 1372]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N129183');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.namenode.TestEditLog.testLoadingWithGaps() due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N129183" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestEditLog<br/>In method org.apache.hadoop.hdfs.server.namenode.TestEditLog.testLoadingWithGaps()<br/>Value loaded from files<br/>Dereferenced at TestEditLog.java:[line 1252]<br/>Known null at TestEditLog.java:[line 1242]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N130276');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.namenode.TestFileJournalManager.testManyLogsWithCorruptInprogress() due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N130276" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFileJournalManager<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFileJournalManager.testManyLogsWithCorruptInprogress()<br/>Value loaded from files<br/>Dereferenced at TestFileJournalManager.java:[line 358]<br/>Known null at TestFileJournalManager.java:[line 349]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N130349');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.namenode.TestFileJournalManager.testManyLogsWithGaps() due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N130349" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFileJournalManager<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFileJournalManager.testManyLogsWithGaps()<br/>Value loaded from files<br/>Dereferenced at TestFileJournalManager.java:[line 326]<br/>Known null at TestFileJournalManager.java:[line 317]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N129676');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Dereference of the result of readLine() without nullcheck in org.apache.hadoop.hdfs.server.namenode.TestFSDirectory.testDumpTree()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N129676" style="display: none;">
<a href="#NP_DEREFERENCE_OF_READLINE_VALUE">Bug type NP_DEREFERENCE_OF_READLINE_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFSDirectory<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFSDirectory.testDumpTree()<br/>Value loaded from line<br/>At TestFSDirectory.java:[line 106]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N132869');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Dereference of the result of readLine() without nullcheck in org.apache.hadoop.hdfs.server.namenode.TestMetaSave.testMetaSave()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N132869" style="display: none;">
<a href="#NP_DEREFERENCE_OF_READLINE_VALUE">Bug type NP_DEREFERENCE_OF_READLINE_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestMetaSave<br/>In method org.apache.hadoop.hdfs.server.namenode.TestMetaSave.testMetaSave()<br/>Value loaded from line<br/>At TestMetaSave.java:[line 115]<br/>Another occurrence at TestMetaSave.java:[line 110]<br/>Another occurrence at TestMetaSave.java:[line 107]<br/>Another occurrence at TestMetaSave.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N132963');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Dereference of the result of readLine() without nullcheck in org.apache.hadoop.hdfs.server.namenode.TestMetaSave.testMetasaveAfterDelete()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N132963" style="display: none;">
<a href="#NP_DEREFERENCE_OF_READLINE_VALUE">Bug type NP_DEREFERENCE_OF_READLINE_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestMetaSave<br/>In method org.apache.hadoop.hdfs.server.namenode.TestMetaSave.testMetasaveAfterDelete()<br/>Value loaded from line<br/>At TestMetaSave.java:[line 159]<br/>Another occurrence at TestMetaSave.java:[line 157]<br/>Another occurrence at TestMetaSave.java:[line 153]<br/>Another occurrence at TestMetaSave.java:[line 155]<br/>Another occurrence at TestMetaSave.java:[line 151]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N133438');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.checkImageAndEditsFilesExistence(File, boolean, boolean) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N133438" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNameEditsConfigs.checkImageAndEditsFilesExistence(File, boolean, boolean)<br/>Local variable stored in JVM register ?<br/>Method invoked at TestNameEditsConfigs.java:[line 99]<br/>Known null at TestNameEditsConfigs.java:[line 99]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99912');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.TestDFSRollback.deleteMatchingFiles(File[], String) due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99912" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSRollback<br/>In method org.apache.hadoop.hdfs.TestDFSRollback.deleteMatchingFiles(File[], String)<br/>Value loaded from arr$<br/>Dereferenced at TestDFSRollback.java:[line 338]<br/>Known null at TestDFSRollback.java:[line 338]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N103052');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.TestDFSUpgrade.deleteStorageFilesWithPrefix(String[], String) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N103052" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSUpgrade<br/>In method org.apache.hadoop.hdfs.TestDFSUpgrade.deleteStorageFilesWithPrefix(String[], String)<br/>Value loaded from arr$<br/>Dereferenced at TestDFSUpgrade.java:[line 426]<br/>Known null at TestDFSUpgrade.java:[line 426]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N105316');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.TestFetchImage.getHighestFsImageOnCluster(MiniDFSCluster) due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N105316" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFetchImage<br/>In method org.apache.hadoop.hdfs.TestFetchImage.getHighestFsImageOnCluster(MiniDFSCluster)<br/>Value loaded from arr$<br/>Dereferenced at TestFetchImage.java:[line 107]<br/>Known null at TestFetchImage.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N110482');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.hdfs.UpgradeUtilities.checksumContents(HdfsServerConstants$NodeType, File) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N110482" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.UpgradeUtilities<br/>In method org.apache.hadoop.hdfs.UpgradeUtilities.checksumContents(HdfsServerConstants$NodeType, File)<br/>Value loaded from list<br/>Method invoked at UpgradeUtilities.java:[line 287]<br/>Known null at UpgradeUtilities.java:[line 286]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N161938');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.ipc.TestIPC.countOpenFileDescriptors() due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N161938" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestIPC<br/>In method org.apache.hadoop.ipc.TestIPC.countOpenFileDescriptors()<br/>Local variable stored in JVM register ?<br/>Dereferenced at TestIPC.java:[line 930]<br/>Known null at TestIPC.java:[line 930]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N167941');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in new org.apache.hadoop.mapred.LocalContainerLauncher(AppContext, TaskUmbilicalProtocol) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N167941" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.LocalContainerLauncher<br/>In method new org.apache.hadoop.mapred.LocalContainerLauncher(AppContext, TaskUmbilicalProtocol)<br/>Value loaded from curLocalFiles<br/>Dereferenced at LocalContainerLauncher.java:[line 108]<br/>Known null at LocalContainerLauncher.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N187026');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Dereference of the result of readLine() without nullcheck in org.apache.hadoop.mapreduce.TestJobMonitorAndPrint.testJobMonitorAndPrint()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N187026" style="display: none;">
<a href="#NP_DEREFERENCE_OF_READLINE_VALUE">Bug type NP_DEREFERENCE_OF_READLINE_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestJobMonitorAndPrint<br/>In method org.apache.hadoop.mapreduce.TestJobMonitorAndPrint.testJobMonitorAndPrint()<br/>Value loaded from line<br/>At TestJobMonitorAndPrint.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N187517');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Immediate dereference of the result of readLine() in org.apache.hadoop.mapreduce.TestLocalRunner.verifyOutput(Path)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N187517" style="display: none;">
<a href="#NP_IMMEDIATE_DEREFERENCE_OF_READLINE">Bug type NP_IMMEDIATE_DEREFERENCE_OF_READLINE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestLocalRunner<br/>In method org.apache.hadoop.mapreduce.TestLocalRunner.verifyOutput(Path)<br/>At TestLocalRunner.java:[line 230]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N197291');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.makeSureCleanedUp(String[], MRAsyncDiskService) due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N197291" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService<br/>In method org.apache.hadoop.mapreduce.util.TestMRAsyncDiskService.makeSureCleanedUp(String[], MRAsyncDiskService)<br/>Value loaded from subDirContent<br/>Dereferenced at TestMRAsyncDiskService.java:[line 323]<br/>Known null at TestMRAsyncDiskService.java:[line 322]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N212720');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.minikdc.MiniKdc.delete(File) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N212720" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.minikdc.MiniKdc<br/>In method org.apache.hadoop.minikdc.MiniKdc.delete(File)<br/>Value loaded from arr$<br/>Dereferenced at MiniKdc.java:[line 489]<br/>Known null at MiniKdc.java:[line 489]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N218071');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Immediate dereference of the result of readLine() in org.apache.hadoop.security.TestProxyUserFromEnv.testProxyUserFromEnvironment()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N218071" style="display: none;">
<a href="#NP_IMMEDIATE_DEREFERENCE_OF_READLINE">Bug type NP_IMMEDIATE_DEREFERENCE_OF_READLINE (click for details)</a>
<br/>In class org.apache.hadoop.security.TestProxyUserFromEnv<br/>In method org.apache.hadoop.security.TestProxyUserFromEnv.testProxyUserFromEnvironment()<br/>At TestProxyUserFromEnv.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N218479');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Dereference of the result of readLine() without nullcheck in org.apache.hadoop.security.TestUserGroupInformation.testGetServerSideGroups()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N218479" style="display: none;">
<a href="#NP_DEREFERENCE_OF_READLINE_VALUE">Bug type NP_DEREFERENCE_OF_READLINE_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.security.TestUserGroupInformation<br/>In method org.apache.hadoop.security.TestUserGroupInformation.testGetServerSideGroups()<br/>Value loaded from line<br/>At TestUserGroupInformation.java:[line 210]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N218540');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Immediate dereference of the result of readLine() in org.apache.hadoop.security.TestUserGroupInformation.testGetServerSideGroups()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N218540" style="display: none;">
<a href="#NP_IMMEDIATE_DEREFERENCE_OF_READLINE">Bug type NP_IMMEDIATE_DEREFERENCE_OF_READLINE (click for details)</a>
<br/>In class org.apache.hadoop.security.TestUserGroupInformation<br/>In method org.apache.hadoop.security.TestUserGroupInformation.testGetServerSideGroups()<br/>At TestUserGroupInformation.java:[line 190]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N224189');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.streaming.UtilTest.recursiveDelete(File) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N224189" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.streaming.UtilTest<br/>In method org.apache.hadoop.streaming.UtilTest.recursiveDelete(File)<br/>Value loaded from arr$<br/>Dereferenced at UtilTest.java:[line 52]<br/>Known null at UtilTest.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N229777');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.util.JarFinder.zipDir(File, String, ZipOutputStream, boolean) due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N229777" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.util.JarFinder<br/>In method org.apache.hadoop.util.JarFinder.zipDir(File, String, ZipOutputStream, boolean)<br/>Value loaded from dirList<br/>Dereferenced at JarFinder.java:[line 80]<br/>Known null at JarFinder.java:[line 79]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N234613');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.util.TestWinUtils.testBasicChmodOnDir() due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N234613" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.testBasicChmodOnDir()<br/>Value loaded from files<br/>Dereferenced at TestWinUtils.java:[line 295]<br/>Known null at TestWinUtils.java:[line 294]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N234686');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.util.TestWinUtils.testBasicChmodOnDir() due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N234686" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.util.TestWinUtils<br/>In method org.apache.hadoop.util.TestWinUtils.testBasicChmodOnDir()<br/>Value loaded from files<br/>Dereferenced at TestWinUtils.java:[line 342]<br/>Known null at TestWinUtils.java:[line 341]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N237421');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyContainerLog(int, List, boolean, String) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N237421" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell<br/>In method org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyContainerLog(int, List, boolean, String)<br/>Local variable stored in JVM register ?<br/>Dereferenced at TestDistributedShell.java:[line 646]<br/>Known null at TestDistributedShell.java:[line 646]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N237494');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyContainerLog(int, List, boolean, String) due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N237494" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell<br/>In method org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyContainerLog(int, List, boolean, String)<br/>Value loaded from arr$<br/>Dereferenced at TestDistributedShell.java:[line 657]<br/>Known null at TestDistributedShell.java:[line 657]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N237570');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyContainerLog(int, List, boolean, String) due to return value of called method</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N237570" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell<br/>In method org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyContainerLog(int, List, boolean, String)<br/>Value loaded from containerFiles<br/>Dereferenced at TestDistributedShell.java:[line 656]<br/>Known null at TestDistributedShell.java:[line 652]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N237646');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyContainerLog(int, List, boolean, String) due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N237646" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell<br/>In method org.apache.hadoop.yarn.applications.distributedshell.TestDistributedShell.verifyContainerLog(int, List, boolean, String)<br/>Value loaded from listOfFiles<br/>Dereferenced at TestDistributedShell.java:[line 645]<br/>Known null at TestDistributedShell.java:[line 643]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N251349');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Immediate dereference of the result of readLine() in org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerEnvVariables()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N251349" style="display: none;">
<a href="#NP_IMMEDIATE_DEREFERENCE_OF_READLINE">Bug type NP_IMMEDIATE_DEREFERENCE_OF_READLINE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.TestContainerLaunch.testContainerEnvVariables()<br/>At TestContainerLaunch.java:[line 536]<br/>Another occurrence at TestContainerLaunch.java:[line 575]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N254917');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Immediate dereference of the result of readLine() in org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerKillOnMemoryOverflow()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N254917" style="display: none;">
<a href="#NP_IMMEDIATE_DEREFERENCE_OF_READLINE">Bug type NP_IMMEDIATE_DEREFERENCE_OF_READLINE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.TestContainersMonitor.testContainerKillOnMemoryOverflow()<br/>At TestContainersMonitor.java:[line 260]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N250098');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Immediate dereference of the result of readLine() in org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerLaunchAndStop()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N250098" style="display: none;">
<a href="#NP_IMMEDIATE_DEREFERENCE_OF_READLINE">Bug type NP_IMMEDIATE_DEREFERENCE_OF_READLINE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.TestContainerManager.testContainerLaunchAndStop()<br/>At TestContainerManager.java:[line 326]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N273570');">
<td>
<span class="priority-2">NP</span>
</td>
<td>Possible null pointer dereference in org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.getProcessList() due to return value of called method</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N273570" style="display: none;">
<a href="#NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">Bug type NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.ProcfsBasedProcessTree<br/>In method org.apache.hadoop.yarn.util.ProcfsBasedProcessTree.getProcessList()<br/>Value loaded from processDirs<br/>Dereferenced at ProcfsBasedProcessTree.java:[line 463]<br/>Known null at ProcfsBasedProcessTree.java:[line 460]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70846');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of results, which is known to be non-null in org.apache.hadoop.examples.pi.Parser.combine(Map)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70846" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.examples.pi.Parser<br/>In method org.apache.hadoop.examples.pi.Parser.combine(Map)<br/>Value loaded from results<br/>Return value of org.apache.hadoop.examples.pi.Util.combine(Collection) of type java.util.List<br/>Redundant null check at Parser.java:[line 156]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N73871');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of clazz, which is known to be non-null in org.apache.hadoop.fs.FileSystem.createFileSystem(URI, Configuration)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N73871" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.fs.FileSystem<br/>In method org.apache.hadoop.fs.FileSystem.createFileSystem(URI, Configuration)<br/>Value loaded from clazz<br/>Return value of org.apache.hadoop.fs.FileSystem.getFileSystemClass(String, Configuration) of type Class<br/>Redundant null check at FileSystem.java:[line 2393]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84398');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of dirEntries, which is known to be non-null in org.apache.hadoop.fs.ftp.FTPFileSystem.delete(FTPClient, Path, boolean)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84398" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.fs.ftp.FTPFileSystem<br/>In method org.apache.hadoop.fs.ftp.FTPFileSystem.delete(FTPClient, Path, boolean)<br/>Value loaded from dirEntries<br/>Return value of org.apache.hadoop.fs.ftp.FTPFileSystem.listStatus(FTPClient, Path) of type org.apache.hadoop.fs.FileStatus[]<br/>Redundant null check at FTPFileSystem.java:[line 321]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N84476');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of org.apache.hadoop.fs.ftp.FTPFileSystem.getFileStatus(FTPClient, Path), which is known to be non-null in org.apache.hadoop.fs.ftp.FTPFileSystem.exists(FTPClient, Path)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N84476" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.fs.ftp.FTPFileSystem<br/>In method org.apache.hadoop.fs.ftp.FTPFileSystem.exists(FTPClient, Path)<br/>Return value of org.apache.hadoop.fs.ftp.FTPFileSystem.getFileStatus(FTPClient, Path) of type org.apache.hadoop.fs.FileStatus<br/>Redundant null check at FTPFileSystem.java:[line 278]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N90994');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of StringBuilder.toString(), which is known to be non-null in new org.apache.hadoop.fs.viewfs.InodeTree(Configuration, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N90994" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.InodeTree<br/>In method new org.apache.hadoop.fs.viewfs.InodeTree(Configuration, String)<br/>Return value of StringBuilder.toString() of type String<br/>Redundant null check at InodeTree.java:[line 338]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94230');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of org.apache.hadoop.hdfs.AppendTestUtil.RANDOM_NUMBER_GENERATOR_SEED which is known to be null in org.apache.hadoop.hdfs.AppendTestUtil.&lt;static initializer for AppendTestUtil&gt;()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94230" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.AppendTestUtil<br/>In method org.apache.hadoop.hdfs.AppendTestUtil.&lt;static initializer for AppendTestUtil&gt;()<br/>Value loaded from field org.apache.hadoop.hdfs.AppendTestUtil.RANDOM_NUMBER_GENERATOR_SEED<br/>Redundant null check at AppendTestUtil.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N94601');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of curPeer, which is known to be non-null in org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N94601" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.BlockReaderFactory<br/>In method org.apache.hadoop.hdfs.BlockReaderFactory.getRemoteBlockReaderFromTcp()<br/>Value loaded from curPeer<br/>Return value of org.apache.hadoop.hdfs.BlockReaderFactory.nextTcpPeer() of type org.apache.hadoop.hdfs.BlockReaderFactory$BlockReaderPeer<br/>Redundant null check at BlockReaderFactory.java:[line 662]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N113638');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of intervals, which is known to be non-null in new org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannelMetrics(IPCLoggerChannel)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N113638" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannelMetrics<br/>In method new org.apache.hadoop.hdfs.qjournal.client.IPCLoggerChannelMetrics(IPCLoggerChannel)<br/>Value loaded from intervals<br/>Return value of org.apache.hadoop.conf.Configuration.getInts(String) of type int[]<br/>Redundant null check at IPCLoggerChannelMetrics.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N121589');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of f, which is known to be non-null in org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.invalidate(String, Block[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N121589" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl<br/>In method org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.invalidate(String, Block[])<br/>Value loaded from f<br/>Return value of org.apache.hadoop.hdfs.server.datanode.ReplicaInfo.getBlockFile() of type java.io.File<br/>Redundant null check at FsDatasetImpl.java:[line 1174]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N118197');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of dir, which is known to be non-null in org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.countRealBlocks(Map)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N118197" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure.countRealBlocks(Map)<br/>Value loaded from dir<br/>Return value of org.apache.hadoop.hdfs.MiniDFSCluster.getFinalizedDir(File, String) of type java.io.File<br/>Redundant null check at TestDataNodeVolumeFailure.java:[line 379]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N125959');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of fos, which is known to be non-null in org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.copyBlocksToLostFound(String, HdfsFileStatus, LocatedBlocks)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N125959" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.NamenodeFsck<br/>In method org.apache.hadoop.hdfs.server.namenode.NamenodeFsck.copyBlocksToLostFound(String, HdfsFileStatus, LocatedBlocks)<br/>Value loaded from fos<br/>Return value of org.apache.hadoop.hdfs.DFSClient.create(String, boolean) of type java.io.OutputStream<br/>Redundant null check at NamenodeFsck.java:[line 534]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N126550');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of locatedBlocks, which is known to be non-null in org.apache.hadoop.hdfs.server.namenode.TestBlockUnderConstruction.writeFile(Path, FSDataOutputStream, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N126550" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestBlockUnderConstruction<br/>In method org.apache.hadoop.hdfs.server.namenode.TestBlockUnderConstruction.writeFile(Path, FSDataOutputStream, int)<br/>Value loaded from locatedBlocks<br/>Return value of org.apache.hadoop.hdfs.DFSClient.getBlockLocations(String, long, long) of type org.apache.hadoop.fs.BlockLocation[]<br/>Redundant null check at TestBlockUnderConstruction.java:[line 79]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N164952');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of hadoopConfDir, which is known to be non-null in org.apache.hadoop.lib.service.hadoop.FileSystemAccessService.init()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N164952" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.lib.service.hadoop.FileSystemAccessService<br/>In method org.apache.hadoop.lib.service.hadoop.FileSystemAccessService.init()<br/>Value loaded from hadoopConfDir<br/>Return value of java.io.File.getAbsoluteFile() of type java.io.File<br/>Redundant null check at FileSystemAccessService.java:[line 179]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N166885');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of info, which is known to be non-null in org.apache.hadoop.mapred.IndexCache.removeMap(String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N166885" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapred.IndexCache<br/>In method org.apache.hadoop.mapred.IndexCache.removeMap(String)<br/>Value loaded from info<br/>Return value of java.util.concurrent.ConcurrentHashMap.get(Object) of type Object<br/>Redundant null check at IndexCache.java:[line 148]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N185866');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of org.apache.hadoop.mapreduce.task.JobContextImpl.getWorkingDirectory(), which is known to be non-null in org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(Job, Path)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N185866" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.JobSubmitter<br/>In method org.apache.hadoop.mapreduce.JobSubmitter.copyAndConfigureFiles(Job, Path)<br/>Return value of org.apache.hadoop.mapreduce.task.JobContextImpl.getWorkingDirectory() of type org.apache.hadoop.fs.Path<br/>Redundant null check at JobSubmitter.java:[line 304]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N197213');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of value, which is known to be non-null in org.apache.hadoop.mapreduce.util.ResourceBundles.getValue(String, String, String, Object)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N197213" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.util.ResourceBundles<br/>In method org.apache.hadoop.mapreduce.util.ResourceBundles.getValue(String, String, String, Object)<br/>Value loaded from value<br/>Return value of java.util.ResourceBundle.getObject(String) of type Object<br/>Redundant null check at ResourceBundles.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N202839');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of jobId, which is known to be non-null in org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices.getJobFromJobIdString(String, AppContext)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N202839" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices.getJobFromJobIdString(String, AppContext)<br/>Value loaded from jobId<br/>Return value of org.apache.hadoop.mapreduce.v2.util.MRApps.toJobID(String) of type org.apache.hadoop.mapreduce.v2.api.records.JobId<br/>Redundant null check at AMWebServices.java:[line 117]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N202917');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of attemptId, which is known to be non-null in org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices.getTaskAttemptFromTaskAttemptString(String, Task)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N202917" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices.getTaskAttemptFromTaskAttemptString(String, Task)<br/>Value loaded from attemptId<br/>Return value of org.apache.hadoop.mapreduce.v2.util.MRApps.toTaskAttemptID(String) of type org.apache.hadoop.mapreduce.v2.api.records.TaskAttemptId<br/>Redundant null check at AMWebServices.java:[line 182]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N202995');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of taskID, which is known to be non-null in org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices.getTaskFromTaskIdString(String, Job)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N202995" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.AMWebServices.getTaskFromTaskIdString(String, Job)<br/>Value loaded from taskID<br/>Return value of org.apache.hadoop.mapreduce.v2.util.MRApps.toTaskID(String) of type org.apache.hadoop.mapreduce.v2.api.records.TaskId<br/>Redundant null check at AMWebServices.java:[line 149]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N204387');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of id, which is known to be non-null in org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.verifyAMJobXML(NodeList, AppContext)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N204387" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebServicesJobs.verifyAMJobXML(NodeList, AppContext)<br/>Value loaded from id<br/>Return value of org.w3c.dom.Element.getElementsByTagName(String) of type org.w3c.dom.NodeList<br/>Redundant null check at TestAMWebServicesJobs.java:[line 526]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N206049');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of serialPart, which is known to be non-null in org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.addDirectoryToSerialNumberIndex(Path)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N206049" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager<br/>In method org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.addDirectoryToSerialNumberIndex(Path)<br/>Value loaded from serialPart<br/>Return value of org.apache.hadoop.fs.Path.getName() of type String<br/>Redundant null check at HistoryFileManager.java:[line 704]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N206127');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of serialPart, which is known to be non-null in org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.removeDirectoryFromSerialNumberIndex(Path)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N206127" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager<br/>In method org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.removeDirectoryFromSerialNumberIndex(Path)<br/>Value loaded from serialPart<br/>Return value of org.apache.hadoop.fs.Path.getName() of type String<br/>Redundant null check at HistoryFileManager.java:[line 684]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N206205');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of old, which is known to be non-null in org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.scanIntermediateDirectory(Path)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N206205" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager<br/>In method org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager.scanIntermediateDirectory(Path)<br/>Value loaded from old<br/>Return value of org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$JobListCache.addIfAbsent(HistoryFileManager$HistoryFileInfo) of type org.apache.hadoop.mapreduce.v2.hs.HistoryFileManager$HistoryFileInfo<br/>Redundant null check at HistoryFileManager.java:[line 851]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N206759');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of taskID, which is known to be non-null in org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices.getSingleTaskCounters(HttpServletRequest, String, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N206759" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.HsWebServices.getSingleTaskCounters(HttpServletRequest, String, String)<br/>Value loaded from taskID<br/>Return value of org.apache.hadoop.mapreduce.v2.util.MRApps.toTaskID(String) of type org.apache.hadoop.mapreduce.v2.api.records.TaskId<br/>Redundant null check at HsWebServices.java:[line 328]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N210802');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of units, which is known to be non-null in org.apache.hadoop.metrics.ganglia.GangliaContext31.emitMetric(String, String, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N210802" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.metrics.ganglia.GangliaContext31<br/>In method org.apache.hadoop.metrics.ganglia.GangliaContext31.emitMetric(String, String, String)<br/>Value loaded from units<br/>Return value of org.apache.hadoop.metrics.ganglia.GangliaContext.getUnits(String) of type String<br/>Redundant null check at GangliaContext31.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N228798');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of addedLine, which is known to be non-null in org.apache.hadoop.tools.rumen.Hadoop20JHParser.getFullLine()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N228798" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.tools.rumen.Hadoop20JHParser<br/>In method org.apache.hadoop.tools.rumen.Hadoop20JHParser.getFullLine()<br/>Value loaded from addedLine<br/>Return value of org.apache.hadoop.tools.rumen.Hadoop20JHParser.getOneLine() of type String<br/>Redundant null check at Hadoop20JHParser.java:[line 196]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N228876');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of org.apache.hadoop.tools.rumen.HadoopLogsAnalyzer.input, which is known to be non-null in org.apache.hadoop.tools.rumen.HadoopLogsAnalyzer.setNextDirectoryInputStream()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N228876" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.tools.rumen.HadoopLogsAnalyzer<br/>In method org.apache.hadoop.tools.rumen.HadoopLogsAnalyzer.setNextDirectoryInputStream()<br/>Value loaded from field org.apache.hadoop.tools.rumen.HadoopLogsAnalyzer.input<br/>Redundant null check at HadoopLogsAnalyzer.java:[line 562]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N227408');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of org.apache.hadoop.tools.TestDistCh.RANDOM_NUMBER_GENERATOR_SEED which is known to be null in org.apache.hadoop.tools.TestDistCh.&lt;static initializer for TestDistCh&gt;()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N227408" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestDistCh<br/>In method org.apache.hadoop.tools.TestDistCh.&lt;static initializer for TestDistCh&gt;()<br/>Value loaded from field org.apache.hadoop.tools.TestDistCh.RANDOM_NUMBER_GENERATOR_SEED<br/>Redundant null check at TestDistCh.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N239175');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of blacklistToAdd, which is known to be non-null in org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(float)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N239175" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl<br/>In method org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(float)<br/>Value loaded from blacklistToAdd<br/>Return value of new java.util.ArrayList() of type void<br/>Redundant null check at AMRMClientImpl.java:[line 237]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N246118');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of app, which is known to be non-null in org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerImpl.getAMContainer(ApplicationAttemptId)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N246118" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerImpl<br/>In method org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerImpl.getAMContainer(ApplicationAttemptId)<br/>Value loaded from app<br/>Return value of org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerImpl.getApplication(ApplicationId) of type org.apache.hadoop.yarn.api.records.ApplicationReport<br/>Redundant null check at ApplicationHistoryManagerImpl.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N246196');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of app, which is known to be non-null in org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerImpl.getContainer(ContainerId)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N246196" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerImpl<br/>In method org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerImpl.getContainer(ContainerId)<br/>Value loaded from app<br/>Return value of org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerImpl.getApplication(ApplicationId) of type org.apache.hadoop.yarn.api.records.ApplicationReport<br/>Redundant null check at ApplicationHistoryManagerImpl.java:[line 199]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N246274');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of app, which is known to be non-null in org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerImpl.getContainers(ApplicationAttemptId)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N246274" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerImpl<br/>In method org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerImpl.getContainers(ApplicationAttemptId)<br/>Value loaded from app<br/>Return value of org.apache.hadoop.yarn.server.applicationhistoryservice.ApplicationHistoryManagerImpl.getApplication(ApplicationId) of type org.apache.hadoop.yarn.api.records.ApplicationReport<br/>Redundant null check at ApplicationHistoryManagerImpl.java:[line 231]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N255802');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of id, which is known to be non-null in org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices.getNodeApp(String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N255802" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices<br/>In method org.apache.hadoop.yarn.server.nodemanager.webapp.NMWebServices.getNodeApp(String)<br/>Value loaded from id<br/>Return value of org.apache.hadoop.yarn.util.ConverterUtils.toApplicationId(RecordFactory, String) of type org.apache.hadoop.yarn.api.records.ApplicationId<br/>Redundant null check at NMWebServices.java:[line 147]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N271583');">
<td>
<span class="priority-2">RCN</span>
</td>
<td>Redundant nullcheck of id, which is known to be non-null in org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.doGet(HttpServletRequest, HttpServletResponse)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N271583" style="display: none;">
<a href="#RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">Bug type RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet<br/>In method org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet.doGet(HttpServletRequest, HttpServletResponse)<br/>Value loaded from id<br/>Return value of org.apache.hadoop.yarn.util.Apps.toAppID(String) of type org.apache.hadoop.yarn.api.records.ApplicationId<br/>Redundant null check at WebAppProxyServlet.java:[line 255]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N132206');">
<td>
<span class="priority-2">REC</span>
</td>
<td>Exception is caught when Exception is not thrown in org.apache.hadoop.hdfs.server.namenode.TestHDFSConcat.testIllegalArg()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N132206" style="display: none;">
<a href="#REC_CATCH_EXCEPTION">Bug type REC_CATCH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestHDFSConcat<br/>In method org.apache.hadoop.hdfs.server.namenode.TestHDFSConcat.testIllegalArg()<br/>At TestHDFSConcat.java:[line 378]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N132608');">
<td>
<span class="priority-2">REC</span>
</td>
<td>Exception is caught when Exception is not thrown in org.apache.hadoop.hdfs.server.namenode.TestListCorruptFileBlocks.testListCorruptFileBlocksInSafeMode()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N132608" style="display: none;">
<a href="#REC_CATCH_EXCEPTION">Bug type REC_CATCH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestListCorruptFileBlocks<br/>In method org.apache.hadoop.hdfs.server.namenode.TestListCorruptFileBlocks.testListCorruptFileBlocksInSafeMode()<br/>At TestListCorruptFileBlocks.java:[line 254]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N133511');">
<td>
<span class="priority-2">REC</span>
</td>
<td>Exception is caught when Exception is not thrown in org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer.canAccess(String, InetSocketAddress)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N133511" style="display: none;">
<a href="#REC_CATCH_EXCEPTION">Bug type REC_CATCH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNameNodeHttpServer.canAccess(String, InetSocketAddress)<br/>At TestNameNodeHttpServer.java:[line 121]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N174482');">
<td>
<span class="priority-2">REC</span>
</td>
<td>Exception is caught when Exception is not thrown in org.apache.hadoop.mapred.TestMapRed.runJob(int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N174482" style="display: none;">
<a href="#REC_CATCH_EXCEPTION">Bug type REC_CATCH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMapRed<br/>In method org.apache.hadoop.mapred.TestMapRed.runJob(int)<br/>At TestMapRed.java:[line 769]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N199470');">
<td>
<span class="priority-2">REC</span>
</td>
<td>Exception is caught when Exception is not thrown in org.apache.hadoop.mapreduce.v2.TestUberAM.testFailingMapper()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N199470" style="display: none;">
<a href="#REC_CATCH_EXCEPTION">Bug type REC_CATCH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.TestUberAM<br/>In method org.apache.hadoop.mapreduce.v2.TestUberAM.testFailingMapper()<br/>At TestUberAM.java:[line 148]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N239320');">
<td>
<span class="priority-2">REC</span>
</td>
<td>Exception is caught when Exception is not thrown in org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAllocation(AMRMClientImpl)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N239320" style="display: none;">
<a href="#REC_CATCH_EXCEPTION">Bug type REC_CATCH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.api.impl.TestAMRMClient<br/>In method org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.testAllocation(AMRMClientImpl)<br/>At TestAMRMClient.java:[line 766]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N238754');">
<td>
<span class="priority-2">REC</span>
</td>
<td>Exception is caught when Exception is not thrown in org.apache.hadoop.yarn.client.TestRMFailover.getHeader(String, String)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N238754" style="display: none;">
<a href="#REC_CATCH_EXCEPTION">Bug type REC_CATCH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.TestRMFailover<br/>In method org.apache.hadoop.yarn.client.TestRMFailover.getHeader(String, String)<br/>At TestRMFailover.java:[line 340]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N253584');">
<td>
<span class="priority-2">REC</span>
</td>
<td>Exception is caught when Exception is not thrown in org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.eventToString(Event, String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N253584" style="display: none;">
<a href="#REC_CATCH_EXCEPTION">Bug type REC_CATCH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.logaggregation.TestLogAggregationService.eventToString(Event, String[])<br/>At TestLogAggregationService.java:[line 983]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N258227');">
<td>
<span class="priority-2">REC</span>
</td>
<td>Exception is caught when Exception is not thrown in org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService.testServiceAclsRefreshWithLocalConfigurationProvider()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N258227" style="display: none;">
<a href="#REC_CATCH_EXCEPTION">Bug type REC_CATCH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMAdminService.testServiceAclsRefreshWithLocalConfigurationProvider()<br/>At TestRMAdminService.java:[line 218]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N245509');">
<td>
<span class="priority-2">REC</span>
</td>
<td>Exception is caught when Exception is not thrown in org.apache.hadoop.yarn.server.TestContainerManagerSecurity.stopContainer(YarnRPC, Token, List, ApplicationAttemptId, NodeId)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N245509" style="display: none;">
<a href="#REC_CATCH_EXCEPTION">Bug type REC_CATCH_EXCEPTION (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.TestContainerManagerSecurity<br/>In method org.apache.hadoop.yarn.server.TestContainerManagerSecurity.stopContainer(YarnRPC, Token, List, ApplicationAttemptId, NodeId)<br/>At TestContainerManagerSecurity.java:[line 439]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84547');">
<td>
<span class="priority-1">RV</span>
</td>
<td>Return value of org.apache.hadoop.fs.permission.FsAction.or(FsAction) ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84547" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.fs.ftp.FTPFileSystem<br/>In method org.apache.hadoop.fs.ftp.FTPFileSystem.getFsAction(int, FTPFile)<br/>Called method org.apache.hadoop.fs.permission.FsAction.or(FsAction)<br/>At FTPFileSystem.java:[line 332]<br/>Another occurrence at FTPFileSystem.java:[line 335]<br/>Another occurrence at FTPFileSystem.java:[line 338]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N85679');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.security.authentication.server.AuthenticationToken.getUserName() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N85679" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.TestHttpFSKerberosAuthenticationHandler<br/>In method org.apache.hadoop.fs.http.server.TestHttpFSKerberosAuthenticationHandler.testGetToken(AuthenticationHandler, String, Text)<br/>Called method org.apache.hadoop.security.authentication.server.AuthenticationToken.getUserName()<br/>At TestHttpFSKerberosAuthenticationHandler.java:[line 158]<br/>Another occurrence at TestHttpFSKerberosAuthenticationHandler.java:[line 160]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N88329');">
<td>
<span class="priority-1">RV</span>
</td>
<td>Return value of new PartialListing(String, FileMetadata[], String[]) ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N88329" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.fs.s3native.InMemoryNativeFileSystemStore<br/>In method org.apache.hadoop.fs.s3native.InMemoryNativeFileSystemStore.list(String, String, int, String)<br/>Called method new org.apache.hadoop.fs.s3native.PartialListing(String, FileMetadata[], String[])<br/>At InMemoryNativeFileSystemStore.java:[line 168]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N91760');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.fs.FileStatus.isDirectory() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N91760" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest<br/>In method org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testInternalDeleteExisting2()<br/>Called method org.apache.hadoop.fs.FileStatus.isDirectory()<br/>At ViewFileSystemBaseTest.java:[line 635]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91830');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.fs.FileStatus.isDirectory() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91830" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest<br/>In method org.apache.hadoop.fs.viewfs.ViewFileSystemBaseTest.testInternalRename2()<br/>Called method org.apache.hadoop.fs.FileStatus.isDirectory()<br/>At ViewFileSystemBaseTest.java:[line 657]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N93001');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DummyHAService.getProxy(Configuration, int) ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N93001" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestFailoverController<br/>In method org.apache.hadoop.ha.TestFailoverController.testFailoverFromNonExistantServiceWithFencer()<br/>Called method org.apache.hadoop.ha.DummyHAService.getProxy(Configuration, int)<br/>At TestFailoverController.java:[line 243]<br/>Another occurrence at TestFailoverController.java:[line 256]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93082');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DummyHAService.getProxy(Configuration, int) ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93082" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestFailoverController<br/>In method org.apache.hadoop.ha.TestFailoverController.testFailoverToNonExistantServiceFails()<br/>Called method org.apache.hadoop.ha.DummyHAService.getProxy(Configuration, int)<br/>At TestFailoverController.java:[line 269]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N93698');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of Object.toString() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N93698" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestNodeFencer<br/>In method org.apache.hadoop.ha.TestNodeFencer.clearMockState()<br/>Called method Object.toString()<br/>At TestNodeFencer.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93768');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of HAServiceTarget.getAddress() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93768" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestNodeFencer<br/>In method org.apache.hadoop.ha.TestNodeFencer.clearMockState()<br/>Called method org.apache.hadoop.ha.HAServiceTarget.getAddress()<br/>At TestNodeFencer.java:[line 53]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94041');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DummyHAService.isAutoFailoverEnabled() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94041" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestZKFailoverController<br/>In method org.apache.hadoop.ha.TestZKFailoverController.testWontRunWhenAutoFailoverDisabled()<br/>Called method org.apache.hadoop.ha.DummyHAService.isAutoFailoverEnabled()<br/>At TestZKFailoverController.java:[line 157]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N114843');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DatanodeDescriptor.numBlocks() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N114843" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager<br/>In method org.apache.hadoop.hdfs.server.blockmanagement.TestBlockManager.testSafeModeIBRAfterIncremental()<br/>Called method org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor.numBlocks()<br/>At TestBlockManager.java:[line 597]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N116697');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.conf.Configured.getConf() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N116697" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBPOfferService<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBPOfferService.setupMocks()<br/>Called method org.apache.hadoop.conf.Configured.getConf()<br/>At TestBPOfferService.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N116767');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DataNode.getDnConf() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N116767" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBPOfferService<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBPOfferService.setupMocks()<br/>Called method org.apache.hadoop.hdfs.server.datanode.DataNode.getDnConf()<br/>At TestBPOfferService.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N116837');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DataNode.getFSDataset() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N116837" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBPOfferService<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBPOfferService.setupMocks()<br/>Called method org.apache.hadoop.hdfs.server.datanode.DataNode.getFSDataset()<br/>At TestBPOfferService.java:[line 111]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N116907');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DataNode.getMetrics() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N116907" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBPOfferService<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBPOfferService.setupMocks()<br/>Called method org.apache.hadoop.hdfs.server.datanode.DataNode.getMetrics()<br/>At TestBPOfferService.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N116977');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DataNode.shouldRun() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N116977" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBPOfferService<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBPOfferService.setupMocks()<br/>Called method org.apache.hadoop.hdfs.server.datanode.DataNode.shouldRun()<br/>At TestBPOfferService.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N117047');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.conf.Configured.getConf() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N117047" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBPOfferService<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBPOfferService.testBPInitErrorHandling()<br/>Called method org.apache.hadoop.conf.Configured.getConf()<br/>At TestBPOfferService.java:[line 311]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N117117');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DataNode.getDnConf() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N117117" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBPOfferService<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBPOfferService.testBPInitErrorHandling()<br/>Called method org.apache.hadoop.hdfs.server.datanode.DataNode.getDnConf()<br/>At TestBPOfferService.java:[line 312]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N117187');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DataNode.getMetrics() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N117187" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBPOfferService<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBPOfferService.testBPInitErrorHandling()<br/>Called method org.apache.hadoop.hdfs.server.datanode.DataNode.getMetrics()<br/>At TestBPOfferService.java:[line 313]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N117257');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DataNode.shouldRun() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N117257" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestBPOfferService<br/>In method org.apache.hadoop.hdfs.server.datanode.TestBPOfferService.testBPInitErrorHandling()<br/>Called method org.apache.hadoop.hdfs.server.datanode.DataNode.shouldRun()<br/>At TestBPOfferService.java:[line 306]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N118869');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.common.StorageInfo.getLayoutVersion() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N118869" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister.setUp()<br/>Called method org.apache.hadoop.hdfs.server.common.StorageInfo.getLayoutVersion()<br/>At TestDatanodeRegister.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N118939');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of BPOfferService.getDataNode() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N118939" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister.setUp()<br/>Called method org.apache.hadoop.hdfs.server.datanode.BPOfferService.getDataNode()<br/>At TestDatanodeRegister.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N119009');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DNConf.getMinimumNameNodeVersion() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N119009" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister.setUp()<br/>Called method org.apache.hadoop.hdfs.server.datanode.DNConf.getMinimumNameNodeVersion()<br/>At TestDatanodeRegister.java:[line 55]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N119079');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DataNode.getDnConf() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N119079" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister.setUp()<br/>Called method org.apache.hadoop.hdfs.server.datanode.DataNode.getDnConf()<br/>At TestDatanodeRegister.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N119149');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DataNode.shouldRun() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N119149" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister.setUp()<br/>Called method org.apache.hadoop.hdfs.server.datanode.DataNode.shouldRun()<br/>At TestDatanodeRegister.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N119219');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.protocol.NamespaceInfo.getSoftwareVersion() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N119219" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister.setUp()<br/>Called method org.apache.hadoop.hdfs.server.protocol.NamespaceInfo.getSoftwareVersion()<br/>At TestDatanodeRegister.java:[line 68]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N119289');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.common.StorageInfo.getLayoutVersion() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N119289" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister.testDifferentLayoutVersions()<br/>Called method org.apache.hadoop.hdfs.server.common.StorageInfo.getLayoutVersion()<br/>At TestDatanodeRegister.java:[line 112]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N119359');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DNConf.getMinimumNameNodeVersion() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N119359" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister.testSoftwareVersionDifferences()<br/>Called method org.apache.hadoop.hdfs.server.datanode.DNConf.getMinimumNameNodeVersion()<br/>At TestDatanodeRegister.java:[line 88]<br/>Another occurrence at TestDatanodeRegister.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N119440');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.protocol.NamespaceInfo.getSoftwareVersion() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N119440" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDatanodeRegister.testSoftwareVersionDifferences()<br/>Called method org.apache.hadoop.hdfs.server.protocol.NamespaceInfo.getSoftwareVersion()<br/>At TestDatanodeRegister.java:[line 87]<br/>Another occurrence at TestDatanodeRegister.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N122326');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.conf.Configured.getConf() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N122326" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.web.resources.TestDatanodeWebHdfsMethods<br/>In method org.apache.hadoop.hdfs.server.datanode.web.resources.TestDatanodeWebHdfsMethods.testDeserializeHAToken()<br/>Called method org.apache.hadoop.conf.Configured.getConf()<br/>At TestDatanodeWebHdfsMethods.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N137261');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of java.util.concurrent.locks.ReentrantReadWriteLock.writeLock() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N137261" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestHAStateTransitions.testTransitionSynchronization()<br/>Called method java.util.concurrent.locks.ReentrantReadWriteLock.writeLock()<br/>At TestHAStateTransitions.java:[line 257]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N139969');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of SnapshotManager.getMaxSnapshotID() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N139969" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotManager<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotManager.testSnapshotLimits()<br/>Called method org.apache.hadoop.hdfs.server.namenode.snapshot.SnapshotManager.getMaxSnapshotID()<br/>At TestSnapshotManager.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N128004');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of CheckpointFaultInjector.shouldCorruptAByte(File) ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N128004" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckpoint<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testNameNodeImageSendFailWrongDigest()<br/>Called method org.apache.hadoop.hdfs.server.namenode.CheckpointFaultInjector.shouldCorruptAByte(File)<br/>At TestCheckpoint.java:[line 670]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N128074');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of CheckpointFaultInjector.shouldSendShortFile(File) ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N128074" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckpoint<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.testNameNodeImageSendFailWrongSize()<br/>Called method org.apache.hadoop.hdfs.server.namenode.CheckpointFaultInjector.shouldSendShortFile(File)<br/>At TestCheckpoint.java:[line 655]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N128556');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of FSNamesystem.getEditLog() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N128556" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCommitBlockSynchronization<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCommitBlockSynchronization.makeNameSystemSpy(Block, INodeFile)<br/>Called method org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getEditLog()<br/>At TestCommitBlockSynchronization.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N128626');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of INodeFile.isUnderConstruction() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N128626" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCommitBlockSynchronization<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCommitBlockSynchronization.makeNameSystemSpy(Block, INodeFile)<br/>Called method org.apache.hadoop.hdfs.server.namenode.INodeFile.isUnderConstruction()<br/>At TestCommitBlockSynchronization.java:[line 60]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N134988');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of FSImage.getEditLog() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N134988" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestSecurityTokenEditLog<br/>In method org.apache.hadoop.hdfs.server.namenode.TestSecurityTokenEditLog.testEditsForCancelOnTokenExpire()<br/>Called method org.apache.hadoop.hdfs.server.namenode.FSImage.getEditLog()<br/>At TestSecurityTokenEditLog.java:[line 183]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N135423');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of FSImage.getStorage() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N135423" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestStartup<br/>In method org.apache.hadoop.hdfs.server.namenode.TestStartup.testSNNStartup()<br/>Called method org.apache.hadoop.hdfs.server.namenode.FSImage.getStorage()<br/>At TestStartup.java:[line 395]<br/>Another occurrence at TestStartup.java:[line 397]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N135504');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of FSImage.getStorage() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N135504" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestStartup<br/>In method org.apache.hadoop.hdfs.server.namenode.TestStartup.verifyDifferentDirs(FSImage, long, long)<br/>Called method org.apache.hadoop.hdfs.server.namenode.FSImage.getStorage()<br/>At TestStartup.java:[line 282]<br/>Another occurrence at TestStartup.java:[line 287]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N135917');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.DFSInputStream.getFileLength() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N135917" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestStreamFile<br/>In method org.apache.hadoop.hdfs.server.namenode.TestStreamFile.testDoGetShouldCloseTheDFSInputStreamIfResponseGetOutPutStreamThrowsAnyException()<br/>Called method org.apache.hadoop.hdfs.DFSInputStream.getFileLength()<br/>At TestStreamFile.java:[line 256]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N103770');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.common.StorageInfo.getCTime() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N103770" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeRegistration<br/>In method org.apache.hadoop.hdfs.TestDatanodeRegistration.testChangeStorageID()<br/>Called method org.apache.hadoop.hdfs.server.common.StorageInfo.getCTime()<br/>At TestDatanodeRegistration.java:[line 182]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N103840');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.common.StorageInfo.getLayoutVersion() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N103840" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeRegistration<br/>In method org.apache.hadoop.hdfs.TestDatanodeRegistration.testChangeStorageID()<br/>Called method org.apache.hadoop.hdfs.server.common.StorageInfo.getLayoutVersion()<br/>At TestDatanodeRegistration.java:[line 183]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N103910');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.protocol.DatanodeID.getDatanodeUuid() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N103910" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeRegistration<br/>In method org.apache.hadoop.hdfs.TestDatanodeRegistration.testRegistrationWithDifferentSoftwareVersions()<br/>Called method org.apache.hadoop.hdfs.protocol.DatanodeID.getDatanodeUuid()<br/>At TestDatanodeRegistration.java:[line 230]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N103980');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.protocol.DatanodeID.getXferPort() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N103980" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeRegistration<br/>In method org.apache.hadoop.hdfs.TestDatanodeRegistration.testRegistrationWithDifferentSoftwareVersions()<br/>Called method org.apache.hadoop.hdfs.protocol.DatanodeID.getXferPort()<br/>At TestDatanodeRegistration.java:[line 229]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N104050');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.common.StorageInfo.getCTime() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N104050" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeRegistration<br/>In method org.apache.hadoop.hdfs.TestDatanodeRegistration.testRegistrationWithDifferentSoftwareVersions()<br/>Called method org.apache.hadoop.hdfs.server.common.StorageInfo.getCTime()<br/>At TestDatanodeRegistration.java:[line 225]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N104120');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getSoftwareVersion() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N104120" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeRegistration<br/>In method org.apache.hadoop.hdfs.TestDatanodeRegistration.testRegistrationWithDifferentSoftwareVersions()<br/>Called method org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getSoftwareVersion()<br/>At TestDatanodeRegistration.java:[line 234]<br/>Another occurrence at TestDatanodeRegistration.java:[line 238]<br/>Another occurrence at TestDatanodeRegistration.java:[line 242]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N104212');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getStorageInfo() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N104212" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeRegistration<br/>In method org.apache.hadoop.hdfs.TestDatanodeRegistration.testRegistrationWithDifferentSoftwareVersions()<br/>Called method org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getStorageInfo()<br/>At TestDatanodeRegistration.java:[line 231]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N104282');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getVersion() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N104282" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeRegistration<br/>In method org.apache.hadoop.hdfs.TestDatanodeRegistration.testRegistrationWithDifferentSoftwareVersions()<br/>Called method org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getVersion()<br/>At TestDatanodeRegistration.java:[line 228]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N104352');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.protocol.DatanodeID.getDatanodeUuid() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N104352" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeRegistration<br/>In method org.apache.hadoop.hdfs.TestDatanodeRegistration.testRegistrationWithDifferentSoftwareVersionsDuringUpgrade()<br/>Called method org.apache.hadoop.hdfs.protocol.DatanodeID.getDatanodeUuid()<br/>At TestDatanodeRegistration.java:[line 277]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N104422');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.protocol.DatanodeID.getXferPort() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N104422" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeRegistration<br/>In method org.apache.hadoop.hdfs.TestDatanodeRegistration.testRegistrationWithDifferentSoftwareVersionsDuringUpgrade()<br/>Called method org.apache.hadoop.hdfs.protocol.DatanodeID.getXferPort()<br/>At TestDatanodeRegistration.java:[line 283]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N104492');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.common.StorageInfo.getCTime() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N104492" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeRegistration<br/>In method org.apache.hadoop.hdfs.TestDatanodeRegistration.testRegistrationWithDifferentSoftwareVersionsDuringUpgrade()<br/>Called method org.apache.hadoop.hdfs.server.common.StorageInfo.getCTime()<br/>At TestDatanodeRegistration.java:[line 273]<br/>Another occurrence at TestDatanodeRegistration.java:[line 288]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N104573');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getSoftwareVersion() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N104573" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeRegistration<br/>In method org.apache.hadoop.hdfs.TestDatanodeRegistration.testRegistrationWithDifferentSoftwareVersionsDuringUpgrade()<br/>Called method org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getSoftwareVersion()<br/>At TestDatanodeRegistration.java:[line 282]<br/>Another occurrence at TestDatanodeRegistration.java:[line 293]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N104654');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getStorageInfo() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N104654" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeRegistration<br/>In method org.apache.hadoop.hdfs.TestDatanodeRegistration.testRegistrationWithDifferentSoftwareVersionsDuringUpgrade()<br/>Called method org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getStorageInfo()<br/>At TestDatanodeRegistration.java:[line 278]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N104724');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getVersion() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N104724" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDatanodeRegistration<br/>In method org.apache.hadoop.hdfs.TestDatanodeRegistration.testRegistrationWithDifferentSoftwareVersionsDuringUpgrade()<br/>Called method org.apache.hadoop.hdfs.server.protocol.DatanodeRegistration.getVersion()<br/>At TestDatanodeRegistration.java:[line 276]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N103539');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.util.DataChecksum.getBytesPerChecksum() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N103539" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDataTransferProtocol<br/>In method org.apache.hadoop.hdfs.TestDataTransferProtocol.testDataTransferProtocol()<br/>Called method org.apache.hadoop.util.DataChecksum.getBytesPerChecksum()<br/>At TestDataTransferProtocol.java:[line 388]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N104969');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of MiniDFSCluster.getDataNodes() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N104969" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDistributedFileSystem<br/>In method org.apache.hadoop.hdfs.TestDistributedFileSystem.testGetFileBlockStorageLocationsError()<br/>Called method org.apache.hadoop.hdfs.MiniDFSCluster.getDataNodes()<br/>At TestDistributedFileSystem.java:[line 764]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N107323');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DFSClient.getClientName() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N107323" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestLeaseRenewer<br/>In method org.apache.hadoop.hdfs.TestLeaseRenewer.createMockClient()<br/>Called method org.apache.hadoop.hdfs.DFSClient.getClientName()<br/>At TestLeaseRenewer.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N107393');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DFSClient.getHdfsTimeout() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N107393" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestLeaseRenewer<br/>In method org.apache.hadoop.hdfs.TestLeaseRenewer.createMockClient()<br/>Called method org.apache.hadoop.hdfs.DFSClient.getHdfsTimeout()<br/>At TestLeaseRenewer.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N107463');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DFSClient.isClientRunning() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N107463" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestLeaseRenewer<br/>In method org.apache.hadoop.hdfs.TestLeaseRenewer.createMockClient()<br/>Called method org.apache.hadoop.hdfs.DFSClient.isClientRunning()<br/>At TestLeaseRenewer.java:[line 63]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N108880');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.hdfs.server.common.StorageInfo.getServiceLayoutVersion() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N108880" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestRollingUpgradeDowngrade<br/>In method org.apache.hadoop.hdfs.TestRollingUpgradeDowngrade.testRejectNewFsImage()<br/>Called method org.apache.hadoop.hdfs.server.common.StorageInfo.getServiceLayoutVersion()<br/>At TestRollingUpgradeDowngrade.java:[line 104]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N109262');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of java.util.concurrent.locks.ReentrantReadWriteLock.writeLock() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N109262" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestSetTimes<br/>In method org.apache.hadoop.hdfs.TestSetTimes.testGetBlockLocationsOnlyUsesReadLock()<br/>Called method java.util.concurrent.locks.ReentrantReadWriteLock.writeLock()<br/>At TestSetTimes.java:[line 302]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N146937');">
<td>
<span class="priority-2">RV</span>
</td>
<td>org.apache.hadoop.http.TestGlobalFilter.access(String) discards result of readLine after checking if it is non-null</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N146937" style="display: none;">
<a href="#RV_DONT_JUST_NULL_CHECK_READLINE">Bug type RV_DONT_JUST_NULL_CHECK_READLINE (click for details)</a>
<br/>In class org.apache.hadoop.http.TestGlobalFilter<br/>In method org.apache.hadoop.http.TestGlobalFilter.access(String)<br/>At TestGlobalFilter.java:[line 95]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N147130');">
<td>
<span class="priority-2">RV</span>
</td>
<td>org.apache.hadoop.http.TestPathFilter.access(String) discards result of readLine after checking if it is non-null</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N147130" style="display: none;">
<a href="#RV_DONT_JUST_NULL_CHECK_READLINE">Bug type RV_DONT_JUST_NULL_CHECK_READLINE (click for details)</a>
<br/>In class org.apache.hadoop.http.TestPathFilter<br/>In method org.apache.hadoop.http.TestPathFilter.access(String)<br/>At TestPathFilter.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N147392');">
<td>
<span class="priority-2">RV</span>
</td>
<td>org.apache.hadoop.http.TestServletFilter.access(String) discards result of readLine after checking if it is non-null</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N147392" style="display: none;">
<a href="#RV_DONT_JUST_NULL_CHECK_READLINE">Bug type RV_DONT_JUST_NULL_CHECK_READLINE (click for details)</a>
<br/>In class org.apache.hadoop.http.TestServletFilter<br/>In method org.apache.hadoop.http.TestServletFilter.access(String)<br/>At TestServletFilter.java:[line 94]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N167101');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getJobID() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N167101" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getJobID()<br/>At JobClientUnitTest.java:[line 154]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N167171');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getNeededMem() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N167171" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getNeededMem()<br/>At JobClientUnitTest.java:[line 164]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N167241');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getNumReservedSlots() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N167241" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getNumReservedSlots()<br/>At JobClientUnitTest.java:[line 161]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N167311');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getNumUsedSlots() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N167311" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getNumUsedSlots()<br/>At JobClientUnitTest.java:[line 160]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N167381');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getPriority() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N167381" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getPriority()<br/>At JobClientUnitTest.java:[line 159]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N167451');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getQueue() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N167451" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getQueue()<br/>At JobClientUnitTest.java:[line 158]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N167521');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getReservedMem() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N167521" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getReservedMem()<br/>At JobClientUnitTest.java:[line 163]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N167591');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getSchedulingInfo() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N167591" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getSchedulingInfo()<br/>At JobClientUnitTest.java:[line 165]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N167661');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getStartTime() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N167661" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getStartTime()<br/>At JobClientUnitTest.java:[line 156]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N167731');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getState() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N167731" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getState()<br/>At JobClientUnitTest.java:[line 155]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N167801');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getUsedMem() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N167801" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getUsedMem()<br/>At JobClientUnitTest.java:[line 162]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N167871');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.JobStatus.getUsername() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N167871" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.JobClientUnitTest<br/>In method org.apache.hadoop.mapred.JobClientUnitTest.testShowJob()<br/>Called method org.apache.hadoop.mapreduce.JobStatus.getUsername()<br/>At JobClientUnitTest.java:[line 157]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N183194');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapreduce.task.JobContextImpl.getJobID() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N183194" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.jobcontrol.TestJobControl<br/>In method org.apache.hadoop.mapred.jobcontrol.TestJobControl.testGetAssignedJobId()<br/>Called method org.apache.hadoop.mapreduce.task.JobContextImpl.getJobID()<br/>At TestJobControl.java:[line 273]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N189122');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapred.ReduceTask.getNumMaps() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N189122" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestShufflePlugin<br/>In method org.apache.hadoop.mapreduce.TestShufflePlugin.testConsumerApi()<br/>Called method org.apache.hadoop.mapred.ReduceTask.getNumMaps()<br/>At TestShufflePlugin.java:[line 170]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N189192');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapred.Task.getPartition() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N189192" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestShufflePlugin<br/>In method org.apache.hadoop.mapreduce.TestShufflePlugin.testConsumerApi()<br/>Called method org.apache.hadoop.mapred.Task.getPartition()<br/>At TestShufflePlugin.java:[line 171]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N189262');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.mapred.Task.getTaskID() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N189262" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.TestShufflePlugin<br/>In method org.apache.hadoop.mapreduce.TestShufflePlugin.testConsumerApi()<br/>Called method org.apache.hadoop.mapred.Task.getTaskID()<br/>At TestShufflePlugin.java:[line 168]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N206438');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of JobHistory.getInitDelaySecs() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N206438" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.TestJobHistory<br/>In method org.apache.hadoop.mapreduce.v2.hs.TestJobHistory.testRefreshJobRetentionSettings()<br/>Called method org.apache.hadoop.mapreduce.v2.hs.JobHistory.getInitDelaySecs()<br/>At TestJobHistory.java:[line 166]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N213748');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of DomainSocket.accept() ignored, is this OK in org.apache.hadoop.net.unix.TestDomainSocket.testServerOptions()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N213748" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_INFERRED">Bug type RV_RETURN_VALUE_IGNORED_INFERRED (click for details)</a>
<br/>In class org.apache.hadoop.net.unix.TestDomainSocket<br/>In method org.apache.hadoop.net.unix.TestDomainSocket.testServerOptions()<br/>Called method org.apache.hadoop.net.unix.DomainSocket.accept()<br/>At TestDomainSocket.java:[line 297]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N229569');">
<td>
<span class="priority-1">RV</span>
</td>
<td>Return value of new org.apache.hadoop.tools.rumen.datatypes.DefaultDataType(String) ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N229569" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.tools.rumen.datatypes.util.MapReduceJobPropertiesParser<br/>In method org.apache.hadoop.tools.rumen.datatypes.util.MapReduceJobPropertiesParser.fromString(String, String)<br/>Called method new org.apache.hadoop.tools.rumen.datatypes.DefaultDataType(String)<br/>At MapReduceJobPropertiesParser.java:[line 211]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N231408');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.fs.FileStatus.getPermission() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N231408" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.util.TestDiskChecker<br/>In method org.apache.hadoop.util.TestDiskChecker._mkdirs(boolean, FsPermission, FsPermission)<br/>Called method org.apache.hadoop.fs.FileStatus.getPermission()<br/>At TestDiskChecker.java:[line 80]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N239056');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.getAvailableResources() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N239056" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.api.async.impl.TestAMRMClientAsync<br/>In method org.apache.hadoop.yarn.client.api.async.impl.TestAMRMClientAsync.testAMRMClientAsync()<br/>Called method org.apache.hadoop.yarn.client.api.async.AMRMClientAsync.getAvailableResources()<br/>At TestAMRMClientAsync.java:[line 132]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N238808');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.getClientRMService() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N238808" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.TestResourceManagerAdministrationProtocolPBClientImpl<br/>In method org.apache.hadoop.yarn.client.TestResourceManagerAdministrationProtocolPBClientImpl.testRefreshNodes()<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.ResourceManager.getClientRMService()<br/>At TestResourceManagerAdministrationProtocolPBClientImpl.java:[line 121]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N264730');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.getApplicationAttemptId() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N264730" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits.getMockApplication(int, String)<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.getApplicationAttemptId()<br/>At TestApplicationLimits.java:[line 141]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N264800');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.getApplicationId() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N264800" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits.getMockApplication(int, String)<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.getApplicationId()<br/>At TestApplicationLimits.java:[line 139]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N264870');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.getUser() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N264870" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits.getMockApplication(int, String)<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.getUser()<br/>At TestApplicationLimits.java:[line 142]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N264940');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of LeafQueue.getMaxApplications() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N264940" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits.setUp()<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getMaxApplications()<br/>At TestApplicationLimits.java:[line 113]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N265010');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of LeafQueue.getMaxApplicationsPerUser() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N265010" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits.setUp()<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getMaxApplicationsPerUser()<br/>At TestApplicationLimits.java:[line 114]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N265080');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of LeafQueue.getMaximumActiveApplications() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N265080" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits.setUp()<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getMaximumActiveApplications()<br/>At TestApplicationLimits.java:[line 115]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N265150');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of LeafQueue.getMaximumActiveApplicationsPerUser() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N265150" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits.setUp()<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getMaximumActiveApplicationsPerUser()<br/>At TestApplicationLimits.java:[line 116]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N265220');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of LeafQueue.getMaximumActiveApplications() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N265220" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits.testActiveApplicationLimits()<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getMaximumActiveApplications()<br/>At TestApplicationLimits.java:[line 345]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N265290');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of LeafQueue.getMaximumActiveApplications() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N265290" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestApplicationLimits.testActiveLimitsWithKilledApps()<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getMaximumActiveApplications()<br/>At TestApplicationLimits.java:[line 384]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N265438');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.getUser() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N265438" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestChildQueueOrder<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestChildQueueOrder.getMockApplication(int, String)<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.getUser()<br/>At TestChildQueueOrder.java:[line 104]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N265629');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of LeafQueue.getNodeLocalityDelay() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N265629" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestLeafQueue<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestLeafQueue.testLocalityScheduling()<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getNodeLocalityDelay()<br/>At TestLeafQueue.java:[line 1359]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N265699');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of LeafQueue.getNodeLocalityDelay() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N265699" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestLeafQueue<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestLeafQueue.testStolenReservedContainer()<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue.getNodeLocalityDelay()<br/>At TestLeafQueue.java:[line 1084]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N265769');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.getUser() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N265769" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestParentQueue<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestParentQueue.getMockApplication(int, String)<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerApplicationAttempt.getUser()<br/>At TestParentQueue.java:[line 117]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N258544');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.yarn.event.AbstractEvent.getType() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N258544" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions.getMockRMNodeStatusEvent()<br/>Called method org.apache.hadoop.yarn.event.AbstractEvent.getType()<br/>At TestRMNodeTransitions.java:[line 156]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N258614');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent.getLatestResponse() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N258614" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions.getMockRMNodeStatusEvent()<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent.getLatestResponse()<br/>At TestRMNodeTransitions.java:[line 155]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N258684');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent.getNodeHealthStatus() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N258684" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions.getMockRMNodeStatusEvent()<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent.getNodeHealthStatus()<br/>At TestRMNodeTransitions.java:[line 154]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N258754');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent.getContainers() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N258754" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions.testContainerUpdate()<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent.getContainers()<br/>At TestRMNodeTransitions.java:[line 217]<br/>Another occurrence at TestRMNodeTransitions.java:[line 228]<br/>Another occurrence at TestRMNodeTransitions.java:[line 233]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N258846');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent.getContainers() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N258846" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions.testExpiredContainer()<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent.getContainers()<br/>At TestRMNodeTransitions.java:[line 178]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N258916');">
<td>
<span class="priority-2">RV</span>
</td>
<td>Return value of org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent.getContainers() ignored, but method has no side effect</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N258916" style="display: none;">
<a href="#RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">Bug type RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMNodeTransitions.testStatusChange()<br/>Called method org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeStatusEvent.getContainers()<br/>At TestRMNodeTransitions.java:[line 269]<br/>Another occurrence at TestRMNodeTransitions.java:[line 273]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N84884');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.fs.http.client.BaseTestHttpFSWith.operation(BaseTestHttpFSWith$Operation) where one case falls through to the next case</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N84884" style="display: none;">
<a href="#SF_SWITCH_FALLTHROUGH">Bug type SF_SWITCH_FALLTHROUGH (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.client.BaseTestHttpFSWith<br/>In method org.apache.hadoop.fs.http.client.BaseTestHttpFSWith.operation(BaseTestHttpFSWith$Operation)<br/>At BaseTestHttpFSWith.java:[lines 502-504]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N84938');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.fs.http.client.BaseTestHttpFSWith.operation(BaseTestHttpFSWith$Operation) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N84938" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.client.BaseTestHttpFSWith<br/>In method org.apache.hadoop.fs.http.client.BaseTestHttpFSWith.operation(BaseTestHttpFSWith$Operation)<br/>At BaseTestHttpFSWith.java:[lines 488-534]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N84991');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.fs.http.client.HttpFSFileSystem.createFileStatus(Path, JSONObject) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N84991" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.client.HttpFSFileSystem<br/>In method org.apache.hadoop.fs.http.client.HttpFSFileSystem.createFileStatus(Path, JSONObject)<br/>At HttpFSFileSystem.java:[lines 817-826]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85559');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.fs.http.server.HttpFSKerberosAuthenticationHandler.managementOperation(AuthenticationToken, HttpServletRequest, HttpServletResponse) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85559" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.HttpFSKerberosAuthenticationHandler<br/>In method org.apache.hadoop.fs.http.server.HttpFSKerberosAuthenticationHandler.managementOperation(AuthenticationToken, HttpServletRequest, HttpServletResponse)<br/>At HttpFSKerberosAuthenticationHandler.java:[lines 107-142]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N88673');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.fs.shell.PathData.expandAsGlob(String, Configuration) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N88673" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.fs.shell.PathData<br/>In method org.apache.hadoop.fs.shell.PathData.expandAsGlob(String, Configuration)<br/>At PathData.java:[lines 354-366]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N88854');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.fs.shell.Test.processPath(PathData) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N88854" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.fs.shell.Test<br/>In method org.apache.hadoop.fs.shell.Test.processPath(PathData)<br/>At Test.java:[lines 71-85]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89647');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.fs.slive.OperationFactory.getOperation(Constants$OperationType) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89647" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.OperationFactory<br/>In method org.apache.hadoop.fs.slive.OperationFactory.getOperation(Constants$OperationType)<br/>At OperationFactory.java:[lines 56-76]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N89884');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.fs.slive.PathFinder.getPath(int, int, PathFinder$Type) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N89884" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.fs.slive.PathFinder<br/>In method org.apache.hadoop.fs.slive.PathFinder.getPath(int, int, PathFinder$Type)<br/>At PathFinder.java:[lines 69-74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N77762');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.fs.TestDFSIO.run(String[]) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N77762" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestDFSIO<br/>In method org.apache.hadoop.fs.TestDFSIO.run(String[])<br/>At TestDFSIO.java:[lines 753-766]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N113117');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.hdfs.protocolPB.PBHelper.convert(DatanodeProtocolProtos$ReceivedDeletedBlockInfoProto) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N113117" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.protocolPB.PBHelper<br/>In method org.apache.hadoop.hdfs.protocolPB.PBHelper.convert(DatanodeProtocolProtos$ReceivedDeletedBlockInfoProto)<br/>At PBHelper.java:[lines 1055-1063]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N124854');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.hdfs.server.namenode.FSNamesystem.internalReleaseLease(LeaseManager$Lease, String, String) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N124854" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSNamesystem<br/>In method org.apache.hadoop.hdfs.server.namenode.FSNamesystem.internalReleaseLease(LeaseManager$Lease, String, String)<br/>At FSNamesystem.java:[lines 3799-3852]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N134935');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.saveNamespaceWithInjectedFault(TestSaveNamespace$Fault) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N134935" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace<br/>In method org.apache.hadoop.hdfs.server.namenode.TestSaveNamespace.saveNamespaceWithInjectedFault(TestSaveNamespace$Fault)<br/>At TestSaveNamespace.java:[lines 138-175]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N100055');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.hdfs.TestDFSRollback.checkResult(HdfsServerConstants$NodeType, String[]) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N100055" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSRollback<br/>In method org.apache.hadoop.hdfs.TestDFSRollback.checkResult(HdfsServerConstants$NodeType, String[])<br/>At TestDFSRollback.java:[lines 78-83]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N144265');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.hdfs.tools.offlineImageViewer.SpotCheckImageVisitor.visitEnclosingElement(ImageVisitor$ImageElement, ImageVisitor$ImageElement, String) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N144265" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.SpotCheckImageVisitor<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.SpotCheckImageVisitor.visitEnclosingElement(ImageVisitor$ImageElement, ImageVisitor$ImageElement, String)<br/>At SpotCheckImageVisitor.java:[lines 56-64]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N142809');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.hdfs.tools.TestGetConf.getAddressListFromTool(TestGetConf$TestType, HdfsConfiguration, boolean) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N142809" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.TestGetConf<br/>In method org.apache.hadoop.hdfs.tools.TestGetConf.getAddressListFromTool(TestGetConf$TestType, HdfsConfiguration, boolean)<br/>At TestGetConf.java:[lines 163-174]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N149376');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.io.TestDataByteBuffers.readJunk(DataInput, Random, long, int) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N149376" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.io.TestDataByteBuffers<br/>In method org.apache.hadoop.io.TestDataByteBuffers.readJunk(DataInput, Random, long, int)<br/>At TestDataByteBuffers.java:[lines 37-58]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N149429');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.io.TestDataByteBuffers.writeJunk(DataOutput, Random, long, int) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N149429" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.io.TestDataByteBuffers<br/>In method org.apache.hadoop.io.TestDataByteBuffers.writeJunk(DataOutput, Random, long, int)<br/>At TestDataByteBuffers.java:[lines 68-78]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N151331');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.io.Text.bytesToCodePoint(ByteBuffer) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N151331" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.io.Text<br/>In method org.apache.hadoop.io.Text.bytesToCodePoint(ByteBuffer)<br/>At Text.java:[lines 622-628]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N151384');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.io.Text.validateUTF8(byte[], int, int) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N151384" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.io.Text<br/>In method org.apache.hadoop.io.Text.validateUTF8(byte[], int, int)<br/>At Text.java:[lines 529-577]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N185813');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.Job.printTaskEvents(TaskCompletionEvent[], Job$TaskStatusFilter, boolean, Configuration$IntegerRanges, Configuration$IntegerRanges) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N185813" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.Job<br/>In method org.apache.hadoop.mapreduce.Job.printTaskEvents(TaskCompletionEvent[], Job$TaskStatusFilter, boolean, Configuration$IntegerRanges, Configuration$IntegerRanges)<br/>At Job.java:[lines 1429-1458]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N196105');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.resolve(TaskCompletionEvent) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N196105" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl<br/>In method org.apache.hadoop.mapreduce.task.reduce.ShuffleSchedulerImpl.resolve(TaskCompletionEvent)<br/>At ShuffleSchedulerImpl.java:[lines 139-156]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N201444');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.completedTask(Task) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N201444" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics<br/>In method org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.completedTask(Task)<br/>At MRAppMetrics.java:[lines 109-114]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N201497');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.endRunningTask(Task) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N201497" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics<br/>In method org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.endRunningTask(Task)<br/>At MRAppMetrics.java:[lines 153-158]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N201550');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.endWaitingTask(Task) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N201550" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics<br/>In method org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.endWaitingTask(Task)<br/>At MRAppMetrics.java:[lines 174-179]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N201603');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.failedTask(Task) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N201603" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics<br/>In method org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.failedTask(Task)<br/>At MRAppMetrics.java:[lines 120-125]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N201656');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.killedTask(Task) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N201656" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics<br/>In method org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.killedTask(Task)<br/>At MRAppMetrics.java:[lines 131-136]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N201709');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.launchedTask(Task) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N201709" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics<br/>In method org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.launchedTask(Task)<br/>At MRAppMetrics.java:[lines 97-102]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N201762');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.runningTask(Task) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N201762" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics<br/>In method org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.runningTask(Task)<br/>At MRAppMetrics.java:[lines 142-147]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N201815');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.waitingTask(Task) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N201815" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics<br/>In method org.apache.hadoop.mapreduce.v2.app.metrics.MRAppMetrics.waitingTask(Task)<br/>At MRAppMetrics.java:[lines 164-169]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N202786');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.processSpeculatorEvent(SpeculatorEvent) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N202786" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator<br/>In method org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator.processSpeculatorEvent(SpeculatorEvent)<br/>At DefaultSpeculator.java:[lines 270-293]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N203280');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock.getCounters(AppContext) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N203280" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.CountersBlock.getCounters(AppContext)<br/>At CountersBlock.java:[lines 195-197]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N205929');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobCounterInfo.getCounters(AppContext, Job) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N205929" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobCounterInfo<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.dao.JobCounterInfo.getCounters(AppContext, Job)<br/>At JobCounterInfo.java:[lines 92-97]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N211229');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(String) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N211229" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.impl.MetricsSystemImpl<br/>In method org.apache.hadoop.metrics2.impl.MetricsSystemImpl.init(String)<br/>At MetricsSystemImpl.java:[lines 154-165]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N212454');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink.loadGangliaConf(AbstractGangliaSink$GangliaConfType) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N212454" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink<br/>In method org.apache.hadoop.metrics2.sink.ganglia.AbstractGangliaSink.loadGangliaConf(AbstractGangliaSink$GangliaConfType)<br/>At AbstractGangliaSink.java:[lines 180-191]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N216071');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.record.compiler.generated.RccTokenManager.getNextToken() where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N216071" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.RccTokenManager<br/>In method org.apache.hadoop.record.compiler.generated.RccTokenManager.getNextToken()<br/>At RccTokenManager.java:[lines 727-754]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N230635');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.util.PureJavaCrc32.update(byte[], int, int) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N230635" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.util.PureJavaCrc32<br/>In method org.apache.hadoop.util.PureJavaCrc32.update(byte[], int, int)<br/>At PureJavaCrc32.java:[lines 84-91]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N230688');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.util.PureJavaCrc32C.update(byte[], int, int) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N230688" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.util.PureJavaCrc32C<br/>In method org.apache.hadoop.util.PureJavaCrc32C.update(byte[], int, int)<br/>At PureJavaCrc32C.java:[lines 81-88]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N239122');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.yarn.client.api.async.impl.TestNMClientAsync.mockNMClient(int) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N239122" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.api.async.impl.TestNMClientAsync<br/>In method org.apache.hadoop.yarn.client.api.async.impl.TestNMClientAsync.mockNMClient(int)<br/>At TestNMClientAsync.java:[lines 381-408]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N250424');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.finished() where one case falls through to the next case</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N250424" style="display: none;">
<a href="#SF_SWITCH_FALLTHROUGH">Bug type SF_SWITCH_FALLTHROUGH (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.finished()<br/>At ContainerImpl.java:[lines 424-428]<br/>Another occurrence at ContainerImpl.java:[lines 436-440]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N250489');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.finished() where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N250489" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerImpl.finished()<br/>At ContainerImpl.java:[lines 414-441]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N261428');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl.updateMetricsForDeactivatedNode(NodeState, NodeState) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N261428" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl<br/>In method org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl.updateMetricsForDeactivatedNode(NodeState, NodeState)<br/>At RMNodeImpl.java:[lines 419-424]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N261481');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl.updateMetricsForRejoinedNode(NodeState) where default case is missing</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N261481" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl<br/>In method org.apache.hadoop.yarn.server.resourcemanager.rmnode.RMNodeImpl.updateMetricsForRejoinedNode(NodeState)<br/>At RMNodeImpl.java:[lines 399-410]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N274481');">
<td>
<span class="priority-2">SF</span>
</td>
<td>Switch statement found in org.apache.hadoop.yarn.util.TestFSDownload.downloadWithFileType(TestFSDownload$TEST_FILE_TYPE) where default case is missing</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N274481" style="display: none;">
<a href="#SF_SWITCH_NO_DEFAULT">Bug type SF_SWITCH_NO_DEFAULT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestFSDownload<br/>In method org.apache.hadoop.yarn.util.TestFSDownload.downloadWithFileType(TestFSDownload$TEST_FILE_TYPE)<br/>At TestFSDownload.java:[lines 473-485]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N69839');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.contrib.bkjournal.TestBookKeeperConfiguration.zkc from instance method org.apache.hadoop.contrib.bkjournal.TestBookKeeperConfiguration.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N69839" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestBookKeeperConfiguration<br/>In method org.apache.hadoop.contrib.bkjournal.TestBookKeeperConfiguration.setup()<br/>Field org.apache.hadoop.contrib.bkjournal.TestBookKeeperConfiguration.zkc<br/>At TestBookKeeperConfiguration.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N69975');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.contrib.bkjournal.TestBookKeeperHACheckpoints.journalCount from instance method org.apache.hadoop.contrib.bkjournal.TestBookKeeperHACheckpoints.setupCluster()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N69975" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestBookKeeperHACheckpoints<br/>In method org.apache.hadoop.contrib.bkjournal.TestBookKeeperHACheckpoints.setupCluster()<br/>Field org.apache.hadoop.contrib.bkjournal.TestBookKeeperHACheckpoints.journalCount<br/>At TestBookKeeperHACheckpoints.java:[line 50]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70373');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.contrib.bkjournal.TestCurrentInprogress.zkc from instance method org.apache.hadoop.contrib.bkjournal.TestCurrentInprogress.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70373" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.contrib.bkjournal.TestCurrentInprogress<br/>In method org.apache.hadoop.contrib.bkjournal.TestCurrentInprogress.setup()<br/>Field org.apache.hadoop.contrib.bkjournal.TestCurrentInprogress.zkc<br/>At TestCurrentInprogress.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N71144');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.examples.terasort.TeraInputFormat.lastResult from instance method org.apache.hadoop.examples.terasort.TeraInputFormat.getSplits(JobContext)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N71144" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.examples.terasort.TeraInputFormat<br/>In method org.apache.hadoop.examples.terasort.TeraInputFormat.getSplits(JobContext)<br/>Field org.apache.hadoop.examples.terasort.TeraInputFormat.lastResult<br/>At TeraInputFormat.java:[line 300]<br/>Another occurrence at TeraInputFormat.java:[line 294]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N71222');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.examples.terasort.TeraInputFormat.lastContext from instance method org.apache.hadoop.examples.terasort.TeraInputFormat.getSplits(JobContext)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N71222" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.examples.terasort.TeraInputFormat<br/>In method org.apache.hadoop.examples.terasort.TeraInputFormat.getSplits(JobContext)<br/>Field org.apache.hadoop.examples.terasort.TeraInputFormat.lastContext<br/>At TeraInputFormat.java:[line 293]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N73019');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.DistributedFSCheck.fsConfig from instance method new org.apache.hadoop.fs.DistributedFSCheck(Configuration)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N73019" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.DistributedFSCheck<br/>In method new org.apache.hadoop.fs.DistributedFSCheck(Configuration)<br/>Field org.apache.hadoop.fs.DistributedFSCheck.fsConfig<br/>At DistributedFSCheck.java:[line 75]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85264');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem.classpathDir from instance method new org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem(BaseTestHttpFSWith$Operation)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85264" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem<br/>In method new org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem(BaseTestHttpFSWith$Operation)<br/>Field org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem.classpathDir<br/>At TestHttpFSFWithSWebhdfsFileSystem.java:[line 50]<br/>Another occurrence at TestHttpFSFWithSWebhdfsFileSystem.java:[line 48]<br/>Another occurrence at TestHttpFSFWithSWebhdfsFileSystem.java:[line 51]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N85353');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem.sslConf from instance method new org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem(BaseTestHttpFSWith$Operation)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N85353" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem<br/>In method new org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem(BaseTestHttpFSWith$Operation)<br/>Field org.apache.hadoop.fs.http.client.TestHttpFSFWithSWebhdfsFileSystem.sslConf<br/>At TestHttpFSFWithSWebhdfsFileSystem.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N85612');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.http.server.HttpFSServerWebApp.SERVER from instance method org.apache.hadoop.fs.http.server.HttpFSServerWebApp.destroy()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N85612" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.http.server.HttpFSServerWebApp<br/>In method org.apache.hadoop.fs.http.server.HttpFSServerWebApp.destroy()<br/>Field org.apache.hadoop.fs.http.server.HttpFSServerWebApp.SERVER<br/>At HttpFSServerWebApp.java:[line 116]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N88907');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.shell.TestCommandFactory.factory from instance method org.apache.hadoop.fs.shell.TestCommandFactory.testSetup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N88907" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.shell.TestCommandFactory<br/>In method org.apache.hadoop.fs.shell.TestCommandFactory.testSetup()<br/>Field org.apache.hadoop.fs.shell.TestCommandFactory.factory<br/>At TestCommandFactory.java:[line 36]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N88974');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.shell.TestCopy.cmd from instance method org.apache.hadoop.fs.shell.TestCopy.resetMock()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N88974" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.shell.TestCopy<br/>In method org.apache.hadoop.fs.shell.TestCopy.resetMock()<br/>Field org.apache.hadoop.fs.shell.TestCopy.cmd<br/>At TestCopy.java:[line 67]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N89041');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.shell.TestCopy.target from instance method org.apache.hadoop.fs.shell.TestCopy.resetMock()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N89041" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.shell.TestCopy<br/>In method org.apache.hadoop.fs.shell.TestCopy.resetMock()<br/>Field org.apache.hadoop.fs.shell.TestCopy.target<br/>At TestCopy.java:[line 66]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N76083');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestChecksumFileSystem.localFs from instance method org.apache.hadoop.fs.TestChecksumFileSystem.resetLocalFs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N76083" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestChecksumFileSystem<br/>In method org.apache.hadoop.fs.TestChecksumFileSystem.resetLocalFs()<br/>Field org.apache.hadoop.fs.TestChecksumFileSystem.localFs<br/>At TestChecksumFileSystem.java:[line 36]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76150');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.args from instance method org.apache.hadoop.fs.TestCommandFormat.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76150" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.setUp()<br/>Field org.apache.hadoop.fs.TestCommandFormat.args<br/>At TestCommandFormat.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N76217');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.expectedArgs from instance method org.apache.hadoop.fs.TestCommandFormat.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N76217" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.setUp()<br/>Field org.apache.hadoop.fs.TestCommandFormat.expectedArgs<br/>At TestCommandFormat.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76284');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.expectedOpts from instance method org.apache.hadoop.fs.TestCommandFormat.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76284" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.setUp()<br/>Field org.apache.hadoop.fs.TestCommandFormat.expectedOpts<br/>At TestCommandFormat.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N76351');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.args from instance method org.apache.hadoop.fs.TestCommandFormat.testArgOpt()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N76351" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testArgOpt()<br/>Field org.apache.hadoop.fs.TestCommandFormat.args<br/>At TestCommandFormat.java:[line 121]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76418');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.expectedArgs from instance method org.apache.hadoop.fs.TestCommandFormat.testArgOpt()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76418" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testArgOpt()<br/>Field org.apache.hadoop.fs.TestCommandFormat.expectedArgs<br/>At TestCommandFormat.java:[line 122]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N76485');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.args from instance method org.apache.hadoop.fs.TestCommandFormat.testOneArg()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N76485" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testOneArg()<br/>Field org.apache.hadoop.fs.TestCommandFormat.args<br/>At TestCommandFormat.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76552');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.expectedArgs from instance method org.apache.hadoop.fs.TestCommandFormat.testOneArg()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76552" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testOneArg()<br/>Field org.apache.hadoop.fs.TestCommandFormat.expectedArgs<br/>At TestCommandFormat.java:[line 62]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N76619');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.args from instance method org.apache.hadoop.fs.TestCommandFormat.testOneOpt()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N76619" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testOneOpt()<br/>Field org.apache.hadoop.fs.TestCommandFormat.args<br/>At TestCommandFormat.java:[line 86]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76686');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.expectedOpts from instance method org.apache.hadoop.fs.TestCommandFormat.testOneOpt()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76686" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testOneOpt()<br/>Field org.apache.hadoop.fs.TestCommandFormat.expectedOpts<br/>At TestCommandFormat.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N76753');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.args from instance method org.apache.hadoop.fs.TestCommandFormat.testOptArg()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N76753" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testOptArg()<br/>Field org.apache.hadoop.fs.TestCommandFormat.args<br/>At TestCommandFormat.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76820');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.expectedArgs from instance method org.apache.hadoop.fs.TestCommandFormat.testOptArg()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76820" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testOptArg()<br/>Field org.apache.hadoop.fs.TestCommandFormat.expectedArgs<br/>At TestCommandFormat.java:[line 109]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N76887');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.expectedOpts from instance method org.apache.hadoop.fs.TestCommandFormat.testOptArg()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N76887" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testOptArg()<br/>Field org.apache.hadoop.fs.TestCommandFormat.expectedOpts<br/>At TestCommandFormat.java:[line 108]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N76954');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.args from instance method org.apache.hadoop.fs.TestCommandFormat.testOptDashArg()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N76954" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testOptDashArg()<br/>Field org.apache.hadoop.fs.TestCommandFormat.args<br/>At TestCommandFormat.java:[line 144]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77021');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.expectedArgs from instance method org.apache.hadoop.fs.TestCommandFormat.testOptDashArg()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77021" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testOptDashArg()<br/>Field org.apache.hadoop.fs.TestCommandFormat.expectedArgs<br/>At TestCommandFormat.java:[line 146]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N77088');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.expectedOpts from instance method org.apache.hadoop.fs.TestCommandFormat.testOptDashArg()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N77088" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testOptDashArg()<br/>Field org.apache.hadoop.fs.TestCommandFormat.expectedOpts<br/>At TestCommandFormat.java:[line 145]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77155');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.args from instance method org.apache.hadoop.fs.TestCommandFormat.testOptStopOptArg()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77155" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testOptStopOptArg()<br/>Field org.apache.hadoop.fs.TestCommandFormat.args<br/>At TestCommandFormat.java:[line 132]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N77222');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.expectedArgs from instance method org.apache.hadoop.fs.TestCommandFormat.testOptStopOptArg()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N77222" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testOptStopOptArg()<br/>Field org.apache.hadoop.fs.TestCommandFormat.expectedArgs<br/>At TestCommandFormat.java:[line 134]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77289');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.expectedOpts from instance method org.apache.hadoop.fs.TestCommandFormat.testOptStopOptArg()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77289" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testOptStopOptArg()<br/>Field org.apache.hadoop.fs.TestCommandFormat.expectedOpts<br/>At TestCommandFormat.java:[line 133]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N77356');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.args from instance method org.apache.hadoop.fs.TestCommandFormat.testTwoArgs()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N77356" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testTwoArgs()<br/>Field org.apache.hadoop.fs.TestCommandFormat.args<br/>At TestCommandFormat.java:[line 73]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77423');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.expectedArgs from instance method org.apache.hadoop.fs.TestCommandFormat.testTwoArgs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77423" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testTwoArgs()<br/>Field org.apache.hadoop.fs.TestCommandFormat.expectedArgs<br/>At TestCommandFormat.java:[line 74]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N77490');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.args from instance method org.apache.hadoop.fs.TestCommandFormat.testTwoOpts()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N77490" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testTwoOpts()<br/>Field org.apache.hadoop.fs.TestCommandFormat.args<br/>At TestCommandFormat.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N77557');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.TestCommandFormat.expectedOpts from instance method org.apache.hadoop.fs.TestCommandFormat.testTwoOpts()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N77557" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestCommandFormat<br/>In method org.apache.hadoop.fs.TestCommandFormat.testTwoOpts()<br/>Field org.apache.hadoop.fs.TestCommandFormat.expectedOpts<br/>At TestCommandFormat.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83873');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.FCStatisticsBaseTest.fc from instance method org.apache.hadoop.fs.TestLocalFsFCStatistics.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83873" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestLocalFsFCStatistics<br/>In method org.apache.hadoop.fs.TestLocalFsFCStatistics.setUp()<br/>Field org.apache.hadoop.fs.FCStatisticsBaseTest.fc<br/>At TestLocalFsFCStatistics.java:[line 39]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N83379');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.FileContextCreateMkdirBaseTest.fc from instance method org.apache.hadoop.fs.TestLocalFSFileContextCreateMkdir.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N83379" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestLocalFSFileContextCreateMkdir<br/>In method org.apache.hadoop.fs.TestLocalFSFileContextCreateMkdir.setUp()<br/>Field org.apache.hadoop.fs.FileContextCreateMkdirBaseTest.fc<br/>At TestLocalFSFileContextCreateMkdir.java:[line 29]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N83446');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.FileContextMainOperationsBaseTest.fc from instance method org.apache.hadoop.fs.TestLocalFSFileContextMainOperations.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N83446" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.TestLocalFSFileContextMainOperations<br/>In method org.apache.hadoop.fs.TestLocalFSFileContextMainOperations.setUp()<br/>Field org.apache.hadoop.fs.FileContextMainOperationsBaseTest.fc<br/>At TestLocalFSFileContextMainOperations.java:[line 35]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N91065');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.FileContextCreateMkdirBaseTest.fc from instance method org.apache.hadoop.fs.viewfs.TestFcCreateMkdirLocalFs.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N91065" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.TestFcCreateMkdirLocalFs<br/>In method org.apache.hadoop.fs.viewfs.TestFcCreateMkdirLocalFs.setUp()<br/>Field org.apache.hadoop.fs.FileContextCreateMkdirBaseTest.fc<br/>At TestFcCreateMkdirLocalFs.java:[line 34]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N91132');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.FileContextMainOperationsBaseTest.fc from instance method org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N91132" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs<br/>In method org.apache.hadoop.fs.viewfs.TestFcMainOperationsLocalFs.setUp()<br/>Field org.apache.hadoop.fs.FileContextMainOperationsBaseTest.fc<br/>At TestFcMainOperationsLocalFs.java:[line 38]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93152');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ha.TestNodeFencer$AlwaysSucceedFencer.fenceCalled from instance method org.apache.hadoop.ha.TestFailoverController.testFailoverAndFailback()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93152" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestFailoverController<br/>In method org.apache.hadoop.ha.TestFailoverController.testFailoverAndFailback()<br/>Field org.apache.hadoop.ha.TestNodeFencer$AlwaysSucceedFencer.fenceCalled<br/>At TestFailoverController.java:[line 58]<br/>Another occurrence at TestFailoverController.java:[line 64]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N93228');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ha.TestNodeFencer$AlwaysFailFencer.fenceCalled from instance method org.apache.hadoop.ha.TestFailoverController.testFailoverFromFaultyServiceFencingFailure()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N93228" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestFailoverController<br/>In method org.apache.hadoop.ha.TestFailoverController.testFailoverFromFaultyServiceFencingFailure()<br/>Field org.apache.hadoop.ha.TestNodeFencer$AlwaysFailFencer.fenceCalled<br/>At TestFailoverController.java:[line 195]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93293');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ha.TestNodeFencer$AlwaysSucceedFencer.fenceCalled from instance method org.apache.hadoop.ha.TestFailoverController.testFailoverFromFaultyServiceSucceeds()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93293" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestFailoverController<br/>In method org.apache.hadoop.ha.TestFailoverController.testFailoverFromFaultyServiceSucceeds()<br/>Field org.apache.hadoop.ha.TestNodeFencer$AlwaysSucceedFencer.fenceCalled<br/>At TestFailoverController.java:[line 172]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N93358');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ha.TestNodeFencer$AlwaysFailFencer.fenceCalled from instance method org.apache.hadoop.ha.TestFailoverController.testFailureToFenceOnFailbackFailsTheFailback()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N93358" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestFailoverController<br/>In method org.apache.hadoop.ha.TestFailoverController.testFailureToFenceOnFailbackFailsTheFailback()<br/>Field org.apache.hadoop.ha.TestNodeFencer$AlwaysFailFencer.fenceCalled<br/>At TestFailoverController.java:[line 362]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93423');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ha.TestNodeFencer$AlwaysFailFencer.fenceCalled from instance method org.apache.hadoop.ha.TestFailoverController.testFencingFailureDuringFailover()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93423" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestFailoverController<br/>In method org.apache.hadoop.ha.TestFailoverController.testFencingFailureDuringFailover()<br/>Field org.apache.hadoop.ha.TestNodeFencer$AlwaysFailFencer.fenceCalled<br/>At TestFailoverController.java:[line 215]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N93488');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ha.TestNodeFencer$AlwaysSucceedFencer.fenceCalled from instance method org.apache.hadoop.ha.TestFailoverController.testSelfFailoverFails()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N93488" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestFailoverController<br/>In method org.apache.hadoop.ha.TestFailoverController.testSelfFailoverFails()<br/>Field org.apache.hadoop.ha.TestNodeFencer$AlwaysSucceedFencer.fenceCalled<br/>At TestFailoverController.java:[line 406]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93553');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ha.TestNodeFencer$AlwaysSucceedFencer.fenceCalled from instance method org.apache.hadoop.ha.TestFailoverController.testWeFenceOnFailbackIfTransitionToActiveFails()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93553" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestFailoverController<br/>In method org.apache.hadoop.ha.TestFailoverController.testWeFenceOnFailbackIfTransitionToActiveFails()<br/>Field org.apache.hadoop.ha.TestNodeFencer$AlwaysSucceedFencer.fenceCalled<br/>At TestFailoverController.java:[line 334]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N93834');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ha.TestNodeFencer$AlwaysSucceedFencer.fenceCalled from instance method org.apache.hadoop.ha.TestNodeFencer.clearMockState()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N93834" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestNodeFencer<br/>In method org.apache.hadoop.ha.TestNodeFencer.clearMockState()<br/>Field org.apache.hadoop.ha.TestNodeFencer$AlwaysSucceedFencer.fenceCalled<br/>At TestNodeFencer.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N93899');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ha.TestNodeFencer$AlwaysFailFencer.fenceCalled from instance method org.apache.hadoop.ha.TestNodeFencer.clearMockState()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N93899" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestNodeFencer<br/>In method org.apache.hadoop.ha.TestNodeFencer.clearMockState()<br/>Field org.apache.hadoop.ha.TestNodeFencer$AlwaysFailFencer.fenceCalled<br/>At TestNodeFencer.java:[line 48]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N94111');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ha.ActiveStandbyElector.NUM_RETRIES from instance method org.apache.hadoop.ha.TestZKFailoverControllerStress.testRandomHealthAndDisconnects()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N94111" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ha.TestZKFailoverControllerStress<br/>In method org.apache.hadoop.ha.TestZKFailoverControllerStress.testRandomHealthAndDisconnects()<br/>Field org.apache.hadoop.ha.ActiveStandbyElector.NUM_RETRIES<br/>At TestZKFailoverControllerStress.java:[line 129]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N113786');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.qjournal.server.JournalFaultInjector.instance from instance method org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testCrashBetweenSyncLogAndPersistPaxosData()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N113786" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager<br/>In method org.apache.hadoop.hdfs.qjournal.client.TestQuorumJournalManager.testCrashBetweenSyncLogAndPersistPaxosData()<br/>Field org.apache.hadoop.hdfs.qjournal.server.JournalFaultInjector.instance<br/>At TestQuorumJournalManager.java:[line 787]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N115835');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase.REPL_FACTOR from instance method org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase.startUpCluster()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N115835" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase<br/>In method org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase.startUpCluster()<br/>Field org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase.REPL_FACTOR<br/>At BlockReportTestBase.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N115902');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase.REPL_FACTOR from instance method org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase.testOneReplicaRbwReportArrivesAfterBlockCompleted()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N115902" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase<br/>In method org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase.testOneReplicaRbwReportArrivesAfterBlockCompleted()<br/>Field org.apache.hadoop.hdfs.server.datanode.BlockReportTestBase.REPL_FACTOR<br/>At BlockReportTestBase.java:[line 587]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N119774');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold.conf from instance method org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold.startUpCluster(long)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N119774" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold.startUpCluster(long)<br/>Field org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold.conf<br/>At TestDnRespectsBlockReportSplitThreshold.java:[line 65]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N119841');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold.bpid from instance method org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold.startUpCluster(long)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N119841" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold<br/>In method org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold.startUpCluster(long)<br/>Field org.apache.hadoop.hdfs.server.datanode.TestDnRespectsBlockReportSplitThreshold.bpid<br/>At TestDnRespectsBlockReportSplitThreshold.java:[line 71]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N119975');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.cluster from instance method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N119975" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache<br/>In method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()<br/>Field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.cluster<br/>At TestFsDatasetCache.java:[line 130]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N120042');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.conf from instance method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N120042" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache<br/>In method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()<br/>Field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.conf<br/>At TestFsDatasetCache.java:[line 118]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N120109');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.dn from instance method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N120109" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache<br/>In method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()<br/>Field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.dn<br/>At TestFsDatasetCache.java:[line 137]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N120176');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.fs from instance method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N120176" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache<br/>In method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()<br/>Field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.fs<br/>At TestFsDatasetCache.java:[line 134]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N120243');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.fsImage from instance method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N120243" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache<br/>In method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()<br/>Field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.fsImage<br/>At TestFsDatasetCache.java:[line 136]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N120310');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.fsd from instance method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N120310" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache<br/>In method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()<br/>Field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.fsd<br/>At TestFsDatasetCache.java:[line 138]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N120377');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.nn from instance method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N120377" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache<br/>In method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()<br/>Field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.nn<br/>At TestFsDatasetCache.java:[line 135]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N120444');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.prevCacheManipulator from instance method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N120444" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache<br/>In method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()<br/>Field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.prevCacheManipulator<br/>At TestFsDatasetCache.java:[line 127]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N120511');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.spyNN from instance method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N120511" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache<br/>In method org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.setUp()<br/>Field org.apache.hadoop.hdfs.server.datanode.TestFsDatasetCache.spyNN<br/>At TestFsDatasetCache.java:[line 140]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N120648');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.TestIncrementalBrVariations.conf from instance method org.apache.hadoop.hdfs.server.datanode.TestIncrementalBrVariations.startUpCluster()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N120648" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestIncrementalBrVariations<br/>In method org.apache.hadoop.hdfs.server.datanode.TestIncrementalBrVariations.startUpCluster()<br/>Field org.apache.hadoop.hdfs.server.datanode.TestIncrementalBrVariations.conf<br/>At TestIncrementalBrVariations.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N120987');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.TestStorageReport.conf from instance method org.apache.hadoop.hdfs.server.datanode.TestStorageReport.startUpCluster()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N120987" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestStorageReport<br/>In method org.apache.hadoop.hdfs.server.datanode.TestStorageReport.startUpCluster()<br/>Field org.apache.hadoop.hdfs.server.datanode.TestStorageReport.conf<br/>At TestStorageReport.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N121054');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.TestStorageReport.bpid from instance method org.apache.hadoop.hdfs.server.datanode.TestStorageReport.startUpCluster()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N121054" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestStorageReport<br/>In method org.apache.hadoop.hdfs.server.datanode.TestStorageReport.startUpCluster()<br/>Field org.apache.hadoop.hdfs.server.datanode.TestStorageReport.bpid<br/>At TestStorageReport.java:[line 64]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N122732');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.path from instance method org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N122732" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest<br/>In method org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.path<br/>At FSAclBaseTest.java:[line 88]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N122799');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.pathCount from instance method org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N122799" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest<br/>In method org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.FSAclBaseTest.pathCount<br/>At FSAclBaseTest.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N136599');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.cluster from instance method org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.setupCluster()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N136599" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.setupCluster()<br/>Field org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.cluster<br/>At TestDelegationTokensWithHA.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N136666');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.dfs from instance method org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.setupCluster()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N136666" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.setupCluster()<br/>Field org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.dfs<br/>At TestDelegationTokensWithHA.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N136733');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.dtSecretManager from instance method org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.setupCluster()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N136733" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.setupCluster()<br/>Field org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.dtSecretManager<br/>At TestDelegationTokensWithHA.java:[line 108]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N136800');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.fs from instance method org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.setupCluster()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N136800" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.setupCluster()<br/>Field org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.fs<br/>At TestDelegationTokensWithHA.java:[line 104]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N136867');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.nn0 from instance method org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.setupCluster()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N136867" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.setupCluster()<br/>Field org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.nn0<br/>At TestDelegationTokensWithHA.java:[line 102]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N136934');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.nn1 from instance method org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.setupCluster()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N136934" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA<br/>In method org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.setupCluster()<br/>Field org.apache.hadoop.hdfs.server.namenode.ha.TestDelegationTokensWithHA.nn1<br/>At TestDelegationTokensWithHA.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N125535');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark.config from instance method new org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark(Configuration)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N125535" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark<br/>In method new org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark(Configuration)<br/>Field org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark.config<br/>At NNThroughputBenchmark.java:[line 116]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N125602');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark.nameNode from instance method org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark.run(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N125602" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark<br/>In method org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark.run(String[])<br/>Field org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark.nameNode<br/>At NNThroughputBenchmark.java:[line 1417]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N125669');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark.nameNodeProto from instance method org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark.run(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N125669" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark<br/>In method org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark.run(String[])<br/>Field org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark.nameNodeProto<br/>At NNThroughputBenchmark.java:[line 1418]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N125736');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark.config from instance method org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark.setConf(Configuration)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N125736" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark<br/>In method org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark.setConf(Configuration)<br/>Field org.apache.hadoop.hdfs.server.namenode.NNThroughputBenchmark.config<br/>At NNThroughputBenchmark.java:[line 1492]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N137923');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.path from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N137923" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.path<br/>At TestAclWithSnapshot.java:[line 95]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N137990');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.pathCount from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N137990" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.pathCount<br/>At TestAclWithSnapshot.java:[line 94]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N138057');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.snapshotName from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N138057" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.snapshotName<br/>At TestAclWithSnapshot.java:[line 96]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N138124');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.snapshotPath from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N138124" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestAclWithSnapshot.snapshotPath<br/>At TestAclWithSnapshot.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N138335');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots.cluster from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N138335" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots.cluster<br/>At TestNestedSnapshots.java:[line 73]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N138402');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots.hdfs from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N138402" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestNestedSnapshots.hdfs<br/>At TestNestedSnapshots.java:[line 76]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N138619');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.cluster from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.testRenameUndo_7()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N138619" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.testRenameUndo_7()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.cluster<br/>At TestRenameWithSnapshots.java:[line 1760]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N138686');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.cluster from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N138686" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.cluster<br/>At TestRenameWithSnapshots.java:[line 109]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N138753');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.fsdir from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N138753" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.fsdir<br/>At TestRenameWithSnapshots.java:[line 114]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N138820');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.fsn from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N138820" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.fsn<br/>At TestRenameWithSnapshots.java:[line 113]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N138887');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.hdfs from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N138887" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestRenameWithSnapshots.hdfs<br/>At TestRenameWithSnapshots.java:[line 116]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N139201');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.cluster from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N139201" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.cluster<br/>At TestSnapshot.java:[line 121]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N139268');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.fsdir from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N139268" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.fsdir<br/>At TestSnapshot.java:[line 126]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N139335');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.fsn from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N139335" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.fsn<br/>At TestSnapshot.java:[line 125]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N139784');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength.cluster from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N139784" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength.cluster<br/>At TestSnapshotFileLength.java:[line 58]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N139851');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength.hdfs from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N139851" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength.hdfs<br/>At TestSnapshotFileLength.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N140376');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.cluster from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N140376" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.cluster<br/>At TestSnapshotNameWithInvalidCharacters.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N140443');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.hdfs from instance method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N140443" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters<br/>In method org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshotNameWithInvalidCharacters.hdfs<br/>At TestSnapshotNameWithInvalidCharacters.java:[line 50]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N126107');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestAllowFormat.cluster from instance method org.apache.hadoop.hdfs.server.namenode.TestAllowFormat.testAllowFormat()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N126107" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestAllowFormat<br/>In method org.apache.hadoop.hdfs.server.namenode.TestAllowFormat.testAllowFormat()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestAllowFormat.cluster<br/>At TestAllowFormat.java:[line 119]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N126628');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.cluster from instance method org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N126628" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.setup()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.cluster<br/>At TestCacheDirectives.java:[line 137]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N126695');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.conf from instance method org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N126695" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.setup()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.conf<br/>At TestCacheDirectives.java:[line 136]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N126762');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.dfs from instance method org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N126762" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.setup()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.dfs<br/>At TestCacheDirectives.java:[line 140]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N126829');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.namenode from instance method org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N126829" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.setup()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.namenode<br/>At TestCacheDirectives.java:[line 142]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N126896');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.prevCacheManipulator from instance method org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N126896" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.setup()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.prevCacheManipulator<br/>At TestCacheDirectives.java:[line 143]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N126963');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.proto from instance method org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N126963" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.setup()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestCacheDirectives.proto<br/>At TestCacheDirectives.java:[line 141]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N128144');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.CheckpointFaultInjector.instance from instance method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N128144" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestCheckpoint<br/>In method org.apache.hadoop.hdfs.server.namenode.TestCheckpoint.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.CheckpointFaultInjector.instance<br/>At TestCheckpoint.java:[line 137]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N130422');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestFsLimits.conf from instance method org.apache.hadoop.hdfs.server.namenode.TestFsLimits.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N130422" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsLimits<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsLimits.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestFsLimits.conf<br/>At TestFsLimits.java:[line 82]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N130489');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestFsLimits.fs from instance method org.apache.hadoop.hdfs.server.namenode.TestFsLimits.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N130489" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsLimits<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsLimits.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestFsLimits.fs<br/>At TestFsLimits.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N130556');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestFsLimits.fsIsReady from instance method org.apache.hadoop.hdfs.server.namenode.TestFsLimits.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N130556" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsLimits<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsLimits.setUp()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestFsLimits.fsIsReady<br/>At TestFsLimits.java:[line 88]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N130623');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestFsLimits.fsIsReady from instance method org.apache.hadoop.hdfs.server.namenode.TestFsLimits.testDuringEditLogs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N130623" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestFsLimits<br/>In method org.apache.hadoop.hdfs.server.namenode.TestFsLimits.testDuringEditLogs()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestFsLimits.fsIsReady<br/>At TestFsLimits.java:[line 185]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N132477');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.FSDirectory.CHECK_RESERVED_FILE_NAMES from instance method org.apache.hadoop.hdfs.server.namenode.TestINodeFile.testReservedFileNames()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N132477" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestINodeFile<br/>In method org.apache.hadoop.hdfs.server.namenode.TestINodeFile.testReservedFileNames()<br/>Field org.apache.hadoop.hdfs.server.namenode.FSDirectory.CHECK_RESERVED_FILE_NAMES<br/>At TestINodeFile.java:[line 704]<br/>Another occurrence at TestINodeFile.java:[line 711]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N134165');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.conf from instance method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N134165" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.setup()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.conf<br/>At TestNamenodeRetryCache.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N134232');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.cluster from instance method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N134232" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.setup()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.cluster<br/>At TestNamenodeRetryCache.java:[line 95]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N134299');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.filesystem from instance method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N134299" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.setup()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.filesystem<br/>At TestNamenodeRetryCache.java:[line 98]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N134366');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.namesystem from instance method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N134366" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.setup()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.namesystem<br/>At TestNamenodeRetryCache.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N134433');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.namesystem from instance method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.testRetryCacheRebuild()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N134433" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.testRetryCacheRebuild()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.namesystem<br/>At TestNamenodeRetryCache.java:[line 431]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N134500');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.cluster from instance method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.testUpdatePipelineWithFailOver()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N134500" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.testUpdatePipelineWithFailOver()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.cluster<br/>At TestNamenodeRetryCache.java:[line 314]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N134567');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.filesystem from instance method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.testUpdatePipelineWithFailOver()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N134567" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.testUpdatePipelineWithFailOver()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.filesystem<br/>At TestNamenodeRetryCache.java:[line 313]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N134634');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.namesystem from instance method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.testUpdatePipelineWithFailOver()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N134634" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache<br/>In method org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.testUpdatePipelineWithFailOver()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestNamenodeRetryCache.namesystem<br/>At TestNamenodeRetryCache.java:[line 312]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N135356');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.s4 from instance method org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.testSnapshotPathINodesWithAddedFile()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N135356" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes<br/>In method org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.testSnapshotPathINodesWithAddedFile()<br/>Field org.apache.hadoop.hdfs.server.namenode.TestSnapshotPathINodes.s4<br/>At TestSnapshotPathINodes.java:[line 354]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N136343');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TransferFsImage.timeout from instance method org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testGetImageTimeout()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N136343" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage<br/>In method org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testGetImageTimeout()<br/>Field org.apache.hadoop.hdfs.server.namenode.TransferFsImage.timeout<br/>At TestTransferFsImage.java:[line 131]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N136410');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.namenode.TransferFsImage.timeout from instance method org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testImageUploadTimeout()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N136410" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage<br/>In method org.apache.hadoop.hdfs.server.namenode.TestTransferFsImage.testImageUploadTimeout()<br/>Field org.apache.hadoop.hdfs.server.namenode.TransferFsImage.timeout<br/>At TestTransferFsImage.java:[line 160]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N97896');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfoCallback from instance method org.apache.hadoop.hdfs.TestBlockReaderFactory.cleanup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N97896" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockReaderFactory<br/>In method org.apache.hadoop.hdfs.TestBlockReaderFactory.cleanup()<br/>Field org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfoCallback<br/>At TestBlockReaderFactory.java:[line 71]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N97963');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting from instance method org.apache.hadoop.hdfs.TestBlockReaderFactory.cleanup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N97963" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockReaderFactory<br/>In method org.apache.hadoop.hdfs.TestBlockReaderFactory.cleanup()<br/>Field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting<br/>At TestBlockReaderFactory.java:[line 70]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98030');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting from instance method org.apache.hadoop.hdfs.TestBlockReaderFactory.testFallbackFromShortCircuitToUnixDomainTraffic()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98030" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockReaderFactory<br/>In method org.apache.hadoop.hdfs.TestBlockReaderFactory.testFallbackFromShortCircuitToUnixDomainTraffic()<br/>Field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting<br/>At TestBlockReaderFactory.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N98097');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfoCallback from instance method org.apache.hadoop.hdfs.TestBlockReaderFactory.testMultipleWaitersOnShortCircuitCache()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N98097" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockReaderFactory<br/>In method org.apache.hadoop.hdfs.TestBlockReaderFactory.testMultipleWaitersOnShortCircuitCache()<br/>Field org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfoCallback<br/>At TestBlockReaderFactory.java:[line 142]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98164');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting from instance method org.apache.hadoop.hdfs.TestBlockReaderFactory.testMultipleWaitersOnShortCircuitCache()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98164" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockReaderFactory<br/>In method org.apache.hadoop.hdfs.TestBlockReaderFactory.testMultipleWaitersOnShortCircuitCache()<br/>Field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting<br/>At TestBlockReaderFactory.java:[line 141]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N98231');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting from instance method org.apache.hadoop.hdfs.TestBlockReaderFactory.testShortCircuitCacheShutdown()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N98231" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockReaderFactory<br/>In method org.apache.hadoop.hdfs.TestBlockReaderFactory.testShortCircuitCacheShutdown()<br/>Field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting<br/>At TestBlockReaderFactory.java:[line 390]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98298');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfoCallback from instance method org.apache.hadoop.hdfs.TestBlockReaderFactory.testShortCircuitCacheTemporaryFailure()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98298" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockReaderFactory<br/>In method org.apache.hadoop.hdfs.TestBlockReaderFactory.testShortCircuitCacheTemporaryFailure()<br/>Field org.apache.hadoop.hdfs.BlockReaderFactory.createShortCircuitReplicaInfoCallback<br/>At TestBlockReaderFactory.java:[line 211]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N98365');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting from instance method org.apache.hadoop.hdfs.TestBlockReaderFactory.testShortCircuitCacheTemporaryFailure()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N98365" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockReaderFactory<br/>In method org.apache.hadoop.hdfs.TestBlockReaderFactory.testShortCircuitCacheTemporaryFailure()<br/>Field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting<br/>At TestBlockReaderFactory.java:[line 210]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98432');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting from instance method org.apache.hadoop.hdfs.TestBlockReaderFactory.testShortCircuitReadFromClientWithoutShm()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98432" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockReaderFactory<br/>In method org.apache.hadoop.hdfs.TestBlockReaderFactory.testShortCircuitReadFromClientWithoutShm()<br/>Field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting<br/>At TestBlockReaderFactory.java:[line 355]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N98499');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting from instance method org.apache.hadoop.hdfs.TestBlockReaderFactory.testShortCircuitReadFromServerWithoutShm()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N98499" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestBlockReaderFactory<br/>In method org.apache.hadoop.hdfs.TestBlockReaderFactory.testShortCircuitReadFromServerWithoutShm()<br/>Field org.apache.hadoop.hdfs.DFSInputStream.tcpReadsDisabledForTesting<br/>At TestBlockReaderFactory.java:[line 310]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N98888');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.DFSClientFaultInjector.instance from instance method org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery.testPipelineRecoveryForLastBlock()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N98888" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery<br/>In method org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery.testPipelineRecoveryForLastBlock()<br/>Field org.apache.hadoop.hdfs.DFSClientFaultInjector.instance<br/>At TestClientProtocolForPipelineRecovery.java:[line 130]<br/>Another occurrence at TestClientProtocolForPipelineRecovery.java:[line 158]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99104');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.TestClientReportBadBlock.buffersize from instance method org.apache.hadoop.hdfs.TestClientReportBadBlock.startUpCluster()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99104" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestClientReportBadBlock<br/>In method org.apache.hadoop.hdfs.TestClientReportBadBlock.startUpCluster()<br/>Field org.apache.hadoop.hdfs.TestClientReportBadBlock.buffersize<br/>At TestClientReportBadBlock.java:[line 81]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99171');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.TestClientReportBadBlock.cluster from instance method org.apache.hadoop.hdfs.TestClientReportBadBlock.startUpCluster()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99171" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestClientReportBadBlock<br/>In method org.apache.hadoop.hdfs.TestClientReportBadBlock.startUpCluster()<br/>Field org.apache.hadoop.hdfs.TestClientReportBadBlock.cluster<br/>At TestClientReportBadBlock.java:[line 77]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99238');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.TestClientReportBadBlock.dfs from instance method org.apache.hadoop.hdfs.TestClientReportBadBlock.startUpCluster()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99238" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestClientReportBadBlock<br/>In method org.apache.hadoop.hdfs.TestClientReportBadBlock.startUpCluster()<br/>Field org.apache.hadoop.hdfs.TestClientReportBadBlock.dfs<br/>At TestClientReportBadBlock.java:[line 80]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99444');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.DFSClientFaultInjector.instance from instance method org.apache.hadoop.hdfs.TestCrcCorruption.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99444" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestCrcCorruption<br/>In method org.apache.hadoop.hdfs.TestCrcCorruption.setUp()<br/>Field org.apache.hadoop.hdfs.DFSClientFaultInjector.instance<br/>At TestCrcCorruption.java:[line 80]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N99578');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.TestDFSClientFailover$InjectingSocketFactory.portToInjectOn from instance method org.apache.hadoop.hdfs.TestDFSClientFailover.testFailoverOnConnectTimeout()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N99578" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSClientFailover<br/>In method org.apache.hadoop.hdfs.TestDFSClientFailover.testFailoverOnConnectTimeout()<br/>Field org.apache.hadoop.hdfs.TestDFSClientFailover$InjectingSocketFactory.portToInjectOn<br/>At TestDFSClientFailover.java:[line 124]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N99782');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.TestDFSClientRetries.conf from instance method org.apache.hadoop.hdfs.TestDFSClientRetries.setupConf()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N99782" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDFSClientRetries<br/>In method org.apache.hadoop.hdfs.TestDFSClientRetries.setupConf()<br/>Field org.apache.hadoop.hdfs.TestDFSClientRetries.conf<br/>At TestDFSClientRetries.java:[line 164]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N105039');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.server.datanode.DataNodeFaultInjector.instance from instance method org.apache.hadoop.hdfs.TestDistributedFileSystem.testGetFileBlockStorageLocationsError()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N105039" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestDistributedFileSystem<br/>In method org.apache.hadoop.hdfs.TestDistributedFileSystem.testGetFileBlockStorageLocationsError()<br/>Field org.apache.hadoop.hdfs.server.datanode.DataNodeFaultInjector.instance<br/>At TestDistributedFileSystem.java:[line 815]<br/>Another occurrence at TestDistributedFileSystem.java:[line 825]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N105510');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.TestFileAppend.fileContents from instance method org.apache.hadoop.hdfs.TestFileAppend.testComplexFlush()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N105510" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileAppend<br/>In method org.apache.hadoop.hdfs.TestFileAppend.testComplexFlush()<br/>Field org.apache.hadoop.hdfs.TestFileAppend.fileContents<br/>At TestFileAppend.java:[line 243]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N105577');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.TestFileAppend.fileContents from instance method org.apache.hadoop.hdfs.TestFileAppend.testSimpleFlush()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N105577" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestFileAppend<br/>In method org.apache.hadoop.hdfs.TestFileAppend.testSimpleFlush()<br/>Field org.apache.hadoop.hdfs.TestFileAppend.fileContents<br/>At TestFileAppend.java:[line 187]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N108021');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.DFSClientFaultInjector.instance from instance method org.apache.hadoop.hdfs.TestPread.testMaxOutHedgedReadPool()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N108021" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.TestPread<br/>In method org.apache.hadoop.hdfs.TestPread.testMaxOutHedgedReadPool()<br/>Field org.apache.hadoop.hdfs.DFSClientFaultInjector.instance<br/>At TestPread.java:[line 265]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N145982');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.fs.DelegationTokenRenewer.renewCycle from instance method org.apache.hadoop.hdfs.web.TestTokenAspect.testRenewal()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N145982" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.web.TestTokenAspect<br/>In method org.apache.hadoop.hdfs.web.TestTokenAspect.testRenewal()<br/>Field org.apache.hadoop.fs.DelegationTokenRenewer.renewCycle<br/>At TestTokenAspect.java:[line 277]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N146321');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.hdfs.web.TestWebHdfsWithAuthenticationFilter.authorized from instance method org.apache.hadoop.hdfs.web.TestWebHdfsWithAuthenticationFilter.testWebHdfsAuthFilter()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N146321" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.web.TestWebHdfsWithAuthenticationFilter<br/>In method org.apache.hadoop.hdfs.web.TestWebHdfsWithAuthenticationFilter.testWebHdfsAuthFilter()<br/>Field org.apache.hadoop.hdfs.web.TestWebHdfsWithAuthenticationFilter.authorized<br/>At TestWebHdfsWithAuthenticationFilter.java:[line 94]<br/>Another occurrence at TestWebHdfsWithAuthenticationFilter.java:[line 100]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N147446');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.http.TestServletFilter.uri from instance method org.apache.hadoop.http.TestServletFilter.testServletFilter()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N147446" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.http.TestServletFilter<br/>In method org.apache.hadoop.http.TestServletFilter.testServletFilter()<br/>Field org.apache.hadoop.http.TestServletFilter.uri<br/>At TestServletFilter.java:[line 140]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N152954');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.io.compress.bzip2.CBZip2InputStream.skipDecompression from instance method org.apache.hadoop.io.compress.bzip2.CBZip2InputStream.read(byte[], int, int)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N152954" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.io.compress.bzip2.CBZip2InputStream<br/>In method org.apache.hadoop.io.compress.bzip2.CBZip2InputStream.read(byte[], int, int)<br/>Field org.apache.hadoop.io.compress.bzip2.CBZip2InputStream.skipDecompression<br/>At CBZip2InputStream.java:[line 400]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N162011');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestIPC.conf from instance method org.apache.hadoop.ipc.TestIPC.setupConf()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N162011" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestIPC<br/>In method org.apache.hadoop.ipc.TestIPC.setupConf()<br/>Field org.apache.hadoop.ipc.TestIPC.conf<br/>At TestIPC.java:[line 103]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N162078');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestIPC.WRITABLE_FAULTS_SLEEP from instance method org.apache.hadoop.ipc.TestIPC.testIOEOnWriteAfterPingClient()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N162078" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestIPC<br/>In method org.apache.hadoop.ipc.TestIPC.testIOEOnWriteAfterPingClient()<br/>Field org.apache.hadoop.ipc.TestIPC.WRITABLE_FAULTS_SLEEP<br/>At TestIPC.java:[line 473]<br/>Another occurrence at TestIPC.java:[line 479]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N162156');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.Server.INITIAL_RESP_BUF_SIZE from instance method org.apache.hadoop.ipc.TestIPCServerResponder.testResponseBuffer()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N162156" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestIPCServerResponder<br/>In method org.apache.hadoop.ipc.TestIPCServerResponder.testResponseBuffer()<br/>Field org.apache.hadoop.ipc.Server.INITIAL_RESP_BUF_SIZE<br/>At TestIPCServerResponder.java:[line 120]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N162223');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestIPCServerResponder.conf from instance method org.apache.hadoop.ipc.TestIPCServerResponder.testResponseBuffer()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N162223" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestIPCServerResponder<br/>In method org.apache.hadoop.ipc.TestIPCServerResponder.testResponseBuffer()<br/>Field org.apache.hadoop.ipc.TestIPCServerResponder.conf<br/>At TestIPCServerResponder.java:[line 124]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N162370');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestMultipleProtocolServer.addr from instance method org.apache.hadoop.ipc.TestMultipleProtocolServer.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N162370" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestMultipleProtocolServer<br/>In method org.apache.hadoop.ipc.TestMultipleProtocolServer.setUp()<br/>Field org.apache.hadoop.ipc.TestMultipleProtocolServer.addr<br/>At TestMultipleProtocolServer.java:[line 195]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N162437');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestMultipleProtocolServer.server from instance method org.apache.hadoop.ipc.TestMultipleProtocolServer.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N162437" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestMultipleProtocolServer<br/>In method org.apache.hadoop.ipc.TestMultipleProtocolServer.setUp()<br/>Field org.apache.hadoop.ipc.TestMultipleProtocolServer.server<br/>At TestMultipleProtocolServer.java:[line 178]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N162574');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestProtoBufRpc.conf from instance method org.apache.hadoop.ipc.TestProtoBufRpc.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N162574" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestProtoBufRpc<br/>In method org.apache.hadoop.ipc.TestProtoBufRpc.setUp()<br/>Field org.apache.hadoop.ipc.TestProtoBufRpc.conf<br/>At TestProtoBufRpc.java:[line 121]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N162641');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestProtoBufRpc.addr from instance method org.apache.hadoop.ipc.TestProtoBufRpc.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N162641" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestProtoBufRpc<br/>In method org.apache.hadoop.ipc.TestProtoBufRpc.setUp()<br/>Field org.apache.hadoop.ipc.TestProtoBufRpc.addr<br/>At TestProtoBufRpc.java:[line 134]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N162708');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestProtoBufRpc.server from instance method org.apache.hadoop.ipc.TestProtoBufRpc.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N162708" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestProtoBufRpc<br/>In method org.apache.hadoop.ipc.TestProtoBufRpc.setUp()<br/>Field org.apache.hadoop.ipc.TestProtoBufRpc.server<br/>At TestProtoBufRpc.java:[line 132]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N162775');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestRPCCompatibility.addr from instance method org.apache.hadoop.ipc.TestRPCCompatibility.testIsMethodSupported()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N162775" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestRPCCompatibility<br/>In method org.apache.hadoop.ipc.TestRPCCompatibility.testIsMethodSupported()<br/>Field org.apache.hadoop.ipc.TestRPCCompatibility.addr<br/>At TestRPCCompatibility.java:[line 330]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N162842');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestRPCCompatibility.server from instance method org.apache.hadoop.ipc.TestRPCCompatibility.testIsMethodSupported()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N162842" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestRPCCompatibility<br/>In method org.apache.hadoop.ipc.TestRPCCompatibility.testIsMethodSupported()<br/>Field org.apache.hadoop.ipc.TestRPCCompatibility.server<br/>At TestRPCCompatibility.java:[line 326]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N162909');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestRPCCompatibility.server from instance method org.apache.hadoop.ipc.TestRPCCompatibility.testProtocolMetaInfoSSTranslatorPB()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N162909" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestRPCCompatibility<br/>In method org.apache.hadoop.ipc.TestRPCCompatibility.testProtocolMetaInfoSSTranslatorPB()<br/>Field org.apache.hadoop.ipc.TestRPCCompatibility.server<br/>At TestRPCCompatibility.java:[line 351]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N162976');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestRPCCompatibility.addr from instance method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion0ClientVersion1Server()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N162976" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestRPCCompatibility<br/>In method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion0ClientVersion1Server()<br/>Field org.apache.hadoop.ipc.TestRPCCompatibility.addr<br/>At TestRPCCompatibility.java:[line 146]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N163043');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestRPCCompatibility.server from instance method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion0ClientVersion1Server()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N163043" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestRPCCompatibility<br/>In method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion0ClientVersion1Server()<br/>Field org.apache.hadoop.ipc.TestRPCCompatibility.server<br/>At TestRPCCompatibility.java:[line 141]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N163110');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestRPCCompatibility.addr from instance method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion1ClientVersion0Server()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N163110" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestRPCCompatibility<br/>In method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion1ClientVersion0Server()<br/>Field org.apache.hadoop.ipc.TestRPCCompatibility.addr<br/>At TestRPCCompatibility.java:[line 162]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N163177');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestRPCCompatibility.server from instance method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion1ClientVersion0Server()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N163177" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestRPCCompatibility<br/>In method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion1ClientVersion0Server()<br/>Field org.apache.hadoop.ipc.TestRPCCompatibility.server<br/>At TestRPCCompatibility.java:[line 158]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N163244');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestRPCCompatibility.addr from instance method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion2ClientVersion1Server()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N163244" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestRPCCompatibility<br/>In method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion2ClientVersion1Server()<br/>Field org.apache.hadoop.ipc.TestRPCCompatibility.addr<br/>At TestRPCCompatibility.java:[line 215]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N163311');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestRPCCompatibility.server from instance method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion2ClientVersion1Server()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N163311" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestRPCCompatibility<br/>In method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion2ClientVersion1Server()<br/>Field org.apache.hadoop.ipc.TestRPCCompatibility.server<br/>At TestRPCCompatibility.java:[line 210]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N163378');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestRPCCompatibility.addr from instance method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion2ClientVersion2Server()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N163378" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestRPCCompatibility<br/>In method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion2ClientVersion2Server()<br/>Field org.apache.hadoop.ipc.TestRPCCompatibility.addr<br/>At TestRPCCompatibility.java:[line 236]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N163445');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestRPCCompatibility.server from instance method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion2ClientVersion2Server()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N163445" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestRPCCompatibility<br/>In method org.apache.hadoop.ipc.TestRPCCompatibility.testVersion2ClientVersion2Server()<br/>Field org.apache.hadoop.ipc.TestRPCCompatibility.server<br/>At TestRPCCompatibility.java:[line 231]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N163512');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestRPCCompatibility.addr from instance method org.apache.hadoop.ipc.TestRPCCompatibility.testVersionMismatch()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N163512" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestRPCCompatibility<br/>In method org.apache.hadoop.ipc.TestRPCCompatibility.testVersionMismatch()<br/>Field org.apache.hadoop.ipc.TestRPCCompatibility.addr<br/>At TestRPCCompatibility.java:[line 307]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N163579');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestRPCCompatibility.server from instance method org.apache.hadoop.ipc.TestRPCCompatibility.testVersionMismatch()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N163579" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestRPCCompatibility<br/>In method org.apache.hadoop.ipc.TestRPCCompatibility.testVersionMismatch()<br/>Field org.apache.hadoop.ipc.TestRPCCompatibility.server<br/>At TestRPCCompatibility.java:[line 303]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N163909');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestSaslRPC.clientFallBackToSimpleAllowed from instance method org.apache.hadoop.ipc.TestSaslRPC.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N163909" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.setup()<br/>Field org.apache.hadoop.ipc.TestSaslRPC.clientFallBackToSimpleAllowed<br/>At TestSaslRPC.java:[line 177]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N163976');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestSaslRPC.conf from instance method org.apache.hadoop.ipc.TestSaslRPC.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N163976" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.setup()<br/>Field org.apache.hadoop.ipc.TestSaslRPC.conf<br/>At TestSaslRPC.java:[line 165]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N164043');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestSaslRPC.enableSecretManager from instance method org.apache.hadoop.ipc.TestSaslRPC.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N164043" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.setup()<br/>Field org.apache.hadoop.ipc.TestSaslRPC.enableSecretManager<br/>At TestSaslRPC.java:[line 175]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N164110');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestSaslRPC.forceSecretManager from instance method org.apache.hadoop.ipc.TestSaslRPC.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N164110" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.setup()<br/>Field org.apache.hadoop.ipc.TestSaslRPC.forceSecretManager<br/>At TestSaslRPC.java:[line 176]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N164177');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestSaslRPC.enableSecretManager from instance method org.apache.hadoop.ipc.TestSaslRPC.testKerberosServerWithInvalidTokens()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N164177" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.testKerberosServerWithInvalidTokens()<br/>Field org.apache.hadoop.ipc.TestSaslRPC.enableSecretManager<br/>At TestSaslRPC.java:[line 835]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N164244');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestSaslRPC.enableSecretManager from instance method org.apache.hadoop.ipc.TestSaslRPC.testKerberosServerWithTokens()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N164244" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.testKerberosServerWithTokens()<br/>Field org.apache.hadoop.ipc.TestSaslRPC.enableSecretManager<br/>At TestSaslRPC.java:[line 825]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N164311');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestSaslRPC.clientFallBackToSimpleAllowed from instance method org.apache.hadoop.ipc.TestSaslRPC.testNoClientFallbackToSimple()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N164311" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.testNoClientFallbackToSimple()<br/>Field org.apache.hadoop.ipc.TestSaslRPC.clientFallBackToSimpleAllowed<br/>At TestSaslRPC.java:[line 694]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N164378');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestSaslRPC.forceSecretManager from instance method org.apache.hadoop.ipc.TestSaslRPC.testNoClientFallbackToSimple()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N164378" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.testNoClientFallbackToSimple()<br/>Field org.apache.hadoop.ipc.TestSaslRPC.forceSecretManager<br/>At TestSaslRPC.java:[line 709]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N164445');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestSaslRPC.enableSecretManager from instance method org.apache.hadoop.ipc.TestSaslRPC.testSimpleServerWithInvalidTokens()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N164445" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.testSimpleServerWithInvalidTokens()<br/>Field org.apache.hadoop.ipc.TestSaslRPC.enableSecretManager<br/>At TestSaslRPC.java:[line 768]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N164512');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestSaslRPC.forceSecretManager from instance method org.apache.hadoop.ipc.TestSaslRPC.testSimpleServerWithInvalidTokens()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N164512" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.testSimpleServerWithInvalidTokens()<br/>Field org.apache.hadoop.ipc.TestSaslRPC.forceSecretManager<br/>At TestSaslRPC.java:[line 771]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N164579');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestSaslRPC.enableSecretManager from instance method org.apache.hadoop.ipc.TestSaslRPC.testSimpleServerWithTokens()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N164579" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.testSimpleServerWithTokens()<br/>Field org.apache.hadoop.ipc.TestSaslRPC.enableSecretManager<br/>At TestSaslRPC.java:[line 747]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N164646');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestSaslRPC.forceSecretManager from instance method org.apache.hadoop.ipc.TestSaslRPC.testSimpleServerWithTokens()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N164646" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.testSimpleServerWithTokens()<br/>Field org.apache.hadoop.ipc.TestSaslRPC.forceSecretManager<br/>At TestSaslRPC.java:[line 755]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N164713');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestSaslRPC.enableSecretManager from instance method org.apache.hadoop.ipc.TestSaslRPC.testTokenOnlyServerWithInvalidTokens()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N164713" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.testTokenOnlyServerWithInvalidTokens()<br/>Field org.apache.hadoop.ipc.TestSaslRPC.enableSecretManager<br/>At TestSaslRPC.java:[line 801]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N164780');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.ipc.TestSaslRPC.enableSecretManager from instance method org.apache.hadoop.ipc.TestSaslRPC.testTokenOnlyServerWithTokens()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N164780" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.ipc.TestSaslRPC<br/>In method org.apache.hadoop.ipc.TestSaslRPC.testTokenOnlyServerWithTokens()<br/>Field org.apache.hadoop.ipc.TestSaslRPC.enableSecretManager<br/>At TestSaslRPC.java:[line 792]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N180624');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.gridmix.Statistics.numMapsSubmitted from instance method org.apache.hadoop.mapred.gridmix.Statistics.add(Statistics$JobStats)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N180624" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Statistics<br/>In method org.apache.hadoop.mapred.gridmix.Statistics.add(Statistics$JobStats)<br/>Field org.apache.hadoop.mapred.gridmix.Statistics.numMapsSubmitted<br/>At Statistics.java:[line 159]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N180691');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.gridmix.Statistics.numReducesSubmitted from instance method org.apache.hadoop.mapred.gridmix.Statistics.add(Statistics$JobStats)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N180691" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Statistics<br/>In method org.apache.hadoop.mapred.gridmix.Statistics.add(Statistics$JobStats)<br/>Field org.apache.hadoop.mapred.gridmix.Statistics.numReducesSubmitted<br/>At Statistics.java:[line 160]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N180758');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.gridmix.Statistics.numMapsSubmitted from instance method org.apache.hadoop.mapred.gridmix.Statistics.addJobStats(Statistics$JobStats)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N180758" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Statistics<br/>In method org.apache.hadoop.mapred.gridmix.Statistics.addJobStats(Statistics$JobStats)<br/>Field org.apache.hadoop.mapred.gridmix.Statistics.numMapsSubmitted<br/>At Statistics.java:[line 134]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N180825');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.gridmix.Statistics.numReducesSubmitted from instance method org.apache.hadoop.mapred.gridmix.Statistics.addJobStats(Statistics$JobStats)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N180825" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.Statistics<br/>In method org.apache.hadoop.mapred.gridmix.Statistics.addJobStats(Statistics$JobStats)<br/>Field org.apache.hadoop.mapred.gridmix.Statistics.numReducesSubmitted<br/>At Statistics.java:[line 135]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N182448');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.gridmix.CommonJobTest.policy from instance method org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N182448" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestGridmixSubmission<br/>In method org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testReplaySubmit()<br/>Field org.apache.hadoop.mapred.gridmix.CommonJobTest.policy<br/>At TestGridmixSubmission.java:[line 157]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N182515');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.gridmix.CommonJobTest.policy from instance method org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N182515" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestGridmixSubmission<br/>In method org.apache.hadoop.mapred.gridmix.TestGridmixSubmission.testStressSubmit()<br/>Field org.apache.hadoop.mapred.gridmix.CommonJobTest.policy<br/>At TestGridmixSubmission.java:[line 166]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N182582');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.gridmix.CommonJobTest.policy from instance method org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N182582" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestLoadJob<br/>In method org.apache.hadoop.mapred.gridmix.TestLoadJob.testReplaySubmit()<br/>Field org.apache.hadoop.mapred.gridmix.CommonJobTest.policy<br/>At TestLoadJob.java:[line 73]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N182649');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.gridmix.CommonJobTest.policy from instance method org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N182649" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestLoadJob<br/>In method org.apache.hadoop.mapred.gridmix.TestLoadJob.testSerialSubmit()<br/>Field org.apache.hadoop.mapred.gridmix.CommonJobTest.policy<br/>At TestLoadJob.java:[line 61]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N182993');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.gridmix.TestSleepJob.policy from instance method org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N182993" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestSleepJob<br/>In method org.apache.hadoop.mapred.gridmix.TestSleepJob.testReplaySubmit()<br/>Field org.apache.hadoop.mapred.gridmix.TestSleepJob.policy<br/>At TestSleepJob.java:[line 105]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N183060');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.gridmix.TestSleepJob.policy from instance method org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N183060" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestSleepJob<br/>In method org.apache.hadoop.mapred.gridmix.TestSleepJob.testSerialSubmit()<br/>Field org.apache.hadoop.mapred.gridmix.TestSleepJob.policy<br/>At TestSleepJob.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N183127');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.gridmix.TestSleepJob.policy from instance method org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N183127" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestSleepJob<br/>In method org.apache.hadoop.mapred.gridmix.TestSleepJob.testStressSubmit()<br/>Field org.apache.hadoop.mapred.gridmix.TestSleepJob.policy<br/>At TestSleepJob.java:[line 113]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N168510');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.MRBench.BASE_DIR from instance method org.apache.hadoop.mapred.MRBench.run(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N168510" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.MRBench<br/>In method org.apache.hadoop.mapred.MRBench.run(String[])<br/>Field org.apache.hadoop.mapred.MRBench.BASE_DIR<br/>At MRBench.java:[line 245]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N172420');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.TestJobEndNotifier$DelayServlet.calledTimes from instance method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N172420" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobEndNotifier<br/>In method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()<br/>Field org.apache.hadoop.mapred.TestJobEndNotifier$DelayServlet.calledTimes<br/>At TestJobEndNotifier.java:[line 117]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N172485');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.TestJobEndNotifier$FailServlet.calledTimes from instance method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N172485" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobEndNotifier<br/>In method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()<br/>Field org.apache.hadoop.mapred.TestJobEndNotifier$FailServlet.calledTimes<br/>At TestJobEndNotifier.java:[line 118]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N172550');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.TestJobEndNotifier$JobEndServlet.calledTimes from instance method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N172550" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobEndNotifier<br/>In method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()<br/>Field org.apache.hadoop.mapred.TestJobEndNotifier$JobEndServlet.calledTimes<br/>At TestJobEndNotifier.java:[line 115]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N172615');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.TestJobEndNotifier$JobEndServlet.requestUri from instance method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N172615" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestJobEndNotifier<br/>In method org.apache.hadoop.mapred.TestJobEndNotifier.setUp()<br/>Field org.apache.hadoop.mapred.TestJobEndNotifier$JobEndServlet.requestUri<br/>At TestJobEndNotifier.java:[line 116]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N173718');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.TestLocalDistributedCacheManager.mockfs from instance method org.apache.hadoop.mapred.TestLocalDistributedCacheManager.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N173718" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestLocalDistributedCacheManager<br/>In method org.apache.hadoop.mapred.TestLocalDistributedCacheManager.setup()<br/>Field org.apache.hadoop.mapred.TestLocalDistributedCacheManager.mockfs<br/>At TestLocalDistributedCacheManager.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N174536');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.TestMapRed.counts from instance method org.apache.hadoop.mapred.TestMapRed.run(String[])</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N174536" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMapRed<br/>In method org.apache.hadoop.mapred.TestMapRed.run(String[])<br/>Field org.apache.hadoop.mapred.TestMapRed.counts<br/>At TestMapRed.java:[line 786]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N174603');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapred.TestMapRed.range from instance method org.apache.hadoop.mapred.TestMapRed.run(String[])</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N174603" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapred.TestMapRed<br/>In method org.apache.hadoop.mapred.TestMapRed.run(String[])<br/>Field org.apache.hadoop.mapred.TestMapRed.range<br/>At TestMapRed.java:[line 785]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N192043');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapreduce.lib.input.TestFileInputFormat.localFs from instance method org.apache.hadoop.mapreduce.lib.input.TestFileInputFormat.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N192043" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.TestFileInputFormat<br/>In method org.apache.hadoop.mapreduce.lib.input.TestFileInputFormat.setup()<br/>Field org.apache.hadoop.mapreduce.lib.input.TestFileInputFormat.localFs<br/>At TestFileInputFormat.java:[line 82]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N203455');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebApp.webProxyBase from instance method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebApp.testMRWebAppRedirection()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N203455" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebApp<br/>In method org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebApp.testMRWebAppRedirection()<br/>Field org.apache.hadoop.mapreduce.v2.app.webapp.TestAMWebApp.webProxyBase<br/>At TestAMWebApp.java:[line 238]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N208312');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobs.appContext from instance method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobs.testJobCountersForKilledJob()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N208312" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobs<br/>In method org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobs.testJobCountersForKilledJob()<br/>Field org.apache.hadoop.mapreduce.v2.hs.webapp.TestHsWebServicesJobs.appContext<br/>At TestHsWebServicesJobs.java:[line 529]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N213264');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.net.TestNetUtils.config from instance method org.apache.hadoop.net.TestNetUtils.resetResolver()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N213264" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.net.TestNetUtils<br/>In method org.apache.hadoop.net.TestNetUtils.resetResolver()<br/>Field org.apache.hadoop.net.TestNetUtils.config<br/>At TestNetUtils.java:[line 368]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N215533');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.record.compiler.generated.Rcc.curDir from instance method org.apache.hadoop.record.compiler.generated.Rcc.Include()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N215533" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.Rcc<br/>In method org.apache.hadoop.record.compiler.generated.Rcc.Include()<br/>Field org.apache.hadoop.record.compiler.generated.Rcc.curDir<br/>At Rcc.java:[line 160]<br/>Another occurrence at Rcc.java:[line 181]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N215611');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.record.compiler.generated.Rcc.curFileName from instance method org.apache.hadoop.record.compiler.generated.Rcc.Include()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N215611" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.Rcc<br/>In method org.apache.hadoop.record.compiler.generated.Rcc.Include()<br/>Field org.apache.hadoop.record.compiler.generated.Rcc.curFileName<br/>At Rcc.java:[line 161]<br/>Another occurrence at Rcc.java:[line 182]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N215689');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.record.compiler.generated.Rcc.curModuleName from instance method org.apache.hadoop.record.compiler.generated.Rcc.Module()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N215689" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.Rcc<br/>In method org.apache.hadoop.record.compiler.generated.Rcc.Module()<br/>Field org.apache.hadoop.record.compiler.generated.Rcc.curModuleName<br/>At Rcc.java:[line 192]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N218671');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.security.TestUserGroupInformation.conf from instance method org.apache.hadoop.security.TestUserGroupInformation.setupUgi()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N218671" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.security.TestUserGroupInformation<br/>In method org.apache.hadoop.security.TestUserGroupInformation.setupUgi()<br/>Field org.apache.hadoop.security.TestUserGroupInformation.conf<br/>At TestUserGroupInformation.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N226291');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.tools.FakeRenewer.lastCanceled from instance method org.apache.hadoop.tools.FakeRenewer.cancel(Token, Configuration)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N226291" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.tools.FakeRenewer<br/>In method org.apache.hadoop.tools.FakeRenewer.cancel(Token, Configuration)<br/>Field org.apache.hadoop.tools.FakeRenewer.lastCanceled<br/>At FakeRenewer.java:[line 50]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N226358');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.tools.FakeRenewer.lastRenewed from instance method org.apache.hadoop.tools.FakeRenewer.renew(Token, Configuration)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N226358" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.tools.FakeRenewer<br/>In method org.apache.hadoop.tools.FakeRenewer.renew(Token, Configuration)<br/>Field org.apache.hadoop.tools.FakeRenewer.lastRenewed<br/>At FakeRenewer.java:[line 44]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N227718');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.tools.TestExternalCall.fs from instance method org.apache.hadoop.tools.TestExternalCall.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N227718" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestExternalCall<br/>In method org.apache.hadoop.tools.TestExternalCall.setup()<br/>Field org.apache.hadoop.tools.TestExternalCall.fs<br/>At TestExternalCall.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N227785');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.tools.TestExternalCall.root from instance method org.apache.hadoop.tools.TestExternalCall.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N227785" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.tools.TestExternalCall<br/>In method org.apache.hadoop.tools.TestExternalCall.setup()<br/>Field org.apache.hadoop.tools.TestExternalCall.root<br/>At TestExternalCall.java:[line 60]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N239374');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.attemptId from instance method org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.startApp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N239374" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.client.api.impl.TestAMRMClient<br/>In method org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.startApp()<br/>Field org.apache.hadoop.yarn.client.api.impl.TestAMRMClient.attemptId<br/>At TestAMRMClient.java:[line 168]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N249028');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.localDir from instance method new org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N249028" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest<br/>In method new org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest()<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.localDir<br/>At BaseContainerManagerTest.java:[line 88]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N249095');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.localFS from instance method new org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N249095" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest<br/>In method new org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest()<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.localFS<br/>At BaseContainerManagerTest.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N249162');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.localLogDir from instance method new org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N249162" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest<br/>In method new org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest()<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.localLogDir<br/>At BaseContainerManagerTest.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N249229');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.remoteLogDir from instance method new org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N249229" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest<br/>In method new org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest()<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.remoteLogDir<br/>At BaseContainerManagerTest.java:[line 94]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N249296');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.tmpDir from instance method new org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N249296" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest<br/>In method new org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest()<br/>Field org.apache.hadoop.yarn.server.nodemanager.containermanager.BaseContainerManagerTest.tmpDir<br/>At BaseContainerManagerTest.java:[line 97]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N261361');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.TestRMAppAttemptTransitions.appId from instance method org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.TestRMAppAttemptTransitions.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N261361" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.TestRMAppAttemptTransitions<br/>In method org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.TestRMAppAttemptTransitions.setUp()<br/>Field org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.TestRMAppAttemptTransitions.appId<br/>At TestRMAppAttemptTransitions.java:[line 256]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N257362');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.rm1 from instance method org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.startRMs()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N257362" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase<br/>In method org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.startRMs()<br/>Field org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.rm1<br/>At RMHATestBase.java:[line 106]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N257429');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.rm2 from instance method org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.startRMs()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N257429" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase<br/>In method org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.startRMs()<br/>Field org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.rm2<br/>At RMHATestBase.java:[line 107]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N257496');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.rm1 from instance method org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.startRMsWithCustomizedRMAppManager()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N257496" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase<br/>In method org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.startRMsWithCustomizedRMAppManager()<br/>Field org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.rm1<br/>At RMHATestBase.java:[line 115]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N257563');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.rm2 from instance method org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.startRMsWithCustomizedRMAppManager()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N257563" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase<br/>In method org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.startRMsWithCustomizedRMAppManager()<br/>Field org.apache.hadoop.yarn.server.resourcemanager.RMHATestBase.rm2<br/>At RMHATestBase.java:[line 123]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N265360');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacityScheduler.B3_CAPACITY from instance method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacityScheduler.testRefreshQueuesWithNewQueue()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N265360" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacityScheduler<br/>In method org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacityScheduler.testRefreshQueuesWithNewQueue()<br/>Field org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestCapacityScheduler.B3_CAPACITY<br/>At TestCapacityScheduler.java:[line 494]<br/>Another occurrence at TestCapacityScheduler.java:[line 513]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N270277');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.counter from instance method org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N270277" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer<br/>In method org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.setUp()<br/>Field org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.counter<br/>At TestDelegationTokenRenewer.java:[line 174]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N270344');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.dispatcher from instance method org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.setUp()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N270344" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer<br/>In method org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.setUp()<br/>Field org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.dispatcher<br/>At TestDelegationTokenRenewer.java:[line 179]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N270411');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.eventQueue from instance method org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N270411" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer<br/>In method org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.setUp()<br/>Field org.apache.hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer.eventQueue<br/>At TestDelegationTokenRenewer.java:[line 178]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N257630');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.resourcemanager.TestAppManager.appEventType from instance method org.apache.hadoop.yarn.server.resourcemanager.TestAppManager.setAppEventType(RMAppEventType)</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N257630" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestAppManager<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestAppManager.setAppEventType(RMAppEventType)<br/>Field org.apache.hadoop.yarn.server.resourcemanager.TestAppManager.appEventType<br/>At TestAppManager.java:[line 87]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N257888');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication.failMove from instance method org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication.setUp()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N257888" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication.setUp()<br/>Field org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication.failMove<br/>At TestMoveApplication.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N257955');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication.failMove from instance method org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication.testMoveRejectedByPermissions()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N257955" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication.testMoveRejectedByPermissions()<br/>Field org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication.failMove<br/>At TestMoveApplication.java:[line 146]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N258022');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication.failMove from instance method org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication.testMoveRejectedByScheduler()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N258022" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication.testMoveRejectedByScheduler()<br/>Field org.apache.hadoop.yarn.server.resourcemanager.TestMoveApplication.failMove<br/>At TestMoveApplication.java:[line 69]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N259287');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.rmAddr from instance method org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N259287" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart<br/>In method org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.setup()<br/>Field org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart.rmAddr<br/>At TestRMRestart.java:[line 120]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N245703');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.server.TestContainerManagerSecurity.yarnCluster from instance method org.apache.hadoop.yarn.server.TestContainerManagerSecurity.testContainerManager()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N245703" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.TestContainerManagerSecurity<br/>In method org.apache.hadoop.yarn.server.TestContainerManagerSecurity.testContainerManager()<br/>Field org.apache.hadoop.yarn.server.TestContainerManagerSecurity.yarnCluster<br/>At TestContainerManagerSecurity.java:[line 138]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N236309');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.TestResourceTrackerPBClientImpl$ResourceTrackerTestImpl.exception from instance method org.apache.hadoop.yarn.TestResourceTrackerPBClientImpl.testNodeHeartbeat()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N236309" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.TestResourceTrackerPBClientImpl<br/>In method org.apache.hadoop.yarn.TestResourceTrackerPBClientImpl.testNodeHeartbeat()<br/>Field org.apache.hadoop.yarn.TestResourceTrackerPBClientImpl$ResourceTrackerTestImpl.exception<br/>At TestResourceTrackerPBClientImpl.java:[line 107]<br/>Another occurrence at TestResourceTrackerPBClientImpl.java:[line 114]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N236385');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.TestResourceTrackerPBClientImpl$ResourceTrackerTestImpl.exception from instance method org.apache.hadoop.yarn.TestResourceTrackerPBClientImpl.testResourceTrackerPBClientImpl()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N236385" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.TestResourceTrackerPBClientImpl<br/>In method org.apache.hadoop.yarn.TestResourceTrackerPBClientImpl.testResourceTrackerPBClientImpl()<br/>Field org.apache.hadoop.yarn.TestResourceTrackerPBClientImpl$ResourceTrackerTestImpl.exception<br/>At TestResourceTrackerPBClientImpl.java:[line 84]<br/>Another occurrence at TestResourceTrackerPBClientImpl.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N275972');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.util.TestRackResolver$MyResolver.resolvedHost1 from instance method org.apache.hadoop.yarn.util.TestRackResolver.testCaching()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N275972" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestRackResolver<br/>In method org.apache.hadoop.yarn.util.TestRackResolver.testCaching()<br/>Field org.apache.hadoop.yarn.util.TestRackResolver$MyResolver.resolvedHost1<br/>At TestRackResolver.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N276698');">
<td>
<span class="priority-1">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.webapp.view.TestInfoBlock.sw from instance method org.apache.hadoop.yarn.webapp.view.TestInfoBlock.setup()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N276698" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.webapp.view.TestInfoBlock<br/>In method org.apache.hadoop.yarn.webapp.view.TestInfoBlock.setup()<br/>Field org.apache.hadoop.yarn.webapp.view.TestInfoBlock.sw<br/>At TestInfoBlock.java:[line 91]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N276765');">
<td>
<span class="priority-2">ST</span>
</td>
<td>Write to static field org.apache.hadoop.yarn.webapp.view.TestInfoBlock.pw from instance method org.apache.hadoop.yarn.webapp.view.TestInfoBlock.setup()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N276765" style="display: none;">
<a href="#ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">Bug type ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.webapp.view.TestInfoBlock<br/>In method org.apache.hadoop.yarn.webapp.view.TestInfoBlock.setup()<br/>Field org.apache.hadoop.yarn.webapp.view.TestInfoBlock.pw<br/>At TestInfoBlock.java:[line 92]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N88399');">
<td>
<span class="priority-1">UC</span>
</td>
<td>Useless condition: it's known that i != 3 at this point</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N88399" style="display: none;">
<a href="#UC_USELESS_CONDITION">Bug type UC_USELESS_CONDITION (click for details)</a>
<br/>In class org.apache.hadoop.fs.s3native.NativeS3FileSystemContractBaseTest<br/>In method org.apache.hadoop.fs.s3native.NativeS3FileSystemContractBaseTest.testDirWithDifferentMarkersWorks()<br/>Value i != 3<br/>Unreachable code at NativeS3FileSystemContractBaseTest.java:[line 102]<br/>At NativeS3FileSystemContractBaseTest.java:[line 100]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N94920');">
<td>
<span class="priority-2">UC</span>
</td>
<td>Useless condition: it's known that result != -1 at this point</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N94920" style="display: none;">
<a href="#UC_USELESS_CONDITION">Bug type UC_USELESS_CONDITION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.DFSInputStream<br/>In method org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream$ReaderStrategy, int, int)<br/>Value result != -1<br/>At DFSInputStream.java:[line 804]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N120715');">
<td>
<span class="priority-1">UC</span>
</td>
<td>Useless condition: it's known that i == 0 at this point</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N120715" style="display: none;">
<a href="#UC_USELESS_CONDITION">Bug type UC_USELESS_CONDITION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.datanode.TestReadOnlySharedStorage<br/>In method org.apache.hadoop.hdfs.server.datanode.TestReadOnlySharedStorage.setup()<br/>Value i == 0<br/>Unreachable code at TestReadOnlySharedStorage.java:[line 101]<br/>At TestReadOnlySharedStorage.java:[line 101]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N143441');">
<td>
<span class="priority-1">UC</span>
</td>
<td>Useless condition: it's known that numBlocks == -1 at this point</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N143441" style="display: none;">
<a href="#UC_USELESS_CONDITION">Bug type UC_USELESS_CONDITION (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent<br/>In method org.apache.hadoop.hdfs.tools.offlineImageViewer.ImageLoaderCurrent.processINode(DataInputStream, ImageVisitor, boolean, String, boolean)<br/>Value numBlocks == -1<br/>Unreachable code at ImageLoaderCurrent.java:[line 739]<br/>At ImageLoaderCurrent.java:[line 739]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N110625');">
<td>
<span class="priority-2">UC</span>
</td>
<td>Useless object stored in variable versionFiles of method org.apache.hadoop.hdfs.UpgradeUtilities.createDataNodeVersionFile(File[], StorageInfo, String, String)</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N110625" style="display: none;">
<a href="#UC_USELESS_OBJECT">Bug type UC_USELESS_OBJECT (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.UpgradeUtilities<br/>In method org.apache.hadoop.hdfs.UpgradeUtilities.createDataNodeVersionFile(File[], StorageInfo, String, String)<br/>Value versionFiles<br/>Type java.io.File[]<br/>At UpgradeUtilities.java:[line 463]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N182168');">
<td>
<span class="priority-2">UC</span>
</td>
<td>Useless object stored in variable metrics of method org.apache.hadoop.mapred.gridmix.TestGridMixClasses.testGridmixSplit()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N182168" style="display: none;">
<a href="#UC_USELESS_OBJECT">Bug type UC_USELESS_OBJECT (click for details)</a>
<br/>In class org.apache.hadoop.mapred.gridmix.TestGridMixClasses<br/>In method org.apache.hadoop.mapred.gridmix.TestGridMixClasses.testGridmixSplit()<br/>Value metrics<br/>Type org.apache.hadoop.tools.rumen.ResourceUsageMetrics<br/>At TestGridMixClasses.java:[line 133]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N216124');">
<td>
<span class="priority-2">UC</span>
</td>
<td>Method org.apache.hadoop.record.compiler.generated.RccTokenManager.SkipLexicalActions(Token) seems to be useless</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N216124" style="display: none;">
<a href="#UC_USELESS_VOID_METHOD">Bug type UC_USELESS_VOID_METHOD (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.RccTokenManager<br/>In method org.apache.hadoop.record.compiler.generated.RccTokenManager.SkipLexicalActions(Token)<br/>At RccTokenManager.java:[line 832]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N252680');">
<td>
<span class="priority-2">UC</span>
</td>
<td>Useless object stored in variable pubRsrcs of method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testFailedPublicResource()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N252680" style="display: none;">
<a href="#UC_USELESS_OBJECT">Bug type UC_USELESS_OBJECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.TestResourceLocalizationService.testFailedPublicResource()<br/>Value pubRsrcs<br/>Type java.util.HashSet<br/>At TestResourceLocalizationService.java:[line 672]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N254632');">
<td>
<span class="priority-2">UC</span>
</td>
<td>Useless object stored in variable localAppLogDirs of method org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.TestNonAggregatingLogHandler.testDelayedDelete()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N254632" style="display: none;">
<a href="#UC_USELESS_OBJECT">Bug type UC_USELESS_OBJECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.TestNonAggregatingLogHandler<br/>In method org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.TestNonAggregatingLogHandler.testDelayedDelete()<br/>Value localAppLogDirs<br/>Type org.apache.hadoop.fs.Path[]<br/>At TestNonAggregatingLogHandler.java:[line 176]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N270478');">
<td>
<span class="priority-2">UC</span>
</td>
<td>Useless object stored in variable expiringKeys of method org.apache.hadoop.yarn.server.resourcemanager.security.TestRMDelegationTokens.testRMDTMasterKeyStateOnRollingMasterKey()</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N270478" style="display: none;">
<a href="#UC_USELESS_OBJECT">Bug type UC_USELESS_OBJECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.security.TestRMDelegationTokens<br/>In method org.apache.hadoop.yarn.server.resourcemanager.security.TestRMDelegationTokens.testRMDTMasterKeyStateOnRollingMasterKey()<br/>Value expiringKeys<br/>Type java.util.HashSet<br/>At TestRMDelegationTokens.java:[line 93]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N274534');">
<td>
<span class="priority-2">UC</span>
</td>
<td>Useless object stored in variable rsrcVis of method org.apache.hadoop.yarn.util.TestFSDownload.testDownloadBadPublic()</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N274534" style="display: none;">
<a href="#UC_USELESS_OBJECT">Bug type UC_USELESS_OBJECT (click for details)</a>
<br/>In class org.apache.hadoop.yarn.util.TestFSDownload<br/>In method org.apache.hadoop.yarn.util.TestFSDownload.testDownloadBadPublic()<br/>Value rsrcVis<br/>Type java.util.HashMap<br/>At TestFSDownload.java:[line 264]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70440');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.contrib.utils.join.DataJoinMapperBase.job</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70440" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.contrib.utils.join.DataJoinMapperBase<br/>Field org.apache.hadoop.contrib.utils.join.DataJoinMapperBase.job<br/>At DataJoinMapperBase.java:[line 50]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N70924');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.examples.pi.math.Montgomery.N_I</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N70924" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.examples.pi.math.Montgomery<br/>Field org.apache.hadoop.examples.pi.math.Montgomery.N_I<br/>At Montgomery.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N70975');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.examples.pi.math.Montgomery.R_1</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N70975" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.examples.pi.math.Montgomery<br/>Field org.apache.hadoop.examples.pi.math.Montgomery.R_1<br/>At Montgomery.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N71026');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.examples.pi.math.Montgomery.s</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N71026" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.examples.pi.math.Montgomery<br/>Field org.apache.hadoop.examples.pi.math.Montgomery.s<br/>At Montgomery.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N74550');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.fs.IOMapperBase.buffer</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N74550" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.fs.IOMapperBase<br/>Field org.apache.hadoop.fs.IOMapperBase.buffer<br/>At IOMapperBase.java:[line 57]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N74601');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.fs.IOMapperBase.fs</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N74601" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.fs.IOMapperBase<br/>Field org.apache.hadoop.fs.IOMapperBase.fs<br/>At IOMapperBase.java:[line 52]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N138954');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSetQuotaWithSnapshot.exception</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N138954" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSetQuotaWithSnapshot<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSetQuotaWithSnapshot.exception<br/>At TestSetQuotaWithSnapshot.java:[line 59]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N139402');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.exception</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N139402" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot<br/>Field org.apache.hadoop.hdfs.server.namenode.snapshot.TestSnapshot.exception<br/>At TestSnapshot.java:[line 104]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N166243');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.lib.wsrs.TestUserProvider.exceptionHelper</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N166243" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.lib.wsrs.TestUserProvider<br/>Field org.apache.hadoop.lib.wsrs.TestUserProvider.exceptionHelper<br/>At TestUserProvider.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N191316');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.rrClass</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N191316" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader<br/>Field org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.rrClass<br/>At CombineFileRecordReader.java:[line 114]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N216228');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.record.compiler.generated.RccTokenManager.debugStream</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N216228" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.record.compiler.generated.RccTokenManager<br/>Field org.apache.hadoop.record.compiler.generated.RccTokenManager.debugStream<br/>At RccTokenManager.java:[line 33]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N224386');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.test.HFSTestCase.hdfsTestHelper</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N224386" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.test.HFSTestCase<br/>Field org.apache.hadoop.test.HFSTestCase.hdfsTestHelper<br/>At HFSTestCase.java:[line 25]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N224437');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.test.HTestCase.exceptionHelper</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N224437" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.test.HTestCase<br/>Field org.apache.hadoop.test.HTestCase.exceptionHelper<br/>At HTestCase.java:[line 46]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N224488');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.test.HTestCase.jettyTestHelper</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N224488" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.test.HTestCase<br/>Field org.apache.hadoop.test.HTestCase.jettyTestHelper<br/>At HTestCase.java:[line 43]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N224539');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.test.HTestCase.testDir</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N224539" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.test.HTestCase<br/>Field org.apache.hadoop.test.HTestCase.testDir<br/>At HTestCase.java:[line 40]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N225817');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.test.UnitTestcaseTimeLimit.globalTimeout</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N225817" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.test.UnitTestcaseTimeLimit<br/>Field org.apache.hadoop.test.UnitTestcaseTimeLimit.globalTimeout<br/>At UnitTestcaseTimeLimit.java:[line 33]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N243996');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.yarn.lib.TestZKClient.tmpDir</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N243996" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.lib.TestZKClient<br/>Field org.apache.hadoop.yarn.lib.TestZKClient.tmpDir<br/>At TestZKClient.java:[line 50]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N271002');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptInfo.containerId</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N271002" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptInfo<br/>Field org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptInfo.containerId<br/>At AppAttemptInfo.java:[line 45]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N271053');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptInfo.nodeId</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N271053" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptInfo<br/>Field org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptInfo.nodeId<br/>At AppAttemptInfo.java:[line 47]</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N271104');">
<td>
<span class="priority-2">UrF</span>
</td>
<td>Unread public/protected field: org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo.schedulerInfo</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N271104" style="display: none;">
<a href="#URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">Bug type URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo<br/>Field org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo.schedulerInfo<br/>At SchedulerTypeInfo.java:[line 34]</p>
</td>
</tr>
<tr class="tablerow0" onclick="toggleRow('N191367');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused public or protected field: org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.fs</td>
</tr>
<tr class="detailrow0">
<td/>
<td>
<p id="N191367" style="display: none;">
<a href="#UUF_UNUSED_PUBLIC_OR_PROTECTED_FIELD">Bug type UUF_UNUSED_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader<br/>Field org.apache.hadoop.mapreduce.lib.input.CombineFileRecordReader.fs<br/>In CombineFileRecordReader.java</p>
</td>
</tr>
<tr class="tablerow1" onclick="toggleRow('N195797');">
<td>
<span class="priority-2">UuF</span>
</td>
<td>Unused public or protected field: org.apache.hadoop.mapreduce.task.ReduceContextImpl.reporter</td>
</tr>
<tr class="detailrow1">
<td/>
<td>
<p id="N195797" style="display: none;">
<a href="#UUF_UNUSED_PUBLIC_OR_PROTECTED_FIELD">Bug type UUF_UNUSED_PUBLIC_OR_PROTECTED_FIELD (click for details)</a>
<br/>In class org.apache.hadoop.mapreduce.task.ReduceContextImpl<br/>Field org.apache.hadoop.mapreduce.task.ReduceContextImpl.reporter<br/>In ReduceContextImpl.java</p>
</td>
</tr>
</table>
<h1>
<a name="Details">Details</a>
</h1>
<h2>
<a name="AT_OPERATION_SEQUENCE_ON_CONCURRENT_ABSTRACTION">AT_OPERATION_SEQUENCE_ON_CONCURRENT_ABSTRACTION: Sequence of calls to concurrent abstraction may not be atomic</a>
</h2>
          
        <p>This code contains a sequence of calls to a concurrent  abstraction
            (such as a concurrent hash map).
            These calls will not be executed atomically.
          
      
<h2>
<a name="BC_EQUALS_METHOD_SHOULD_WORK_FOR_ALL_OBJECTS">BC_EQUALS_METHOD_SHOULD_WORK_FOR_ALL_OBJECTS: Equals method should not assume anything about the type of its argument</a>
</h2>

<p>
The <code>equals(Object o)</code> method shouldn't make any assumptions
about the type of <code>o</code>. It should simply return
false if <code>o</code> is not the same type as <code>this</code>.
</p>

    
<h2>
<a name="BC_VACUOUS_INSTANCEOF">BC_VACUOUS_INSTANCEOF: instanceof will always return true</a>
</h2>

<p>
This instanceof test will always return true (unless the value being tested is null).
Although this is safe, make sure it isn't
an indication of some misunderstanding or some other logic error.
If you really want to test the value for being null, perhaps it would be clearer to do
better to do a null test rather than an instanceof test.
</p>

    
<h2>
<a name="BC_UNCONFIRMED_CAST">BC_UNCONFIRMED_CAST: Unchecked/unconfirmed cast</a>
</h2>

<p>
This cast is unchecked, and not all instances of the type casted from can be cast to
the type it is being cast to. Check that your program logic ensures that this
cast will not fail.
</p>

    
<h2>
<a name="BIT_IOR_OF_SIGNED_BYTE">BIT_IOR_OF_SIGNED_BYTE: Bitwise OR of signed byte value</a>
</h2>

<p> Loads a byte value (e.g., a value loaded from a byte array or returned by a method
with return type byte)  and performs a bitwise OR with
that value. Byte values are sign extended to 32 bits
before any any bitwise operations are performed on the value.
Thus, if <code>b[0]</code> contains the value <code>0xff</code>, and
<code>x</code> is initially 0, then the code
<code>((x &lt;&lt; 8) | b[0])</code>  will sign extend <code>0xff</code>
to get <code>0xffffffff</code>, and thus give the value
<code>0xffffffff</code> as the result.
</p>

<p>In particular, the following code for packing a byte array into an int is badly wrong: </p>
<pre>
int result = 0;
for(int i = 0; i &lt; 4; i++)
  result = ((result &lt;&lt; 8) | b[i]);
</pre>

<p>The following idiom will work instead: </p>
<pre>
int result = 0;
for(int i = 0; i &lt; 4; i++)
  result = ((result &lt;&lt; 8) | (b[i] &amp; 0xff));
</pre>


    
<h2>
<a name="ICAST_QUESTIONABLE_UNSIGNED_RIGHT_SHIFT">ICAST_QUESTIONABLE_UNSIGNED_RIGHT_SHIFT: Unsigned right shift cast to short/byte</a>
</h2>

<p>
The code performs an unsigned right shift, whose result is then
cast to a short or byte, which discards the upper bits of the result.
Since the upper bits are discarded, there may be no difference between
a signed and unsigned right shift (depending upon the size of the shift).
</p>

    
<h2>
<a name="BX_UNBOXING_IMMEDIATELY_REBOXED">BX_UNBOXING_IMMEDIATELY_REBOXED: Boxed value is unboxed and then immediately reboxed</a>
</h2>

  <p>A boxed value is unboxed and then immediately reboxed.
</p>

    
<h2>
<a name="DM_BOXED_PRIMITIVE_FOR_PARSING">DM_BOXED_PRIMITIVE_FOR_PARSING: Boxing/unboxing to parse a primitive</a>
</h2>

  <p>A boxed primitive is created from a String, just to extract the unboxed primitive value.
  It is more efficient to just call the static parseXXX method.</p>

    
<h2>
<a name="DM_BOXED_PRIMITIVE_TOSTRING">DM_BOXED_PRIMITIVE_TOSTRING: Method allocates a boxed primitive just to call toString</a>
</h2>

  <p>A boxed primitive is allocated just to call toString(). It is more effective to just use the static
  form of toString which takes the primitive value. So,</p>
  <table>
     <tr><th>Replace...</th><th>With this...</th></tr>
     <tr><td>new Integer(1).toString()</td><td>Integer.toString(1)</td></tr>
     <tr><td>new Long(1).toString()</td><td>Long.toString(1)</td></tr>
     <tr><td>new Float(1.0).toString()</td><td>Float.toString(1.0)</td></tr>
     <tr><td>new Double(1.0).toString()</td><td>Double.toString(1.0)</td></tr>
     <tr><td>new Byte(1).toString()</td><td>Byte.toString(1)</td></tr>
     <tr><td>new Short(1).toString()</td><td>Short.toString(1)</td></tr>
     <tr><td>new Boolean(true).toString()</td><td>Boolean.toString(true)</td></tr>
  </table>

    
<h2>
<a name="DM_NUMBER_CTOR">DM_NUMBER_CTOR: Method invokes inefficient Number constructor; use static valueOf instead</a>
</h2>
      
      <p>
      Using <code>new Integer(int)</code> is guaranteed to always result in a new object whereas
      <code>Integer.valueOf(int)</code> allows caching of values to be done by the compiler, class library, or JVM.
      Using of cached values avoids object allocation and the code will be faster.
      </p>
      <p>
      Values between -128 and 127 are guaranteed to have corresponding cached instances
      and using <code>valueOf</code> is approximately 3.5 times faster than using constructor.
      For values outside the constant range the performance of both styles is the same.
      </p>
      <p>
      Unless the class must be compatible with JVMs predating Java 1.5,
      use either autoboxing or the <code>valueOf()</code> method when creating instances of
      <code>Long</code>, <code>Integer</code>, <code>Short</code>, <code>Character</code>, and <code>Byte</code>.
      </p>
      
    
<h2>
<a name="BX_BOXING_IMMEDIATELY_UNBOXED_TO_PERFORM_COERCION">BX_BOXING_IMMEDIATELY_UNBOXED_TO_PERFORM_COERCION: Primitive value is boxed then unboxed to perform primitive coercion</a>
</h2>

  <p>A primitive boxed value constructed and then immediately converted into a different primitive type
(e.g., <code>new Double(d).intValue()</code>). Just perform direct primitive coercion (e.g., <code>(int) d</code>).</p>

    
<h2>
<a name="CNT_ROUGH_CONSTANT_VALUE">CNT_ROUGH_CONSTANT_VALUE: Rough value of known constant found</a>
</h2>
      
    <p>It's recommended to use the predefined library constant for code clarity and better precision.</p>

    
<h2>
<a name="CO_COMPARETO_INCORRECT_FLOATING">CO_COMPARETO_INCORRECT_FLOATING: compareTo()/compare() incorrectly handles float or double value</a>
</h2>

  <p>This method compares double or float values using pattern like this: val1 &gt; val2 ? 1 : val1 &lt; val2 ? -1 : 0.
This pattern works incorrectly for -0.0 and NaN values which may result in incorrect sorting result or broken collection 
(if compared values are used as keys). Consider using Double.compare or Float.compare static methods which handle all 
the special cases correctly.</p>

    
<h2>
<a name="DB_DUPLICATE_BRANCHES">DB_DUPLICATE_BRANCHES: Method uses the same code for two branches</a>
</h2>
      
      <p>
      This method uses the same code to implement two branches of a conditional branch.
    Check to ensure that this isn't a coding mistake.
      </p>
      
   
<h2>
<a name="DC_DOUBLECHECK">DC_DOUBLECHECK: Possible double check of field</a>
</h2>

  <p> This method may contain an instance of double-checked locking.&nbsp;
  This idiom is not correct according to the semantics of the Java memory
  model.&nbsp; For more information, see the web page
  <a href="http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html"
  >http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html</a>.</p>

    
<h2>
<a name="DE_MIGHT_IGNORE">DE_MIGHT_IGNORE: Method might ignore exception</a>
</h2>

  <p> This method might ignore an exception.&nbsp; In general, exceptions
  should be handled or reported in some way, or they should be thrown
  out of the method.</p>

    
<h2>
<a name="DLS_DEAD_LOCAL_STORE">DLS_DEAD_LOCAL_STORE: Dead store to local variable</a>
</h2>

<p>
This instruction assigns a value to a local variable,
but the value is not read or used in any subsequent instruction.
Often, this indicates an error, because the value computed is never
used.
</p>
<p>
Note that Sun's javac compiler often generates dead stores for
final local variables.  Because FindBugs is a bytecode-based tool,
there is no easy way to eliminate these false positives.
</p>

    
<h2>
<a name="DLS_DEAD_LOCAL_STORE_SHADOWS_FIELD">DLS_DEAD_LOCAL_STORE_SHADOWS_FIELD: Dead store to local variable that shadows field</a>
</h2>

<p>
This instruction assigns a value to a local variable,
but the value is not read or used in any subsequent instruction.
Often, this indicates an error, because the value computed is never
used. There is a field with the same name as the local variable. Did you
mean to assign to that variable instead?
</p>

    
<h2>
<a name="DM_BOOLEAN_CTOR">DM_BOOLEAN_CTOR: Method invokes inefficient Boolean constructor; use Boolean.valueOf(...) instead</a>
</h2>

  <p> Creating new instances of <code>java.lang.Boolean</code> wastes
  memory, since <code>Boolean</code> objects are immutable and there are
  only two useful values of this type.&nbsp; Use the <code>Boolean.valueOf()</code>
  method (or Java 1.5 autoboxing) to create <code>Boolean</code> objects instead.</p>

    
<h2>
<a name="DM_STRING_CTOR">DM_STRING_CTOR: Method invokes inefficient new String(String) constructor</a>
</h2>

  <p> Using the <code>java.lang.String(String)</code> constructor wastes memory
  because the object so constructed will be functionally indistinguishable
  from the <code>String</code> passed as a parameter.&nbsp; Just use the
  argument <code>String</code> directly.</p>

    
<h2>
<a name="DM_EXIT">DM_EXIT: Method invokes System.exit(...)</a>
</h2>

  <p> Invoking System.exit shuts down the entire Java virtual machine. This
   should only been done when it is appropriate. Such calls make it
   hard or impossible for your code to be invoked by other code.
   Consider throwing a RuntimeException instead.</p>

    
<h2>
<a name="DM_DEFAULT_ENCODING">DM_DEFAULT_ENCODING: Reliance on default encoding</a>
</h2>

<p> Found a call to a method which will perform a byte to String (or String to byte) conversion, and will assume that the default platform encoding is suitable. This will cause the application behaviour to vary between platforms. Use an alternative API and specify a charset name or Charset object explicitly.  </p>

      
<h2>
<a name="DM_NEXTINT_VIA_NEXTDOUBLE">DM_NEXTINT_VIA_NEXTDOUBLE: Use the nextInt method of Random rather than nextDouble to generate a random integer</a>
</h2>

  <p>If <code>r</code> is a <code>java.util.Random</code>, you can generate a random number from <code>0</code> to <code>n-1</code>
using <code>r.nextInt(n)</code>, rather than using <code>(int)(r.nextDouble() * n)</code>.
</p>
<p>The argument to nextInt must be positive. If, for example, you want to generate a random
value from -99 to 0, use <code>-r.nextInt(100)</code>.
</p>

    
<h2>
<a name="DMI_HARDCODED_ABSOLUTE_FILENAME">DMI_HARDCODED_ABSOLUTE_FILENAME: Code contains a hard coded reference to an absolute pathname</a>
</h2>

<p>This code constructs a File object using a hard coded to an absolute pathname
(e.g., <code>new File("/home/dannyc/workspace/j2ee/src/share/com/sun/enterprise/deployment");</code>
</p>

    
<h2>
<a name="DMI_DOH">DMI_DOH: D'oh! A nonsensical method invocation</a>
</h2>
      
    <p>
This partical method invocation doesn't make sense, for reasons that should be apparent from inspection.
</p>


    
<h2>
<a name="DMI_RANDOM_USED_ONLY_ONCE">DMI_RANDOM_USED_ONLY_ONCE: Random object created and used only once</a>
</h2>

<p> This code creates a java.util.Random object, uses it to generate one random number, and then discards
the Random object. This produces mediocre quality random numbers and is inefficient.
If possible, rewrite the code so that the Random object is created once and saved, and each time a new random number
is required invoke a method on the existing Random object to obtain it.
</p>

<p>If it is important that the generated Random numbers not be guessable, you <em>must</em> not create a new Random for each random
number; the values are too easily guessable. You should strongly consider using a java.security.SecureRandom instead
(and avoid allocating a new SecureRandom for each random number needed).
</p>

    
<h2>
<a name="EC_UNRELATED_TYPES">EC_UNRELATED_TYPES: Call to equals() comparing different types</a>
</h2>

<p> This method calls equals(Object) on two references of different
class types and analysis suggests they will be to objects of different classes 
at runtime. Further, examination of the equals methods that would be invoked suggest that either
this call will always return false, or else the equals method is not be symmetric (which is 
a property required by the contract
for equals in class Object). 
</p>

    
<h2>
<a name="EC_BAD_ARRAY_COMPARE">EC_BAD_ARRAY_COMPARE: Invocation of equals() on an array, which is equivalent to ==</a>
</h2>

<p>
This method invokes the .equals(Object o) method on an array. Since arrays do not override the equals
method of Object, calling equals on an array is the same as comparing their addresses. To compare the
contents of the arrays, use <code>java.util.Arrays.equals(Object[], Object[])</code>.
To compare the addresses of the arrays, it would be
less confusing to explicitly check pointer equality using <code>==</code>.
</p>

    
<h2>
<a name="EI_EXPOSE_REP">EI_EXPOSE_REP: May expose internal representation by returning reference to mutable object</a>
</h2>

  <p> Returning a reference to a mutable object value stored in one of the object's fields
  exposes the internal representation of the object.&nbsp;
   If instances
   are accessed by untrusted code, and unchecked changes to
   the mutable object would compromise security or other
   important properties, you will need to do something different.
  Returning a new copy of the object is better approach in many situations.</p>

    
<h2>
<a name="EI_EXPOSE_REP2">EI_EXPOSE_REP2: May expose internal representation by incorporating reference to mutable object</a>
</h2>

  <p> This code stores a reference to an externally mutable object into the
  internal representation of the object.&nbsp;
   If instances
   are accessed by untrusted code, and unchecked changes to
   the mutable object would compromise security or other
   important properties, you will need to do something different.
  Storing a copy of the object is better approach in many situations.</p>

    
<h2>
<a name="EQ_COMPARETO_USE_OBJECT_EQUALS">EQ_COMPARETO_USE_OBJECT_EQUALS: Class defines compareTo(...) and uses Object.equals()</a>
</h2>

  <p> This class defines a <code>compareTo(...)</code> method but inherits its
  <code>equals()</code> method from <code>java.lang.Object</code>.
    Generally, the value of compareTo should return zero if and only if
    equals returns true. If this is violated, weird and unpredictable
    failures will occur in classes such as PriorityQueue.
    In Java 5 the PriorityQueue.remove method uses the compareTo method,
    while in Java 6 it uses the equals method.</p>

<p>From the JavaDoc for the compareTo method in the Comparable interface:
<blockquote>
It is strongly recommended, but not strictly required that <code>(x.compareTo(y)==0) == (x.equals(y))</code>.
Generally speaking, any class that implements the Comparable interface and violates this condition
should clearly indicate this fact. The recommended language
is "Note: this class has a natural ordering that is inconsistent with equals."
</blockquote></p>

    
<h2>
<a name="EQ_CHECK_FOR_OPERAND_NOT_COMPATIBLE_WITH_THIS">EQ_CHECK_FOR_OPERAND_NOT_COMPATIBLE_WITH_THIS: Equals checks for incompatible operand</a>
</h2>

  <p> This equals method is checking to see if the argument is some incompatible type
(i.e., a class that is neither a supertype nor subtype of the class that defines
the equals method). For example, the Foo class might have an equals method
that looks like:
</p>
<pre>
public boolean equals(Object o) {
  if (o instanceof Foo)
    return name.equals(((Foo)o).name);
  else if (o instanceof String)
    return name.equals(o);
  else return false;
</pre>

<p>This is considered bad practice, as it makes it very hard to implement an equals method that
is symmetric and transitive. Without those properties, very unexpected behavoirs are possible.
</p>

    
<h2>
<a name="ES_COMPARING_STRINGS_WITH_EQ">ES_COMPARING_STRINGS_WITH_EQ: Comparison of String objects using == or !=</a>
</h2>

  <p>This code compares <code>java.lang.String</code> objects for reference
equality using the == or != operators.
Unless both strings are either constants in a source file, or have been
interned using the <code>String.intern()</code> method, the same string
value may be represented by two different String objects. Consider
using the <code>equals(Object)</code> method instead.</p>

    
<h2>
<a name="FE_FLOATING_POINT_EQUALITY">FE_FLOATING_POINT_EQUALITY: Test for floating point equality</a>
</h2>
   
    <p>
    This operation compares two floating point values for equality.
    Because floating point calculations may involve rounding,
   calculated float and double values may not be accurate.
    For values that must be precise, such as monetary values,
   consider using a fixed-precision type such as BigDecimal.
    For values that need not be precise, consider comparing for equality
    within some range, for example:
    <code>if ( Math.abs(x - y) &lt; .0000001 )</code>.
   See the Java Language Specification, section 4.2.4.
    </p>
    
     
<h2>
<a name="VA_FORMAT_STRING_USES_NEWLINE">VA_FORMAT_STRING_USES_NEWLINE: Format string should use %n rather than \n</a>
</h2>

<p>
This format string include a newline character (\n). In format strings, it is generally
 preferable better to use %n, which will produce the platform-specific line separator.
</p>

     
<h2>
<a name="GC_UNRELATED_TYPES">GC_UNRELATED_TYPES: No relationship between generic parameter and method argument</a>
</h2>
     
     <p> This call to a generic collection method contains an argument
     with an incompatible class from that of the collection's parameter
    (i.e., the type of the argument is neither a supertype nor a subtype
        of the corresponding generic type argument).
     Therefore, it is unlikely that the collection contains any objects
    that are equal to the method argument used here.
    Most likely, the wrong value is being passed to the method.</p>
    <p>In general, instances of two unrelated classes are not equal.
    For example, if the <code>Foo</code> and <code>Bar</code> classes
    are not related by subtyping, then an instance of <code>Foo</code>
        should not be equal to an instance of <code>Bar</code>.
    Among other issues, doing so will likely result in an equals method
    that is not symmetrical. For example, if you define the <code>Foo</code> class
    so that a <code>Foo</code> can be equal to a <code>String</code>,
    your equals method isn't symmetrical since a <code>String</code> can only be equal
    to a <code>String</code>.
    </p>
    <p>In rare cases, people do define nonsymmetrical equals methods and still manage to make
    their code work. Although none of the APIs document or guarantee it, it is typically
    the case that if you check if a <code>Collection&lt;String&gt;</code> contains
    a <code>Foo</code>, the equals method of argument (e.g., the equals method of the
    <code>Foo</code> class) used to perform the equality checks.
    </p>
     
    
<h2>
<a name="HE_EQUALS_USE_HASHCODE">HE_EQUALS_USE_HASHCODE: Class defines equals() and uses Object.hashCode()</a>
</h2>

  <p> This class overrides <code>equals(Object)</code>, but does not
  override <code>hashCode()</code>, and inherits the implementation of
  <code>hashCode()</code> from <code>java.lang.Object</code> (which returns
  the identity hash code, an arbitrary value assigned to the object
  by the VM).&nbsp; Therefore, the class is very likely to violate the
  invariant that equal objects must have equal hashcodes.</p>

<p>If you don't think instances of this class will ever be inserted into a HashMap/HashTable,
the recommended <code>hashCode</code> implementation to use is:</p>
<pre>public int hashCode() {
  assert false : "hashCode not designed";
  return 42; // any arbitrary constant will do
  }</pre>

    
<h2>
<a name="ICAST_IDIV_CAST_TO_DOUBLE">ICAST_IDIV_CAST_TO_DOUBLE: Integral division result cast to double or float</a>
</h2>

<p>
This code casts the result of an integral division (e.g., int or long division)
operation to double or
float.
Doing division on integers truncates the result
to the integer value closest to zero.  The fact that the result
was cast to double suggests that this precision should have been retained.
What was probably meant was to cast one or both of the operands to
double <em>before</em> performing the division.  Here is an example:
</p>
<blockquote>
<pre>
int x = 2;
int y = 5;
// Wrong: yields result 0.0
double value1 =  x / y;

// Right: yields result 0.4
double value2 =  x / (double) y;
</pre>
</blockquote>

    
<h2>
<a name="ICAST_INTEGER_MULTIPLY_CAST_TO_LONG">ICAST_INTEGER_MULTIPLY_CAST_TO_LONG: Result of integer multiplication cast to long</a>
</h2>

<p>
This code performs integer multiply and then converts the result to a long,
as in:</p>
<pre>
    long convertDaysToMilliseconds(int days) { return 1000*3600*24*days; }
</pre>
<p>
If the multiplication is done using long arithmetic, you can avoid
the possibility that the result will overflow. For example, you
could fix the above code to:</p>
<pre>
    long convertDaysToMilliseconds(int days) { return 1000L*3600*24*days; }
</pre>
or
<pre>
    static final long MILLISECONDS_PER_DAY = 24L*3600*1000;
    long convertDaysToMilliseconds(int days) { return days * MILLISECONDS_PER_DAY; }
</pre>

    
<h2>
<a name="IJU_SETUP_NO_SUPER">IJU_SETUP_NO_SUPER: TestCase defines setUp that doesn't call super.setUp()</a>
</h2>

<p> Class is a JUnit TestCase and implements the setUp method. The setUp method should call
super.setUp(), but doesn't.</p>

    
<h2>
<a name="IL_INFINITE_LOOP">IL_INFINITE_LOOP: An apparent infinite loop</a>
</h2>

<p>This loop doesn't seem to have a way to terminate (other than by perhaps
throwing an exception).</p>

    
<h2>
<a name="IM_BAD_CHECK_FOR_ODD">IM_BAD_CHECK_FOR_ODD: Check for oddness that won't work for negative numbers </a>
</h2>

<p>
The code uses x % 2 == 1 to check to see if a value is odd, but this won't work
for negative numbers (e.g., (-5) % 2 == -1). If this code is intending to check
for oddness, consider using x &amp; 1 == 1, or x % 2 != 0.
</p>

    
<h2>
<a name="INT_BAD_COMPARISON_WITH_NONNEGATIVE_VALUE">INT_BAD_COMPARISON_WITH_NONNEGATIVE_VALUE: Bad comparison of nonnegative value with negative constant or zero</a>
</h2>

<p> This code compares a value that is guaranteed to be non-negative with a negative constant or zero.
</p>

    
<h2>
<a name="INT_VACUOUS_COMPARISON">INT_VACUOUS_COMPARISON: Vacuous comparison of integer value</a>
</h2>

<p> There is an integer comparison that always returns
the same value (e.g., x &lt;= Integer.MAX_VALUE).
</p>

    
<h2>
<a name="IS2_INCONSISTENT_SYNC">IS2_INCONSISTENT_SYNC: Inconsistent synchronization</a>
</h2>

  <p> The fields of this class appear to be accessed inconsistently with respect
  to synchronization.&nbsp; This bug report indicates that the bug pattern detector
  judged that
  </p>
  <ul>
  <li> The class contains a mix of locked and unlocked accesses,</li>
  <li> The class is <b>not</b> annotated as javax.annotation.concurrent.NotThreadSafe,</li>
  <li> At least one locked access was performed by one of the class's own methods, and</li>
  <li> The number of unsynchronized field accesses (reads and writes) was no more than
       one third of all accesses, with writes being weighed twice as high as reads</li>
  </ul>

  <p> A typical bug matching this bug pattern is forgetting to synchronize
  one of the methods in a class that is intended to be thread-safe.</p>

  <p> You can select the nodes labeled "Unsynchronized access" to show the
  code locations where the detector believed that a field was accessed
  without synchronization.</p>

  <p> Note that there are various sources of inaccuracy in this detector;
  for example, the detector cannot statically detect all situations in which
  a lock is held.&nbsp; Also, even when the detector is accurate in
  distinguishing locked vs. unlocked accesses, the code in question may still
  be correct.</p>


    
<h2>
<a name="JLM_JSR166_UTILCONCURRENT_MONITORENTER">JLM_JSR166_UTILCONCURRENT_MONITORENTER: Synchronization performed on util.concurrent instance</a>
</h2>

<p> This method performs synchronization an object that is an instance of
a class from the java.util.concurrent package (or its subclasses). Instances
of these classes have their own concurrency control mechanisms that are orthogonal to
the synchronization provided by the Java keyword <code>synchronized</code>. For example,
synchronizing on an <code>AtomicBoolean</code> will not prevent other threads
from modifying the  <code>AtomicBoolean</code>.</p>
<p>Such code may be correct, but should be carefully reviewed and documented,
and may confuse people who have to maintain the code at a later date.
</p>


<h2>
<a name="LI_LAZY_INIT_UPDATE_STATIC">LI_LAZY_INIT_UPDATE_STATIC: Incorrect lazy initialization and update of static field</a>
</h2>

<p> This method contains an unsynchronized lazy initialization of a static field.
After the field is set, the object stored into that location is further updated or accessed.
The setting of the field is visible to other threads as soon as it is set. If the
futher accesses in the method that set the field serve to initialize the object, then
you have a <em>very serious</em> multithreading bug, unless something else prevents
any other thread from accessing the stored object until it is fully initialized.
</p>
<p>Even if you feel confident that the method is never called by multiple
threads, it might be better to not set the static field until the value
you are setting it to is fully populated/initialized.

    
<h2>
<a name="LI_LAZY_INIT_STATIC">LI_LAZY_INIT_STATIC: Incorrect lazy initialization of static field</a>
</h2>

<p> This method contains an unsynchronized lazy initialization of a non-volatile static field.
Because the compiler or processor may reorder instructions,
threads are not guaranteed to see a completely initialized object,
<em>if the method can be called by multiple threads</em>.
You can make the field volatile to correct the problem.
For more information, see the
<a href="http://www.cs.umd.edu/~pugh/java/memoryModel/">Java Memory Model web site</a>.
</p>

    
<h2>
<a name="ME_MUTABLE_ENUM_FIELD">ME_MUTABLE_ENUM_FIELD: Enum field is public and mutable</a>
</h2>

  <p>A mutable public field is defined inside a public enum, thus can be changed by malicious code or by accident from another package.
  Though mutable enum fields may be used for lazy initialization, it's a bad practice to expose them to the outer world.
  Consider declaring this field final and/or package-private.</p>

    
<h2>
<a name="ME_ENUM_FIELD_SETTER">ME_ENUM_FIELD_SETTER: Public enum method unconditionally sets its field</a>
</h2>

  <p>This public method declared in public enum unconditionally sets enum field, thus this field can be changed by malicious code 
  or by accident from another package. Though mutable enum fields may be used for lazy initialization, it's a bad practice to expose them to the outer world.
  Consider removing this method or declaring it package-private.</p>

    
<h2>
<a name="MS_MUTABLE_ARRAY">MS_MUTABLE_ARRAY: Field is a mutable array</a>
</h2>

<p> A final static field references an array
   and can be accessed by malicious code or
        by accident from another package.
   This code can freely modify the contents of the array.</p>

    
<h2>
<a name="MS_MUTABLE_COLLECTION">MS_MUTABLE_COLLECTION: Field is a mutable collection</a>
</h2>

 <p>A mutable collection instance is assigned to a final static field, 
   thus can be changed by malicious code or by accident from another package.
   Consider wrapping this field into Collections.unmodifiableSet/List/Map/etc.
   to avoid this vulnerability.</p>

    
<h2>
<a name="MS_MUTABLE_COLLECTION_PKGPROTECT">MS_MUTABLE_COLLECTION_PKGPROTECT: Field is a mutable collection which should be package protected</a>
</h2>

 <p>A mutable collection instance is assigned to a final static field, 
   thus can be changed by malicious code or by accident from another package.
   The field could be made package protected to avoid this vulnerability. 
   Alternatively you may wrap this field into Collections.unmodifiableSet/List/Map/etc.
   to avoid this vulnerability.</p>

    
<h2>
<a name="MS_CANNOT_BE_FINAL">MS_CANNOT_BE_FINAL: Field isn't final and can't be protected from malicious code</a>
</h2>

  <p>
 A mutable static field could be changed by malicious code or
        by accident from another package.
   Unfortunately, the way the field is used doesn't allow
   any easy fix to this problem.</p>

    
<h2>
<a name="MS_SHOULD_BE_FINAL">MS_SHOULD_BE_FINAL: Field isn't final but should be</a>
</h2>

   <p>
This static field public but not final, and
could be changed by malicious code or
        by accident from another package.
        The field could be made final to avoid
        this vulnerability.</p>

    
<h2>
<a name="MS_FINAL_PKGPROTECT">MS_FINAL_PKGPROTECT: Field should be both final and package protected</a>
</h2>

 <p>
   A mutable static field could be changed by malicious code or
        by accident from another package.
        The field could be made package protected and/or made final
   to avoid
        this vulnerability.</p>

    
<h2>
<a name="MS_OOI_PKGPROTECT">MS_OOI_PKGPROTECT: Field should be moved out of an interface and made package protected</a>
</h2>

<p>
 A final static field that is
defined in an interface references a mutable
   object such as an array or hashtable.
   This mutable object could
   be changed by malicious code or
        by accident from another package.
   To solve this, the field needs to be moved to a class
   and made package protected
   to avoid
        this vulnerability.</p>

    
<h2>
<a name="MS_PKGPROTECT">MS_PKGPROTECT: Field should be package protected</a>
</h2>

  <p> A mutable static field could be changed by malicious code or
   by accident.
   The field could be made package protected to avoid
   this vulnerability.</p>

    
<h2>
<a name="EI_EXPOSE_STATIC_REP2">EI_EXPOSE_STATIC_REP2: May expose internal static state by storing a mutable object into a static field</a>
</h2>

  <p> This code stores a reference to an externally mutable object into a static
   field.
   If unchecked changes to
   the mutable object would compromise security or other
   important properties, you will need to do something different.
  Storing a copy of the object is better approach in many situations.</p>

    
<h2>
<a name="MS_EXPOSE_REP">MS_EXPOSE_REP: Public static method may expose internal representation by returning array</a>
</h2>

  <p> A public static method returns a reference to
   an array that is part of the static state of the class.
   Any code that calls this method can freely modify
   the underlying array.
   One fix is to return a copy of the array.</p>

    
<h2>
<a name="MWN_MISMATCHED_WAIT">MWN_MISMATCHED_WAIT: Mismatched wait()</a>
</h2>

<p> This method calls Object.wait() without obviously holding a lock
on the object.&nbsp;  Calling wait() without a lock held will result in
an <code>IllegalMonitorStateException</code> being thrown.</p>

    
<h2>
<a name="NM_CLASS_NOT_EXCEPTION">NM_CLASS_NOT_EXCEPTION: Class is not derived from an Exception, even though it is named as such</a>
</h2>

<p> This class is not derived from another exception, but ends with 'Exception'. This will
be confusing to users of this class.</p>

    
<h2>
<a name="NM_SAME_SIMPLE_NAME_AS_INTERFACE">NM_SAME_SIMPLE_NAME_AS_INTERFACE: Class names shouldn't shadow simple name of implemented interface</a>
</h2>

  <p> This class/interface has a simple name that is identical to that of an implemented/extended interface, except
that the interface is in a different package (e.g., <code>alpha.Foo</code> extends <code>beta.Foo</code>).
This can be exceptionally confusing, create lots of situations in which you have to look at import statements
to resolve references and creates many
opportunities to accidentally define methods that do not override methods in their superclasses.
</p>

    
<h2>
<a name="NM_SAME_SIMPLE_NAME_AS_SUPERCLASS">NM_SAME_SIMPLE_NAME_AS_SUPERCLASS: Class names shouldn't shadow simple name of superclass</a>
</h2>

  <p> This class has a simple name that is identical to that of its superclass, except
that its superclass is in a different package (e.g., <code>alpha.Foo</code> extends <code>beta.Foo</code>).
This can be exceptionally confusing, create lots of situations in which you have to look at import statements
to resolve references and creates many
opportunities to accidentally define methods that do not override methods in their superclasses.
</p>

    
<h2>
<a name="NM_FIELD_NAMING_CONVENTION">NM_FIELD_NAMING_CONVENTION: Field names should start with a lower case letter</a>
</h2>

  <p>
Names of fields that are not final should be in mixed case with a lowercase first letter and the first letters of subsequent words capitalized.
</p>

    
<h2>
<a name="NM_METHOD_NAMING_CONVENTION">NM_METHOD_NAMING_CONVENTION: Method names should start with a lower case letter</a>
</h2>

  <p>
Methods should be verbs, in mixed case with the first letter lowercase, with the first letter of each internal word capitalized.
</p>

    
<h2>
<a name="NM_VERY_CONFUSING_INTENTIONAL">NM_VERY_CONFUSING_INTENTIONAL: Very confusing method names (but perhaps intentional)</a>
</h2>

  <p> The referenced methods have names that differ only by capitalization.
This is very confusing because if the capitalization were
identical then one of the methods would override the other. From the existence of other methods, it
seems that the existence of both of these methods is intentional, but is sure is confusing.
You should try hard to eliminate one of them, unless you are forced to have both due to frozen APIs.
</p>

    
<h2>
<a name="NN_NAKED_NOTIFY">NN_NAKED_NOTIFY: Naked notify</a>
</h2>

  <p> A call to <code>notify()</code> or <code>notifyAll()</code>
  was made without any (apparent) accompanying
  modification to mutable object state.&nbsp; In general, calling a notify
  method on a monitor is done because some condition another thread is
  waiting for has become true.&nbsp; However, for the condition to be meaningful,
  it must involve a heap object that is visible to both threads.</p>

  <p> This bug does not necessarily indicate an error, since the change to
  mutable object state may have taken place in a method which then called
  the method containing the notification.</p>

    
<h2>
<a name="NP_DEREFERENCE_OF_READLINE_VALUE">NP_DEREFERENCE_OF_READLINE_VALUE: Dereference of the result of readLine() without nullcheck</a>
</h2>

  <p> The result of invoking readLine() is dereferenced without checking to see if the result is null. If there are no more lines of text
to read, readLine() will return null and dereferencing that will generate a null pointer exception.
</p>

    
<h2>
<a name="NP_EQUALS_SHOULD_HANDLE_NULL_ARGUMENT">NP_EQUALS_SHOULD_HANDLE_NULL_ARGUMENT: equals() method does not check for null argument</a>
</h2>
      
      <p>
      This implementation of equals(Object) violates the contract defined
      by java.lang.Object.equals() because it does not check for null
      being passed as the argument.  All equals() methods should return
      false if passed a null value.
      </p>
      
   
<h2>
<a name="NP_IMMEDIATE_DEREFERENCE_OF_READLINE">NP_IMMEDIATE_DEREFERENCE_OF_READLINE: Immediate dereference of the result of readLine()</a>
</h2>

  <p> The result of invoking readLine() is immediately dereferenced. If there are no more lines of text
to read, readLine() will return null and dereferencing that will generate a null pointer exception.
</p>

    
<h2>
<a name="NP_LOAD_OF_KNOWN_NULL_VALUE">NP_LOAD_OF_KNOWN_NULL_VALUE: Load of known null value</a>
</h2>

  <p> The variable referenced at this point is known to be null due to an earlier
   check against null. Although this is valid, it might be a mistake (perhaps you
intended to refer to a different variable, or perhaps the earlier check to see if the
variable is null should have been a check to see if it was non-null).
</p>

    
<h2>
<a name="NP_NULL_PARAM_DEREF">NP_NULL_PARAM_DEREF: Method call passes null for non-null parameter</a>
</h2>
      
      <p>
      This method call passes a null value for a non-null method parameter.
    Either the parameter is annotated as a parameter that should
    always be non-null, or analysis has shown that it will always be
    dereferenced.
      </p>
      
   
<h2>
<a name="NP_NULL_PARAM_DEREF_ALL_TARGETS_DANGEROUS">NP_NULL_PARAM_DEREF_ALL_TARGETS_DANGEROUS: Method call passes null for non-null parameter</a>
</h2>
      
      <p>
      A possibly-null value is passed at a call site where all known
      target methods require the parameter to be non-null.
    Either the parameter is annotated as a parameter that should
    always be non-null, or analysis has shown that it will always be
    dereferenced.
      </p>
      
   
<h2>
<a name="NP_NULL_PARAM_DEREF_NONVIRTUAL">NP_NULL_PARAM_DEREF_NONVIRTUAL: Non-virtual method call passes null for non-null parameter</a>
</h2>
      
      <p>
      A possibly-null value is passed to a non-null method parameter.
    Either the parameter is annotated as a parameter that should
    always be non-null, or analysis has shown that it will always be
    dereferenced.
      </p>
      
   
<h2>
<a name="NP_ALWAYS_NULL">NP_ALWAYS_NULL: Null pointer dereference</a>
</h2>

<p> A null pointer is dereferenced here.&nbsp; This will lead to a
<code>NullPointerException</code> when the code is executed.</p>

    
<h2>
<a name="NP_NULL_ON_SOME_PATH">NP_NULL_ON_SOME_PATH: Possible null pointer dereference</a>
</h2>

<p> There is a branch of statement that, <em>if executed,</em>  guarantees that
a null value will be dereferenced, which
would generate a <code>NullPointerException</code> when the code is executed.
Of course, the problem might be that the branch or statement is infeasible and that
the null pointer exception can't ever be executed; deciding that is beyond the ability of FindBugs.
</p>

    
<h2>
<a name="NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE">NP_NULL_ON_SOME_PATH_FROM_RETURN_VALUE: Possible null pointer dereference due to return value of called method</a>
</h2>
      
<p> The return value from a method is dereferenced without a null check,
and the return value of that method is one that should generally be checked
for null.  This may lead to a <code>NullPointerException</code> when the code is executed.
</p>
      
   
<h2>
<a name="NP_NULL_ON_SOME_PATH_EXCEPTION">NP_NULL_ON_SOME_PATH_EXCEPTION: Possible null pointer dereference in method on exception path</a>
</h2>

<p> A reference value which is null on some exception control path is
dereferenced here.&nbsp; This may lead to a <code>NullPointerException</code>
when the code is executed.&nbsp;
Note that because FindBugs currently does not prune infeasible exception paths,
this may be a false warning.</p>

<p> Also note that FindBugs considers the default case of a switch statement to
be an exception path, since the default case is often infeasible.</p>

    
<h2>
<a name="NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH">NP_GUARANTEED_DEREF_ON_EXCEPTION_PATH: Value is null and guaranteed to be dereferenced on exception path</a>
</h2>
          
              <p>
              There is a statement or branch on an exception path
                that if executed guarantees that
              a value is null at this point, and that
              value that is guaranteed to be dereferenced
              (except on forward paths involving runtime exceptions).
              </p>
          
      
<h2>
<a name="OBL_UNSATISFIED_OBLIGATION">OBL_UNSATISFIED_OBLIGATION: Method may fail to clean up stream or resource</a>
</h2>
          
          <p>
          This method may fail to clean up (close, dispose of) a stream,
          database object, or other
          resource requiring an explicit cleanup operation.
          </p>

          <p>
          In general, if a method opens a stream or other resource,
          the method should use a try/finally block to ensure that
          the stream or resource is cleaned up before the method
          returns.
          </p>

          <p>
          This bug pattern is essentially the same as the
          OS_OPEN_STREAM and ODR_OPEN_DATABASE_RESOURCE
          bug patterns, but is based on a different
          (and hopefully better) static analysis technique.
          We are interested is getting feedback about the
          usefulness of this bug pattern.
          To send feedback, either:
          </p>
          <ul>
            <li>send email to findbugs@cs.umd.edu</li>
            <li>file a bug report: <a href="http://findbugs.sourceforge.net/reportingBugs.html">http://findbugs.sourceforge.net/reportingBugs.html</a></li>
          </ul>

          <p>
          In particular,
          the false-positive suppression heuristics for this
          bug pattern have not been extensively tuned, so
          reports about false positives are helpful to us.
          </p>

          <p>
          See Weimer and Necula, <i>Finding and Preventing Run-Time Error Handling Mistakes</i>, for
          a description of the analysis technique.
          </p>
          
      
<h2>
<a name="OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE">OBL_UNSATISFIED_OBLIGATION_EXCEPTION_EDGE: Method may fail to clean up stream or resource on checked exception</a>
</h2>
          
          <p>
          This method may fail to clean up (close, dispose of) a stream,
          database object, or other
          resource requiring an explicit cleanup operation.
          </p>

          <p>
          In general, if a method opens a stream or other resource,
          the method should use a try/finally block to ensure that
          the stream or resource is cleaned up before the method
          returns.
          </p>

          <p>
          This bug pattern is essentially the same as the
          OS_OPEN_STREAM and ODR_OPEN_DATABASE_RESOURCE
          bug patterns, but is based on a different
          (and hopefully better) static analysis technique.
          We are interested is getting feedback about the
          usefulness of this bug pattern.
          To send feedback, either:
          </p>
          <ul>
            <li>send email to findbugs@cs.umd.edu</li>
            <li>file a bug report: <a href="http://findbugs.sourceforge.net/reportingBugs.html">http://findbugs.sourceforge.net/reportingBugs.html</a></li>
          </ul>

          <p>
          In particular,
          the false-positive suppression heuristics for this
          bug pattern have not been extensively tuned, so
          reports about false positives are helpful to us.
          </p>

          <p>
          See Weimer and Necula, <i>Finding and Preventing Run-Time Error Handling Mistakes</i>, for
          a description of the analysis technique.
          </p>
          
      
<h2>
<a name="ODR_OPEN_DATABASE_RESOURCE">ODR_OPEN_DATABASE_RESOURCE: Method may fail to close database resource</a>
</h2>

<p> The method creates a database resource (such as a database connection
or row set), does not assign it to any
fields, pass it to other methods, or return it, and does not appear to close
the object on all paths out of the method.&nbsp; Failure to
close database resources on all paths out of a method may
result in poor performance, and could cause the application to
have problems communicating with the database.
</p>

    
<h2>
<a name="OS_OPEN_STREAM">OS_OPEN_STREAM: Method may fail to close stream</a>
</h2>

<p> The method creates an IO stream object, does not assign it to any
fields, pass it to other methods that might close it,
or return it, and does not appear to close
the stream on all paths out of the method.&nbsp; This may result in
a file descriptor leak.&nbsp; It is generally a good
idea to use a <code>finally</code> block to ensure that streams are
closed.</p>

    
<h2>
<a name="RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE">RCN_REDUNDANT_NULLCHECK_WOULD_HAVE_BEEN_A_NPE: Nullcheck of value previously dereferenced</a>
</h2>

<p> A value is checked here to see whether it is null, but this value can't
be null because it was previously dereferenced and if it were null a null pointer
exception would have occurred at the earlier dereference.
Essentially, this code and the previous dereference
disagree as to whether this value is allowed to be null. Either the check is redundant
or the previous dereference is erroneous.</p>

    
<h2>
<a name="RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE">RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE: Redundant nullcheck of value known to be non-null</a>
</h2>

<p> This method contains a redundant check of a known non-null value against
the constant null.</p>

    
<h2>
<a name="RCN_REDUNDANT_NULLCHECK_OF_NULL_VALUE">RCN_REDUNDANT_NULLCHECK_OF_NULL_VALUE: Redundant nullcheck of value known to be null</a>
</h2>

<p> This method contains a redundant check of a known null value against
the constant null.</p>

    
<h2>
<a name="REC_CATCH_EXCEPTION">REC_CATCH_EXCEPTION: Exception is caught when Exception is not thrown</a>
</h2>
  
  <p>
  This method uses a try-catch block that catches Exception objects, but Exception is not
  thrown within the try block, and RuntimeException is not explicitly caught.  It is a common bug pattern to
  say try { ... } catch (Exception e) { something } as a shorthand for catching a number of types of exception
  each of whose catch blocks is identical, but this construct also accidentally catches RuntimeException as well,
  masking potential bugs.
  </p>
  <p>A better approach is to either explicitly catch the specific exceptions that are thrown,
  or to explicitly catch RuntimeException exception, rethrow it, and then catch all non-Runtime Exceptions, as shown below:</p>
  <pre>
  try {
    ...
  } catch (RuntimeException e) {
    throw e;
  } catch (Exception e) {
    ... deal with all non-runtime exceptions ...
  }</pre>
  
     
<h2>
<a name="RR_NOT_CHECKED">RR_NOT_CHECKED: Method ignores results of InputStream.read()</a>
</h2>

  <p> This method ignores the return value of one of the variants of
  <code>java.io.InputStream.read()</code> which can return multiple bytes.&nbsp;
  If the return value is not checked, the caller will not be able to correctly
  handle the case where fewer bytes were read than the caller requested.&nbsp;
  This is a particularly insidious kind of bug, because in many programs,
  reads from input streams usually do read the full amount of data requested,
  causing the program to fail only sporadically.</p>

    
<h2>
<a name="SR_NOT_CHECKED">SR_NOT_CHECKED: Method ignores results of InputStream.skip()</a>
</h2>

  <p> This method ignores the return value of
  <code>java.io.InputStream.skip()</code> which can skip multiple bytes.&nbsp;
  If the return value is not checked, the caller will not be able to correctly
  handle the case where fewer bytes were skipped than the caller requested.&nbsp;
  This is a particularly insidious kind of bug, because in many programs,
  skips from input streams usually do skip the full amount of data requested,
  causing the program to fail only sporadically. With Buffered streams, however,
  skip() will only skip data in the buffer, and will routinely fail to skip the
  requested number of bytes.</p>

    
<h2>
<a name="RV_DONT_JUST_NULL_CHECK_READLINE">RV_DONT_JUST_NULL_CHECK_READLINE: Method discards result of readLine after checking if it is non-null</a>
</h2>

   <p> The value returned by readLine is discarded after checking to see if the return
value is non-null. In almost all situations, if the result is non-null, you will want
to use that non-null value. Calling readLine again will give you a different line.</p>

    
<h2>
<a name="RV_RETURN_VALUE_IGNORED_BAD_PRACTICE">RV_RETURN_VALUE_IGNORED_BAD_PRACTICE: Method ignores exceptional return value</a>
</h2>

   <p> This method returns a value that is not checked. The return value should be checked
since it can indicate an unusual or unexpected function execution. For
example, the <code>File.delete()</code> method returns false
if the file could not be successfully deleted (rather than
throwing an Exception).
If you don't check the result, you won't notice if the method invocation
signals unexpected behavior by returning an atypical return value.
</p>

    
<h2>
<a name="RV_RETURN_VALUE_IGNORED">RV_RETURN_VALUE_IGNORED: Method ignores return value</a>
</h2>

   <p> The return value of this method should be checked. One common
cause of this warning is to invoke a method on an immutable object,
thinking that it updates the object. For example, in the following code
fragment,</p>
<blockquote>
<pre>
String dateString = getHeaderField(name);
dateString.trim();
</pre>
</blockquote>
<p>the programmer seems to be thinking that the trim() method will update
the String referenced by dateString. But since Strings are immutable, the trim()
function returns a new String value, which is being ignored here. The code
should be corrected to: </p>
<blockquote>
<pre>
String dateString = getHeaderField(name);
dateString = dateString.trim();
</pre>
</blockquote>

    
<h2>
<a name="RV_RETURN_VALUE_IGNORED_INFERRED">RV_RETURN_VALUE_IGNORED_INFERRED: Method ignores return value, is this OK?</a>
</h2>

<p>This code calls a method and ignores the return value. The return value
is the same type as the type the method is invoked on, and from our analysis it looks
like the return value might be important (e.g., like ignoring the
return value of <code>String.toLowerCase()</code>).
</p>
<p>We are guessing that ignoring the return value might be a bad idea just from
a simple analysis of the body of the method. You can use a @CheckReturnValue annotation
to instruct FindBugs as to whether ignoring the return value of this method
is important or acceptable.
</p>
<p>Please investigate this closely to decide whether it is OK to ignore the return value.
</p>

    
<h2>
<a name="RV_NEGATING_RESULT_OF_COMPARETO">RV_NEGATING_RESULT_OF_COMPARETO: Negating the result of compareTo()/compare()</a>
</h2>

  <p> This code negatives the return value of a compareTo or compare method.
This is a questionable or bad programming practice, since if the return
value is Integer.MIN_VALUE, negating the return value won't
negate the sign of the result. You can achieve the same intended result
by reversing the order of the operands rather than by negating the results.
</p>

    
<h2>
<a name="RV_01_TO_INT">RV_01_TO_INT: Random value from 0 to 1 is coerced to the integer 0</a>
</h2>

  <p>A random value from 0 to 1 is being coerced to the integer value 0. You probably
want to multiple the random value by something else before coercing it to an integer, or use the <code>Random.nextInt(n)</code> method.
</p>

    
<h2>
<a name="RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT">RV_RETURN_VALUE_IGNORED_NO_SIDE_EFFECT: Return value of method without side effect is ignored</a>
</h2>

<p>This code calls a method and ignores the return value. However our analysis shows that
the method (including its implementations in subclasses if any) does not produce any effect 
other than return value. Thus this call can be removed.
</p>
<p>We are trying to reduce the false positives as much as possible, but in some cases this warning might be wrong.
Common false-positive cases include:</p>
<p>- The method is designed to be overridden and produce a side effect in other projects which are out of the scope of the analysis.</p>
<p>- The method is called to trigger the class loading which may have a side effect.</p>
<p>- The method is called just to get some exception.</p>
<p>If you feel that our assumption is incorrect, you can use a @CheckReturnValue annotation
to instruct FindBugs that ignoring the return value of this method is acceptable.
</p>

    
<h2>
<a name="RV_RETURN_VALUE_OF_PUTIFABSENT_IGNORED">RV_RETURN_VALUE_OF_PUTIFABSENT_IGNORED: Return value of putIfAbsent ignored, value passed to putIfAbsent reused</a>
</h2>
          
        The <code>putIfAbsent</code> method is typically used to ensure that a
        single value is associated with a given key (the first value for which put
        if absent succeeds).
        If you ignore the return value and retain a reference to the value passed in,
        you run the risk of retaining a value that is not the one that is associated with the key in the map.
        If it matters which one you use and you use the one that isn't stored in the map,
        your program will behave incorrectly.
          
      
<h2>
<a name="SA_FIELD_SELF_COMPARISON">SA_FIELD_SELF_COMPARISON: Self comparison of field with itself</a>
</h2>

<p> This method compares a field with itself, and may indicate a typo or
a logic error.  Make sure that you are comparing the right things.
</p>

    
<h2>
<a name="SBSC_USE_STRINGBUFFER_CONCATENATION">SBSC_USE_STRINGBUFFER_CONCATENATION: Method concatenates strings using + in a loop</a>
</h2>

<p> The method seems to be building a String using concatenation in a loop.
In each iteration, the String is converted to a StringBuffer/StringBuilder,
   appended to, and converted back to a String.
   This can lead to a cost quadratic in the number of iterations,
   as the growing string is recopied in each iteration. </p>

<p>Better performance can be obtained by using
a StringBuffer (or StringBuilder in Java 1.5) explicitly.</p>

<p> For example:</p>
<pre>
  // This is bad
  String s = "";
  for (int i = 0; i &lt; field.length; ++i) {
    s = s + field[i];
  }

  // This is better
  StringBuffer buf = new StringBuffer();
  for (int i = 0; i &lt; field.length; ++i) {
    buf.append(field[i]);
  }
  String s = buf.toString();
</pre>

    
<h2>
<a name="SC_START_IN_CTOR">SC_START_IN_CTOR: Constructor invokes Thread.start()</a>
</h2>

  <p> The constructor starts a thread. This is likely to be wrong if
   the class is ever extended/subclassed, since the thread will be started
   before the subclass constructor is started.</p>

    
<h2>
<a name="SE_COMPARATOR_SHOULD_BE_SERIALIZABLE">SE_COMPARATOR_SHOULD_BE_SERIALIZABLE: Comparator doesn't implement Serializable</a>
</h2>

  <p> This class implements the <code>Comparator</code> interface. You
should consider whether or not it should also implement the <code>Serializable</code>
interface. If a comparator is used to construct an ordered collection
such as a <code>TreeMap</code>, then the <code>TreeMap</code>
will be serializable only if the comparator is also serializable.
As most comparators have little or no state, making them serializable
is generally easy and good defensive programming.
</p>

    
<h2>
<a name="SF_SWITCH_NO_DEFAULT">SF_SWITCH_NO_DEFAULT: Switch statement found where default case is missing</a>
</h2>

  <p> This method contains a switch statement where default case is missing.
  Usually you need to provide a default case.</p>
  <p>Because the analysis only looks at the generated bytecode, this warning can be incorrect triggered if
the default case is at the end of the switch statement and the switch statement doesn't contain break statements for other
cases.

    
<h2>
<a name="SF_SWITCH_FALLTHROUGH">SF_SWITCH_FALLTHROUGH: Switch statement found where one case falls through to the next case</a>
</h2>

  <p> This method contains a switch statement where one case branch will fall through to the next case.
  Usually you need to end this case with a break or return.</p>

    
<h2>
<a name="SS_SHOULD_BE_STATIC">SS_SHOULD_BE_STATIC: Unread field: should this field be static?</a>
</h2>

  <p> This class contains an instance final field that
   is initialized to a compile-time static value.
   Consider making the field static.</p>

    
<h2>
<a name="ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD">ST_WRITE_TO_STATIC_FROM_INSTANCE_METHOD: Write to static field from instance method</a>
</h2>

  <p> This instance method writes to a static field. This is tricky to get
correct if multiple instances are being manipulated,
and generally bad practice.
</p>

    
<h2>
<a name="STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE">STCAL_INVOKE_ON_STATIC_DATE_FORMAT_INSTANCE: Call to static DateFormat</a>
</h2>

<p>As the JavaDoc states, DateFormats are inherently unsafe for multithreaded use.
The detector has found a call to an instance of DateFormat that has been obtained via a static
field. This looks suspicous.</p>
<p>For more information on this see <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6231579">Sun Bug #6231579</a>
and <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6178997">Sun Bug #6178997</a>.</p>


<h2>
<a name="STCAL_STATIC_SIMPLE_DATE_FORMAT_INSTANCE">STCAL_STATIC_SIMPLE_DATE_FORMAT_INSTANCE: Static DateFormat</a>
</h2>

<p>As the JavaDoc states, DateFormats are inherently unsafe for multithreaded use.
Sharing a single instance across thread boundaries without proper synchronization will result in erratic behavior of the
application.</p>
<p>You may also experience serialization problems.</p>
<p>Using an instance field is recommended.</p>
<p>For more information on this see <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6231579">Sun Bug #6231579</a>
and <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6178997">Sun Bug #6178997</a>.</p>


<h2>
<a name="SWL_SLEEP_WITH_LOCK_HELD">SWL_SLEEP_WITH_LOCK_HELD: Method calls Thread.sleep() with a lock held</a>
</h2>
      
      <p>
      This method calls Thread.sleep() with a lock held.  This may result
      in very poor performance and scalability, or a deadlock, since other threads may
      be waiting to acquire the lock.  It is a much better idea to call
      wait() on the lock, which releases the lock and allows other threads
      to run.
      </p>
      
   
<h2>
<a name="UC_USELESS_CONDITION">UC_USELESS_CONDITION: Condition has no effect</a>
</h2>

<p>This condition always produces the same result as the value of the involved variable was narrowed before. 
Probably something else was meant or condition can be removed.</p>

    
<h2>
<a name="UC_USELESS_VOID_METHOD">UC_USELESS_VOID_METHOD: Useless non-empty void method</a>
</h2>

<p>Our analysis shows that this non-empty void method does not actually perform any useful work.
Please check it: probably there's a mistake in its code or its body can be fully removed.
</p>
<p>We are trying to reduce the false positives as much as possible, but in some cases this warning might be wrong.
Common false-positive cases include:</p>
<p>- The method is intended to trigger loading of some class which may have a side effect.</p>
<p>- The method is intended to implicitly throw some obscure exception.</p>

    
<h2>
<a name="UC_USELESS_OBJECT">UC_USELESS_OBJECT: Useless object created</a>
</h2>

<p>Our analysis shows that this object is useless. 
It's created and modified, but its value never go outside of the method or produce any side-effect.
Either there is a mistake and object was intended to be used or it can be removed.</p>
<p>This analysis rarely produces false-positives. Common false-positive cases include:</p>
<p>- This object used to implicitly throw some obscure exception.</p>
<p>- This object used as a stub to generalize the code.</p>
<p>- This object used to hold strong references to weak/soft-referenced objects.</p>

    
<h2>
<a name="UL_UNRELEASED_LOCK">UL_UNRELEASED_LOCK: Method does not release lock on all paths</a>
</h2>

<p> This method acquires a JSR-166 (<code>java.util.concurrent</code>) lock,
but does not release it on all paths out of the method.  In general, the correct idiom
for using a JSR-166 lock is:
</p>
<pre>
    Lock l = ...;
    l.lock();
    try {
        // do something
    } finally {
        l.unlock();
    }
</pre>

    
<h2>
<a name="URF_UNREAD_FIELD">URF_UNREAD_FIELD: Unread field</a>
</h2>

  <p> This field is never read.&nbsp; Consider removing it from the class.</p>

    
<h2>
<a name="URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD">URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD: Unread public/protected field</a>
</h2>

  <p> This field is never read.&nbsp;
The field is public or protected, so perhaps
    it is intended to be used with classes not seen as part of the analysis. If not,
consider removing it from the class.</p>

    
<h2>
<a name="DMI_INVOKING_TOSTRING_ON_ARRAY">DMI_INVOKING_TOSTRING_ON_ARRAY: Invocation of toString on an array</a>
</h2>

<p>
The code invokes toString on an array, which will generate a fairly useless result
such as [C@16f0472. Consider using Arrays.toString to convert the array into a readable
String that gives the contents of the array. See Programming Puzzlers, chapter 3, puzzle 12.
</p>

    
<h2>
<a name="UUF_UNUSED_FIELD">UUF_UNUSED_FIELD: Unused field</a>
</h2>

  <p> This field is never used.&nbsp; Consider removing it from the class.</p>

    
<h2>
<a name="UUF_UNUSED_PUBLIC_OR_PROTECTED_FIELD">UUF_UNUSED_PUBLIC_OR_PROTECTED_FIELD: Unused public or protected field</a>
</h2>

  <p> This field is never used.&nbsp;
The field is public or protected, so perhaps
    it is intended to be used with classes not seen as part of the analysis. If not,
consider removing it from the class.</p>

    
<h2>
<a name="UWF_NULL_FIELD">UWF_NULL_FIELD: Field only ever set to null</a>
</h2>

  <p> All writes to this field are of the constant value null, and thus
all reads of the field will return null.
Check for errors, or remove it if it is useless.</p>

    
<h2>
<a name="VO_VOLATILE_INCREMENT">VO_VOLATILE_INCREMENT: An increment to a volatile field isn't atomic</a>
</h2>

<p>This code increments a volatile field. Increments of volatile fields aren't
atomic. If more than one thread is incrementing the field at the same time,
increments could be lost.
</p>

    
<h2>
<a name="WMI_WRONG_MAP_ITERATOR">WMI_WRONG_MAP_ITERATOR: Inefficient use of keySet iterator instead of entrySet iterator</a>
</h2>

<p> This method accesses the value of a Map entry, using a key that was retrieved from
a keySet iterator. It is more efficient to use an iterator on the entrySet of the map, to avoid the
Map.get(key) lookup.</p>

        
<h2>
<a name="XSS_REQUEST_PARAMETER_TO_SERVLET_WRITER">XSS_REQUEST_PARAMETER_TO_SERVLET_WRITER: Servlet reflected cross site scripting vulnerability</a>
</h2>

    <p>This code directly writes an HTTP parameter to Servlet output, which allows for a reflected cross site scripting
vulnerability. See <a href="http://en.wikipedia.org/wiki/Cross-site_scripting">http://en.wikipedia.org/wiki/Cross-site_scripting</a>
for more information.</p>
<p>FindBugs looks only for the most blatant, obvious cases of cross site scripting.
If FindBugs found <em>any</em>, you <em>almost certainly</em> have more cross site scripting
vulnerabilities that FindBugs doesn't report. If you are concerned about cross site scripting, you should seriously
consider using a commercial static analysis or pen-testing tool.
</p>


    </body>
</html>
